{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"The robust European language model benchmark. <p>EuroEval is a language model benchmarking framework that supports evaluating all types of language models out there: encoders, decoders, encoder-decoders, base models, and instruction tuned models. EuroEval has been battle-tested for more than three years and are the standard evaluation benchmark for many companies, universities and organisations around Europe.</p> <p>Check out the leaderboards to see how different language models perform on a wide range of tasks in various European languages. The leaderboards are updated regularly with new models and new results. All benchmark results have been computed using the associated EuroEval Python package, which you can use to replicate all the results. It supports all models on the Hugging Face Hub, as well as models accessible through 100+ different APIs, including models you are hosting yourself via, e.g., Ollama or LM Studio.</p> <p>The idea of EuroEval grew out of the development of Danish language model R\u00f8B\u00c6RTa in 2021, when we realised that there was no standard way to evaluate Danish language models. It started as a hobby project including Danish, Swedish and Norwegian, but has since grown to include 12+ European languages.</p> <p>EuroEval is maintained by Dan Saattrup Smart from the Alexandra Institute, and is funded by the EU project TrustLLM.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#how-do-you-determine-if-a-model-is-commercial-or-not","title":"How do you determine if a model is \"Commercial\" or not?","text":"<p>We generally determine this based on whether a model's license allows commercial use of the model. However if we are aware that a model is trained on data, that does not allow for commercial use, we will specify it as non-commercial model, despite the stated license. If you find an issue with any of models feel free to open an issue.</p>"},{"location":"faq/#not-finding-the-answer-that-you-are-looking-for","title":"Not finding the answer that you are looking for?","text":"<p>If don't find the answer that you are looking for feel free to ask your question in the forum.</p>"},{"location":"methodology/","title":"Evaluation Methodology","text":"<p>The evaluation methodology is different depending on the architecture of the model. For encoder models, we use a finetuning approach, where we finetune the model on the training data of the task, and evaluate it on the test data. For decoder models, we use either a few-shot or zero-shot approach, where we evaluate the model on the test data without any finetuning, but where the few-shot examples come from the training data of the task. It has been shown that the few-shot approach corresponds to finetuning in the sense of being equivalent to gradient updates on the training data, making the two evaluation methodologies comparable.</p>"},{"location":"methodology/#robust-evaluation","title":"Robust Evaluation","text":"<p>For each model and dataset, we evaluate the model as described above 10 times, each time on a bootstrapped (i.e., sampling with replacement) version of the training and test set. The evaluation score is then the mean of these scores, along with a 95% confidence interval, computed as the mean \u00b1 1.96 x standard error of the mean, where the standard error of the mean is the sample standard deviation divided by the square root of the number of samples.</p> <p>The bootstrap theorem means that this mean and associated confidence interval will be asymptotically correct, giving us a more reliable estimate of the true performance of the model, rather than just the performance on a single test set, which can be noisy.</p>"},{"location":"methodology/#formulating-nlu-tasks-as-generative-tasks","title":"Formulating NLU Tasks as Generative Tasks","text":"<p>In this section we describe how we rephrase the NLU tasks as text-to-text tasks, which makes it possible to evaluate generative models on the tasks. We set up the prompts differently depending on whether the model is instruction tuned or not, as the instruction tuned models require a different prompt structure to ensure that they generate the correct output.</p> <p>For the base (i.e., non-instruction tuned) models, we use the following prompt structure:</p> <pre><code>[prefix prompt]\n\n{% for each few-shot example %}\n  [document prefix]: [few-shot example document]\n\n  [label prefix]: [few-shot example label]\n{% end for %}\n\n[document prefix]: [new document]\n\n[label prefix]:\n</code></pre> <p>For the instruction tuned models, we use the following prompt structure:</p> <pre><code>{% for each few-shot example %}\n  USER: [instruction with few-shot example]\n  ASSISTANT: [label]\n{% end for %}\nUSER: [instruction with new example]\nASSISTANT:\n</code></pre> <p>Here we would use the model's chat template to set up the <code>USER</code> and <code>ASSISTANT</code> parts of the prompt. See all the specific prompts used for each dataset in the dataset configs module.</p> <p>For the sentiment classification task, we simply have the models generate translations of the three labels (positive, negative and neutral). For the linguistic acceptability task, also a text classification task, we use the translations of \"yes\" and \"no\" as the two labels, corresponding to whether the document is grammatically correct or not. For the extractive question answering task, we have the model output the answer directly. For this task we found that changing the label prefix from \"Answer\" to \"Answer in max 3 words\" resulted in a drastic improvement, due to many of the answers of instruction tuned models starting with unnecessary text akin to \"The answer is\". Lastly, for the named entity recognition task, we require the output to be a JSON dictionary, with keys being the translated named entity tags, and values being lists of named entities of that category. To ensure that we are not biasing the evaluation toward models knowing the JSON format, we employ structured generation using the XGrammar package, which modifies the logits outputted by the model to ensure that the output is always a valid JSON dictionary in the aforementioned format.</p>"},{"location":"methodology/#score-aggregation","title":"Score Aggregation","text":"<p>From the raw scores of the 10 evaluations per dataset, we need to aggregate the model scores into a single score. We want an aggregation method that satisfies the following criteria:</p> <ul> <li>Task Fairness: Each task should be weighted equally.</li> <li>Comparison: If we evaluate models in multiple languages, then it should be   possible to meaningfully compare the language scores of these models with each other.</li> <li>Robustness: If two models do not have a significantly different score on a   dataset, then the aggregated score should reflect this.</li> <li>Magnitude Preservation: The magnitude of the difference between the dataset score   of two models should be reflected in the aggregated score.</li> <li>Minimal Change: Adding a new model should minimally affect the aggregated scores   of the other models.</li> </ul> <p>Before we introduce our chosen aggregation method, we will briefly discuss some common aggregation methods and how they do not satisfy the criteria.</p> <p>The mean score is the most common aggregation method, which would simply be the mean of the 10 scores for each dataset, and then the mean of the dataset scores for each task. This method does not satisfy the Task Fairness criterion, as it does not take into account that metrics have different ranges and variances. The Comparison criterion is also not satisfied, as datasets vary from language to language, with some datasets being more difficult than others. It does, however, satisfy the Robustness, Magnitude Preservation and Minimal Change criteria.</p> <p>The mean rank is another common aggregation method, where we compute the rank of each model on each dataset, and then take the mean of the ranks. This method satisfies the Task Fairness criterion, as it re-casts the scores into a common comparable framework, which therefore weights each task equally. For the same reason, it also satisfies the Comparison criterion (it is important here that we evaluate all the models on all the languages for this to be satisfied). It does not satisfy the Robustness and Magnitude Preservation criteria, by definition of rank. It partially satisfies the Minimal Change criterion, since it only affects the scores of the models which are worse than the new model.</p> <p>We thus see that the mean score and mean rank methods satisfy a disjoint set of the criteria, but that they together satisfy all the criteria. Based on this observation, we introduce the mean rank score method, defined as follows. For each dataset, we start by sorting the models by their mean score on the dataset. As with a rank, we assign the best model with rank score 1. For the next best model, we conduct a one-tailed Welch's t-test to see if the next best model is significantly worse than the first model (p &lt; 0.05). If so, we compute the absolute difference between the mean score of the two models, and divide that by the standard deviation of all the mean scores of the models on the dataset.</p> <p>We then add this to the rank score of the first model. We continue this process for all the models to get the rank scores for the dataset, and to compute the overall score for the model, we take the mean of the rank scores for the datasets. We note that the mean rank score has an intuitive interpretation: it is the average number of standard deviations from the best scoring model (+1).</p> <p>This metric satisfies Task Fairness since we normalise all the scores by dividing by the standard deviation of the dataset scores. The Robustness criterion is satisfied due to our use of a one-tailed Welch's t-test. The Magnitude Preservation criterion is also satisfied, as the magnitude of the difference between the dataset score of two models is reflected in the rank score. It also satisfies Comparison, as we compare the models on a common scale (same argument as the mean rank method). Finally, the Minimal Change criterion is partially satisfied, as adding new models only minimally changes the score of existing models. Concretely, adding new scores will affect the standard deviation normalising factor (this effect tends to zero as the number of models grows, however), and if the model beats all the other models then all the scores will be affected, due to the relative nature of the metric.</p>"},{"location":"methodology/#papers","title":"Papers","text":"<p>Check out more in-depth descriptions of the methodology in the associated research papers:</p> <ul> <li>Encoder vs Decoder: Comparative Analysis of Encoder and Decoder Language Models on   Multilingual NLU Tasks</li> <li>ScandEval: A Benchmark for Scandinavian Natural Language   Processing</li> </ul>"},{"location":"python-package/","title":"The <code>euroeval</code> Python Package","text":"<p>The <code>euroeval</code> Python package is the Python package used to evaluate language models in EuroEval. This page will give you a brief overview of the package and how to use it. You can also check out the full API reference for more details.</p>"},{"location":"python-package/#installation","title":"Installation","text":"<p>To install the package simply write the following command in your favorite terminal:</p> <pre><code>$ pip install euroeval[all]\n</code></pre> <p>This will install the EuroEval package with all extras. You can also install the minimal version by leaving out the <code>[all]</code>, in which case the package will let you know when an evaluation requires a certain extra dependency, and how you install it.</p>"},{"location":"python-package/#quickstart","title":"Quickstart","text":""},{"location":"python-package/#benchmarking-from-the-command-line","title":"Benchmarking from the Command Line","text":"<p>The easiest way to benchmark pretrained models is via the command line interface. After having installed the package, you can benchmark your favorite model like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt;\n</code></pre> <p>Here <code>model</code> is the HuggingFace model ID, which can be found on the HuggingFace Hub. By default this will benchmark the model on all the tasks available. If you want to benchmark on a particular task, then use the <code>--task</code> argument:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task sentiment-classification\n</code></pre> <p>We can also narrow down which languages we would like to benchmark on. This can be done by setting the <code>--language</code> argument. Here we thus benchmark the model on the Danish sentiment classification task:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task sentiment-classification --language da\n</code></pre> <p>Multiple models, datasets and/or languages can be specified by just attaching multiple arguments. Here is an example with two models:</p> <pre><code>$ euroeval --model &lt;model-id1&gt; --model &lt;model-id2&gt;\n</code></pre> <p>The specific model version/revision to use can also be added after the suffix '@':</p> <pre><code>$ euroeval --model &lt;model-id&gt;@&lt;commit&gt;\n</code></pre> <p>This can be a branch name, a tag name, or a commit id. It defaults to 'main' for latest.</p> <p>See all the arguments and options available for the <code>euroeval</code> command by typing</p> <pre><code>$ euroeval --help\n</code></pre>"},{"location":"python-package/#benchmarking-from-a-script","title":"Benchmarking from a Script","text":"<p>In a script, the syntax is similar to the command line interface. You simply initialise an object of the <code>Benchmarker</code> class, and call this benchmark object with your favorite model:</p> <pre><code>&gt;&gt;&gt; from euroeval import Benchmarker\n&gt;&gt;&gt; benchmark = Benchmarker()\n&gt;&gt;&gt; benchmark(model=\"&lt;model&gt;\")\n</code></pre> <p>To benchmark on a specific task and/or language, you simply specify the <code>task</code> or <code>language</code> arguments, shown here with same example as above:</p> <pre><code>&gt;&gt;&gt; benchmark(model=\"&lt;model&gt;\", task=\"sentiment-classification\", language=\"da\")\n</code></pre> <p>If you want to benchmark a subset of all the models on the Hugging Face Hub, you can simply leave out the <code>model</code> argument. In this example, we're benchmarking all Danish models on the Danish sentiment classification task:</p> <pre><code>&gt;&gt;&gt; benchmark(task=\"sentiment-classification\", language=\"da\")\n</code></pre>"},{"location":"python-package/#benchmarking-from-docker","title":"Benchmarking from Docker","text":"<p>A Dockerfile is provided in the repo, which can be downloaded and run, without needing to clone the repo and installing from source. This can be fetched programmatically by running the following:</p> <pre><code>$ wget https://raw.githubusercontent.com/EuroEval/EuroEval/main/Dockerfile.cuda\n</code></pre> <p>Next, to be able to build the Docker image, first ensure that the NVIDIA Container Toolkit is installed and configured. Ensure that the the CUDA version stated at the top of the Dockerfile matches the CUDA version installed (which you can check using <code>nvidia-smi</code>). After that, we build the image as follows:</p> <pre><code>$ docker build --pull -t euroeval -f Dockerfile.cuda .\n</code></pre> <p>With the Docker image built, we can now evaluate any model as follows:</p> <pre><code>$ docker run -e args=\"&lt;euroeval-arguments&gt;\" --gpus 1 --name euroeval --rm euroeval\n</code></pre> <p>Here <code>&lt;euroeval-arguments&gt;</code> consists of the arguments added to the <code>euroeval</code> CLI argument. This could for instance be <code>--model &lt;model-id&gt; --task sentiment-classification</code>.</p>"},{"location":"datasets/","title":"Datasets","text":"<p>\ud83d\udc48 Choose a language on the left to see all the evaluation datasets available for that language.</p>"},{"location":"datasets/danish/","title":"\ud83c\udde9\ud83c\uddf0 Danish","text":"<p>This is an overview of all the datasets used in the Danish part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/danish/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/danish/#angry-tweeets","title":"Angry Tweeets","text":"<p>This dataset was published in this paper and was a crowd-sourcing effort to annotate sentiment of Danish tweets.</p> <p>The original full dataset consists of 3,458 samples, and we are using a split of 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). All the samples in the original test set are included in our test set, but our test set is furthermore using a subset of the original training set as test samples as well. The original dataset did not have a validation split, so we have created one by sampling from the training set.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Jeg tror, det der var kampen. Goff virker lost\",\n  \"label\": \"negative\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"@USER @USER Vi bruger ogs\u00e5 snildt 1-2 timer (nogle gange flere timer end det) p\u00e5 at putte den yngste. Det er oftest Tommi, som g\u00f8r det, for jeg g\u00e5r helt amok i processen. S\u00e5 sm\u00f8rer jeg madpakker og rydder op i stedet.\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Er du nysgerrig p\u00e5, hvordan du diskvalificerer dig selv fra at blive taget seri\u00f8st i den offentlige debat? Naser har svaret. #dkpol #dkmedier [LINK]\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er tweets og deres sentiment, som kan v\u00e6re 'positiv', 'neutral' eller 'negativ'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tweet: {text}\nSentiment: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tweet: {text}\n\nKlassificer sentimentet i tweetet. Svar kun med 'positiv', 'neutral' eller 'negativ'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positiv</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutral</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negativ</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset angry-tweeets\n</code></pre>"},{"location":"datasets/danish/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/danish/#dansk","title":"DANSK","text":"<p>This dataset was published in this paper and is a manually annotated subset of Danish Gigaword with the 18 different named entities, following the OntoNotes 5.0 scheme. It was annotated by 10 different annotators.</p> <p>The original full dataset consists of 15,062 samples, and we are using a split of 1,024 / 256 / 1,024 samples for training, validation and testing, respectively (so 2,304 samples used in total). All samples in the validation and test sets of our version also belong to the original validation and test set, respectively.</p> <p>We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003 labelling scheme, which is more common in the NER literature. The mapping is as follows:</p> <ul> <li><code>PERSON</code> \u27a1\ufe0f <code>PER</code></li> <li><code>LOCATION</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>FACILITY</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>GPE</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>ORGANIZATION</code> \u27a1\ufe0f <code>PER</code></li> <li><code>EVENT</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>LANGUAGE</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>PRODUCT</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>WORK OF ART</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>NORP</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>CARDINAL</code> \u27a1\ufe0f <code>O</code></li> <li><code>DATE</code> \u27a1\ufe0f <code>O</code></li> <li><code>LAW</code> \u27a1\ufe0f <code>O</code></li> <li><code>MONEY</code> \u27a1\ufe0f <code>O</code></li> <li><code>ORDINAL</code> \u27a1\ufe0f <code>O</code></li> <li><code>PERCENT</code> \u27a1\ufe0f <code>O</code></li> <li><code>QUANTITY</code> \u27a1\ufe0f <code>O</code></li> <li><code>TIME</code> \u27a1\ufe0f <code>O</code></li> </ul> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['I', 'dette', 'efter\u00e5r', 'har', 'Gr\u00f8nland', 'taget', 'en', 'stor', 'beslutning', 'ved', 'folkeafstemningen', 'den', '25.', 'november', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['\u00c5h', ',', 'Petra', ',', 'vis', 'mig', 'din', 'krop', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Fravalget', 'af', 'revision', 'registreres', 'automatisk', 'ved', 'anmeldelse', 'af', 'stiftelse', 'af', 'selskabet', 'hos', 'Erhvervs-styrelsen', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er s\u00e6tninger og JSON-ordb\u00f8ger med de navngivne enheder, som forekommer i den givne s\u00e6tning.\n</code></pre></li> <li>Base prompt template:   <pre><code>S\u00e6tning: {text}\nNavngivne enheder: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>S\u00e6tning: {text}\n\nIdentific\u00e9r de navngivne enheder i s\u00e6tningen. Du skal outputte dette som en JSON-ordbog med n\u00f8glerne 'person', 'sted', 'organisation' og 'diverse'. V\u00e6rdierne skal v\u00e6re lister over de navngivne enheder af den type, pr\u00e6cis som de forekommer i s\u00e6tningen.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diverse</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diverse</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset dansk\n</code></pre>"},{"location":"datasets/danish/#unofficial-dane","title":"Unofficial: DaNE","text":"<p>This dataset was published in this paper and is a manually NER annotated version of the Danish Universal Dependencies treebank. The NER labels follow the CoNLL-2003 labelling scheme.</p> <p>The original full dataset consists of 4,383 / 564 / 565 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['Det', 'var', 'det', '\u00e5r', ',', 'hans', 'f\u00f8rste', 'LP', ',', '\"', 'With', 'A', 'Little', 'Help', 'From', 'My', 'Friends', '\"', ',', 'udkom', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Eddie', 'Carbone', ',', 'italiensk-amerikansk', 'havnearbejder', 'i', 'New', 'York', '.'], dtype=object),\n  \"labels\": array(['B-PER', 'I-PER', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'I-LOC', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['\"', 'Jeg', 'er', 'mig', '!', '\"', 'insisterer', 'han', 'under', 'det', 'flere', 'hundrede', '\u00e5r', 'gamle', 'egetr\u00e6', ',', 'liggende', ',', 'som', 'den', 'popflab', 'han', 'er', ',', 'p\u00e5', 'ryggen', 'i', 'sine', 'orange', 'jeans', ',', 't-shirt', '-', 'som', 'naturligvis', 'stiller', 'et', 'solbrunt', 'beh\u00e5ret', 'bryst', 'til', 'skue', '-', 'et', 'par', '68er', '\"', 'make', 'love', 'not', 'war', '\"', 'solbriller', 'han', 'netop', 'har', 'k\u00f8bt', 'i', 'Paris', ',', 'og', 'en', 'Kings', 'i', 'k\u00e6ften', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p>"},{"location":"datasets/danish/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/danish/#scala-da","title":"ScaLA-da","text":"<p>This dataset was published in this paper and was automatically created from the Danish Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 5,512 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Samme dame dukkede netop nu op sammen med Odd-Catla's erkl\u00e6rede yndling, v\u00e6bneren Aikin af Cantir.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Gebyrets st\u00f8rrelse afh\u00e6nger nemlig af helt, i hvilken kategori den p\u00e5g\u00e6ldende \\\"levnedsmiddelvirksomhed\\\" placeres.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Den statsansatte dyrl\u00e6ge Kronf\u00e5gels p\u00e5 slagteri i Kristiansstad, Karl Erik Bj\u00f8rkman, understreger, bel\u00e6gningen hos producenten betyder meget for dyrenes trivsel:\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er s\u00e6tninger og om de er grammatisk korrekte.\n</code></pre></li> <li>Base prompt template:   <pre><code>S\u00e6tning: {text}\nGrammatisk korrekt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>S\u00e6tning: {text}\n\nBestem om s\u00e6tningen er grammatisk korrekt eller ej. Svar med 'ja', hvis s\u00e6tningen er korrekt, og 'nej', hvis den ikke er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nej</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-da\n</code></pre>"},{"location":"datasets/danish/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/danish/#scandiqa-da","title":"ScandiQA-da","text":"<p>This dataset was published in this paper and was automatically created from the Danish part of the MKQA dataset. The MKQA dataset is based on the English Natural Questions dataset, based on search queries from the Google search engine. The questions and answers were manually translated to Danish (and other languages) as part of MKQA, and the contexts were in ScandiQA-da machine translated using the DeepL translation API. A rule-based approach was used to ensure that the translated contexts still contained the answer to the question, potentially by changing the answers slightly.</p> <p>The original full dataset consists of 6,810 / 500 / 500 samples for training, validation and testing, respectively (so 3,328 samples used in total). We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, where the splits are made by randomly sampling from the full dataset without considering the original train/validation/test splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"\\\"(Sittin\\' On) The Dock of the Bay\\\" er en sang, der er skrevet af soul-sangeren Otis Redding og guitaristen Steve Cropper sammen. Den blev indspillet af Redding to gange i 1967, herunder en gang f\u00e5 dage f\u00f8r hans d\u00f8d i et flystyrt. Sangen blev udgivet p\u00e5 Stax Records\\' Volt-label i 1968 og blev den f\u00f8rste posthume single, der l\u00e5 \u00f8verst p\u00e5 hitlisterne i USA. Den n\u00e5ede op som nummer 3 p\u00e5 den britiske single-liste.\",\n  \"question\": \"Hvem sang sitting on the dock of the bay?\",\n  \"answers\": {\n    \"answer_start\": array([79]),\n    \"text\": array([\"Otis Redding\"], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"The Cat in the Hat Knows a Lot About That!\\nKatten i hatten ved meget om det!\\n\\n\\n\\nKatten i hatten pilot\\n\\n\\n\\nGenre\\nB\u00f8rne-tv/undervisning/komedie\\n\\n\\nInstrueret af\\nTony Collingwood\\n\\n\\nStemmer fra\\nMartin Short\\nJacob Ewaniuk\\nAlexa Torrington\\nRob Tinkler\\n\\n\\nKomponist af temamusik\\nDavid Schweitzer\\n\\n\\nKomponist(er)\\nDavid Schweitzer\\n\\n\\nOprindelsesland\\nCanada\\nDet Forenede Kongerige\\nUSA\\n\\n\\nOprindelige sprog\\nEngelsk\\n\\n\\nAntal s\u00e6soner\\n2\\n\\n\\nAntal episoder\\n60 (liste over episoder)\\n\\n\\nProduktion\\n\\n\\nL\u00f8betid\\n30 minutter\\n\\n\\nProduktionsselskab(er)\\nCollingwood O'Hare Productions\\nPortfolio Entertainment\\nRandom House Children's Entertainment\\nTreehouse TV\\n\\n\\nDistribut\u00f8r\\nTreehouse TV\\n\\n\\nUdgivelse\\n\\n\\nOprindelige netv\u00e6rk\\nTreehouse TV (Canada)\\nPBS Kids (USA)\\nCITV og Tiny Pop (UK)\\n\\n\\nBilledformat\\n480i (SDTV)\\n1080i (HDTV)\\n\\n\\nOriginaludgivelse\\n7. august 2010 (2010-08-07) - nu\\n\\n\\nEksterne links\\n\\n\\nWebsted\\npbskids.org/catinthehat/\",\n  \"question\": \"Hvem synger titelmelodien til the cat in the hat?\",\n  \"answers\": {\n    \"answer_start\": array([269]),\n    \"text\": array([\"David Schweitzer\"], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Modern Slavery Act 2015\\nLoven om moderne slaveri fra 2015 er en lov fra Det Forenede Kongeriges parlament. Den har til form\u00e5l at bek\u00e6mpe slaveri i Det Forenede Kongerige og konsoliderer tidligere lovovertr\u00e6delser vedr\u00f8rende menneskehandel og slaveri. Loven g\u00e6lder for England og Wales. Lovforslaget blev forelagt underhuset i udkast i oktober 2013 af James Brokenshire, parlamentarisk undersekret\u00e6r for kriminalitet og sikkerhed, i oktober 2013. Lovforslagets sponsorer i indenrigsministeriet var Theresa May og Lord Bates. Det fik kongelig samstemmende udtalelse og blev lov den 26. marts 2015.\",\n  \"question\": \"Hvorn\u00e5r tr\u00e5dte den moderne slaveri i kraft?\",\n  \"answers\": {\n    \"answer_start\": array([580]),\n    \"text\": array([\"26. marts 2015\"], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er tekster med tilh\u00f8rende sp\u00f8rgsm\u00e5l og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nSp\u00f8rgsm\u00e5l: {question}\nSvar med maks. 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBesvar f\u00f8lgende sp\u00f8rgsm\u00e5l om teksten ovenfor med maks. 3 ord.\n\nSp\u00f8rgsm\u00e5l: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scandiqa-da\n</code></pre>"},{"location":"datasets/danish/#unofficial-belebele-da","title":"Unofficial: BeleBele-da","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Tekst: Prognoserne siger, at stormen, der er omkring 645 mil (1040 km) vest for Kap Verde-\u00f8erne, sandsynligvis vil forsvinde, f\u00f8r den truer nogen landomr\u00e5der. Fred har i \u00f8jeblikket vinde p\u00e5 165 km/t og bev\u00e6ger sig mod nordvest. Fred er den heftigste tropiske cyklon, der nogensinde er blevet registreret s\u00e5 sydligt og \u00f8stligt i Atlanterhavet, siden man begyndte at bruge satellitbilleder, og kun den tredje store orkan, der er registreret \u00f8st for 35\u00b0V.\\nSp\u00f8rgsm\u00e5l: Da Fred befandt sig n\u00e6r Kap Verde-\u00f8erne, hvilken retning bev\u00e6gede den sig s\u00e5 mod?\\nSvarmuligheder:\\na. Vest\\nb. Syd\\nc. \u00d8st\\nd. Nordvest\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tekst: \"Siden Pakistan i 1947 blev uafh\u00e6ngigt af det britiske styre, har den pakistanske pr\u00e6sident udpeget \"\"politiske agenter\"\", som styrer FATA, og som har n\u00e6sten fuldst\u00e6ndig kontrol over omr\u00e5derne. Disse agenter er ansvarlige for at levere regerings- og retstjenester i henhold til artikel 247 i den pakistanske forfatning.\"\\nSp\u00f8rgsm\u00e5l: Hvem leverer retslige tjenester til FATA?\\nSvarmuligheder:\\na. Den pakistanske regering\\nb. Politiske agenter\\nc. Pakistans pr\u00e6sident\\nd. Den britiske regering\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tekst: Alle er en del af samfundet og benytter transportsystemerne. N\u00e6sten alle klager over transportsystemerne. I udviklede lande h\u00f8rer du sj\u00e6ldent liges\u00e5 mange klager over vandkvalitet eller broer, der styrter sammen. Hvorfor giver transportsystemerne anledning til s\u00e5danne klager, hvorfor svigter de p\u00e5 daglig basis? Er transportingeni\u00f8rer blot inkompetente? Eller foreg\u00e5r der noget mere fundamentalt?\\nSp\u00f8rgsm\u00e5l: Hvilken offentlig service siges at skabe st\u00f8rst utilfredshed i udviklede lande?\\nSvarmuligheder:\\na. Vandkvalitet\\nb. Brobyggelse\\nc. Offentlig transport\\nd. Uddannelse\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-da\n</code></pre>"},{"location":"datasets/danish/#unofficial-multiwikiqa-da","title":"Unofficial: MultiWikiQA-da","text":"<p>This dataset will be published in an upcoming paper, and contains Danish Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": 'R\u00f8dsp\u00e6tten (Pleuronectes platessa) er en fladfisk, der findes overalt i de danske farvande. Den er i \u00f8vrigt udbredt fra Middelhavet til Island og Hvidehavet. Den foretr\u00e6kker steder, hvor bunden best\u00e5r af sten, sand og grus. De unge r\u00f8dsp\u00e6tter findes p\u00e5 lavt vand, mens de voksne foretr\u00e6kker 10-50 meters dybde. R\u00f8dsp\u00e6tten er en h\u00f8jrevendt fladfisk, idet det normalt er h\u00f8jre side, der under larvens forvandling bliver til overside.\\n\\nUdseende \\nR\u00f8dsp\u00e6tten kan blive op til 100 centimeter, men bliver i Danmark sj\u00e6ldent over 50 centimeter. Den kendes bedst p\u00e5, at der bag \u00f8jnene l\u00f8ber en buet k\u00f8l med 4-7 benknuder. Sk\u00e6llene er sm\u00e5 og glatte og ikke taglagte. Munden er lille med ret tykke l\u00e6ber. Begge \u00f8jne findes normalt p\u00e5 fiskens h\u00f8jre side. P\u00e5 oversiden er r\u00f8dsp\u00e6tten oftest brunlig med et gr\u00f8nligt sk\u00e6r og med spredte r\u00f8dlige pletter, der ofte er omgivet af lyse eller m\u00f8rke ringe. Undersiden er hvid.\\n\\nLevevis \\nR\u00f8dsp\u00e6tten lever is\u00e6r af b\u00f8rsteorme og tyndskallede muslinger. Den er mest aktiv i d\u00f8gnets m\u00f8rke timer, mens den skjuler sig p\u00e5 bunden om dagen. Den skifter farve efter bundens farve og struktur. R\u00f8dsp\u00e6ttens naturlige fjender er ud over mennesket f.eks. krabber og torsk.\\n\\nForplantning \\nHannerne bliver i Nords\u00f8en k\u00f8nsmodne 3-4 \u00e5r gamle og en l\u00e6ngde p\u00e5 20 centimeter, mens hunnerne k\u00f8nsmodner et par \u00e5r senere. I \u00d8sters\u00f8en bliver begge k\u00f8n tidligere k\u00f8nsmodne. Gydningen foreg\u00e5r normalt i 20-50 meters dybde i perioden januar til juni. R\u00f8dsp\u00e6tten foretr\u00e6kker en temperatur p\u00e5 6\\xa0\u00b0C til gydningen. \u00c6ggene er glasklare med en diameter p\u00e5 cirka 2 millimeter og flyder op til overfladen. Efter 2-3 uger kl\u00e6kkes de 6 millimeter store larver. Larverne lever af planktonorganismer og begynder efter cirka 5 uger med en l\u00e6ngde p\u00e5 1 centimeter en forvandling, hvor venstre \u00f8je vandrer op over hovedet, der vrides, og kroppen bliver bredere. Til at begynde med sv\u00f8mmer de sm\u00e5 r\u00f8dsp\u00e6tter skr\u00e5t og siden med h\u00f8jre side opad. Med en l\u00e6ngde p\u00e5 1,2-1,4 centimeter skifter de fra et pelagisk liv til at leve p\u00e5 lavt vand langs kysterne. I det f\u00f8rste efter\u00e5r m\u00e5ler r\u00f8dsp\u00e6tten 7-12 centimeter og tr\u00e6kker ud, for at overvintre p\u00e5 dybere vand.\\n\\nKilder/Henvisninger \\n\\n C. V. Otterstr\u00f8m (1881-1962).\\xa0Danmarks Fauna. Fisk II. Bl\u00f8dfinnefisk. G.E.C. Gads Forlag. K\u00f8benhavn 1914.\\n\\nFladfisk',\n    \"question\": 'Hvilken side af r\u00f8dsp\u00e6tten vender typisk opad?',\n    \"answers\": {\n        \"answer_start\": array([369]),\n        \"text\": array(['h\u00f8jre side'], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": 'Mzilikazi (\"blodvejen\" eller \"den store vej\" ca. 1790\u20139. september 1868) var en sydafrikansk konge som grundlagde matabelekonged\u00f8mmet i det omr\u00e5de, som nu er Zimbabwe. Han var s\u00f8n af Matshobana og blev f\u00f8dt n\u00e6r Mkuze i Zululand (nu del af Sydafrika) og d\u00f8de ved Ingama i Matabeleland (n\u00e6r Bulawayo, Zimbabwe). Mange regner ham som den st\u00f8rste sydafrikanske milit\u00e6rleder efter zulukongen Shaka.\\n\\nHan f\u00f8rte sin stamme, khumalo, p\u00e5 en 800 km lang rejse fra Zululand til det, som nu er Zimbabwe. P\u00e5 vejen viste han betydelige statsmandsevner, da han samlede sit eget folk og de mange stammer han erobrede, til et stort,  etnisk rigt og centraliseret konged\u00f8mme.\\n\\nHan var oprindelig en af Shakas l\u00f8jtnanter, men i 1823 gjorde han opr\u00f8r. Frem for at m\u00f8de rituel henrettelse, flygtede han sammen med sin stamme. Han rejste f\u00f8rst til Mozambique og i 1826 ind i Transvaal p\u00e5 grund af fortsatte angreb fra sine fjender.\\n\\nFortsatte angreb fik ham f\u00f8rst til at flytte til dagens Botswana og i 1837 til det, som nu er Zambia Han klarede ikke at erobre den indf\u00f8dte kololo\u2013nation der og rejste til det, som blev kendt som Matabeleland (i dagens Zimbabwe) og slog sig ned der i 1840.\\n\\nEfter hans ankomst organiserede han sine tilh\u00e6ngere i et milit\u00e6rsystem med regiment\u2013kraaler som kong Shakas, som blev st\u00e6rke nok til at afvise boernes angreb i 1847\u20131851 og tvinge den Sydfrikanske Republiks regering til at underskrive en fredsaftale med ham i 1852.\\n\\nMzilikazi var generelt venlig over for europ\u00e6isk rejsende, f\u00f8rte opdagelsen af guld i Matabeleland i 1867 til en flom af bos\u00e6ttere, som han ikke kunne kontrollere, og som f\u00f8rte til konged\u00f8mmets endelige nederlag under hans efterf\u00f8lger Lobengula.\\n\\nKongelige fra historiske riger',\n    \"question\": 'Med hvilket \u00f8genavn var Mzilikazi kendt?',\n    \"answers\": {\n        \"answer_start\": array([11]),\n        \"text\": array(['\"blodvejen\" eller \"den store vej\"'], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": 'Jean-Nicolas Bouilly (24. januar 1763 i La Coudraye ved Tours \u2013 14. april 1842 i Paris) var en fransk forfatter. \\n\\nEfter at have studeret jura sluttede Bouilly sig ved revolutionens udbrud til Mirabeau og Barnave og bekl\u00e6dte forskellige embeder, i hvilke han navnlig virkede for indf\u00f8relsen af prim\u00e6rskoler og for folkeoplysning i det hele taget. Senere trak han sig tilbage og vedblev at leve uafh\u00e6ngig til sin d\u00f8d. 1790 opf\u00f8rtes hans op\u00e9ra comique Pierre le Grand, med musik af Gr\u00e9try. Af hans senere dramatiske arbejder kan n\u00e6vnes L\\'abb\u00e9 de l\\'\u00c9p\u00e9e(1795), Les deux journ\u00e9es (1800), komponeret af Cherubini, Fanchon (1802), komponeret af Himmel, L\\'intrigue aux fen\u00eatres, Une folie (1803, med musik af M\u00e9hul; p\u00e5 dansk ved N.T. Bruun: \"Ungdom og Galskab\" [1806], med musik af Du Puy), Mme. de S\u00e9vign\u00e9 (1805) og s\u00e5 videre. Desuden oversatte han flere stykker af Kotzebue. Hans skrifter for ungdommen stod i sin tid i h\u00f8j kurs; hans stil er vidtsv\u00e6vende og retorisk, hans billeder skruede, hele tonen s\u00e5 sentimental, at han fik navnet le po\u00e8te lacrymal. Af disse skrifter kan n\u00e6vnes: Contes offerts aux enfants de France, Contes \u00e0 ma fille (1809), Conseils \u00e0 ma fille (1811) og Les jeunes femmes (1819).\\n\\nKilder \\n\\n \\n\\nDramatikere fra Frankrig\\nFranskm\u00e6nd i 1700-tallet\\nFranskm\u00e6nd i 1800-tallet\\nSalmonsens',\n    \"question\": 'Med hvilke politiske personer allierede Bouilly sig ved revolutionens begyndelse?',\n    \"answers\": {\n        \"answer_start\": array([193]),\n        \"text\": array(['Mirabeau og Barnave'], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er tekster med tilh\u00f8rende sp\u00f8rgsm\u00e5l og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nSp\u00f8rgsm\u00e5l: {question}\nSvar med maks. 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBesvar f\u00f8lgende sp\u00f8rgsm\u00e5l om teksten ovenfor med maks. 3 ord.\n\nSp\u00f8rgsm\u00e5l: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-da\n</code></pre>"},{"location":"datasets/danish/#knowledge","title":"Knowledge","text":""},{"location":"datasets/danish/#danske-talemader","title":"Danske Talem\u00e5der","text":"<p>This dataset was created by The Danish Language and Literature Society, published here. The dataset features Danish idioms along with their official meaning. For each idiom, three negative samples were created: (a) a random idiom, (b) a concrete made-up idiom, and (c) an abstract made-up idiom. The dataset was created to evaluate the ability of language models to understand Danish idioms.</p> <p>The original full dataset consists of 1,000 samples. We use a 128 / 64 / 808 split for training, validation and testing, respectively (so 1,000 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hvad betyder udtrykket 'tale nogen efter munden'?\\nSvarmuligheder:\\na. v\u00e6re f\u00f8jelig og give nogen ret selvom man ikke n\u00f8dvendigvis er enig\\nb. erkl\u00e6re sig helt enig med en anden person\\nc. sige det pr\u00e6cis samme som en anden; efterabe\\nd. v\u00e6re egoistisk og sn\u00e6versynet; kun t\u00e6nke p\u00e5 sig selv\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvad betyder udtrykket 'der falder en sten fra \u00e9ns hjerte'?\\nSvarmuligheder:\\na. en bestemt (kriminel, efters\u00f8gt) person er forsvundet\\nb. man bliver fri for en sorg eller bekymring; man bliver lettet\\nc. man mister \u00e9n man har k\u00e6r\\nd. en sten forlader et hjerte man er i besiddelse af\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvad betyder udtrykket 'have spidse albuer'?\\nSvarmuligheder:\\na. person der har det meget d\u00e5rligt fysisk og psykisk\\nb. have ophobet vrede over l\u00e6ngere tid\\nc. h\u00e6vde sig p\u00e5 andres bekostning\\nd. have knogler der tr\u00e6der tydeligt frem p\u00e5 ens albuer\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Hvad er betydningen af f\u00f8lgende talem\u00e5de: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Hvad er betydningen af f\u00f8lgende talem\u00e5de: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset danske-talemaader\n</code></pre>"},{"location":"datasets/danish/#danish-citizen-tests","title":"Danish Citizen Tests","text":"<p>This dataset was created by scraping the Danish citizenship tests (indf\u00f8dsretspr\u00f8ven) and permanent residency tests (medborgerskabspr\u00f8ven) from 2016 to 2024. These are available on the official website of the Danish Ministry of International Recruitment and Integration.</p> <p>The original full dataset consists of 870 samples. We use an 345 / 90 / 525 split for training, validation and testing, respectively. Here all the citizenship tests belong to the test split, as well as the newest permanent residency tests. The validation split contains the newer permanent residency tests after the ones in the test split, and the training split contains the oldest permanent residency tests.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hvilket parti tilh\u00f8rte Lars L\u00f8kke Rasmussen, da han var statsminister i perioderne 2009-11 og 2015-19?\\nSvarmuligheder:\\na. Venstre\\nb. Socialdemokratiet\\nc. Det Konservative Folkeparti\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvilket af f\u00f8lgende omr\u00e5der har kommunerne ansvaret for driften af?\\nSvarmuligheder:\\na. Domstole\\nb. Vuggestuer\\nc. Sygehuse\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvilken organisation blev Danmark medlem af i 1945?\\nSvarmuligheder:\\na. Verdenshandelsorganisationen (WTO)\\nb. Den Europ\u00e6iske Union (EU)\\nc. De Forenede Nationer (FN)\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset danish-citizen-tests\n</code></pre>"},{"location":"datasets/danish/#unofficial-mmlu-da","title":"Unofficial: MMLU-da","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Danish was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hvilket af f\u00f8lgende coronavirusser har for\u00e5rsaget tusindvis af d\u00f8dsfald over hele verden som en 'opst\u00e5et' virus?\\nSvarmuligheder:\\na. MERS\\nb. SARS\\nc. OC43\\nd. HKU1\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvilken orbitale v\u00e6g er mest sandsynligt at kollapse i en 'blow out' fraktur?\\nSvarmuligheder:\\na. Taget\\nb. Gulvet\\nc. Den laterale v\u00e6g\\nd. Den mediale v\u00e6g\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvad er navnet p\u00e5 den st\u00f8rste struktur i Teotihuac\u00e1n, og hvor mange platforme og pyramider blev bygget der?\\nSvarmuligheder:\\na. M\u00e5nepyramiden; 250\\nb. Templet for den fjerkr\u00e6kl\u00e6dte slange; 400\\nc. Solpyramiden; 600\\nd. Inskriptionstemplen; 700\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul>"},{"location":"datasets/danish/#unofficial-arc-da","title":"Unofficial: ARC-da","text":"<p>This dataset is a machine translated version of the English ARC dataset and features US grade-school science questions. The translation to Danish was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Et farmaceutisk firma har offentliggjort resultaterne af et begr\u00e6nset eksperiment, der unders\u00f8ger den beskyttende virkning af en kemisk forbindelse mod h\u00f8je doser af UV-str\u00e5ler p\u00e5 hudceller. Senere blev det opdaget, at resultaterne ikke var reproducerbare. Hvilken handling kunne forskere fra firmaet have foretaget for at undg\u00e5 at offentligg\u00f8re fejlagtige resultater?\\nSvarmuligheder:\\na. Udf\u00f8r flere fors\u00f8g.\\nb. Brug kun lave niveauer af str\u00e5ling.\\nc. Brug forskellige b\u00f8lgel\u00e6ngder af str\u00e5ling.\\nd. Unders\u00f8g resultaterne af lignende eksperimenter, f\u00f8r man dannede en hypotese.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En ingeni\u00f8r skal beregne den potentielle energi af en rutschebanekabine \u00f8verst p\u00e5 en skr\u00e5ning. Hvilken information ville bedst hj\u00e6lpe ingeni\u00f8ren med at bestemme den potentielle energi af kabine?\\nSvarmuligheder:\\na. den afstand, som rutschebanekabinen skal rejse\\nb. massen af rutschebanekabinen ved fuld kapacitet\\nc. den gennemsnitlige v\u00e6gt af en tom rutschebanekabine\\nd. retningen, som rutschebanekabinen bev\u00e6ger sig i\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En studerende h\u00e6ldte vand i en plastbakke. Studerende satte derefter bakken i fryseren. Hvilken egenskab ved vand \u00e6ndrede sig, da vandet fryser?\\nSvarmuligheder:\\na. Vandet blev til en gas.\\nb. Massen af vandet steg.\\nc. Vandet tog en bestemt form.\\nd. Smagen af vandet \u00e6ndrede sig ikke.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul>"},{"location":"datasets/danish/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/danish/#hellaswag-da","title":"HellaSwag-da","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Disse mennesker tr\u00e6der pedalerne med kun det ene ben og st\u00e5r midt p\u00e5 cyklen med det andet ben, der holder deres h\u00e6nder oppe. n\u00e6ste g\u00f8r de\\nSvarmuligheder:\\na. en anden \u00f8velse, hvor de s\u00e6tter det ene ben p\u00e5 pedalen, mens de har det andet ben ude og hopper op og ned.\\nb. tager hinandens h\u00e6nder og udf\u00f8rer en eller anden dansebev\u00e6gelse p\u00e5 b\u00f8rsterne, som de bruger til at snurre rundt med deres kroppe og hoppe med h\u00e6nderne oppe.\\nc. drejer med deres forstenede h\u00e6nder, laver en U-vending og starter derefter deres handlinger igen og igen.\\nd. skifter til at st\u00e5 ved hj\u00e6lp af to arme for at balancere sig selv.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] S\u00e5dan dr\u00e6ber du frugtfluer [title] Brug r\u00e5dden frugt. [step] Dit problem med frugtfluer begyndte sandsynligvis f\u00f8rst, da du opdagede, at du havde efterladt nogle frugter, der til sidst blev r\u00e5dne. Brug den metode, der samlede fluene f\u00f8rste gang til at fange dem igen, men denne gang f\u00f8r dem til en mere morbide slutning.\\nSvarmuligheder:\\na. Dr\u00e6b fluene ved at tr\u00e6kke dem fra deres rede eller ved at bruge tunge k\u00e6der med t\u00e6nger til at fange dem og placere dem i en spand eller stuen. Du kan ogs\u00e5 bruge dyreaff\u00f8ring s\u00e5som fiske- og ande-urin.\\nb. Placer et stykke r\u00e5dden frugt i en sk\u00e5l og str\u00e6k klart plastik over toppen. Sk\u00e6r flere sm\u00e5 huller i plastikken med en tandstik og lad det st\u00e5 t\u00e6t p\u00e5 stedet med fluene.\\nc. Efter at have fors\u00f8gt at fange dobbelt s\u00e5 mange fluer, som du kan, skal du fjerne de ubehagelige frugtstykker fra pakken og bage dem i 2-3 minutter. Fluene vil flyde \u00f8verst p\u00e5 den s\u00f8de marmelade, n\u00e5r du fjerner frugten fra marmeladen.\\nd. [substeps] Tjek d\u00e5ser for knotten, melbiller og fluer. K\u00f8b blomster fra havecentret, hvis du ikke har al produktion i n\u00e6rheden.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En mand st\u00e5r indend\u00f8rs p\u00e5 en platform foran tre tilskuere og l\u00f8fter en tung v\u00e6gtstang. En mand n\u00e6rmer sig en v\u00e6gtstang p\u00e5 gulvet og st\u00e5r foran den og forbereder sig p\u00e5 at l\u00f8fte den. manden\\nSvarmuligheder:\\na. l\u00f8fter v\u00e6gtstangen, der h\u00e6nger i luften p\u00e5 platformen, og vender sig mod tilskuerne.\\nb. l\u00f8fter v\u00e6gtstangen og viser, hvordan han udf\u00f8rer det, idet han pauser p\u00e5 hver stang for at m\u00e5le v\u00e6gten.\\nc. b\u00f8jer sig derefter i kn\u00e6ene og l\u00e6gger h\u00e6nderne p\u00e5 v\u00e6gtens stangdel.\\nd. l\u00f8fter derefter klokken p\u00e5 sine skuldre, l\u00e6ner sig tilbage, s\u00e6tter armene bag hovedet og l\u00f8fter den let.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-da\n</code></pre>"},{"location":"datasets/danish/#unofficial-goldenswag-da","title":"Unofficial: GoldenSwag-da","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"S\u00e5dan giver du dig selv en fransk manicure ved hj\u00e6lp af tape. Gnid en vatpind med neglelakfjerner p\u00e5 alle dine negle. Det vil ikke kun fjerne afskallet lak eller rester af lak, men det vil ogs\u00e5 fjerne fugtighedscreme fra neglen. Hvis du har et fugtighedsbevarende middel, s\u00e5som lotion eller olie, p\u00e5 neglen, vil lakken ikke sidde ordentligt fast.\\nSvarmuligheder:\\na. Kom lakfjerneren i en lille sk\u00e5l. Du skal bruge den om et par minutter til at f\u00e5 denne opl\u00f8sning p\u00e5 t\u00e6erne.\\nb. Fordel et fugtgivende pulver over alle dine negle med cirkul\u00e6re bev\u00e6gelser, indtil du kommer i kontakt med huden. Pol\u00e9r altid neglene, inden du g\u00e5r i gang.\\nc. Skum vattet i lakfjerneren. Brug en bl\u00f8d vaskeklud til at samle lakken op.\\nd. S\u00f8rg for, at du har skabt et perfekt l\u00e6rred til din franske manicure. P\u00e5f\u00f8r din basisfarve p\u00e5 hele neglen.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"S\u00e5dan forbedrer du et lille barns tale. Kom ned p\u00e5 deres niveau. S\u00e6t dig p\u00e5 hug eller p\u00e5 gulvet. Det vil f\u00e5 deres opm\u00e6rksomhed.\\nSvarmuligheder:\\na. Du vil tale med dit barn i stedet for til det. Hun vil ogs\u00e5 kunne se din mund og f\u00e5 visuelle tegn p\u00e5, hvordan man siger bestemte lyde.\\nb. L\u00f8ft om n\u00f8dvendigt h\u00e6nderne sammen til knytn\u00e6ver. Hvis du str\u00e6kker dine h\u00e6nder til knytn\u00e6ver og g\u00f8r det, mens du taler, vil dit barn sandsynligvis g\u00f8re det samme.\\nc. Pr\u00f8v at v\u00e6re s\u00e5 stille som muligt, og tal kun til dem, n\u00e5r de er rolige. Hvis du taler l\u00e6nge nok, vil de til sidst h\u00f8re din stemme.\\nd. Lad dem bede dig om at rykke t\u00e6ttere p\u00e5 dem. Hvis det er muligt, s\u00e5 brug en siddepind i hovedh\u00f8jde.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"S\u00e5dan bruger du en bodysuit. V\u00e6lg en bodysuit, der smigrer dine yndlingstr\u00e6k. Med s\u00e5 mange muligheder og stilarter kan bodysuiten virkelig v\u00e6re universelt flatterende. For at finde en body, der ser godt ud p\u00e5 dig, skal du overveje, hvilken del af din krop du vil fremh\u00e6ve.\\nSvarmuligheder:\\na. Det kan v\u00e6re underarmene, benene eller andre steder, der stikker ud. M\u00e5ske har du for eksempel en flot l\u00e6bespalte, som du gerne vil fremh\u00e6ve.\\nb. Find ud af, hvilken del af din krop du vil fremh\u00e6ve, og sk\u00e6r s\u00e5 ned p\u00e5 det, der fremh\u00e6ver denne del. Hvis du for eksempel \u00f8nsker, at overdelene skal fremh\u00e6ve dine bryster mest muligt, kan bikinitrusserne ogs\u00e5 b\u00e6res omkring det omr\u00e5de.\\nc. Hvis du for eksempel er stolt af dine tonede arme, skal du v\u00e6lge en body uden \u00e6rmer eller med halterneck. Start med en bodysuit i t-shirt-stil, hvis du er ved at varme op til trenden.\\nd. Beslut dig for, hvor mange forskellige dele af dig, din body skal fremh\u00e6ve. Hvis du for eksempel vil have et sporty look, skal din body ogs\u00e5 fremh\u00e6ve en del af din krop i stedet for en s\u00e6rlig i\u00f8jnefaldende del.\",\n  \"label\": \"c\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er multiple choice sp\u00f8rgsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rgsm\u00e5l: {text}\nSvarmuligheder:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar ovenst\u00e5ende sp\u00f8rgsm\u00e5l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-da\n</code></pre>"},{"location":"datasets/danish/#summarization","title":"Summarization","text":""},{"location":"datasets/danish/#nordjylland-news","title":"Nordjylland News","text":"<p>This dataset is based on news articles from the Danish news site TV2 Nord, where the summaries are taken as the introductory paragraphs of the articles.</p> <p>The original full dataset consists of 75,200 samples. We use an 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Jacob Emil Andersen viste s\u00f8ndag rundt p\u00e5 Halvorsminde Efterskole ved Hj\u00f8rring. Skolen har ligget p\u00e5 samme sted siden 1903. Han er selv elev, da en IT-linje p\u00e5 skolen fangede hans interesse. -\u00a0Det betyder meget for mig, jeg ville ikke have v\u00e6ret lige s\u00e5 interesseret\u00a0i den her skole, hvis der ikke havde v\u00e6ret IT, fort\u00e6ller Jacob Emil Andersen, der oprindeligt stammer fra Aalborg, til TV2 Nord. En af dem, han viser rundt til Efterskolernes dag, er Isabella Kristensen, der g\u00e5r i skole i Hune. Hun er p\u00e5 jagt efter noget helt specielt. -\u00a0Helt sikkert dans, springgymnastik og fitness med noget puls, forklarer Isabella Kristensen til TV2 Nord. Netop efterskolernes specialisering er en af grundene til, at rekordmange v\u00e6lger at bruge et \u00e5r v\u00e6k fra familien i 8.-, 9.- eller 10.-klasse. De s\u00e6rlige linjefag har man flere af p\u00e5 Halvorsminde Efterskole. Jern og metal, arbejde med tr\u00e6 og vinterbadning er blot nogle af de aktiviteter, eleverne kan st\u00f8de ind i p\u00e5 de forskellige linjefag, som skolen tilbyder. Men efterskolerne skal ogs\u00e5 huske at have fokus p\u00e5 den\u00a0faglighe kvalitet,\u00a0lyder det fra forstanderen. -\u00a0Vi skal v\u00e6re skarpe p\u00e5 nogle nicheprodukter og nogle linjer med noget god kvalitet. S\u00e5 skal vi ogs\u00e5 lave god skole, fort\u00e6ller\u00a0forstander p\u00e5 Halvorsminde Efterskole, Jens Beermann, til TV2 Nord. Han bliver bakket op af sin kollega fra H\u00f8rby Efterskole ved S\u00e6by omkring 30 kilometer fra Halvorsminde. - N\u00e5r man laver sit valgfagsudbud, skal det ikke v\u00e6re tilf\u00e6ldigt. Man skal ikke t\u00e6nke, at \u2019det er smart! Det m\u00e5 tr\u00e6kke elever, det her!\u2019 Der skal v\u00e6re en velovervejet refleksion i forhold til, om det passer ind i det, vi gerne vil som skole,, siger forstander p\u00e5 H\u00f8rby Efterskole, Mogens Vesterg\u00e5rd, til TV2 Nord. Alene i Nordjylland gik mere end 2.000 elever p\u00e5 efterskole i skole\u00e5ret 2018-2019. B\u00e5de Halvorsminde Efterskole og H\u00f8rby Skole har plads til 130 elever. Og noget tyder p\u00e5, at der i hvert fald er sikret en ny\u00a0elev til n\u00e6ste skole\u00e5r efter dagens \u00e5bent hus. -\u00a0Jeg synes at det ser sp\u00e6ndende ud, og jeg har endnu mere lyst til at g\u00e5 her nu, siger Isabella Kristensen.\",\n  \"target_text\": \"S\u00f8ndag inviterede efterskoler landet over potentielle nye elever inden for. Efterskolerne specialiserer sig for at tiltr\u00e6kke elever, men den gode faglighed m\u00e5 ikke blive glemt, lyder det fra nordjyske forstandere.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Efter en nat med spejl glatte veje i Nordjylland melder Nordjyllands Politi om en helt problemfri morgen.\u00a0Selvom politikredse i TV2 Nords sendeomr\u00e5de melder om en rolig nat uden st\u00f8rre uheld, s\u00e5\u00a0kan de bilister, der skal af sted l\u00f8rdag morgen godt forvente\u00a0lidt l\u00e6ngere rejsetid. Der er nemlig stadig glatte veje, og der er faldet en del sne i Nordjylland.\u00a0Saltvogne og sneplove har allerede v\u00e6ret p\u00e5 vejene, og Politiet opfordre forsat bilisterne til at k\u00f8re forsigtigt ude p\u00e5 de snefyldte veje.\",\n  \"target_text\": \"Nordjyllands Politi melder om en stille morgen trods glatte veje og stort snefald i nat.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Det var meget t\u00e6t p\u00e5 at g\u00e5 galt for en 10-\u00e5rig tysk dreng onsdag eftermiddag. Klokken 15:55 modtog alarmcentralen et opkald om en drengen, der var begravet i sand ved Vorup\u00f8r Strand. - Nogle b\u00f8rn legede p\u00e5 stranden, og her har de s\u00e5 gravet et hul ind i klitten. Det er s\u00e5 det, der er kollapset omkring drengen, fort\u00e6ller vagtchef Carsten Henriksen ved Midt- og Vestjyllands Politi. Det vides ikke pr\u00e6cist, hvor meget sand der v\u00e6ltede ned over barnet, men det var nok til, at drengen ikke selv kunne komme fri. De tilstedev\u00e6rende p\u00e5 stranden m\u00e5tte grave ham fri. Han var\u00a0helt begravet i sand i omkring fem minutter. - Der var en tysk l\u00e6ge p\u00e5 stranden, der kunne give f\u00f8rstehj\u00e6lp, indtil ambulancen kunne komme frem, fort\u00e6ller vagtchefen. Drengen kom sig hurtigt og har det godt, men blev alligevel k\u00f8rt til tjek p\u00e5 Aalborg Sygehus.\",\n  \"target_text\": \"B\u00f8rn p\u00e5 Vorup\u00f8r Strand havde gravet et hul ind i klitterne, som kollapsede omkring en 10-\u00e5rig dreng.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er nyhedsartikler med tilh\u00f8rende resum\u00e9er.\n</code></pre></li> <li>Base prompt template:   <pre><code>Nyhedsartikel: {text}\nResum\u00e9: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Nyhedsartikel: {text}\n\nSkriv et resum\u00e9 af ovenst\u00e5ende artikel.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset nordjylland-news\n</code></pre>"},{"location":"datasets/dutch/","title":"\ud83c\uddf3\ud83c\uddf1 Dutch","text":"<p>This is an overview of all the datasets used in the Dutch part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/dutch/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/dutch/#dbrd","title":"DBRD","text":"<p>This dataset was published in this paper and features Dutch book reviews from Hebban.nl, annotated with sentiment labels, written by the users of the website.</p> <p>The original full dataset consists of 20,000 / 2,200 samples for training and testing, respectively. We use a 1,014 / 253 / 2,014 split for training, validation and testing, respectively (so 3,328 samples used in total). The training and testing splits are subsets of the original splits, and the validation split is a disjoint subset of the original training split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Het boek geeft uitleg in de basis technieken en heeft handige tips, hoe je de klassieke recepten ook gewoon zelf kan maken, ze zijn geschreven in een soort leermodus, dit alles ondersteunt door stap voor stap foto\u2019s.\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Dit boek is het debuut van de Zuid-Afrikaanse schrijver S J Naud\u00e9 , het heeft diverse prijzen gewonnen waaronder de UJ Debutprys 2012.\\nHet is een verhalenbundel, met verhalen over personages, die metaforisch rondtrekkende vogels genoemd worden. Ze vliegen letterlijk rusteloos over de wereld. De een is een muzikante die drie continenten over reist om haar broers en zussen te ontmoeten, een man volgt zijn minnaar via Londen en Berlijn naar een kasteel , in Milaan is een futuristisch lawaaimachine te zien en een andere vrouw wil er voor zorgen dat er geen hiv meer voorkomt in Afrika. Zo zijn er nog een paar verhalen. Het ene verhaal heeft me meer geraakt dan het andere, het beste verhaal vind ik het verhaal waarin een man voor zijn doodzieke moeder zorgt, samen met een Japanse man.\\nDe thema\u2019s die in dit boek voorkomen zijn liefde, troost, acceptatie en succes. Leven en dood, reizen, gevoel en verstand komen steeds weer aan bod in de verhalen. Iedereen zoekt naar antwoorden die niet gegeven worden.\\nHet is een boek dat je niet even snel leest, het zijn allemaal op zich zelf staande verhalen, hoewel sommige personen in andere verhalen weer naar voren komen. Wat precies het verband daar tussen is, heb ik niet kunnen ontdekken.\\nHet is een boek dat niet echt vrolijk is, veel verhalen zijn somber. Doordat er veel Afrikaanse namen in voorkomen raak je af en toe de draad kwijt.\\nIk ben niet erg gecharmeerd van dit boek en geef het 2 sterren .\",\n  \"label\": \"negative\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Voor mij het zwakste boek van Coben tot nu toe.\\nHet was alsof ik naar een slechte B-film aan het kijken was. Bordkartonnen personages die me totaal onverschillig lieten. Deus ex machina's die de plot ongeloofwaardig maken.\\nVerloren is als een slecht, onevenwichtig James Bond verhaal. Veel actie zonder context, background en motivatie.\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Hieronder staan tweets en hun sentiment, dat 'positief', 'neutraal' of 'negatief' kan zijn.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tweet: {text}\nSentiment: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tweet: {text}\n\nClassificeer het sentiment in de tweet. Antwoord met 'positief', 'neutraal' of 'negatief'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positief</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negatief</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset dbrd\n</code></pre>"},{"location":"datasets/dutch/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/dutch/#conll-nl","title":"CoNLL-nl","text":"<p>This dataset was published in this paper and consists of named entity recognition annotations of the Belgian newspaper \"De Morgen\" of 2000.</p> <p>The original full dataset consists of 8,324 / 1,916 / 1,518 samples for training, validation and testing, respectively (so 11,758 samples used in total). We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['Puitstraat', '6', ',', '8890', 'Moorslede', '.'], dtype=object),\n  \"labels\": array(['B-LOC', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object),\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Monami-Van', 'Roost', 'had', 'nochtans', 'verloren', '.'], dtype=object),\n  \"labels\": array(['B-PER', 'I-PER', 'O', 'O', 'O', 'O'], dtype=object),\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Het', 'overwicht', 'lag', 'op', 'nieuw', 'nummers', 'als', \"'\", 'Maria', 'Maria', \"'\", ',', \"'\", 'Put', 'Your', 'Lights', 'On', \"'\", 'en', \"'\", 'Smooth', \"'\", ',', 'stuk', 'voor', 'stuk', 'knappe', 'songs', 'die', 'zich', 'op', 'de', 'koop', 'toe', 'in', 'korte', ',', 'krachtige', 'versies', 'lieten', 'bewonderen', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object),\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Hieronder staan zinnen en JSON woordenboeken met de genoemde entiteiten die voorkomen in de gegeven zin.\n</code></pre></li> <li>Base prompt template:   <pre><code>Zin: {text}\nGenoemde entiteiten: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Zin: {text}\n\nIdentificeer de genoemde entiteiten in de zin. Je moet dit uitvoeren als een JSON-woordenboek met de sleutels 'persoon', 'locatie', 'organisatie' en 'diversen'. De waarden moeten lijsten zijn van de genoemde entiteiten van dat type, precies zoals ze voorkomen in de zin.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>persoon</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>persoon</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>locatie</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>locatie</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisatie</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisatie</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diversen</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diversen</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset conll-nl\n</code></pre>"},{"location":"datasets/dutch/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/dutch/#scala-nl","title":"ScaLA-nl","text":"<p>This dataset was published in this paper and was automatically created from the Dutch Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 13,603 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Met het toepassen van zelfbestuur wordt ook al op de lagere school begonnen.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Vragen, die door een leek niet zo eenvoudig te zijn.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"U ziet een soort eng nachtclubomgeving, waar een groepje schertsaristocraten glazig zit te lachen om haar zouteloze tussenteksten, waarin ze wanhopig probeert een intelligent ondertoontje te leggen.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Hieronder staan zinnen en of ze grammaticaal correct zijn.\n</code></pre></li> <li>Base prompt template:   <pre><code>Zin: {text}\nGrammaticaal correct: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Zin: {text}\n\nBepaal of de zin grammaticaal correct is of niet. Antwoord met 'ja' als de zin correct is en 'nee' als dat niet het geval is.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nee</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-nl\n</code></pre>"},{"location":"datasets/dutch/#unofficial-dutch-cola","title":"Unofficial: Dutch CoLA","text":"<p>This dataset is published here and is a manually annotated linguistic acceptability dataset, with documents coming from descriptions of Dutch syntax.</p> <p>The original full dataset consists of 19,900 / 2,400 / 2,400 samples for training, validation and testing, respectively (so 24,700 samples used in total). We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively. The original splits were imbalanced, so we ensure a 50/50 split of correct/incorrect samples in the new splits. All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Tasman heeft geen Maori gezien.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Jan is vrij bang voor honden en ik ben het zeer erg voor spinnen.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Wat is het duidelijk dat Jan zal krijgen?\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p>"},{"location":"datasets/dutch/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/dutch/#squad-nl","title":"SQuAD-nl","text":"<p>This dataset is published here and is a machine translated dataset of the English SQuAD and XQuAD datasets, created for the Dutch-language DUMB benchmark. Google Translate was used to translate the original datasets to Dutch. The test data was manually corrected by eight BSc students as part of their thesis work.</p> <p>The original SQuAD and XQuAD datasets are based on English Wikipedia articles and the questions and answers are written by crowdworkers.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"Windows 8 bevat ook verbeterde ondersteuning voor mobiel breedband; het besturingssysteem kan nu de plaatsing van een simkaart detecteren en automatisch verbindingsinstellingen configureren (inclusief APN's en carrier-branding), en het internetgebruik verminderen om bandbreedte op gemeten netwerken te besparen. Windows 8 voegt ook een ge\u00efntegreerde instelling voor vliegtuigmodus toe om ook alle draadloze connectiviteit wereldwijd uit te schakelen. Vervoerders kunnen ook accountbeheersystemen aanbieden via Windows Store-apps, die automatisch kunnen worden ge\u00efnstalleerd als onderdeel van het verbindingsproces en gebruiksstatistieken bieden op hun respectievelijke tegel.\",\n  \"question\": 'Wat registreert het plaatsen van een simkaart?',\n  \"answers\": {\n    \"answer_start\": array([68]),\n    \"text\": array(['het besturingssysteem'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Het Duitse systeem van hoger onderwijs omvat twee vormen van academische instellingen: universiteiten en hogescholen (Fachhochschule). De universiteit van Jena is de grootste van de vier universiteiten van Th\u00fcringen en biedt bijna elke discipline. Het werd opgericht in 1558 en heeft vandaag 21.000 studenten. De op een na grootste is de Technische Universit\u00e4t Ilmenau met 7.000 studenten, opgericht in 1894, die veel technische disciplines biedt, zoals techniek en wiskunde. De universiteit van Erfurt, gesticht in 1392, heeft tegenwoordig 5.000 studenten en legt de nadruk op geesteswetenschappen en lerarenopleiding. De Bauhaus-universiteit Weimar is met 4.000 studenten de kleinste universiteit van Th\u00fcringen en is gespecialiseerd in creatieve vakken zoals architectuur en kunst. Het werd opgericht in 1860 en kreeg tijdens het interbellum bekendheid als de belangrijkste kunstacademie van Duitsland, het Bauhaus.',\n  \"question\": 'Wat is de grootste school in Th\u00fcringen?',\n  \"answers\": {\n    \"answer_start\": array([135]),\n    \"text\": array(['De universiteit van Jena'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Door di\u00ebten in westerse landen te vergelijken, hebben onderzoekers ontdekt dat hoewel de Fransen meer dierlijk vet eten, de incidentie van hartaandoeningen in Frankrijk laag blijft. Dit fenomeen wordt de Franse paradox genoemd en wordt verondersteld te ontstaan door de beschermende voordelen van het regelmatig consumeren van rode wijn. Afgezien van de mogelijke voordelen van alcohol zelf, waaronder verminderde aggregatie van bloedplaatjes en vasodilatatie, bieden polyfenolen (bijv. Resveratrol), voornamelijk in de druivenschil, andere vermoedelijke gezondheidsvoordelen, zoals:',\n  \"question\": 'Wat eten mensen in Frankrijk meer van dat in de meeste westerse landen?',\n  \"answers\": {\n    \"answer_start\": array([102]),\n    \"text\": array(['dierlijk vet'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Hieronder volgen teksten met bijbehorende vragen en antwoorden.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nVraag: {question}\nAntwoord in max 3 woorden: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBeantwoord de volgende vraag over de bovenstaande tekst in maximaal 3 woorden.\n\nVraag: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset squad-nl\n</code></pre>"},{"location":"datasets/dutch/#unofficial-belebele-nl","title":"Unofficial: BeleBele-nl","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Tekst: Mystiek is het geloven in, identificeren met of bewustzijn van een ultieme werkelijkheid, goddelijkheid, spirituele waarheid of God. De kerkganger streeft naar een directe gewaarwording, intu\u00eftie of inzicht in de goddelijke werkelijkheid. Volgers streven een bepaalde manier van leven na of willen ervaringen opdoen die ze datzelfde gevoel geven. In tegenstelling tot andere religieuze overtuigingen en aanbidding, legt mystiek nadruk op de rechtstreekse persoonlijke beleving van een unieke staat van bewustzijn, vooral van een vredige, inzichtelijke, gelukzalige of extatische aard.\\nVraag: Wat is geen juiste omschrijving van mystiek?\\nAntwoordopties:\\na. De nadruk ligt op het ervaren van een vredige, gelukzalige staat van bewustzijn\\nb. Volgers van mystiek streven bewustwording na van een spirituele werkelijkheid\\nc. Volgers van mystiek passen gebruiken toe die hun inzicht in een goddelijke werkelijkheid vergroten\\nd. De nadruk op het streven naar een directe persoonlijke beleving is vergelijkbaar met veel andere vormen van religieuze overtuiging en aanbidding\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tekst: Het favoriete maaltje van ocelotten zijn kleine dieren. Ze vangen apen, slangen, knaagdieren en vogels als dat lukt. De ocelot jaagt bijna uitsluitend op dieren die veel kleiner zijn dan hij zelf is. Geleerden vermoeden dat ocelotten hun reukvermogen gebruiken om op kleine dieren (hun prooi) te jagen, door aan de grond te ruiken waar deze zijn geweest. Ze kunnen door nachtvisie heel goed in het donker zien en bewegen zich heel onopvallend voort. Ocelotten jagen op prooi door zich \u00e9\u00e9n te maken met de omgeving en vervolgens op hun prooi te springen.\\nVraag: Welke uitspraak over een ocelot is onjuist?\\nAntwoordopties:\\na. Ze kunnen goed in het donker jagen\\nb. Ze bewegen zich in stilte voort\\nc. Hun reukvermogen is zwak\\nd. Ze jagen het liefst op kleine dieren\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tekst: Er was 120-160 kubieke meter brandstof aan boord van de Luno toen het schip motorproblemen kreeg en door de harde wind en golven tegen de golfbreker werd geduwd. De twaalf crewleden zijn met helikopters in veiligheid gebracht, met als enige verwonding een gebroken neus. Het 100 meter lange schip was onderweg om de gebruikelijke lading kunstmest op te halen. In eerste instantie vreesden autoriteiten dat het vaartuig met de lading zou kunnen gaan lekken.\\nVraag: Waar vreesden de autoriteiten volgens de tekst in eerste instantie voor wat betreft de Luno?\\nAntwoordopties:\\na. Gebrek aan een lading kunstmest\\nb. Golven en harde wind\\nc. Lekken van brandstof\\nd. Verwondingen van bemanningsleden\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Hieronder staan meerkeuzevragen (met antwoorden).\n</code></pre></li> <li>Base prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAntwoord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantwoord de bovenstaande vraag met 'a', 'b', 'c' of 'd', en niets anders.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-nl\n</code></pre>"},{"location":"datasets/dutch/#unofficial-multiwikiqa-nl","title":"Unofficial: MultiWikiQA-nl","text":"<p>This dataset will be published in an upcoming paper, and contains Dutch Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Het Tokyo Aquatics Centre (Japans: \u6771\u4eac\u30a2\u30af\u30a2\u30c6\u30a3\u30af\u30b9\u30bb\u30f3\u30bf, T\u014dky\u014d akuatikusu sent\u0101) is een zwembad in de Japanse hoofdstad Tokio. Het ligt in het stadsdeel Tatsumi dat deel uit maakt van de wijk Koto. De bouw begon in april 2017 en werd in februari 2020 afgewerkt. De offici\u00eble opening werd uitgesteld vanwege de coronapandemie en vond plaats op 26 oktober 2020. Het zwembad werd gebouwd voor de Olympische en Paralympische Spelen in 2020 en biedt plaats aan vijftienduizend toeschouwers. Tijdens de Olympische Spelen zullen het baanzwemmen, schoonspringen en synchroonzwemmen er plaatsvinden; het waterpolotoernooi wordt gehouden in het nabijgelegen Tokyo Tatsumi International Swimming Center.\\n\\nHet zwembadcomplex heeft twee zwembaden en een duikbad. Het dak werd eerst op de grond gebouwd en vervolgens geleidelijk verhoogd tot een hoogte van 37 meter. Het is 160 meter lang, 130 meter breed en 10 meter dik. Het dak weegt 7.000 ton. Het zwembad blijft na de Olympische en Paralympische spelen in gebruik als zwemarena, evenwel met een in aantal gereduceerde publiekstribune. Tevens wordt het een publiek zwembad.\\n\\nZwembad in Japan\\nKoto\\nAccommodatie tijdens de Olympische Zomerspelen 2020\\nSportaccommodatie in Tokio\",\n    \"question\": \"In welke plaats is het Tokyo Aquatics Centre gevestigd?\",\n    \"answers\": {\n        \"answer_start\": array([128]),\n        \"text\": array([\"in het stadsdeel Tatsumi dat deel uit maakt van de wijk Koto\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"J.F. Scholten &amp; Zonen was een textielfabriek in Enschede\\n\\nOntstaansgeschiedenis\\n\\nDe grondlegger voor wat later J.F. Scholten &amp; zonen zou gaan heten is de schoolmeester Tijs Lammerink. Van 1800 tot 1810 is hij schoolmeester in Usselo en drijft hij daarnaast handel met de Usselose boeren, hij koopt het door hun geweven linnen op en verkoopt dit weer. In 1808 trouwt Tijs Lammerink met Geesken ten Thij en breidt hij zijn handelaarsactiviteiten uit. Hij koopt herberg \\\"de Swaene\\\" van de familie Wagelaar en koopt in korte tijd nog twee panden waarin hij in 1815 een katoenspinnerij en een zwartververij begint.\\n\\nHuwelijk dochter\\nIn 1838 huwt de dochter van Tijs Lammerink, Bertiena, met Jan Frederik Scholten. Deze wordt opgenomen in het bedrijf van zijn schoonvader om het na diens overlijden alleen voort te zetten. De fabriek wordt getroffen door de stadsbrand van Enschede (1862)  en vanaf dat moment besluit J.F. Scholten zijn werkzaamheden voort te zetten met zijn drie zonen Jan, Gijs en Theunis. Ze vernieuwen de spinnerij en maken hem stoomgedreven, en daarmee klaar voor de toekomst. De merknaam die ze blijven voeren is \\\"De Swan\\\" naar de naam van de herberg waarin Tijs Lammerink zijn werkzaamheden begon.\\n\\nZonen\\nOok oudste zoon Jan krijgt een aantal zonen waarmee het voortbestaan van de fabriek wordt gewaarborgd. Na 1889 worden de zoons van Jan Scholten, te weten Jan Fredrik Scholten (1867-1943), Jan Bernard Scholten (1870-1947) en Julius Scholten (1871-1969) geleidelijk in de firma opgenomen.\\nDe lijn wordt voortgezet in 1931 en 1934 wanneer de zoons van Julius Scholten, respectievelijk Jan Scholten (1903) en Jan Fredrik Scholten (1910) als firmanten in het bedrijf worden opgenomen.\\n\\nNaamloze Vennootschap en overname\\nIn 1936 wordt de firma omgezet in een naamloze vennootschap. Er werden goederen gefabriceerd voor de binnenlandse markt en stapelartikelen voor Nederlands-Indi\u00eb op consignatie-basis. In 1956 werden de N.V. Katoenfabrieken v/h Arntzenius Jannink &amp; Co. te Goor door J.F. Scholten &amp; Zonen N.V. overgenomen.\\n\\nAfbraak\\nIn 1977 wordt de fabriek afgebroken. Op de plaats staat nu het Medisch Spectrum Twente\\n\\nGeschiedenis van Enschede\\nEconomie in Enschede\\nVoormalig Nederlands textielbedrijf\",\n    \"question\": \"Welke logement verwierf Lammerink van de familie Wagelaar?\",\n    \"answers\": {\n        \"answer_start\": array([467]),\n        \"text\": array([\"\\\"de Swaene\\\"\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Een haardplaat is een metalen plaat achter of onder een open haard, meestal van gietijzer.\\n\\nToelichting\\n\\nFunctie van een haardplaat\\nHaardplaten achter in de haard zijn bedoeld om warmte te verspreiden, haardplaten onder de haard om vonken op te vangen en zo brand te voorkomen. De meeste nog bewaarde haardplaten - in Nederland zijn er nog duizenden - zijn versierd met een beeltenis.\\n\\nEen open haard heeft een rendement van zo'n 10 tot 15%, wat betekent dat 85 tot 90 % van de warmte via de schoorsteen verloren gaat. Met een haardplaat achter de haard kan het rendement van een open haard worden verbeterd. Een haardplaat achter het vuur van de open haard neemt warmte op en straalt deze weer uit. Hoe dikker de plaat, hoe sterker de werking. Het rendement van een open haard kan met een haardplaat tot 50% verbeterd worden.\\n\\nGeschiedenis van de haardplaat\\n\\nHaardplaten deden hun intrede in de 15e eeuw. Voor die tijd bestond de achterkant van een open haard uit steen. Enkele haardplaten werden vooral gebruikt in Engeland, Frankrijk en Nederland. In Duitsland werden ook wel haardplaten gebruikt, vooral in de Eifel, maar in de rest van Duitsland zag men vooral haardkasten, dit waren meerdere haardplaten die met lijsten aan elkaar verbonden waren en zo een kast vormden. Deze haardkasten waren ook algemeen in de Scandinavische landen. Later werden de platen voor deze kachelkasten van keramiek gemaakt en ontstond de tegelkachel die in Duitsland, Scandinavi\u00eb en Oost-Europa zeer algemeen was en hier en daar nog is.\\n\\nHaardplaten en kachelplaten ontstonden ongeveer gelijk en hebben hun oorsprong in de Eiffel en Elzas. De gietijzeren platen werden gegoten in een zandbed. Aanvankelijk waren de platen eenvoudig, maar al snel werden er houtsneden of stempels in het zandbed gedrukt waardoor de plaat een reli\u00ebf kreeg. Naarmate de vraag naar haard- en kachelplaten toenam werden de reli\u00ebfs verfraaid; later ontstonden complete taferelen. De versiering van haardplaten kent vele thema's: Bijbelse taferelen, allegorische voorstellingen, familiewapens, portretten, herdenkingen enz. De taferelen werden meestal gesneden naar het voorbeeld van prenten of gravures uit die tijd. Ook waren er modellenboeken in omloop. Er zijn maar weinig kunstenaars die zich specifiek richtten op haardplaten. Gelet op de versieringen zijn de Nederlandse haardplaten uit de 17e eeuw het meest opmerkelijk. Een haardplaat uit deze periode is te herkennen aan rijke versieringen rond een middentafereel. De versieringen bestonden vaak uit dolfijnen, slangen, salamanders, zeenimfen en schelpen. De zijkanten waren omrand met bloemen, bladeren en vruchten. De Duitse platen uit die tijd zijn veel soberder, meer rechttoe rechtaan. Ook de vorm van de Nederlandse en Duitse platen verschilden, de Nederlandse platen hebben meestal een ronde vorm aan de bovenkant terwijl de Duitse platen recht zijn.\\n\\nNederland heeft het Haardplatenmuseum in Klarenbeek.  Sommige musea hebben wel bijzondere haardplaten in bezit zoals Museum De Waag in Deventer en het Rijksmuseum in Amsterdam. De grootste Europese collectie haardplaten - circa 400 stuks - is te vinden in het stadhuis van D\u00fcsseldorf, Duitsland.\\n\\nOnderhoudstips voor de haardplaat\\nHaardplaten slijten vrijwel niet. Eventuele roest kan met een staalborstel verwijderd worden. Vroeger werden de platen ook wel gezandstraald, maar hierbij verloren versierde platen veel van hun oorspronkelijke reli\u00ebf. Tegenwoordig bestaan er meer verfijnde straaltechnieken waarmee bijvoorbeeld verf en roest van een plaat kan worden verwijderd. Stralen wordt door gespecialiseerde bedrijven gedaan omdat de straalmethode, het straalmiddel, de druk en de grootte van de korrel het resultaat bepalen. Ondeskundig stralen kan de plaat beschadigen. Na het schoonmaken kan de plaat het best worden ingesmeerd met kachelpoets. Sommige mensen maken de plaat schoon met petroleum. Dit middel is echter ongeschikt, de plaat wordt er blijvend dof van.\\n\\nExterne links\\n Tour stadhuis D\u00fcsseldorf\\n Haardplaten in musea\\n Voorbeelden van oude haardplaten met hun symbolen\\n\\nBouwkundig onderdeel\\nVerwarming\",\n    \"question\": \"Hoe effici\u00ebnt is een open haard als er geen haardplaat gebruikt wordt?\",\n    \"answers\": {\n        \"answer_start\": array([425]),\n        \"text\": array([\"zo'n 10 tot 15%\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Hieronder volgen teksten met bijbehorende vragen en antwoorden.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nVraag: {question}\nAntwoord in max 3 woorden: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBeantwoord de volgende vraag over de bovenstaande tekst in maximaal 3 woorden.\n\nVraag: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-nl\n</code></pre>"},{"location":"datasets/dutch/#knowledge","title":"Knowledge","text":""},{"location":"datasets/dutch/#mmlu-nl","title":"MMLU-nl","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Dutch was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Polarisatie is een eigenschap van\\nAntwoordopties:\\na. transversale golven.\\nb. longitudinale golven.\\nc. alle golven.\\nd. Geen van deze.\",\n  \"label\": \"a\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Welk internetbedrijf gaat onder de afkorting AOL?\\nAntwoordopties:\\na. Amerika Over Lijnen\\nb. Amerika Online\\nc. Amerikanen op Links\\nd. Amerikanen op LOR\",\n  \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Deze vraag verwijst naar de volgende informatie. Lees het volgende fragment. Nooit waren talenten van het hoogste genie van de meest verheven soort overvloediger geschonken aan een mens. Het genie van Napoleon is verbazingwekkend. Alle takken van menselijke kennis leken even vertrouwd voor zijn gigantische geest. Zijn conversaties op St. Helena, verspreid over de talloze en omvangrijke herdenkingsstukken van degenen die ze verzamelden, zijn gevuld met de grootste interesse. Tijdens de lange doodsstrijd van zijn gevangenschap en zijn dood, sprak hij met volledige vrijheid over de gebeurtenissen van zijn wonderbaarlijke carri\\u00e8re, en over al die onderwerpen van moralen, politiek en religie, die het meest diep de welvaart van ons ras betreffen. Er is geen geest die niet zal worden versterkt door bekendheid met deze diepzinnige gedachten, uitgedrukt met zoveel gloed van gevoel en energie van dictie. \\u2014 John S. C. Abbott, historicus, Napoleon op St. Helena, 1855 Napoleon hielp de Franse Revolutie tot een internationale beweging te maken in de gebieden die hij veroverde.\\nAntwoordopties:\\na. Door een universele valuta op basis van de Franse frank op te leggen\\nb. Door de brute onderdrukking van guerrilla-verzet\\nc. Door het afschaffen van feodalisme en herenboerderijen\\nd. Door het aanmoedigen van het gebruik van Frans als universele taal\",\n  \"label\": \"c\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Hieronder staan meerkeuzevragen (met antwoorden).\n</code></pre></li> <li>Base prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAntwoord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantwoord de bovenstaande vraag met 'a', 'b', 'c' of 'd', en niets anders.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-nl\n</code></pre>"},{"location":"datasets/dutch/#unofficial-arc-nl","title":"Unofficial: ARC-nl","text":"<p>This dataset is a machine translated version of the English ARC dataset and features US grade-school science questions. The translation to Dutch was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"In een graslandecosysteem, als de populatie van adelaars plotseling afneemt, wat zal waarschijnlijk het effect zijn op de rest van het ecosysteem?\\nAntwoordopties:\\na. Het ecosysteem zal overbevolkt worden met slangen.\\nb. Er zal een afname zijn in de populatie van slangen in het ecosysteem.\\nc. De voedingswaarde van de bodem zal afnemen in het ecosysteem.\\nd. Er zullen meer soorten planten beginnen te groeien in het ecosysteem.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ptolemeus was een oude astronoom die dacht dat de Aarde het centrum van het universum was. Toen hij observaties deed die hiermee niet overeenkwamen, stelde hij een verschijnsel genaamd \\\"epicycli\\\" voor om de observaties te verklaren. Hoe was Ptolemeus' proces vergelijkbaar met het moderne wetenschappelijke proces?\\nAntwoordopties:\\na. Ptolemeus baseerde zijn model deels op een geloofssysteem.\\nb. Observaties inspireerden Ptolemeus om zijn verklaringen aan te passen.\\nc. Ptolemeus probeerde het universum te beschrijven in plaats van het te verklaren.\\nd. Experimenten vormden de basis van Ptolemeus' model van het universum.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Wat onderscheidt de organismen in het rijk Fungi van andere eukaryotische organismen?\\nAntwoordopties:\\na. Fungi zijn eencellig.\\nb. Fungi reproduceren seksueel.\\nc. Fungi verkrijgen voedingsstoffen door middel van absorptie.\\nd. Fungi maken voedsel door middel van fotosynthese.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Hieronder staan meerkeuzevragen (met antwoorden).\n</code></pre></li> <li>Base prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAntwoord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantwoord de bovenstaande vraag met 'a', 'b', 'c' of 'd', en niets anders.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset arc-nl\n</code></pre>"},{"location":"datasets/dutch/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/dutch/#hellaswag-nl","title":"HellaSwag-nl","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,310 samples. We use an 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[header] Hoe maak je organische babydoekjes? [title] Kies een rol organische papieren handdoeken. [step] Deze dienen als de eigenlijke doekjes. Experimenteer met verschillende merken en texturen totdat je degene vindt die het beste werkt voor de huid van je baby.\\nAntwoordopties:\\na. Het is belangrijk om organische papieren handdoeken te gebruiken, omdat niet-organische papieren handdoeken bleekmiddel, verf en andere chemicali\\u00ebn kunnen bevatten die vaak worden gebruikt bij de productie van papierproducten. [substeps] Over het algemeen maken bekende merken van papieren handdoeken betere doekjes dan de goedkopere, generieke versies.\\nb. Je kunt een papieren handdoek gebruiken die gebruikt wordt voor luierdoekjes, maar je kunt dezelfde ook gebruiken voor andere doekjes. [substeps] Je kunt drie- of vierzijdige doekjes gebruiken om je te helpen bij het mengen van alle melk, yoghurt en water die je in \\u00e9\\u00e9n container hebt gemengd.\\nc. Als je zelfgemaakte lotion gebruikt, gebruik dan geen papieren handdoeken; deze moeten ook van niet-papier zijn. Rol een grote rol kleine papieren handdoeken uit en houd rekening met de algehele geur van de pad.\\nd. [substeps] Spreid het droge doekje uit over het hele oppervlak van de huid van je baby en vermijd contact met het droge doekje (tondeuse, kam of puimsteen). [title] Plaats de fles boven een kom met warm water gedurende 10 minuten.\",\n  \"label\": \"a\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] Hoe maak je een jurk zonder patroon [title] Koop een jurkmodel. [step] Je hebt een verstelbaar jurkmodel nodig om ervoor te zorgen dat je jurkontwerpen op exact de maat worden gemaakt die je nodig hebt. Verstelbare jurkmodellen zijn verkrijgbaar voor ongeveer $ 250 nieuw.\\nAntwoordopties:\\na. [substeps] Je kunt een schoenmakersstof, bedrukte binnenbekleding of bedrukt behang gebruiken om je jurkmodel te maken. Kies het patroon en knip het patroon zelf uit.\\nb. [title] Stel je jurkmodel af op de hoogte-, taille- en torso-maten die je gaat gebruiken voor je prototypejurk. [title] Maak een schets van de jurk die je wilt maken.\\nc. Als je van plan bent om strapless jurken te dragen, wil je misschien een jurkmodel kopen met een grotere voor-achter-maat. [title] Plaats je jurkmodel op de tafel.\\nd. Je kunt ook een jurkmodel in de supermarkt kopen. [substeps] Als je een strapless jurk wilt, kies dan voor een mouwloze jurk.\",\n  \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] Hoe citrusvruchten te raspen [title] Was de citrusvrucht. [step] Voordat je begint, spoel de vrucht af onder stromend koel water en wrijf het vervolgens zachtjes schoon met een schone doek of papieren handdoek. Een lichte spoeling helpt bij het verwijderen van het natuurlijke wasachtige residu aan de buitenkant van de vrucht.\\nAntwoordopties:\\na. [substeps] Zorg ervoor dat de vrucht volledig is afgespoeld voordat je doorgaat naar de volgende stap. De meeste citrusvruchten hebben het beschadigde deel verwijderd, maar met het middenstuk kun je afwisselen tussen het opfrissen van de schil met water en het verwijderen van de schil.\\nb. [substeps] Het werk kan het beste ook laat in de avond worden gedaan, nadat de suiker is verdampt. [title] Maak een zure citrus door een kom met zout in het water te dompelen.\\nc. Je kunt de citrusvrucht ook kort laten weken in een ondiepe kom met water. [substeps] Het is belangrijk om citrusvruchten altijd te wassen wanneer je ze raspt, omdat de buitenkant het deel is dat daadwerkelijk in je voedsel terechtkomt.\\nd. [title] Doe het mengsel van rasp in een druppelaar. [step] Commercieel verkrijgbare rasp komt van de schil van de citrusboom.\",\n  \"label\": \"c\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Hieronder staan meerkeuzevragen (met antwoorden).\n</code></pre></li> <li>Base prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAntwoord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantwoord de bovenstaande vraag met 'a', 'b', 'c' of 'd', en niets anders.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-nl\n</code></pre>"},{"location":"datasets/dutch/#unofficial-goldenswag-nl","title":"Unofficial: GoldenSwag-nl","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Hoe leer je je kind een potlood vasthouden? Koop het juiste potlood voor je kind. Het gebruik van korte potloden, zoals golfpotloden of gewone potloden die doormidden zijn gebroken, kan kinderen helpen om zelf de juiste greep te vinden. Korte potloden hebben minder ruimte voor overbodige vingers, dus je kind heeft weinig keus dan de juiste drievingerige greep te gebruiken.\\nAntwoordopties:\\na. Je kunt korte potloden kopen bij de meeste hobby- en kantoorboekhandels. Help je kind met een potloodgreep.\\nb. Goede potloden om mee te beginnen zijn de \"p\" en \"g\" potloden. Begin in de onderste potloodhouder in het midden en let goed op hoe je kind het potlood op zijn plaats probeert te houden.\\nc. Ga voor meer informatie over het hanteren van een potlood naar. Maak onderscheid tussen potloden die met de handen worden aangedreven en potloden die met beide handen worden gebruikt.\\nd. Met een vinger met een langere potloodpunt kunnen kinderen potloden met veel meer controle vasthouden. Met een vinger met een lagere punt kun je proberen om zowat elke vingerpositie onder controle te houden.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hoe ontstop je een langzaam lopende afvoer van de badkamer gootsteen. Verzamel je materialen. In plaats van te vertrouwen op afvoerreinigingsproducten, die vaak bijtend zijn en allergische reacties en ademhalingsproblemen kunnen veroorzaken, kun je huishoudelijke artikelen gebruiken die je waarschijnlijk al in huis hebt. Je hebt nodig: Doekjes zuiveringszout azijn citroen kokend water. Meet je ingredi\u00ebnten af.\\nAntwoordopties:\\na. Een afvoer met een diameter van ongeveer 0,64 centimeter. Was gootsteenontstoppingsproducten met de hand is een gebruikelijke methode, maar je kunt ze bij de meeste bouwmarkten kopen.\\nb. Je hebt als basis bloem, zuiveringszout, witte azijn en water nodig. Je kunt een maatbeker gebruiken om ze af te meten, of zelfs een waterkoker.\\nc. Neem \u00bc kopje zuiveringszout, 1 kopje witte azijn en 1 grote pan water om te koken. Zorg dat je een vod of gootsteenstopper bij de hand hebt.\\nd. Hoewel niet alle kleine gootstenen verstopt zijn, kan heet water helpen om de verstopte gaten te verwijderen. Het gebruik van een maatbeker om je ingredi\u00ebnten af te meten is vooral belangrijk omdat kokend water ook vuil zoals lichaamsresten, klei en zelfs dierlijke uitwerpselen introduceert.\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hoe doe je een dip powder manicure? Gebruik nagellakremover en een nagelriemduwer. Als je nagellak op je nagels hebt, verwijder deze dan met nagellakremover zonder aceton op een niet-pluizend wattenschijfje. Gebruik een nagelriemduwer om je nagelriemen voorzichtig een beetje naar achteren te duwen.\\nAntwoordopties:\\na. Gebruik alleen nagellakremover of een nagelriemduwer als je vieze handen hebt. Schrijf op je nagels met de nagelriemduwer.\\nb. Duw ze niet krachtig terug zodat je geen pijn veroorzaakt aan je vingers of teennagels. Druk ze echter wel stevig aan met je vingers.\\nc. Beweeg de drukker in een ronddraaiende beweging om de doorbloeding te stimuleren. Breng een leave-in conditioner aan nadat je je nagelriemen hebt ingesmeerd.\\nd. Verwijder voorzichtig overtollige nagelriemen met een nagelriemtrimmer of schraper. Dit zorgt ervoor dat nieuwe nagelgroei zichtbaar wordt, zodat je manicure langer meegaat voordat je hem moet opvullen.\",\n  \"label\": \"d\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Hieronder staan meerkeuzevragen (met antwoorden).\n</code></pre></li> <li>Base prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAntwoord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Vraag: {text}\nAntwoordopties:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantwoord de bovenstaande vraag met 'a', 'b', 'c' of 'd', en niets anders.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-nl\n</code></pre>"},{"location":"datasets/dutch/#summarization","title":"Summarization","text":""},{"location":"datasets/dutch/#wikilingua-nl","title":"WikiLingua-nl","text":"<p>This dataset was published here and consists of Dutch WikiHow articles and their summaries, where a summary consists of the first sentence of each \"how-to\" step in the article (and this first sentence is not included in the article text).</p> <p>The original full dataset consists of 21,345 / 3,058 / 6,105 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Je gaat de ham ongeveer 15 tot 20 minuten glaceren voordat hij klaar is met koken. Om het glazuur op tijd klaar te hebben, begin je met de bereiding ervan ongeveer 45 tot 60 minuten voordat je verwacht dat de ham klaar zal zijn. Snelle glazuren zijn in een paar minuten klaar, en zelfs de glazuren die op het fornuis moeten sudderen, nemen minder dan 15 minuten in beslag. Voor de eenvoudigste optie zonder te koken, klop je gewoon 270 g donkerbruine suiker met 60 ml sinaasappelsap, rode wijn of cognac. Meng de ingredi\\u00ebnten in een kleine kom totdat de suiker volledig is opgelost. Als alternatief, combineer je 270 g lichtbruine suiker, 160 ml sojasaus, en twee gehakte knoflookteentjes in een kleine steelpan -- breng dan de ingredi\\u00ebnten aan de kook op gemiddeld vuur. Zet  de temperatuur lager zodra het mengsel aan de kook is. Roer het af en toe door en laat het 3-5 minuten sudderen, of tot het iets is ingedikt. Zet dan het vuur uit en laat het glazuur minstens 10 tot 15 minuten afkoelen alvorens het over de ham te strijken. Klop 320 ml melasse, 160 ml bourbon en \\u00bd theelepel (1 g) gemalen kruidnagel in een kleine steelpan. Breng de ingredi\\u00ebnten aan de kook op middelmatig vuur, zet het vuur dan laag en laat het onder af en toe roeren, sudderen gedurende 3-5 minuten. Op het moment dat het mengsel iets verdikt is, zet je het vuur uit en laat je het 10 tot 15 minuten afkoelen. Combineer 180 ml ahornsiroop, 120 ml sinaasappelmarmelade, 2 eetlepels (30 g) ongezouten boter, 1 eetlepel (16 g) Dijon-mosterd, 1 theelepel (2 g) gemalen zwarte peper, en \\u00bc theelepel gemalen kaneel in een kleine steelpan. Laat het mengsel op matig vuur sudderen, onder af en toe roeren, gedurende 5-10 minuten, of totdat het stroperig is en is ingedikt tot 240 ml. Laat het glazuur minstens 10 tot 15 minuten afkoelen alvorens het over de ham te strijken. Er zijn talloze recepten voor glazuren te vinden, maar het bedenken van een eigen glazuur is eenvoudig. Experimenteer met ingredi\\u00ebnten tot je de zoete, zure en hartige smaken in balans hebt gebracht. Streef naar ongeveer 240 tot 500 ml glazuur, en reserveer ongeveer een derde ervan voor op de eettafel. De basisingredi\\u00ebnten van een glazuur zijn een zoetstof (zoals bruine suiker of melasse), een zuur (zoals azijn of sinaasappelsap), en kruiden of specerijen (zoals tijm of kruidnagel).\",\n  \"target_text\": \"Bereid het glazuur voor nadat je de ham in de oven hebt gezet. Klop een glazuur van bruine suiker voor een eenvoudige klassieker. Sudder een sojasausglazuur voor een hartige smaak. Combineer bourbon, melasse en kruidnagel voor een diep, warm glazuur. Maak een esdoorn-sinaasappelglazuur voor een pittige, opvallende smaakcombinatie. Bedenk je eigen aangepaste glazuur.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Je koplampen zijn je meest belangrijke levenslijn tijdens het rijden in het donker. Als ze niet in goede conditie zijn, vergroot je onnodig het risico op een ongeval. Houd je koplampen schoon door ze om de paar weken te wassen -- dit houdt de helderheid en scherpte van de lichtbundel hoog. Als een koplamp opbrandt, vervang deze dan zo snel mogelijk en rijd niet in het donker totdat de lamp hersteld is. Het is daarnaast overigens ook verboden om auto te rijden zonder goed werkende koplampen. Bovendien moet je voor de meeste zichtbaarheid je voorruit, ramen en spiegels zo helder en schoon maken als je kunt. Veeg deze belangrijke onderdelen van je auto niet schoon met je hand -- de natuurlijke olie van je huid kan vlekken op de spiegel achterlaten. Gebruik in plaats daarvan een krant of microvezeldoekje. De verstralerlichten van je auto kunnen je veiligheid significant vergroten wanneer je 's nachts rijdt, maar alleen als je ze correct gebruikt. Verstralers gebruik je bij het rijden door zeer donkere gebieden met weinig zicht, waar er niet veel verkeer is. In deze gevallen kunnen verstralers je gezichtsbereik veel breder en langer maken, dus gebruik ze waar nodig.  Zorg dat je verstralers uitschakelt wanneer je achter een andere auto rijdt of als er tegenliggers zijn. In deze gevallen kan het heldere licht van de verstralers andere automobilisten verblinden, waardoor het moeilijker voor hen wordt om veilig te rijden. Als je afslaat bij een bocht of over een heuveltop gaat en de zwakke gloed ziet van de koplampen van een andere auto, zet je verstralers dan voor alle zekerheid uit, zodat de andere bestuurder niet plotseling wordt verblind. Soms, zijn de koplampen van een auto schuiner naar de grond gericht dan nodig is, of zijn ze niet perfect symmetrisch uitgelijnd. De helderste koplampen in de wereld zijn niet nuttig als de weg voor je niet naar behoren verlichten. Dus als je merkt dat het moeilijk is om de weg voor je te zien tijdens het rijden in het donker, dan kun je overwegen om je koplampen opnieuw bij te stellen. Bij een professionele garage is deze procedure meestal heel snel en goedkoop geregeld. Het is ook mogelijk om zelf je koplampen bij te stellen. Aangezien iedere auto anders is, zal je de handleiding van je auto moeten raadplegen. Wees geduldig, want het kan even duren om koplampen perfect uitgelijnd te krijgen. In een perfecte wereld zouden andere bestuurders altijd hun verstralers dimmen als ze je zien, net zoals jij voor hen zou doen. Helaas willen automobilisten dit nog wel eens vergeten. Als een tegemoetkomende auto verstralers aan heeft staan, kijk daar dan niet naar, want het felle licht kan je tijdelijk verblinden. Kijk in plaats daarvan naar de rechterkant van je rijbaan (of in landen waar je aan de linkerkant van de weg rijdt, naar links), terwijl je vanuit je perifere zicht op gevaren let. Dit houdt je zo opmerkzaam mogelijk op de gevaren om je heen, met behoud van je zicht. Als een auto achter je verstralers aan heeft staan, probeer dan je achteruitkijkspiegel te verstellen om het licht uit je ogen te houden. Je kunt zelfs de spiegel zo instellen dat het licht weerkaatst naar de bestuurder van die auto, om hem te wijzen op zijn fout. Als je verwacht dat je veel 's nachts gaat rijden en onder mistige omstandigheden, dan kun je overwegen om te investeren in een set mistlampen. Vaak zijn deze lichten laag gemonteerd op de voorbumper om zoveel mogelijk wegdek te verlichten (mist is het dunst tot op een halve meter of zo boven het wegdek). Niet alle aftermarket lichten zijn even goed gemaakt, dus praat met je autodealer alvorens deze aanschaf te doen. Gebruik nooit je standaard verstralers in de mist. De reflecterende waterdeeltjes waaruit mist bestaat kunnen het heldere licht naar je terugkaatsen, waardoor je nog minder van de weg kunt zien dan zonder licht. De koplampen van andere auto's (en vooral verstralers) kunnen unieke uitdagingen vormen voor chauffeurs met een bril. Glazen kunnen soms tegemoetkomend licht op manieren reflecteren die een verduisterende schittering vormt voor de brildrager. Om dit te voorkomen kun je contactlenzen proberen of een brilglazen kopen met een anti-reflecterende coating, om deze effecten te minimaliseren. Als je een paar speciale brilglazen koopt, leg die dan in je auto zodat je ze altijd bij de hand hebt wanneer je de weg op gaat.\",\n  \"target_text\": \"Houd je koplampen, spiegels en voorruit in topconditie. Gebruik je verstraler voor situaties met weinig licht. Pas eventueel je koplampen aan. Ga op de juiste manier om met verstralers van andere weggebruikers door naar de kant van de weg te kijken. Overweeg om lage mistlampen te installeren. Draag je een bril, gebruik dan een anti-reflecterende coating.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Over het algemeen hebben raszuivere Cavaliers voorspelbare eigenschappen. Als je een raszuivere Cavalier koopt, kun je verwachten dat ze energieke, knuffelbare huisdieren zijn met een redelijk te onderhouden vacht. Genetisch bepaald hebben Cavaliers een neiging tot zorgeloosheid. Als je een rashond koopt, kun je een dergelijk karakter verwachten. Niet raszuivere Cavaliers kunnen sommige van de biologische eigenschappen overnemen van om het even welk ander ras waar ze mee gekruist zijn. Als ze zijn gekruist met een jachthond, dan kunnen ze een sterker jachtinstinct hebben, op dezelfde manier kunnen ze, als ze met een ras zijn gekruist met minder energie, zoals de shih tzu, dat energieke enthousiasme kwijtraken waar je in de eerste plaats op gevallen bent. Mensen hebben hun zinnen gezet op raszuivere Cavaliers. Dit betekent dat ze uit een beperkte genenpoel gefokt zijn. Om aangeduid te worden als raszuiver, wordt er op veel plaatsen inteelt gedaan met hun honden, en anderen hebben onwetend gefokt met een genenpoel die te klein is. Dit heeft heel realistische en bijzonder ongewenste consequenties. Raszuivere Cavaliers hebben een verhoogd risico op hartklachten, hernia en/of ernstige neurologische aandoeningen.   Hartziekte: in Engeland heeft 59% van de Cavaliers ouder dan 4 jaar een hartruis. Zijnde bijna tweederden van de populatie Cavaliers in Engeland is dit een uitzonderlijk statistisch gegeven.  Chiari misvorming en Syringomyelia: Kort gezegd betekent deze aandoening dat de schedel van de hond te klein is voor zijn hersenen. Dit veroorzaakt afschuwelijke zenuwpijn. Het diergeneeskundige leerboek \\\"Breed Predispositions to Disease in the Dogs and Cats\\\" bestempelt deze aandoening als \\\"veel voorkomend\\\" met tekenen die zich ontwikkelen tussen de leeftijd van 5 maanden tot 3 jaar.   Epilepsie: Honden kunnen op elk moment aanvallen ontwikkelen, maar tussen de 6 maanden en 6 jaar is de meest voorkomende periode.  Hernia:  Dit is een andere \\\"veelvoorkomende\\\" afwijking, vooral als Cavaliers ouder worden.  In de meeste gevallen zul je niet weten dat je Cavalier gevoelig is voor een hernia, tot je hem stijf ziet lopen of zijn hoofd met tegenzin naar beneden brengt naar zijn voerbak of waterbak.\",\n  \"target_text\": \"Overweeg de voordelen als je kiest voor een raszuivere Cavalier. Stel vast wat de schaduwzijden zijn van het kopen van een rashond. Houd algemene gezondheidsproblemen van de Cavalier in gedachten.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Hieronder volgen artikelen met bijbehorende samenvattingen.\n</code></pre></li> <li>Base prompt template:   <pre><code>Artikel: {text}\nSamenvatting: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Artikel: {text}\n\nSchrijf een samenvatting van het bovenstaande artikel.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset wiki-lingua-nl\n</code></pre>"},{"location":"datasets/english/","title":"\ud83c\uddec\ud83c\udde7 English","text":"<p>This is an overview of all the datasets used in the English part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/english/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/english/#sst-5","title":"SST-5","text":"<p>This dataset was published in this paper and is based on movie reviews from rottentomatoes.com, labelled by crowdsourced workers on Amazon Mechanical Turk.</p> <p>The original full dataset consists of 8,540 / 1,100 / 2,210 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.</p> <p>The original dataset consists of 5 labels instead of our usual 3, but we map them to <code>positive</code>, <code>neutral</code> and <code>negative</code> as follows:</p> <ul> <li><code>very negative</code> \u27a1\ufe0f <code>negative</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negative</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutral</code></li> <li><code>positive</code> \u27a1\ufe0f <code>positive</code></li> <li><code>very positive</code> \u27a1\ufe0f <code>positive</code></li> </ul> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"the leads are natural and lovely , the pace is serene , the humor wry and sprightly .\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"labute ca n't avoid a fatal mistake in the modern era : he 's changed the male academic from a lower-class brit to an american , a choice that upsets the novel 's exquisite balance and shreds the fabric of the film .\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"no cliche escapes the perfervid treatment of gang warfare called ces wild .\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>The following are texts and their sentiment, which can be 'positive', 'neutral' or 'negative'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nSentiment: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nClassify the sentiment in the text. Answer with 'positive', 'neutral' or 'negative'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positive</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutral</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negative</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset sst5\n</code></pre>"},{"location":"datasets/english/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/english/#conll-en","title":"CoNLL-en","text":"<p>This dataset was published in this paper and was part of the CoNNL-2003 shared task. The data comes from the Reuters Corpus and consists of news articles between August 1996 and August 1997, labelled with named entities.</p> <p>The original full dataset consists of 14,041 / 3,250 / 3,453 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  'tokens': array(['SK', 'Slavia', 'Praha', '3', '1', '2', '0', '6', '3', '5'], dtype=object),\n  'labels': array(['B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Guy', 'Whittingham', 'stole', 'three', 'points', 'for', 'the', 'Yorkshire', 'side', 'with', 'a', 'goal', '10', 'minutes', 'from', 'time', '.'], dtype=object),\n  'labels': array(['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Dean', 'Palmer', 'hit', 'his', '30th', 'homer', 'for', 'the', 'Rangers', '.'], dtype=object),\n  'labels': array(['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Below are sentences and JSON dictionaries with the named entities that occur in the given sentence.\n</code></pre></li> <li>Base prompt template:   <pre><code>Sentence: {text}\nNamed entities: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sentence: {text}\n\nIdentify the named entities in the sentence. You should output this as a JSON dictionary with the keys being 'person', 'location', 'organization' and 'miscellaneous'. The values should be lists of the named entities of that type, exactly as they appear in the sentence.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>location</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>location</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organization</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organization</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>miscellaneous</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>miscellaneous</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset conll-en\n</code></pre>"},{"location":"datasets/english/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/english/#scala-en","title":"ScaLA-En","text":"<p>This dataset was published in this paper and was automatically created from the English Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original full dataset consists of 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"And so we have to labour and to work, and to work hard, to give reality to our dreams.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"This couch is also quite big, it fits three people quite comfortably, and if I have or friends staying over, it opens up into a full double bed.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"While studies the psychology of art have focused on individual works and distinctions between representative / non-representative topics, no work has been completed on the aesthetic appreciation of collections or of devotional themes.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>The following are sentences and whether they are grammatically correct.\n</code></pre></li> <li>Base prompt template:   <pre><code>Sentence: {text}\nGrammatically correct: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sentence: {text}\n\nDetermine whether the sentence is grammatically correct or not. Reply with 'yes' if the sentence is correct and 'no' if it is not.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>yes</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>no</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-en\n</code></pre>"},{"location":"datasets/english/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/english/#squad","title":"SQuAD","text":"<p>This dataset was published in this paper, which is based on English Wikipedia articles and the questions and answers are written by crowdworkers.</p> <p>The original full dataset consists of 130,000 / 11,900 samples for training and validation, respectively. We use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). The new training split is a subset of the original training split, and the new validation and test splits are disjoint subsets of the original validation split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": 'The Federation of International Gymnastics (FIG) was founded in Liege in 1881. By the end of the nineteenth century, men\\'s gymnastics competition was popular enough to be included in the first \"modern\" Olympic Games in 1896. From then on until the early 1950s, both national and international competitions involved a changing variety of exercises gathered under the rubric, gymnastics, that would seem strange to today\\'s audiences and that included for example, synchronized team floor calisthenics, rope climbing, high jumping, running, and horizontal ladder. During the 1920s, women organized and participated in gymnastics events. The first women\\'s Olympic competition was primitive, only involving synchronized calisthenics and track and field. These games were held in 1928, in Amsterdam.',\n  \"question\": 'When was gymnastics included in the Olympics?',\n  \"answers\": {\n    \"answer_start\": array([219], dtype=int32),\n    \"text\": array(['1896'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"London's buildings are too diverse to be characterised by any particular architectural style, partly because of their varying ages. Many grand houses and public buildings, such as the National Gallery, are constructed from Portland stone. Some areas of the city, particularly those just west of the centre, are characterised by white stucco or whitewashed buildings. Few structures in central London pre-date the Great Fire of 1666, these being a few trace Roman remains, the Tower of London and a few scattered Tudor survivors in the City. Further out is, for example, the Tudor period Hampton Court Palace, England's oldest surviving Tudor palace, built by Cardinal Thomas Wolsey c.1515.\",\n  \"question\": \"The area west of London's city is characterized by what type of building?\",\n  \"answers\": {\n    \"answer_start\": array([328], dtype=int32),\n    \"text\": array(['white stucco or whitewashed'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Along with the rest of South West England, Plymouth has a temperate oceanic climate (K\u00f6ppen Cfb) which is generally wetter and milder than the rest of England. This means a wide range of exotic plants can be grown. The annual mean temperature is approximately 11 \u00b0C (52 \u00b0F). Due to the modifying effect of the sea the seasonal range is less than in most other parts of the UK. As a result of this summer highs are lower than its southerly latitude should warrant, but as a contrast the coldest month of February has mean minimum temperatures as mild as between 3 and 4 \u00b0C (37 and 39 \u00b0F). Snow is rare, not usually equating to more than a few flakes, but there have been exclusions, namely the European winter storms of 2009-10 which, in early January, covered Plymouth in at least 1 inch (2.5 cm) of snow; more on higher ground. Another period of notable snow occurred from 17\u201319 December 2010 when up to 8 inches (20 cm) of snow fell through the period \u2013 though only 2 inches (5.1 cm) would lie at any one time due to melt. Over the 1961\u20131990 period, annual snowfall accumulation averaged less than 7 cm (3 in) per year. July and August are the warmest months with mean daily maxima over 19 \u00b0C (66 \u00b0F).',\n  \"question\": 'What month in Plymouth has the lowest temperatures?',\n  \"answers\": {\n    \"answer_start\": array([503], dtype=int32),\n    \"text\": array(['February'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>The following are texts with accompanying questions and answers.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nQuestion: {question}\nAnswer in max 3 words:\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nAnswer the following question about the above text in at most 3 words.\n\nQuestion: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset squad\n</code></pre>"},{"location":"datasets/english/#unofficial-belebele-en","title":"Unofficial: BeleBele-en","text":"<p>This dataset was published in this paper and features reading comprehension questions across 122 languages. The dataset was created by professional translators who translated 900 multiple-choice questions from English into other languages, with answers carefully validated by native speakers.</p> <p>The original dataset consists of 900 samples, and we use 256 / 64 / 580 samples for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": 'Text: \"\"\"We will endeavour to cut carbon dioxide emissions per unit of GDP by a notable margin by 2020 from the 2005 level,\"\" Hu said. He did not set a figure for the cuts, saying they will be made based on China\\'s economic output. Hu encouraged developing countries \"\"to avoid the old path of polluting first and cleaning up later.\"\" He added that \"\"they should not, however, be asked to take on obligations that go beyond their development stage, responsibility and capabilities.\"\"\"\\nQuestion: What did Hu suggest that developing countries do?\\nChoices:\\na. Take on obligations that push their development stage\\nb. Focus on economic output\\nc. Go beyond their current responsibilities\\nd. Avoiding old paths of pollution',\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": 'Text: \"All of the cave entrances, which were named \"\"The Seven Sisters\"\", are at least 100 to 250 meters (328 to 820 feet) in diameter. Infrared images show that the temperature variations from night and day show that they are likely caves. \"\"They are cooler than the surrounding surface in the day and warmer at night. Their thermal behavior is not as steady as large caves on Earth that often maintain a fairly constant temperature, but it is consistent with these being deep holes in the ground,\"\" said Glen Cushing of the United States Geological Survey (USGS) Astrogeology Team and of Northern Arizona University located in Flagstaff, Arizona.\"\\nQuestion: What information suggests that The Seven Sisters are caves?\\nChoices:\\na. Temperature variations\\nb. The diameter of the cave entrances\\nc. Geological surveys\\nd. Pictures of caves on Earth',\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": 'Text: The proposed amendment already passed both houses in 2011. A change was made this legislative session when the second sentence was deleted first by the House of Representatives and then was passed in a similar form by the Senate Monday. The failure of the second sentence, which proposes to ban same-sex civil unions, could possibly open the door for civil unions in the future. Following the process, HJR-3 will be reviewed again by the next elected legislature in either 2015 or 2016 to remain in process.\\nQuestion: According to the passage, when was the second sentence deleted?\\nChoices:\\na. During the legislative session\\nb. In 2011\\nc. On Monday\\nd. In 2015',\n  \"label\": \"a\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>The following are texts with accompanying questions and answers.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nQuestion: {question}\nAnswer in max 3 words:\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nAnswer the following question about the above text in at most 3 words.\n\nQuestion: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-en\n</code></pre>"},{"location":"datasets/english/#unofficial-multiwikiqa-en","title":"Unofficial: MultiWikiQA-en","text":"<p>This dataset will be published in an upcoming paper, and contains English Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Stagecoach in Norfolk (formerly Norfolk Green) was a bus operator based in King's Lynn in Norfolk, England. It operated public bus services in the counties of Norfolk, Cambridgeshire and Lincolnshire as well as numerous school and college services. It was a subsidiary of Stagecoach.\\n\\nIn April 2018, Stagecoach ceased operations in Norfolk. Services were taken over by First Norfolk &amp; Suffolk, Lynx, Sanders Coaches, Stagecoach in Peterborough (the Interconnect 505) and West Norfolk Community Transport.\\n\\nHistory\\n\\nNorfolk Green was formed in 1996 with a fleet of four buses. In 1999 the Saham Toney depot was sold to Konectbus with four coaches.\\n\\nIn April 2011, Norfolk Green purchased the King's Lynn based services of First East England.\\n\\nOn 17 December 2013, Norfolk Green was sold to Stagecoach following the retirement of Ben Colson after ill health. Unusually, Stagecoach did not immediately apply its corporate brand, but retained the Norfolk Green trading name and livery, although the fleet received Stagecoach fleet numbers. All buses were rebranded between 2015 and late 2017.\\n\\nIn January 2018, Stagecoach announced it was reviewing its operations in Norfolk in response to the challenging economic environment, blaming a combination of rising operating costs and pressure on public sector budgets. The company said it met with trade union representatives to minimise the impact on staff and launched a consultation with employees over the potential closure of its King's Lynn depot. The company hoped to relocate the majority of its staff with other operators or elsewhere within the Stagecoach East area, which includes Bedford, Cambridge, Huntingdon and Peterborough.\\n\\nRoutes\\nRoutes operated by Stagecoach Norfolk included the very popular  Coasthopper services between King's Lynn and Cromer, the Interconnect 505 between King's Lynn and Spalding, a town service network in King's Lynn, a city service in Ely and many rural and interurban bus services across Norfolk, Cambridgeshire and Lincolnshire.\\n\\nFleet\\nAs at July 2013, the fleet consisted of 74 buses. Fleet livery is two tone green. Twelve Optare Solo Slimlines wear a dark blue, yellow and green livery for the Coasthopper group of services. A large proportion of buses are also named after local characters and personalities.\\n\\nUpon Stagecoach's purchase of Norfolk Green, in the summer of 2016 Stagecoach Norfolk went onto replace the fleet of Coasthopper Optare Solo's with Alexander Dennis Enviro200s. In addition, and later on, they purchased brand new Optare Solos. These new buses feature a new updated Coasthopper 'Flying Kite' livery, free Wi-Fi, USB charging points and leather seating.\\n\\nReferences\\n\\nExternal links\\n\\nCompany website\\n\\nStagecoach Group bus operators in England\\nTransport companies established in 1966\\nTransport companies disestablished in 2018\\n1996 establishments in England\\n2018 disestablishments in England\\nBritish companies established in 1996\\nBritish companies disestablished in 2018\\nFormer bus operators in Norfolk\\nFormer bus operators in Cambridgeshire\\nFormer bus operators in Lincolnshire\",\n    \"question\": \"What is the date of formation of Norfolk Green?\",\n    \"answers\": {\n        \"answer_start\": array([543]),\n        \"text\": array([\"1996\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Lara Stalder (born 15 May 1994) is a Swiss ice hockey forward and member of the Swiss national ice hockey team, currently playing with Bryn\u00e4s IF Dam of the Swedish Women's Hockey League (SDHL). She played with the Minnesota Duluth Bulldogs women's ice hockey team from 2013 to 2017, and with Link\u00f6ping HC from 2017 to 2019.\\n\\nPlaying career \\nAcross four seasons with Minnesota-Duluth, Stalder put up 148 points in 134 games, leading the team in points in her final season, as well as being named WCHA Player of the Year and Student-Athlete of the Year, and being a top-three finalist for the Patty Kazmaier Award. In 2016, she was drafted 20th overall by the Boston Pride of the National Women's Hockey League (NWHL).\\n\\nAfter missing most of the 2018\u201319 season due to a shoulder injury, Stalder left Link\u00f6ping to sign with Bryn\u00e4s. In 2020, she was named SDHL Player of the Year after putting up 71 points in 36 games, being the first woman to win Guldhj\u00e4lmen. The 42 goals she would score that year is the second highest single-season total in SDHL history, and her 71 points the third highest single-season total in SDHL history.\\n\\nInternational  \\nStalder made her senior national team debut at the 2011 IIHF Women's World Championship. She has represented Switzerland at the Winter Olympics in 2014 and won the bronze medal after defeating Sweden in the bronze medal playoff. She would score 6 points in 6 games at the 2018 Winter Olympics, as Switzerland finished in 5th place.\\n\\nCareer statistics\\n\\nAwards and honors\\n\\nNCAA\\nWCHA Offensive Player of the Week (Week of 17 January 2017)\\nWCHA Offensive Player of the Week (Week of 24 January 2017)\\nWCHA Offensive Player of the Week (Week of 31 January 2017)\\nWCHA Offensive Player of the Month, January 2017\\nWomen's Hockey Commissioners' Association National Division I Player of the Month, January 2017\\nPatty Kazmaier Award Top-3 Finalist, 2016\u201317 season\\n2016-17 AHCA-CCM Women's University Division I First-Team All-American\\n\\nSDHL \\n\\n Guldhj\u00e4lmen (Golden Helmet), MVP of the SDHL as selected by players, 2019\u201320 season\\n SDHL Forward of the Year, 2019\u201320 season\\n\\nReferences\\n\\nExternal links\\n\\nMinnesota Duluth bio\\n\\n1994 births\\nLiving people\\nSportspeople from Lucerne\\nSwiss women's ice hockey forwards\\nIce hockey players at the 2014 Winter Olympics\\nIce hockey players at the 2018 Winter Olympics\\nIce hockey players at the 2022 Winter Olympics\\nOlympic bronze medalists for Switzerland\\nOlympic ice hockey players for Switzerland\\nOlympic medalists in ice hockey\\nMedalists at the 2014 Winter Olympics\\nBryn\u00e4s IF (women) players\\nLink\u00f6ping HC (women) players\\nMinnesota Duluth Bulldogs women's ice hockey players\\nSwiss expatriate ice hockey people\\nSwiss expatriate sportspeople in Sweden\\nSwiss expatriate sportspeople in the United States\",\n    \"question\": \"Which SDHL award did Lara Stalder receive during the 2019-2020 season?\",\n    \"answers\": {\n        \"answer_start\": array([945]),\n        \"text\": array([\"Guldhj\u00e4lmen\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"TCG Barbaros (F 244) is the lead ship of  of the Turkish Navy.\\n\\nDevelopment and design \\n\\nBarbaros-class frigates were designed in Germany and are part of the MEKO group of modular warships, in this case the MEKO 200 design. Two ships were built in Germany and two in Turkey with German assistance. They are larger than the previous s and are also faster due to using CODOG machinery rather than pure diesels.\\n\\nThe first two vessels (F 244 and F 245) are defined as the Barbaros class (MEKO 200 TN Track II-A) while the last two vessels (F 246 and F 247) are defined as the Salih Reis class (MEKO 200 TN Track II-B) by the Turkish Navy.\\n\\nSalih Reis subclass ships are built with 8-cell Mk. 41 VLS and longer than Barbaros class vessels to accommodate 16-cell Mk. 41 VLS upgrade in the future while Barbaros-class vessels built with  Mk.29 Sea Sparrow launchers that planned to be replaced by 8-cell Mk. 41 VLS.\\n\\nConstruction and career \\nBarbaros was launched on 29 September 1993 by Blohm+Voss in Hamburg and commissioned on 23 May 1997.\\n\\nOn 9 March 2019, her crew saluted to the tomb of Barbaros Hayreddin while crossing Bosporus.\\n\\nOn 26 August 2020, TCG Barbaros and  sailed alongside  in Eastern Mediterranean Sea. Later that year on 3 October, she underwent alongside USS Roosevelt.\\n\\nReferences\\n\\nExternal links\\n\\n The First Upgraded MEKO 200 Frigate Of Turkish Navy\\n BARBAROS CLASS ( MEKO 200 Track II) (Turkey)\\n\\n1993 ships\\nShips built in Germany\\nFrigates of the Turkish Navy\\nBarbaros-class frigates of the Turkish Navy\",\n    \"question\": \"Could you tell me about the MEKO group?\",\n    \"answers\": {\n        \"answer_start\": array([172]),\n        \"text\": array([\"modular warships\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>The following are texts with accompanying questions and answers.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nQuestion: {question}\nAnswer in max 3 words:\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nAnswer the following question about the above text in at most 3 words.\n\nQuestion: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-en\n</code></pre>"},{"location":"datasets/english/#knowledge","title":"Knowledge","text":""},{"location":"datasets/english/#life-in-the-uk","title":"Life in the UK","text":"<p>This dataset was published here was scraped from lifeintheuktestweb.co.uk and contains multiple choice questions about UK history, culture, and citizenship requirements. The website was created to help people pass the Life in the UK Test for UK citizenship.</p> <p>The original dataset consists of 1,450 samples. After processing (removing questions with overly short or long texts, repetitive content, and true/false questions), we have 1,206 samples remaining. From these, we use 438 / 256 / 512 samples for our training, validation and test splits, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"What is the capital of the United Kingdom?\\nChoices:\\na. London\\nb. Manchester\\nc. Birmingham\\nd. Edinburgh\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"What TWO houses were confronted during the Wars of the Roses?\\nChoices:\\na. The House of Lancaster\\nb. The House of Leicester\\nc. The House of Canterbury\\nd. The House of York\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"What is the name of the War Memorial located in Whitehall?\\nChoices:\\na. Dumfries\\nb. Cenotaph\\nc. Royal Crescent\\nd. The White Tower\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>The following are multiple choice questions (with answers).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAnswer: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nAnswer the above question by replying with 'a', 'b', 'c' or 'd', and nothing else.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset life-in-the-uk\n</code></pre>"},{"location":"datasets/english/#unofficial-mmlu","title":"Unofficial: MMLU","text":"<p>This dataset was published in this paper and features questions within 57 different topics, such as elementary mathematics, US history and law.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Use the following key to translate the given formula of PL to natural, English sentences. A: Marina reads a Percy Jackson book. B: Izzy plays Minecraft. C: Emily stops working. D: Russell makes dinner. E: Ashleigh stops by. ~(A \u2283 B) \u2022 (B \u2283 ~E)\\nChoices:\\na. It's not the case that Marina's reading a Percy Jackson book entails that Izzy plays Minecraft, but Izzy's playing Minecraft does entail that Ashleigh doesn't stop by.\\nb. If Marina doesn't read a Percy Jackson book, then Izzy plays Minecraft, which entails that Ashleigh doesn't stop by.\\nc. Marina's reading a Percy Jackson book does not entail that Izzy plays Minecraft, but Izzy plays Minecraft provided that Ashleigh doesn't stop by.\\nd. It's not true that Marina reads a Percy Jackson book only when Izzy plays Minecraft, but Izzy plays Minecraft only when Ashleigh stops by.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"As of 2017, the share of GDP spent on the military by the United States is about\\nChoices:\\na. 1%\\nb. 3%\\nc. 6%\\nd. 10%\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Question 13. A buyer sent a signed letter to a seller that stated: \\\"Ship 100 boxes of nails at $3 per box, the price quoted in your circular.\\\" The seller mailed the buyer a signed form acknowledgment that agreed to the buyer's terms and stated on the reverse side: \\\"Disputes regarding quality shall be arbitrated.\\\" The buyer did not reply to the seller's acknowledgment, and the seller shipped the nails. When the buyer received the nails, it found their quality to be unsatisfactory and sued the seller for breach of warranty. The seller has asked an attorney whether the parties' contract requires arbitration of the buyer's claim. What is the best advice the attorney can provide?\\nChoices:\\na. A contract was formed pursuant to conduct when the buyer received the nails, and a court would exclude the arbitration provision from the contract.\\nb. A contract was formed when the seller mailed its acknowledgment, and the arbitration term became part of the contract. arbitration term became part of the contract.\\nc. A contract was formed when the seller mailed its acknowledgment, and the court must decide whether the arbitration term should be excluded as a material alteration of the contract.\\nd. No contract exists, because the arbitration term in the seller's acknowledgment created a counteroffer that the buyer never accepted.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>The following are multiple choice questions (with answers).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAnswer: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nAnswer the above question by replying with 'a', 'b', 'c' or 'd', and nothing else.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu\n</code></pre>"},{"location":"datasets/english/#unofficial-arc","title":"Unofficial: ARC","text":"<p>This dataset was published in this paper and features US grade-school science questions.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Several horses grazed in a fenced area across from a home. On rainy days, soil would wash down a slope and run toward the home. After the horses were moved a few years later, the soil no longer washed down when it rained. What could account for this change?\\nChoices:\\na. The grass grew and kept the soil intact.\\nb. The fence kept the soil contained.\\nc. The soil was completely gone.\\nd. The amount of rain decreased.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"How do moose use a learned behavior to protect themselves?\\nChoices:\\na. They have hollow hair to keep warm in the winter.\\nb. They roll in a pool of muddy water to avoid fly bites.\\nc. They have keen hearing to sense danger in the forest.\\nd. They use their wide hooves to prevent sinking in deep snow.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"A plant that grows red flowers was crossed with the same kind of plant that grows white flowers. Their offspring grew pink flowers. Which best explains why the offspring grew pink flowers?\\nChoices:\\na. The offspring experienced a genetic mutation.\\nb. The offspring resulted from asexual reproduction.\\nc. The genes for flower color exhibited incomplete dominance.\\nd. A gene for pink-colored flowers was recessive in one of the parents.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>The following are multiple choice questions (with answers).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAnswer: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nAnswer the above question by replying with 'a', 'b', 'c' or 'd', and nothing else.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset arc\n</code></pre>"},{"location":"datasets/english/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/english/#hellaswag","title":"HellaSwag","text":"<p>This dataset was published in this paper and is based on both video descriptions from ActivityNet as well as how-to articles from WikiHow.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[header] How to solo travel to chile [title] Decide how you will get to chile. [step] Start by figuring out how you will get to chile. If you live in north america, you may decide to fly into a major city in the country, such as santiago, and then take public transit to get around or fly within chile.\\nChoices:\\na. If you live in south america, it may be possible to take a bus or a train into chile, depending on your budget and your timeframe for the trip. [substeps] There is no special visa required for you to travel into chile and no fee to cross the border into chile.\\nb. If you live in australia, you will need to negotiate a road trip, such as a train or bus, to get around chile. [substeps] Plan out the route in advance of arrival so that you can do the same to chile in the future.\\nc. If you live in a rural area or you do not plan to travel for a long time, you may opt to take a bus. Using a bus or subway to get around chile is a good route to travel.\\nd. If you live in a smaller area, or if you live near a large tourist attraction, you may decide to fly in the opposite direction. [substeps] Skiing, mountain climbing, and bicycle riding are examples of solo travel.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"The video begins with a title sequence. a young man\\nChoices:\\na. prepares to black out.\\nb. is shown in a gym performing tricks with a jump rope as music plays in the background.\\nc. is seen talking continuously about slamming the mouth of a chimpanzee into the camera.\\nd. is standing outside with a basketball in his hand, alternating between shots of dribbling for the ball.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"A herb garden appears with a woman standing next to it in a large garden next to a wheelbarrow filled with mulch. the woman\\nChoices:\\na. moves the mulch across the ground in the wheelbarrow, falling backwards on attempts.\\nb. takes some of the mulch away and starts bagging it in the wheelbarrow.\\nc. begins to talk to the camera while gesturing to the flowerbed and the mulch, before eventually picking up a handful of the mulch.\\nd. then begins to mulch close to the wheelbarrow with mulching tool in her hand and while waving her arms in the air.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>The following are multiple choice questions (with answers).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAnswer: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nOptions:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nAnswer the above question by replying with 'a', 'b', 'c' or 'd', and nothing else.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag\n</code></pre>"},{"location":"datasets/english/#summarization","title":"Summarization","text":""},{"location":"datasets/english/#cnndailymail","title":"CNN/DailyMail","text":"<p>This dataset was published in this paper and is based on news articles from CNN and DailyMail, with the summaries derived from bullet points written by the authors of the articles.</p> <p>The original full dataset consists of 287,113 / 13,368 / 11,490 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Reality TV star and conservative firebrand Sarah Palin said today she's 'interested' in running for president in 2016 but stopped short of saying she'd actually seek higher office. 'Yeah, I mean, of course, when you have a servant\u2019s heart, when you know that there is opportunity to do all you can to put yourself forward in the name of offering service, anybody would be interested,' Palin told ABC News reporter Neal Karlinsky. Later stating, 'America has had enough of seeing that...sign on the Oval Office door saying, \\\"No Girls Allowed.\\\" ' 'It doesn't necessarily have to be me though,' she said. Scroll down for video . Conservative firebrand Sarah Palin said today she's 'interested' in running for president in 2016 but stopped short of saying she'd actually seek higher office . GIRL POWER: 'America has had enough of seeing that...sign on the Oval Office door saying, \\\"No Girls Allowed,\\\" ' Palin said . NOM NOM NOM: Palin made the comments while serving wild boar chili to the Salvation Army in Las Vegas, Nevada, on Friday. She was hosting an episode of Sportsman Channel program Hunt.Fish.Feed . ABC News caught up with Palin while she was serving wild boar chili to the homeless at a Las Vegas, Nevada, Salvation Army for an episode of Sportsman Channel program Hunt.Fish.Feed. She's also in the midst of promoting her hunting show, Amazing Alaska, about to begin its second season. Palin said the GOP needs to nominate a candidate 'who can take on Hillary' and 'show the nation what it is going to take to get the country back on the right track.' 'Because we can't afford status quo,' the former Alaska governor said in a clip of the interview released by ABC this afternoon. 'Status quo lately has been Latin for, \\\"We're getting screwed,' and status quo has got to go.' The Republican nominee out to be someone can 'turn things around, someone who will, in some respects, I don\u2019t know, maybe be considered a bit avant garde, to the establishment anyway, because this next person has got to realize this is war, this is war for our hunters\u2019 future,' she said at another point in the interview, according to ABC. Asked about former Florida Gov. Jeb Bush's candidacy and 2012 Republican presidential nominee Mitt Romney, Palin snarked, 'I can\u2019t wait for new energy.' Moments later asserting that the GOP primary 'had better be a competition and not a coronation.' Palin, the 2008 vice presidential nominee, said she doesn't 'have to be' the Republican candidate for president but she's 'happy to drive that competition, because competition will make everyone better and produce more and be more candid regarding their solutions they will offer this country. 'I am very interested in that competitive process and, again, not necessarily me.' Former Alaska Palin is pictured here on Thursday at an event to promote her television show, Amazing America with Sarah Palin, at the Shooting, Hunting and Outdoor Trade Show in Las Vegas . The hard-charging, Tea Party icon appears to have a change of heart in the last week about the Oval Office needing a female touch. 'I don't give a flying flip about what gender the person will be,' Palin told Inside Edition after host Deborah Norville asker her about the importance of electing a female president. 'I want the absolute best because America deserves the best, in terms of leadership, getting this country on the right track,' she continued. She ultimately concluded 'it would be nice' to have a woman president, though, 'and it will be nice to see women jump into the ring.' Voicing her support for female candidates in December, Palin told\u00a0Extra TV, 'I would love to see a woman on both sides of the aisle shooting for that top spot.'\",\n  \"target_text\": \"'When you know that there is opportunity to do all you can to put yourself forward in the name of offering service, anybody would be interested'\\nPalin added: 'It doesn't necessarily have to be me though'\\nThe conservative firebrand appears to have a change of heart about the Oval Office needing a female touch .\\nLast week she said: 'I don't give a flying flip about what gender the person will be'\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"By . Amanda Williams . The dictionary makers have taken to Twitter to find new words for the next edition of the lexicon - asking users to choose which words should make the final edition . The latest edition of the Collins English Dictionary could include Twitter slang words such as 'adorkable' and 'fatberg'. The dictionary makers have taken to Twitter to find new words for the next edition of the lexicon - asking users to choose which words should make the final edition. The list of suggested words includes fracktivist - someone who protests against fracking - and felfie, a term used to describe a farmer who takes a selfie, or photograph of themselves. The 12th edition of the dictionary will be the first to contain a word that has been voted for by Twitter users - who have until midnight on May 28 to vote for the new word. Once selected, it will be included in the next edition of the dictionary, which is released in October. The dictionary publisher says that the rise of social media and the hashtag has seen new words and ideas - that they scout for every year - become mainstream much quicker than in the past. Andrew Freeman, associate publisher at Collins, said: 'Twitter offers us an immediate snapshot of how much a word is used. 'The tried and tested approach to compiling dictionaries has to adapt to embrace the ways in which language is developing through use on social media, and this is a fun way to get Twitter users involved in defining the English language.' Collins has been publishing the dictionary since 1819 and is the largest single volume dictionary in print, with the words it contains sourced from the Collins Corpus, which contains more than 4.5 billion words, as well as the open source site collinsdictionary.com, where users can submit words for consideration. The latest edition of the Collins English Dictionary could include Twitter slang words such as 'adorkable' The word felfie, a term used to describe a farmer who takes a selfie, or photograph of themselves could also be included . Nomakeupselfie - a selfie of a woman without make-up, posted online to raise awareness for a charity - is also in the running to be used in the dictionary . Lucy Mangan, a blogger for collinsdictionary.com and a contributor to the Collins English Dictionary, said: 'Twitter is the perfect place to find out what people are really saying and how they\u2019re saying it. 'It\u2019s a space in which you\u2019re freer than almost anywhere else to combine old words, resurrect others or invent totally new ones whenever the need arises.' According to language experts, the list, which also contains the word adorkable, referring to someone who is dorky in an adorable way, is a sign of the way language is changing in the 21st century. Ian Brookes, lexicographer and consultant editor to the Collins English Dictionary, said: 'Language has always had to develop in response to changes in society and technology. In the 20th century the development of the motor car, air travel, television, and the personal computer changed the things that people did and so brought many new words into the language. 'In the 21st century, the growth of social media has had a comparable effect. Twitter users can vote for their choice by visiting twictionary.collinsdictionary.com . Adorkable - dorky in an adorable way . Fatberg - a large mass of solid waste, grease etc, clogging a sewage system . Felfie - a farmer selfie . Gaybourhood - a gay-friendly neighbourhood, e.g. Castro in San Francisco . Nomakeupselfie - a selfie of a woman without make-up, posted online to raise awareness for a charity . Vaguebooking - posting a deliberately vague status updates on social media to prompt a response . Duckface - the traditional pouting facial expression in selfies . Fracktivist - an activist who protests against fracking . Euromaiden - the original pro-Europe protests in Ukraine, named for Maidan Square in Kiev .\",\n  \"target_text\": \"Dictionary makers have taken to Twitter to find new words for next edition .\\nThe suggested words include fracktivist - an anti-fracking protester .\\nFelfie - a term used to describe a farmer who takes a selfie - also included .\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"There were three of them, one of them probably a child, and at least one met a gruesome end at the hands of a terrifying predator. About 67 million years later, a Wyoming rancher led scientists to their remains. Now experts are digging out one of the most complete skeletons yet of a Triceratops, the three-horned, plant-eating dinosaur that was one of the last of the giant reptiles. \\\"There's only three other skeletons that will match the completeness of one of the specimens we're excavating right now,\\\" said paleontologist Peter Larson, president of the Black Hills Institute of Geological Research. Most of the remains found before now have included fewer than half of the prehistoric creatures' bones, Larson said Monday. The most complete to date, now on display at the Houston Museum of Natural Science in Texas, has about 76% of its skeleton. \\\"The largest, more mature individual appears to be the most complete,\\\" Larson said. \\\"One is just a bit smaller, and there's another one that by live weight is probably only half the size.\\\" Will mammoths be brought back to life? Liquid blood fuels cloning hopes . The dig is going on near Newcastle, Wyoming, more than 200 miles north of Cheyenne. \\\"The fact that there are three of them together is really cool,\\\" Larson said. The trio could be male and female and their young, or they could be two females looking after a juvenile dinosaur, he said. And before now, there was no indication that the Triceratops moved in groups. The Black Hills Institute is working with the Naturalis Biodiversity Center, from the Netherlands, on the dig. Larson called the discovery of a young Triceratops a \\\"very significant\\\" find as well, since it will give scientists an insight into how the great lizards grew up. Newly discovered dinosaur fossil is a primitive bird . Triceratops lived in the twilight of the Cretaceous Period, about a half a million years before the dinosaurs' extinction. Much of what is now the Great Plains and southern Canada was once part of a vast inland sea, and the region is rich in fossils. \\\"Like most of the specimens that were found, it was brought to our attention by a rancher,\\\"  Larson said. The rancher sent photos to the Black Hills Institute, located in neighboring South Dakota, in late 2012. Excavation began in May and is expected to take about a month. So far, the bones that have turned up point to a violent end, probably at the hands of the feared Tyrannosaurus rex. On the largest of the three specimens, at least two of the major limb bones were \\\"bitten through,\\\" Larson said. \\\"If you can imagine, this is a bone that is nearly four feet long,\\\" he said. But a T.rex \\\"would kind of chop the carcass up with their giant, shearing jaws,\\\" ripping through flesh and bone alike. \\\"I think we also have a feeding site for Tyrannosaurus rex, which is very exciting,\\\" he said. \\\"This is potentially a site where we can learn the behavior of two different species.\\\" More science news on CNN's Light Years blog .\",\n  \"target_text\": \"A rancher led scientists to the remains of three Triceratops .\\nOne of the three may be the most complete skeleton yet found .\\nA young dinosaur is among the trio .\\nAt least one may have been killed by a Tyrannosaurus rex .\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>The following are articles with accompanying summaries.\n</code></pre></li> <li>Base prompt template:   <pre><code>News article: {text}\nSummary: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>News article: {text}\n\nWrite a summary of the above article.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset cnn-dailymail\n</code></pre>"},{"location":"datasets/estonian/","title":"\ud83c\uddea\ud83c\uddea Estonian","text":"<p>This is an overview of all the datasets used in the Estonian part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/estonian/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/estonian/#estonian-valence-corpus","title":"Estonian Valence Corpus","text":"<p>This dataset was published in this paper. The dataset was compiled of articles of different rubrics of online dailies, weeklies, and reader comments, while the polarity of each paragraph was determined by native Estonian readers.</p> <p>There are 4 labels in the original dataset instead of the usual 3. Examples with the labels representing 'mixed' emotion (vastuoluline) were filtered out mainly to be consistent with rest of the languages in EuroEval.</p> <p>The original full dataset consists of 3,277 / 818 samples for the training and test splits, respectively. Having filtered out 'mixed' examples, we truncate the train split to 1,024 examples, and redistribute the rest to validation and test resulting in the final size of 1,024 / 256 / 2,048 for the training, validation and test splits, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"S\u00fcgisest algav pikk koolitee Oskari perekonda ei hirmuta.\",\n  \"label\": \"positiivne\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Sellises eas, nagu teie olete, tundub muidugi ka 20-aastane \u00fcsna laps ...\",\n  \"label\": \"neutraalne\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"ka ainus m\u00e4rkimisv\u00e4\u00e4rne saavutus temalt selle loo esituse juures.\",\n  \"label\": \"negatiivne\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>J\u00e4rgmised on dokumendid ja nende meelestatus, mis v\u00f5ib olla 'positiivne', 'neutraalne' v\u00f5i 'negatiivne'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Dokument: {text}\nMeelestatus: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Dokument: {text}\n\nKlassifitseeri dokument meelestatuse j\u00e4rgi. V\u00f5imalikud vastused: 'positiivne', 'neutraalne' v\u00f5i 'negatiivne'. Muud vastused ei ole lubatud.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positiivne</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutraalne</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negatiivne</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset estonian-valence\n</code></pre>"},{"location":"datasets/estonian/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/estonian/#estner","title":"EstNER","text":"<p>This dataset was published in this paper. The dataset is a manually annotated collection of Estonian news and social media texts.</p> <p>The original dataset contains 16,966 / 3,297 / 2,797 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": [\"Katse\", \"l\u00f5puni\", \"j\u00e4tkas\", \"34aastane\", \"tiitlijahtija\", \"kolmel\", \"rattal\", \".\"],\n  \"labels\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]\n}\n</code></pre> <pre><code>{\n  \"tokens\": [\"\u201c\", \"Kui\", \"tegemist\", \"oleks\", \"olnud\", \"piletiga\", \"peoga\", \",\", \"peaksime\", \"inimestele\", \"raha\", \"tagasi\", \"maksma\", \",\", \"n\u00fc\u00fcd\", \"saame\", \"\u00fcksnes\", \"k\u00fclalistelt\", \"vabandust\", \"paluda\", \",\u201d\u00fctles\", \"J\u00e4rvamaa\", \"omavalitsuste\", \"liidu\", \"tegevdirektor\", \"Krista\", \"Nurm\", \"ajalehele\", \"J\u00e4rvamaa\", \"Teataja\", \".\"],\n  \"labels\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"I-ORG\", \"B-MISC\", \"B-PER\", \"I-PER\", \"O\", \"B-MISC\", \"I-MISC\", \"O\"]\n}\n</code></pre> <pre><code>{\n  \"tokens\": [\"Makke\", \"l\u00f5petas\", \"Quincy\", \"keskkooli\", \"Illinoisi\", \"osariigis\", \"ja\", \"plaanib\", \"sportlasstipendiumi\", \"abil\", \"edasi\", \"\u00f5ppida\", \"L\u00e4\u00e4ne-Illinoisi\", \"\u00fclikoolis\", \",\", \"mille\", \"korvpallimeeskond\", \"kuulub\", \"USA\", \"\u00fcli\u00f5pilasliiga\", \"NCAA\", \"esimesse\", \"divisjoni\", \".\"],\n  \"labels\": [\"B-PER\", \"O\", \"B-ORG\", \"I-ORG\", \"B-MISC\", \"I-MISC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"B-ORG\", \"O\", \"O\", \"O\"]\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Allpool on laused ja JSON-s\u00f5nastikud, mis sisaldavad antud lauses esinevaid nimetatud \u00fcksuseid.\n</code></pre></li> <li>Base prompt template:   <pre><code>Lause: {text}\nNimetatud \u00fcksused: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Lause: {text}\n\nTuvasta lauses nimetatud \u00fcksused. V\u00e4ljund peaks olema JSON-s\u00f5nastik, mille v\u00f5tmed on 'inimene', 'asukoht', 'organisatsioon' ja 'muu'.\nV\u00e4\u00e4rtused peaksid olema kindlat t\u00fc\u00fcpi nimetatud \u00fcksuste loendid, t\u00e4pselt nii nagu need lauses esinevad.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>inimene</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>inimene</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>asukoht</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>asukoht</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisatsioon</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisatsioon</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>muu</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>muu</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset estner\n</code></pre>"},{"location":"datasets/estonian/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/estonian/#grammar-et","title":"Grammar-et","text":"<p>The dataset is a reorganized and simplified version of the TartuNLP EstGEC dataset dataset. The dataset includes the original sentences and their corrected versions.</p> <p>The original full dataset consists of 7,937 / 1,000 samples for training and testing, respectively. The original dataset consists of 8,937 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively. The test split is extended with additional examples from the train split. The validation split is also created using examples from the train split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Meie kahe rahva peaks l\u00f5petama tobedused teineteise vastu ja m\u00f5ista et tuleme siin naabrideks olema igavesti.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Esiteks valid sa raamatu ise, kui sul on seda vaja, n\u00e4iteks \u00f5ppekirjanduse puhul, v\u00f5i tuleb see mingil teisel p\u00f5hjusel l\u00e4bi lugeda, n\u00e4iteks s\u00f5bra n\u00f5uandel.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ma olen kindel et mitte amet rikkub inimest, aga raha.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>J\u00e4rgnevad on laused ja kas need on grammatiliselt \u00f5iged.\n</code></pre></li> <li>Base prompt template:   <pre><code>Lause: {text}\nGrammatikaliselt \u00f5ige:: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Lause: {text}\n\nOtsusta, kas lause on grammatiliselt \u00f5ige v\u00f5i mitte. Vasta {labels_str}, ja mitte midagi muud.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset grammar-et\n</code></pre>"},{"location":"datasets/estonian/#unofficial-scala-da","title":"Unofficial: ScaLA-da","text":"<p>This dataset was published in this paper and was automatically created from the Estonian Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 19,298 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Selleks kirjeldatakse programmi k\u00e4itumust spetsiaalse juhtvoograafi ehk CFG abil (CFG - Control Flow Graph).\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Karuks \u00fctleb, et oma natuuri t\u00f5ttu huvitub ta ka v\u00e4ga paljudest muudest asjadest: sise- ja v\u00e4lispoliitikast, ajaloost, erinevatest \u00fchiskonnaprobleemidest.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Juta teab oma kogemusest, et selline s\u00f6\u00f6k tahab pikka ja tunneb kohe \u00e4ra, et varem valmis tehtud asi on mikrolaineahjus \u00fcles soojendatud.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>J\u00e4rgnevad on laused ja kas need on grammatiliselt \u00f5iged.\n</code></pre></li> <li>Base prompt template:   <pre><code>Lause: {text}\nGrammatikaliselt \u00f5ige: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>S\u00e6tning: {text}\n\nBestem om s\u00e6tningen er grammatisk korrekt eller ej. Svar med 'ja', hvis s\u00e6tningen er korrekt, og 'nej', hvis den ikke er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>jah</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>ei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-et\n</code></pre>"},{"location":"datasets/estonian/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/estonian/#multiwikiqa-et","title":"MultiWikiQA-et","text":"<p>This dataset will be published in an upcoming paper, and contains Estonian Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"K\u00f5rg\u00f5zstani 2010. aasta \u00fclest\u00f5us, m\u00e4ss,  revolutsioon v\u00f5i riigip\u00f6\u00f6re oli s\u00fcndmusteahel, mis kukutas president Kurmanbek Bakijevi ja t\u00f5i v\u00f5imule ajutise valitsuse Roza Otunbajevaga eesotsas.\\n\\nRahutused algasid 6. aprillil Talasis ja levisid j\u00e4rgmisel p\u00e4eval teistesse K\u00f5rg\u00f5zstani p\u00f5hjaosa linnadesse. Rahutustes hukkus v\u00e4hemalt 85 inimest, t\u00e4iendavaid ohvreid t\u00f5id kaasa j\u00e4rgnenud korratused.\\n\\nRahutuste p\u00f5hjused \\n\\nV\u00f5imuvahetuse j\u00e4rel kokku tulnud \"s\u00f5ltumatu \u00fchiskondlik komisjon\" 6. kuni 8. aprilli s\u00fcndmuste uurimiseks, leidis, et rahutused p\u00f5hjustas Bakijevi korruptsioonis, onupojapoliitikas ja riigi vara k\u00f5rvaletoimetamises s\u00fc\u00fcdistatud valitsuse \"laostav poliitika\", sotsiaalse kindlustunde v\u00e4henemine, laiade \u00fchiskonnakihtide vaesumine (\u001b[48;56;245;2016;3430tostuj\u00f5u v\u00e4henemine ja kiire inflatsioon), opositsiooni ja ajakirjanike laiaulatuslik tagakiusamine, poliitiliste m\u00f5rvade seeria ning s\u00f5ltumatute tr\u00fckiv\u00e4ljaannete, raadio- ja telekanalite sulgemine.\\n\\nRahutuste vahetuks k\u00e4ivitajaks on peetud hinnat\u00f5usu. Elektri- ja k\u00fcttehinnad olid kahekordistunud, t\u00f5usnud olid n\u00e4iteks mobiilteenuste hinnad.\\n\\nTalasi s\u00fcndmused \\n\\n6. aprilli hommikul vahistati Talasis partei Ata-Meken aseesimees Bolotbek \u0160ernijazov. L\u00f5unaks kogunes sadu vahistatu poolehoidjaid miilitsajaoskonna juurde ja \u0160ernijazov vabastati. Meeleavaldajad liikusid oblastivalitsuse hoone juurde ja v\u00f5tsid pantvangi oblastijuhi. Hangiti kive ja bensiini, valmistati ette pudeleid s\u00fc\u00fcteseguga.\\n\\n\u00d5htul saabusid Bi\u0161kekist lennukid ja helikopterid 200 korrakaitsej\u00f5udude teenistujaga, kes pidid asepeaminister Ak\u00f5lbek D\u017eaparovi juhtimisel l\u00e4bi viima erioperatsiooni oblastijuhi vabastamiseks. Meeleavaldajate vastu kasutati pisargaasi, kummikuule ja valgusm\u00fcra granaate(?). Oblastijuht vabastati ja Bolotbek \u0160ernijazov v\u00f5eti j\u00f5udu kasutades uuesti vahi alla.\\n\\nRahvahulk piiras sisse grupi miilitsat\u00f6\u00f6tajaid, asus neid peksma ja s\u00fc\u00fctas oblastivalitsuse hoone, kuhu umbes 150 miilitsat varjunud olid. Miilitsail l\u00f5ppes erivarustus, t\u00e4iendusi toonud s\u00f5iduki h\u00f5ivasid m\u00e4ssajad ja kasutasid valdusse v\u00f5etud vahendeid miilitsa vastu.\\n\\n\u00d6\u00f6l vastu 7. aprilli vahistati Bi\u0161kekis ja O\u0161is mitu opositsioonijuhti, sealhulgas \u00d6m\u00fcrbek Tekebajev, Almazbek Atambajev ja Temir Sarijev.\\n\\nTuhanded inimesed kogunesid piirama presidendi- ja valitsushoonet Bi\u0161kekis. Julgeolekuj\u00f5ud kasutasid rahva laialiajamiseks tulirelvi. Bakijev lahkus pealinnast D\u017ealal-Abadi. Roza Otunbajeva, Tekebajev, Atambajev ja teised tuntud opositsion\u00e4\u00e4rid kuulutasid endid ajutiseks valitsuseks. Bakijev varjas end kuni 15. aprillini ja lahkus seej\u00e4rel Valgevenesse.\\n\\nViited\\n\\nK\u00f5rg\u00f5zstani poliitika\\n2010\\nRevolutsioonid\",\n    \"question\": \"Kes eemaldati v\u00f5imult K\u00f5rg\u00f5zstani 2010. aasta rahutuste ajal?\",\n    \"answers\": {\n        \"answer_start\": array([100]),\n        \"text\": array([\"president Kurmanbek Bakijev\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Lepna haruraamatukogu on raamatukogu, mis tegutseb L\u00e4\u00e4ne-Viru maakonnas Rakvere vallas Lepna k\u00fclas. See on S\u00f5meru raamatukogu struktuuri\u00fcksus.\\n\\nAjalugu \\n\\nRaamatukogu t\u00e4pne ja ametlik asutamise aeg pole kindlalt teada. Raamatukogus leiduvas kroonika kirjutaja arvates ulatub see 1892. aastasse, kuid dokumentaalset kinnitust sellele ei ole leitud. Kirjas on, et raamatukogu asutati T\u00f5rma valla kooli juurde. K\u00fcll aga saab ajalehest Virulane (10. mai 1928) lugeda, et Rakvere valla avalik raamatukogu asutati 1925. aasta l\u00f5pul \"Avalikkude raamatukogu seaduse\" alusel ja alustas tegevust 1. jaanuaril 1926.\\n\\nRaamatukogu alusp\u00f5hi t\u00f6\u00f6tati v\u00e4lja Rakvere vallas t\u00f6\u00f6tavate seltside poolt, kes oma raamatukogud t\u00e4ies ulatuses avalikule raamatukogule \u00fcle andsid. Raamatukogu tegevust toetasid rahaliselt nii Rakvere vald kui Haridusministeerium.\\n\\nRakvere valla avaliku raamatukogu all t\u00f6\u00f6tasid erinevad osakonnad (7. osakond),\\xa0mille juhatajateks olid nii koolide juhatajad ja teised haridustegelased. Edukamaks osakonnaks aga peeti M\u00e4dapea osakonda, mida juhatas M\u00e4dapea Algkooli juhataja Jakob Awik. Raamatukogu asus M\u00e4dapea m\u00f5isas, M\u00e4dapea Algkooliga \u00fche katuse all. 1934. aastal laenutas raamatuid v\u00e4lja toonane kooli\u00f5petaja Helene Tammik.\\n\\n1965\u20131991 oli M\u00e4dapea m\u00f5is Energia kolhoosi hallata.\\n\\n1991 avati Lepna alevikus paiknev Lepna teeninduspunkt kortermaja neljatoalises korteris kolmandal korrusel. Raamatukogu kogu oli jaotunud kahte hoonesse: M\u00e4dapea m\u00f5isa ja Lepna kortermajja.\\n\\n1995 kolis raamatukogu M\u00e4dapealt Lepna alevikku kortermaja kahte korterisse, mis asusid maja kolmandal korrusel.\\n\\n26. juunist 1996 nimetatakse M\u00e4dapea raamatukogu Lepna raamatukoguks.\\n\\nAlates 12. septembrist 2018 kuulub raamatukogu haruraamatukoguna S\u00f5meru raamatukogustruktuuri.\\n\\nRaamatukogul on kaks teeninduspunkti: Veltsi Lasteaed-Algkoolis ja Lasila P\u00f5hikoolis.\\n\\nT\u00f6\u00f6tajad \\nM\u00e4dapea raamatukogu t\u00f6\u00f6tajad alates 1927. aastast vastavalt Lepna raamatukogu \u00fcleandmise ja vastuv\u00f5tmise aktidele:\\n Jakob Awik 1927\\n Helene Tammik 1934\\n Ellen Kuusik 01.11.1945\u201320.02.1954\\n Salme Partei 20.02.1949\u201325.11.1954\\n Vilma Niitla (Laar) 25.11.1954\u201325.05.1955\\n Evi Suurv\u00e4li 25.05.1955\u201306.08.1956\\n Elvi Sats 06.08.1956\u201330.05.1957\\n Maie Tiigi 30.05.1957\u201305.04.1959\\n Vaike Salamets 05.04.1959\u201315.09.1961\\n Elfride Salum\u00e4e 15.09.1961\u201328.03.1963\\n Linda R\u00fcnk 28.03.1963\u201307.03.1964\\n Evi Lahi 07.03.1964\u201301.08.1964\\n Liia Pall 1964\u20131947\\n Ille Laarman 1975\u20131977\\n Anne Pilipenko1978\u201320.09.2009 (M\u00e4dapea Raamatukogu / Lepna Raamatukogu)\\n Jaana Ant 01.09.2009\u201301.07.2016\\n Olga Samra (raamatukogu direktori kohuset\u00e4itja) 01.09.2016-m\u00e4rts 2017\\n Silja Raudsepp m\u00e4rts 2017\u2013 august 2018\\n Jaana Ant 22.10.2018 \u2013\\n\\nKirjandus \\n Virulane, 10. mai 1928. lk 4\\n\\nViited\\n\\nV\u00e4lislingid \\n Rakvere valla koduleht, rakvere valla raamatukogud\\n Lepna raamatukogu koduleht\\n Lepna raamatukogu Facebookis\\n\\nL\u00e4\u00e4ne-Viru maakonna raamatukogud\\nRakvere vald\",\n    \"question\": \"Kes valitses M\u00e4dapea m\u00f5isat ajavahemikul 1965\u20131991?\",\n    \"answers\": {\n        \"answer_start\": array([1261]),\n        \"text\": array([\"Energia kolhoosi\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Kannuka pank ehk Kannuka klindineemik on P\u00f5hja-Eesti panga osa Ida-Viru maakonnas Narva-J\u00f5esuu linnas ja Sillam\u00e4e linnas. Kannuka pank algab peale S\u00f5tke klindilahest ja kulgeb kuni Pimestiku panga moodustavate klindisaarteni.\\n\\nKannuka klindineemik on l\u00e4\u00e4nepoolsem 2,5 km pikkune ja 1,5 km laiune osa Vaivara Sinim\u00e4gedega sarnase, Sillam\u00e4e rikkev\u00f6\u00f6ndi, tektooniliselt rikutud keerulise ehitusega klindiv\u00f6\u00f6ndist. Panga paeplatoo k\u00f5rgub 28...30 meetrit \u00fcle merepinna. Paeplatool avanevad \u00f5hukese moreenikihi all Kesk-Ordoviitsiumi Volhovi lademe Toila kihistu glaukoniiti sisaldavad lubjakivid.\\n\\nKlindiserv on kaetud rusukalletega ning paljandid peaaegu puuduvad v\u00e4lja arvatud Sillam\u00e4e linnas m\u00f5ned \u00fcksikud l\u00f5igud. Kannuka pank on n\u00fc\u00fcdisajal kasvanud suures osas Sillam\u00e4e linna sisse, kuid kohati on s\u00e4ilinud v\u00e4ikeste l\u00f5ikudena ka pangale omast klindimetsa.\\n\\nVaata ka\\nEesti pankade loend\\nMerik\u00fcla pank\\nPargim\u00e4e pank\\nPimestiku pank\\nP\u00f5rguaugum\u00e4e pank\\nTornim\u00e4e pank\\nUtria k\u00f5rgekallas\\nUdria maastikukaitseala\\nUtria savikallas\\nVaivara klindil\u00f5ik\\nPuhkovo-Olgina klindiplatoo (Puhkovo-Vodava-Olgina klindiplatoo)\\nLaagna klindisaarestik\\n\\nKirjandus\\nKalle Suuroja. P\u00f5hja-Eesti pangad, Tallinn 2004.\\n\\nIda-Viru maakonna paljandid\\nNarva-J\u00f5esuu linn\",\n    \"question\": \"Mis klindiv\u00f6\u00f6ndis asub Kannuka pank?\",\n    \"answers\": {\n        \"answer_start\": array([330]),\n        \"text\": array([\"Sillam\u00e4e rikkev\u00f6\u00f6ndi\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>J\u00e4rgnevad on tekstid koos k\u00fcsimuste ja vastustega.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nK\u00fcsimus: {question}\nVasta maksimaalselt 3 s\u00f5naga: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nVasta j\u00e4rgmisele k\u00fcsimusele \u00fclevaltoodud teksti kohta maksimaalselt 3 s\u00f5naga.\n\nK\u00fcsimus: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-et\n</code></pre>"},{"location":"datasets/estonian/#knowledge","title":"Knowledge","text":""},{"location":"datasets/estonian/#exam-et","title":"Exam-et","text":"<p>This dataset was released in this repository and contains questions with multiple-choice answers from Estonian high-school tests.</p> <p>The original full dataset contains 1,614 samples in a single split, across eight different subjects. We use a 512 / 64 / 896 split for training, validation and testing, respectively, with stratification based on the subject.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Kas v\u00e4ide iseloomustab Eestit perioodil 1920-1934 v\u00f5i 1934-1940: riigikogu valiti iga kolme aasta j\u00e4rel?\\nVastusevariandid:\\na. Eesti 1920-1934\\nb. Eesti 1934-1940\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Kas v\u00e4ide on t\u00f5ene v\u00f5i v\u00e4\u00e4r? Veendumuste p\u00e4rast v\u00f5ib isikult Eesti kodakondsuse \u00e4ra v\u00f5tta.\\nVastusevariandid:\\na. t\u00f5ene\\nb. v\u00e4\u00e4r\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Kellel on Eesti vabariigis \u00f5igus kehtestada eriolukord?\\nVastusevariandid:\\na. politseil\\nb. \u00f5iguskantsleril\\nc. vabariigi valitsusel\\nd. riigikohtul\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>J\u00e4rgnevad on vastusevariantidega k\u00fcsimused (koos vastustega).\n</code></pre></li> <li>Base prompt template:   <pre><code>K\u00fcsimus: {text}\nVastusevariandid:\na. {option_a}\nb. {option_b}\nVastus: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>K\u00fcsimus: {text}\nVastusevariandid:\na. {option_a}\nb. {option_b}\n(...)\no. {option_o}\n\nVasta \u00fclaltoodud k\u00fcsimusele ainult 'a', 'b', (...), 'n' v\u00f5i 'o', ja mitte millegi\nmuuga.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset exam-et\n</code></pre>"},{"location":"datasets/estonian/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/estonian/#winogrande-et","title":"WinoGrande-ET","text":"<p>The dataset includes the WinoGrande test set translated and culturally adapted by hand by a professional translator (citation TBA). The structure of the dataset is identical to the original. Since train and dev splits were not translated manually, we employ the GPT-4o model to translate the expected number of examples starting from the beginning of the respective splits. The final dataset size is 1,024 / 256 / 1,767 for the training, validation and test splits, respectively.</p> <p>Here are a few examples from the training split (note that unlike the test split these are machine translated):</p> <p><pre><code>{\n  \"text\": \"Ian vabatahtlikult s\u00f5i Dennise menudo p\u00e4rast seda, kui oli juba kausi s\u00f6\u00f6nud, sest _ p\u00f5lgas soolte s\u00f6\u00f6mist.\\nVastusevariandid:\\na. Ian\\nb. Dennis\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ian vabatahtlikult s\u00f5i Dennise menudo p\u00e4rast seda, kui oli juba kausit\u00e4ie s\u00f6\u00f6nud, sest _ nautis soolte s\u00f6\u00f6mist.\\nVastusevariandid:\\na. Ian\\nb. Dennis\", \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ta ei tule kunagi minu koju, aga mina l\u00e4hen alati tema majja, sest _ on v\u00e4iksem.\\nVastusevariandid:\\na. kodu\\nb. maja\",\n  \"label\": \"a\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Sulle esitatakse l\u00fcngaga (_) tekst\u00fclesanne ja kaks vastusevarianti (a ja b).\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst\u00fclesanne: {text}\nVastusevariandid:\na. {option_a}\nb. {option_b}\nVastus: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst\u00fclesanne: {text}\nVastusevariandid:\na. {option_a}\nb. {option_b}\n\nSinu \u00fclesanne on valida l\u00fcnka sobiv vastusevariant. Vasta ainult 'a' v\u00f5i 'b'. Muud vastused ei ole lubatud.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset winogrande-et\n</code></pre>"},{"location":"datasets/estonian/#summarization","title":"Summarization","text":""},{"location":"datasets/estonian/#errnews","title":"ERRNews","text":"<p>The dataset was released in this paper.</p> <p>The dataset consists of news story transcripts of ERR News broadcasts scraped from from the ERR Archive News generated by an ASR pipeline paired with the human written summary from the archive.</p> <p>The original full dataset consists of 10,420 / 523 / 523 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively. The test split is extended with additional examples from the train split.</p> <p><pre><code>{\n  \"text\": \"Ta mainis seda, et et ta on mures, et Kreml on oma propagandakampaaniat ka Eesti suhtes tugevdanud. Aga ma ise \u00fctlesin talle, et kui ta peab silmas seda postitust, siis tegemist on Jaak Madissoni kolme aasta taguse taguse m\u00f5tteavaldusega, nagu ta oli 20 aastane ja ei olnud veel meie erakonna liige ja, ja Jaak Madison ei ole tegelikult selle teemaga hiljem minu teada tegelenud. Jaak Madisson teemal olen r\u00e4\u00e4kinud, palusin tal selle postituse k\u00f5rvaldada ja \u00fctles ka, et nojah, et aga seal ei ole ju midagi, ma lihtsalt arutlesin sel teemal ja seal ei ole midagi, seal ei ole midagi p\u00fc\u00fcda siia k\u00fclge panna mingisugust silti, nagu me oleksime mingisugune Hitler, juugend. No andke andeks ja, ja mina \u00fctlen teile, kui te seda teemat tahate \u00fcleval hoida, laske k\u00e4ia, me ei saa teid takistada, aga te teete Kremli t\u00f6\u00f6d, tehke oma j\u00e4reldused, te teete Kremli t\u00f6\u00f6d, see on just see, mida Krem tahab. Et kuskilt otsitakse \u00fcles mingi vana postitus, kuskil puhutakse sellele tuul, purjedesse s\u00fc\u00fcdistatakse v\u00e4rskelt riigikogu liikmeks saanud noort meest kolme aasta taguses naiivses poisikese s\u00f5nav\u00f5tus. Ma ei saa teid takistada selles, aga ma \u00fctlen teile, et see ei ole \u00f5ige, mida te, Jaak Madisson, sel ajal ei olnud erakonna liige, kolm aastat tagasi, kui te otsite v\u00e4lja kolme aasta taguse postituse, millest mul ei olnud kuni t\u00e4nase p\u00e4evani \u00f5rna aimugi siis ei saa see olla erakonna seisukoht. Tegemist on Jaak Madissoni kolme aasta taguse taguse m\u00f5tteavaldusega kui ta oli 20 aastane. Ja ei olnud veel meie erakonna liige.\",\n  \"target_text\": \"Eesti Konservatiivse Rahvaerakonna esimehe Mart Helme s\u00f5nul on riigikokku valitud erakonnakaaslase Jaak Madisoni sotsiaalmeedias levinud natsi-Saksamaad kiitev blogitekst \u00fcksikisiku arvamus ning lihtsalt hinnang Saksamaale ja tolle majandusele.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Eelk\u00f5ige uute toodete ja teenuste disainimisel me p\u00fc\u00fcame l\u00e4htuda v\u00f5i soovitav oleks disaineritel l\u00e4htuda eelk\u00f5ige vajadusest ja mitte ainult l\u00f5bu p\u00e4rast maailma kuhja ta v\u00f5ib-olla mittevajalike asjadega. Te annate v\u00e4lja ka need tootedisaini auhinnad nimega Bruno, kas \u00fctleme siis auhinnatakse ka rohkem neid inimesi, kes siin rohkem sellist vajadusp\u00f5hist disaini hindavad? Disaini auhind, t\u00e4nase pruun antakse v\u00e4lja iga kahe aasta tagant ja, ja tegelikult t\u00f5en\u00e4oliselt on enamus tooteid hakatud juba disainima kaks aastat tagasi tootearendusprotsess on p\u00e4ris pikk, aga kuna meil on rahvusvahelisel \u017e\u00fcriil ette kirjutatud kriteeriumid, mille j\u00e4rgi nad hindavad, siis ma v\u00f5in \u00f6elda, et seal edetabeli l\u00f5pus alles on esteetika ga esimesed mitu mitu kategooriat on p\u00fchendatud eelk\u00f5ige just ka kasutaja mugavusele kasutaja vajadusele keskkonnas\u00f5bralikkusele materjalide taaskasutusele, nii et, et h\u00e4sti palju kategooriaid on tulnud nagu tavap\u00e4rase disaini hindamisele juurde. Kui vanasti hinnati v\u00f5ibolla ainult vormi ja emotsiooni ja ilu, siis n\u00fc\u00fcd on disainerite ees palju suuremad n\u00f5udmised. See festival kestab p\u00e4ris mitu p\u00e4eva, et oskate te kohe anda m\u00f5ne soovituse ka, et mida inimesed saaksid vaatama-kuulama tulla. Jah, no arvestades praeguseid niisuguseid olusid, et v\u00e4ga palju inimesi ei kuhjuks \u00fchel ajal, siis me oleme praegu \u00f5nnega koos, et meie \u00fcritus k\u00f5igepealt toimub P\u00f5jala tehases, kus mahub isegi siis, kui inimesed peaksid seisma kaks pluss kaks, mida nad ilmselt peaksidki tegema, mahub 500 inimest ja kuna n\u00e4itused on lahti kella 12. kaheksani iga p\u00e4ev, siis v\u00f5ib hajutatult k\u00e4ia neid vaatamas terve n\u00e4dala jooksul. Aga kes tahab nagu pidulikumalt osaleda n\u00e4ituste \u00fcldisel avamisel, kus saab n\u00e4ha ka, et ausi, kas teksadega p\u00e4\u00e4seb paradiisi, on n\u00e4ituse nimi, aga ma etenduse nimi on Totali outo fassion. Et siis v\u00f5ib tulla esmasp\u00e4eval juba kella viieks kohale ja kuni peaaegu kella kaheksani toimuvad siis k\u00f5ikide n\u00e4ituste avamised ja, ja siis ka see maaetendus, mida ma nimetasin\",\n  \"target_text\": \"T\u00e4na algab Eesti Disaini\u00f6\u00f6 festival, mis sel aastal toimub juba 15. korda.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Mihhail Korbilt saadikupuutumatuse \u00e4rav\u00f5tmine oli vajalik selleks, et tema suhtes saaks j\u00e4tkata kriminaalmenetlust. Riigiprokuratuur esitas \u00f5iguskantslerile sellekohase taotluse kuu aega tagasi. Peaprokur\u00f6ri taotlusest n\u00e4htub, et riigikogu liikmele Mihhail Korbile on esitatud kahtlustus karistusseadustiku paragrahv 298 prim l\u00f5ikes \u00fcks s\u00e4testatud kuriteo toimepanemises. See on m\u00f5juv\u00f5imuga kauplemine. L\u00fchidalt v\u00e4idab peaprokur\u00f6r, et Mihhail Korb lubas Hillar Tederile \u00fcheksandal veebruaril 2020 kasutada oma m\u00f5juv\u00f5imu Tallinna linnapea Mihhail K\u00f5lvarti \u00fcle. Selleks, et kolmas isik, porto Franco osa\u00fching, saaks ametiisikult Mihhail K\u00f5lvartilt avaliku huvi seisukohalt p\u00f5hjendamatu eelise. See siis puudutas servituudi hinda. Ja k\u00fcsimus sellest, et kas porto Franco peaks v\u00e4ljas\u00f5idud rajama enda maale v\u00f5i peaks saama rajada need linnamaale ja madalama hinna eest, kui algselt v\u00e4lja pakuti. Ning Madiselisas. Olles kriminaaltoimiku materjalidega ja ka j\u00e4lituslubadega tutvunud kinnitan teile, et m\u00e4rki sellest, et tegemist oleks ilmselgelt p\u00f5hjendamatu menetlusega v\u00f5i poliitiliselt kallutatud menetlusega. Meie ei leidnud. Mihhail Korb tuletas oma s\u00f5nav\u00f5tus meelde, et kahtlustuse esitamisest on m\u00f6\u00f6das 15 kuud ja tegelikult oleks asi juba ammu v\u00f5inud kohtus olla, sest tema on huvitatud maksimaalselt kiirest t\u00f5e v\u00e4ljaselgitamisest. T\u00e4na ma p\u00f6\u00f6rdun kogu saali poole, samuti toetada minul saadikute puutumatuse \u00e4rav\u00f5tmise. Seda k\u00f5ik selleks, et maksimaalselt kiiresti teieni j\u00f5uda. Saadikupuutumatuse \u00e4rav\u00f5tmise poolt h\u00e4\u00e4letas 82 saadikut, vastu ei olnud keegi, m\u00f5ned j\u00e4tsid h\u00e4\u00e4letamata.\",\n  \"target_text\": \"\u00d5iguskantsler \u00dclle Madise tegi Riigikogule ettepaneku anda n\u00f5usolek Riigikogu liikmelt Mihhail Korbilt saadikupuutumatuse \u00e4rav\u00f5tmiseks.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Allpool on dokumendid koos kokkuv\u00f5tetega.\n</code></pre></li> <li>Base prompt template:   <pre><code>Dokument: {text}\nKokkuv\u00f5te: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Document: {text}\n\nKoosta \u00fclaltoodud dokumendi kokkuv\u00f5te.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset err-news\n</code></pre>"},{"location":"datasets/faroese/","title":"\ud83c\uddeb\ud83c\uddf4 Faroese","text":"<p>This is an overview of all the datasets used in the Faroese part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/faroese/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/faroese/#fosent","title":"FoSent","text":"<p>This dataset was published in this paper and is based on 170 news articles from the Faroese news sites Portalurin and Dimmal\u00e6tting. The sentiment labels were manually annotated by two native speakers.</p> <p>The original full dataset consists of 245 samples, which consisted of both a news article, a chosen sentence from the article, and the sentiment label. We use both the news article and the chosen sentence as two separate samples, to increase the size of the dataset (keeping them within the same dataset split). In total, we use a 72 / 40 / 279 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Eg koyri teg, t\u00fa koyrir meg Hetta er \u00e1rst\u00ed\u00f0in, har vit vanliga fara \u00ed j\u00f3labor\u00f0hald at hugna okkum saman vi\u00f0 vinum og starvsfel\u00f8gum. Og h\u00f3ast vit kanska ikki hittast og koma saman \u00e1 j\u00fast sama h\u00e1tt, sum \u00e1\u00f0renn korona rakti samfelagi\u00f0, so eru \u00f3iva\u00f0 n\u00f3gv sum kortini gle\u00f0a seg til hesa t\u00ed\u00f0ina vi\u00f0 hugna og veitslulag Eins og undanfarin \u00e1r, fara R\u00e1\u00f0i\u00f0 fyri Fer\u00f0slutrygd (\u00ed samstarvi vi\u00f0 Betri Trygging og Trygd) at fremja \u00e1tak fyri at ste\u00f0ga r\u00faskoyring. Hetta ver\u00f0ur gj\u00f8rt vi\u00f0 filminum \u00a0\u201dEg koyri teg, t\u00fa koyrir meg\u201d, i\u00f0 er \u00farsliti\u00f0 av st\u00f3ru hugskotskappingini hj\u00e1 R\u00e1\u00f0num fyri Fer\u00f0slutrygd s\u00ed\u00f0sta vetur. Filmsl\u00fdsingin ver\u00f0ur \u00ed\u00a0hesum d\u00f8gum v\u00edst \u00ed sj\u00f3nvarpi, biografi og \u00e1 sosialum mi\u00f0lum. Brynhild Nols\u00f8e \u00ed L\u00e1gab\u00f8 \u00far V\u00e1gi vann kappingina, og luttekur saman vi\u00f0 vinf\u00f3lki \u00ed l\u00fdsingini. Brynhild kennir sj\u00e1lv til avbj\u00f3\u00f0ingarnar av at vera partur av n\u00e1ttarl\u00edvinum \u00ed\u00a0a\u00f0rari bygd, enn teirri t\u00fa b\u00fdrt \u00ed. T\u00ed bygdi hennara hugskot \u00e1 egnar royndir. \u00cd vinarb\u00f3lkinum hj\u00e1 Brynhild hava tey gj\u00f8rt eina avtalu, i\u00f0 byggir \u00e1 tankan: \u201dEg koyri teg, t\u00fa koyrir meg.\u201d Hetta merkir, at tey skiftast um at koyra: - Avtalan er tann, at um eitt vinf\u00f3lk er fari\u00f0 \u00ed b\u00fdin og eg liggi heima, so ringja tey til m\u00edn, og eg fari upp at koyra tey. Um eg eri farin \u00ed b\u00fdin og okkurt vinf\u00f3lk liggur heima,\u00a0so koma tey eisini upp at koyra meg. Ta\u00f0 er l\u00edkamiki\u00f0 um ta\u00f0 er morgun, dagur ella n\u00e1tt, greiddi Brynhild fr\u00e1 \u00ed l\u00fdsingarfilminum, i\u00f0 er komin burtur \u00far hugskotinum hj\u00e1\u00a0Brynhild. Vit valdu at gera eina hugskotskapping, har ung f\u00f3lk sluppu at seta dagsskr\u00e1nna, og \u00farsliti\u00f0 gj\u00f8rdist hesin filmurin, i\u00f0 byggir \u00e1 tey hugskot, i\u00f0 tey ungu sj\u00e1lvi h\u00f8vdu, sigur Lovisa Petersen Glerfoss, stj\u00f3ri \u00ed R\u00e1\u00f0num fyri Fer\u00f0slutrygd. Eftir at vinnarin var\u00f0 funnin, hevur Brynhild arbeitt saman vi\u00f0 eini l\u00fdsingarstovu vi\u00f0 at menna hugskoti\u00f0 til eina lidna l\u00fdsing. \u00cd l\u00fdsingini s\u00edggja vit Brynhild og hennara\u00a0vinf\u00f3lk \u00ed b\u00fdnum og \u00e1 veg til h\u00fas. \u00cd samr\u00e1\u00f0 vi\u00f0 Brynhild er l\u00fdsingin blivin jalig og uppbyggjandi, heldur enn ford\u00f8mandi og neilig. Hugbur\u00f0urin til r\u00faskoyring er broyttur munandi seinastu n\u00f3gvu \u00e1rini, og heili 98% av f\u00f8royingum siga at r\u00faskoyring ver\u00f0ur ikki g\u00f3\u00f0tikin. Men kortini ver\u00f0a bilf\u00f8rarar\u00a0javnan tiknir vi\u00f0 promillu \u00ed bl\u00f3\u00f0inum. Harafturat er r\u00faskoyring ors\u00f8k til fj\u00f3r\u00f0u hv\u00f8rja dey\u00f0svanlukku \u00ed fer\u00f0sluni, v\u00edsa t\u00f8l \u00far nor\u00f0urlondum. T\u00ed er ta\u00f0 eisini \u00ed 2021\u00a0t\u00fddningarmiki\u00f0 at tosa um at ste\u00f0ga r\u00faskoyring! \u00c1taki\u00f0 heldur fram hetta til n\u00fdggj\u00e1rs og l\u00f8greglan ger r\u00faskanningar, me\u00f0an \u00e1taki\u00f0 er. Eisini fer l\u00f8greglan at lata bilf\u00f8rarum, sum hava s\u00edni vi\u00f0urskifti \u00ed ordan, sn\u00f8ggar lyklaringar vi\u00f0 bo\u00f0skapinum \\\"Eg koyri teg, t\u00fa koyrir meg\\\". \",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Vestmanna sk\u00fali hevur hesar lei\u00f0reglur \u00ed sambandi vi\u00f0 sj\u00fakar n\u00e6mingar: Ta\u00f0 er \u00f3gvuliga umr\u00e1\u00f0andi at n\u00e6mingar, sum ikki eru koppsettir, og hava veri\u00f0 \u00ed samband vi\u00f0 f\u00f3lk, sum eru testa\u00f0 positiv fyri koronu, halda tilm\u00e6lini. \",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Landsverk arbei\u00f0ur \u00ed l\u00f8tuni vi\u00f0 at f\u00e1a trailaran, sum er fult lasta\u00f0ur, upp aftur, og arbei\u00f0i\u00f0 fer v\u00e6ntandi at taka nakrar t\u00edmar, t\u00ed st\u00f3rar maskinur skulu til, og t\u00e6r mugu koyra um Ei\u00f0iskar\u00f0 fyri at koma til hj\u00e1lpar. \",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Her eru nakrir tekstir flokka\u00f0ir eftir lyndi, sum kann vera 'positivt', 'neutralt' ella 'negativt'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nLyndi: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekstur: {text}\n\nFlokka lyndi\u00f0 \u00ed tekstinum. Svara vi\u00f0 'positivt', 'neutralt' ella 'negativt'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positivt</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutralt</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negativt</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset fosent\n</code></pre>"},{"location":"datasets/faroese/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/faroese/#fone","title":"FoNE","text":"<p>This dataset was published in this paper and is based on news articles from Sosialurin. The named entities were automatically tagged, but verified manually. They use a superset of the CoNNL-2003 dataset, with the following additional entity types: <code>Date</code>, <code>Money</code>, <code>Percent</code> and <code>Time</code>. We remove these additional entity types from our dataset and keep only the original CoNNL-2003 entity types (<code>PER</code>, <code>ORG</code>, <code>LOC</code>, <code>MISC</code>).</p> <p>The original full dataset consists of 6,286 samples, which we split into 1,024 / 256 / 2,048 samples for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  'tokens': array(['Millum', 'teirra', 'er', 'Tommy', 'Petersen', ',', 'sum', 'eitt', 'skifti', 'hev\u00f0i', 'ES', 'sum', 's\u00edtt', 'm\u00e1ls\u00f8ki', '\u00ed', 'Tinganesi', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Fleiri', 'l\u00e6rarat\u00edmar', 'skulu', '\u00ed', '\u00e1r', 'br\u00fakast', '\u00e1', 'HF', '-', 'sk\u00falanum', '\u00ed', 'Klaksv\u00edk', ',', 'men', 'samb\u00e6rt', 'lei\u00f0aranum', '\u00e1', 'sk\u00falanum', 'hevur', 'ta\u00f0', 'bara', 'vi\u00f0', 's\u00e6r', ',', 'at', 'l\u00e6rarar', ',', 'sum', 'eru', 'b\u00fasitandi', '\u00ed', 'Klaksv\u00edk', ',', 'koma', 'at', 'fer\u00f0ast', 'minni', '\u00e1', 'Kambsdal', 'og', '\u00edsta\u00f0in', 'br\u00faka', 'meira', 'undirv\u00edsingart\u00ed\u00f0', '\u00ed', 'b\u00fdnum', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Solei\u00f0is', ',', 'at', 'Starvsstovan', 'kann', 'fylgja', 'vi\u00f0', ',', 'at', 'ta\u00f0', 'ikki', 'er', 'n\u00fdliga', 'heiliv\u00e1gsvi\u00f0gj\u00f8rdur', 'fiskur', ',', 'sum', 'tikin', 'ver\u00f0ur', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Her eru nakrir setningar og nakrar JSON or\u00f0ab\u00f8kur vi\u00f0 nevndar eindir, sum eru \u00ed setningunum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setningur: {text}\nNevndar eindir: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setningur: {text}\n\nGreini\u00f0 nevndu einingarnar \u00ed setningunni. \u00de\u00fa \u00e6ttir a\u00f0 skila \u00feessu sem JSON or\u00f0ab\u00f3k me\u00f0 lyklunum 'pers\u00f3nur', 'sta\u00f0ur', 'felagsskapur' og 'ymiskt'. Gildin \u00e6ttu a\u00f0 vera listi yfir nevndu einingarnar af \u00feeirri ger\u00f0, n\u00e1kv\u00e6mlega eins og \u00fe\u00e6r koma fram \u00ed setningunni.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>pers\u00f3nur</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>pers\u00f3nur</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sta\u00f0ur</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sta\u00f0ur</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>felagsskapur</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>felagsskapur</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>ymiskt</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>ymiskt</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset fone\n</code></pre>"},{"location":"datasets/faroese/#unofficial-wikiann-fo","title":"Unofficial: WikiANN-fo","text":"<p>This dataset was part of the WikiANN dataset (also known as PAN-X), published in this paper. It is based on Wikipedia articles, and the labels have been automatically annotated using knowledge base mining. There are no <code>MISC</code> entities in this dataset, so we only keep the <code>PER</code>, <code>LOC</code> and <code>ORG</code> entities.</p> <p>The original full dataset consists of an unknown amount of samples, which we split into 1,024 / 256 / 2,048 samples for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  'tokens': array([\"'\", \"''\", 'P\u00f3lland', \"''\", \"'\"], dtype=object),\n  'labels': array(['O', 'O', 'B-LOC', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Skulu', '\u00farvalssvimjararnir', 'betra', '\u00farslit', 's\u00edni', ',', 'so', 'er', 'ney\u00f0ugt', 'hj\u00e1', 'teimum', 'at', 'fara', 'uttanlands', 'at', 'venja', '(', 'Danmark', ',', 'USA', ')', ';', 'hinvegin', 'minkar', 'hetta', 'um', 'kappingina', 'hj\u00e1', 'teimum', 'heimligu', 'svimjarunum', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Nor\u00f0uramerika', '-', '16', '%'], dtype=object),\n  'labels': array(['B-LOC', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Her eru nakrir setningar og nakrar JSON or\u00f0ab\u00f8kur vi\u00f0 nevndar eindir, sum eru \u00ed setningunum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setningur: {text}\nNevndar eindir: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setningur: {text}\n\nGreini\u00f0 nevndu einingarnar \u00ed setningunni. \u00de\u00fa \u00e6ttir a\u00f0 skila \u00feessu sem JSON or\u00f0ab\u00f3k me\u00f0 lyklunum 'pers\u00f3nur', 'sta\u00f0ur', 'felagsskapur' og 'ymiskt'. Gildin \u00e6ttu a\u00f0 vera listi yfir nevndu einingarnar af \u00feeirri ger\u00f0, n\u00e1kv\u00e6mlega eins og \u00fe\u00e6r koma fram \u00ed setningunni.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>pers\u00f3nur</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>pers\u00f3nur</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sta\u00f0ur</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sta\u00f0ur</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>felagsskapur</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>felagsskapur</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>ymiskt</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>ymiskt</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset wikiann-fo\n</code></pre>"},{"location":"datasets/faroese/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/faroese/#scala-fo","title":"ScaLA-fo","text":"<p>This dataset was published in this paper and was automatically created from the Faroese Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 1,621 samples, from which we use 1,024 / 256 / 1,024 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hann tala\u00f0i t\u00ed \u00ed samkomuh\u00fasinum vi\u00f0 J\u00f6darnar og vi\u00f0 teir, sum \u00f3tta\u00f0ust Gu\u00f0, og \u00e1 torginum hv\u00f6nn dag vi\u00f0 teir, sum hann har hitti vi\u00f0.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hann finnur fyrst br\u00f3\u00f0ur s\u00edn, S\u00edmun, og sigur vi\u00f0 hann: \\\"hava Vit funni\u00f0 Messias\\\" sum er ta\u00f0 sama sum Kristus; ta\u00f0 er: salva\u00f0ur.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hetta hendi tr\u00edggjar fer\u00f0ir, og alt fyri eitt var\u00f0 luturin tikin upp aftur himmals til.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Hetta eru nakrir setningar og um teir eru m\u00e1ll\u00e6ruliga r\u00e6ttir.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setningur: {text}\nM\u00e1ll\u00e6ruliga r\u00e6ttur: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setningur: {text}\n\nGreini\u00f0 hvort setningurin er m\u00e1ll\u00e6ruliga r\u00e6ttur ella ikki. Svari\u00f0 skal vera 'ja' um setningurin er r\u00e6ttur og 'nei' um hann ikki er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-fo\n</code></pre>"},{"location":"datasets/faroese/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/faroese/#foqa","title":"FoQA","text":"<p>This dataset was published in this paper and is based on the Faroese Wikipedia. The questions and answers were automatically generated using GPT-4-turbo, which were verified by a native speaker, and some of them were also corrected by the same native speaker.</p> <p>The original full dataset consists of 2,000 samples, and we split these into 848 / 128 / 1,024 samples for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"Felagsskapur ST fyri undirv\u00edsing, v\u00edsindum og mentan (\u00e1 enskum: United Nations Educational, Scientific and Cultural Organization, stytt UNESCO) er ein serstovnur undir Sameindu Tj\u00f3\u00f0um, stovna\u00f0ur \u00ed 1946. Endam\u00e1li\u00f0 vi\u00f0 felagskapinum er at menna \u00fatb\u00fagving, gransking og mentan og at fremja samstarv millum tey 195 limalondini og teir 8 atlimirnar, i\u00f0 eru F\u00f8royar, Cura\u00e7ao, Aruba, Jomfr\u00faoyggjar, Caymanoyggjar, Makao, Ni\u00f0urlendsku Antillurnar og Tokelau. F\u00f8royar fingu atlimaskap \u00ed 2009 . Atlimaskapur gevur \u00f8ll tey somu r\u00e6ttindi sum limaskapur. Limalondini skipa seg vi\u00f0 hv\u00f8r s\u00edni UNESCO nevnd. Fyrsta f\u00f8royska UNESCO nevndin var\u00f0 skipa\u00f0 \u00ed mai 2012. \\n\\nUNESCO tekur s\u00e6r millum anna\u00f0 av at meta um, hv\u00f8rji pl\u00e1ss \u00ed heiminum skulu f\u00e1a status sum World Heritage Sites (heimsarvur). Limalond UNESCO samtyktu \u00ed 1972 millumtj\u00f3\u00f0as\u00e1ttm\u00e1lan um at verja heimsins mentanar- og n\u00e1tt\u00faruarv. Ors\u00f8kin er vandin fyri, at n\u00e1tt\u00faru\u00f8ki, fornfr\u00f8\u00f0ilig minnismerki og mentanarvir\u00f0i forfarast orsaka\u00f0 av fer\u00f0af\u00f3lkavinnu, d\u00e1lking, kr\u00edggi ella vanligari \u00f3r\u00f8kt.\\n\\nHygg eisini at \\n\\n Millumtj\u00f3\u00f0as\u00e1ttm\u00e1li UNESCO um vernd av heimsins mentanar- og n\u00e1tt\u00faruarvi.\\n\\nKeldur\\n\\nSl\u00f3\u00f0ir \u00fateftir \\n\\n UNESCO World Heritage Centre\\n\\nST\\nHeimsarvar\",\n  \"question\": \"Hvat g\u00f3\u00f0kendu UNESCO-limalondini \u00ed 1972?\",\n  \"answers\": {\n    \"answer_start\": array([806]),\n    \"text\": array([\"millumtj\u00f3\u00f0as\u00e1ttm\u00e1lan um at verja heimsins mentanar- og n\u00e1tt\u00faruarv\"], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Levi Niclasen, sum yrkjari betri kendur sum \u00d3\u00f0in \u00d3dn (f\u00f8ddur 1. mai 1943 \u00e1 Tv\u00f8royri, uppvaksin \u00ed Hvalba) er ein f\u00f8royskur rith\u00f8vundur, t\u00f3nleikari, l\u00e6rari og politikari. \\n\\nAftan \u00e1 barnask\u00falan arbeiddi hann \u00ed kolinum \u00ed Hvalba. \u00cd 1957 stovna\u00f0i hann saman vi\u00f0 br\u00f8\u00f0um s\u00ednum ein t\u00f3nleikab\u00f3lk, og br\u00e1tt blivu teir kendir sum Hvalbiarbr\u00f8\u00f0urnir. Teir g\u00f3vu \u00fat tv\u00e6r stak pl\u00e1tur \u00ed 1962. Hann var \u00ed Gr\u00f8nlandi 1960 og 1961 og arbeiddi \u00e1 landi \u00ed F\u00f8royingahavnini fyri Nordafar. \\nHann f\u00f3r s\u00ed\u00f0an \u00e1 l\u00e6rarask\u00fala \u00ed Havn og t\u00f3k pr\u00f3gv fr\u00e1 F\u00f8roya L\u00e6rarask\u00fala \u00ed 1967. Var settur sum l\u00e6rari vi\u00f0 Hvalbiar sk\u00fala 1. august 1967. Hevur veri\u00f0 sk\u00falalei\u00f0ari vi\u00f0 Hvalbiar sk\u00fala fr\u00e1 1. august 1979. Hann hevur eisini veri\u00f0 \u00e1 Fr\u00f3\u00f0skaparsetri F\u00f8roya og fullf\u00f8rt n\u00e1m \u00ed f\u00f8royskum og b\u00f3kmentum 1969-70. Hann hevur \u00fatgivi\u00f0 fleiri yrkingas\u00f8vn og eisini eitt stutts\u00f8gusavn og eina b\u00f3k vi\u00f0 b\u00e6\u00f0i yrkingum og stutts\u00f8gum. Hann hevur eisini t\u00fdtt tv\u00e6r b\u00f8kur til f\u00f8royskt.\\n\\n\u00datg\u00e1vur  \\nGivi\u00f0 \u00fat \u00e1 egnum forlagi:\\nHvirlur (yrkingasavn) 1970\\nEg eri \u00ed iva (yrkingasavn) 1970 \\nTey \u00ed ur\u00f0ini (s\u00f8gusavn) 1973 \\nRey\u00f0ibarmur (yrkingar og stutts\u00f8gur) 1974\\nVi\u00f0r\u00e1k og M\u00f3tr\u00e1k (yrkingasavn) 1975\\n\u00d3ttast ikki (yrkingasavn) 1975\\nN\u00edvandi ni\u00f0a (yrkingasavn) 1983 \\nLova\u00f0 er lygnin (yrkingasavn) 1983 \\nEg eigi eina mynd (yrkingasavn) 1987\\n\\nT\u00fd\u00f0ingar \\nEydnur\u00edki prinsurin (Oscar Wilde) (F\u00f8roya L\u00e6rarafelag 1977). \\nHeilaga landi\u00f0 (P\u00e4r Lagerkvist) (felagi\u00f0 Var\u00f0in 1986).\\n\\nFamilja \\nForeldur: Thomasia Niclasen, f. Thomasen \u00e1 Giljanesi \u00ed V\u00e1gum og Hentzar Niclasen, kongsb\u00f3ndi \u00e1 Hamri \u00ed Hvalba. Giftist \u00ed 1971 vi\u00f0 S\u00fasonnu Niclasen, f. Holm. Hon er f\u00f8dd \u00ed Hvalba \u00ed 1950. Tey eiga tr\u00edggjar synir: T\u00f3rarinn, T\u00f3roddur og Nj\u00e1lur.\\n\\nKeldur \\n\\nF\u00f8royskir t\u00fd\u00f0arar\\nF\u00f8royskir rith\u00f8vundar\\nF\u00f8royskir yrkjarar\\nF\u00f8royskir l\u00e6rarar\\nHvalbingar\\nF\u00f8\u00f0ingar \u00ed 1943\",\n  \"question\": \"Hvar var Levi Niclasen settur \u00ed starv \u00ed Gr\u00f8nlandi \u00ed 1961?\",\n  \"answers\": {\n    \"answer_start\": array([431]),\n    \"text\": array([\"F\u00f8royingahavnini\"], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Giro d'Italia (\u00e1 f\u00f8royskum Kring Italia) er ein av teimum trimum st\u00f3ru teinas\u00fakklukappingunum og ver\u00f0ur hildin hv\u00f8rt \u00e1r \u00ed mai/juni og varir \u00ed 3 vikur. Kappingin fer fram \u00ed Italia, men partar av kappigini kunnu eisini fara fram \u00ed onkrum \u00f8r\u00f0um landi \u00ed Evropa, t.d. byrja\u00f0i Giro d'Italia \u00ed Ni\u00f0urlondum \u00ed 2016 og \u00ed Danmark \u00ed 2014.\\n\\nGiro d'Italia var\u00f0 fyrstu fer\u00f0 hildi\u00f0 \u00ed 1909, har i\u00f0 tilsamans 8 teinar \u00e1 2448\\xa0km v\u00f3ru s\u00fakkla\u00f0ir. Kappingin er saman vi\u00f0 Tour de France og Vuelta a Espa\u00f1a ein av teimum trimum klassisku teinakappingunum, har Tour de France t\u00f3 er tann mest t\u00fd\u00f0andi.\\n\\nHar tann fremsti s\u00fakklarin \u00ed Tour de France er kendur fyri at s\u00fakkla \u00ed gulari troyggju, so s\u00fakklar fremsti s\u00fakklarin \u00ed Giro d\u00b4Italia \u00ed lj\u00f3sarey\u00f0ari troyggju, \u00e1 italskum nevnd Maglia rosa. Tann fremsti fjallas\u00fakklarin s\u00fakklar \u00ed gr\u00f8nari troyggju (Maglia Verde), me\u00f0an s\u00fakklarin vi\u00f0 flestum stigum koyrir \u00ed lilla (Maglia ciclimano). \u00cd 2007 var\u00f0 tann hv\u00edta ungd\u00f3mstroyggjan innf\u00f8rd aftur, eftir at hon hev\u00f0i veri\u00f0 burturi \u00ed n\u00f8kur \u00e1r, hon nevnist Maglia Bianca.\\n\\nTr\u00edggir s\u00fakklarar hava vunni\u00f0 kappingina fimm fer\u00f0ir: Alfredo Binda, Fausto Coppi og Eddy Merckx. Italiuma\u00f0urin Felice Gimondi hevur sta\u00f0i\u00f0 \u00e1 sigurspallinum n\u00edggju fer\u00f0ir, har hann tr\u00edggjar fer\u00f0ir hevur vunni\u00f0, tv\u00e6r fer\u00f0ir \u00e1 \u00f8\u00f0rum pl\u00e1ssi og f\u00fdra fer\u00f0ir \u00e1 tri\u00f0japl\u00e1ssi.\\n\\nYvirlit yvir vinnarar\\n\\nByrjan \u00ed \u00f8\u00f0rum londum\\n\\nKeldur \\n\\nGiro d'Italia\",\n  \"question\": \"Hv\u00f8r hevur fimm fer\u00f0ir vunni\u00f0 Giro d'Italia?\",\n  \"answers\": {\n    \"answer_start\": array([1089]),\n    \"text\": array([\"Alfredo Binda, Fausto Coppi og Eddy Merckx\"], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Hetta eru tekstir saman vi\u00f0 spurningum og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekstur: {text}\nSpurningur: {question}\nSvara vi\u00f0 \u00ed mesta lagi trimum or\u00f0um: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekstur: {text}\n\nSvara hesum spurninginum um tekstin uppiyvir vi\u00f0 \u00ed mesta lagi trimum or\u00f0um.\n\nSpurningur: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset foqa\n</code></pre>"},{"location":"datasets/faroese/#unofficial-multiwikiqa-fo","title":"Unofficial: MultiWikiQA-fo","text":"<p>This dataset will be published in an upcoming paper, and contains Faroese Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": 'Ali Babba- og 49 a\u00f0rar bla\u00f0greinir er eitt savn vi\u00f0 fimmti greinum, i\u00f0 H\u00f8gni Mohr hevur skriva\u00f0 og lati\u00f0 prenta\u00f0 \u00ed Dimmal\u00e6tting og Vinnuvitan fr\u00e1 desember 2004 til februar 2006.\\n\\nS\u00f8gugongd \\nGreinasavni\u00f0 sn\u00fdr seg um f\u00f3lk, sum b\u00fagva \u00ed F\u00f8royum, og onnur, i\u00f0 hava tilkn\u00fdti til hetta landi\u00f0, men b\u00fagva uttanlands. Tekstirnir hava sum innihald tr\u00fd ey\u00f0kend sl\u00f8g av menniskjum: tey \u00e1v\u00edsu \u00f3kendu, sum standa aftan fyri tey kendu; onnur, i\u00f0 eru mitt \u00ed einum serliga spennandi starvi; og hini, i\u00f0 virka fremst \u00ed vinnul\u00edvinum. Savni\u00f0 er sostatt grunda\u00f0 \u00e1 tr\u00edggjar greinar\u00f8\u00f0ir, i\u00f0 j\u00fast eru greiddar \u00far hondum eftir hesum trimum leistum.\\n\\nLes eisini \\nMohr, H\u00f8gni (2010) T\u00e1 dey\u00f0in ver\u00f0ur avd\u00faka\u00f0ur. \u00d8giliga egi\u00f0 forlag. ISBN 9789991880518Styrkin \u00ed b\u00f3kini er tann beinrakna tekstin, t\u00e6r hugtakandi, men kn\u00f8ppu or\u00f0ingarnar, mi\u00f0lingin av sterkum menniskjaligum kenslum, st\u00faran, gle\u00f0i, \u00f3tta og sorg, og so tann einfalda, positiva mennsikjafatanin \\xa0- Erhard Jacobsen, umm\u00e6lari.Mohr, H\u00f8gni (2017) Fractura nasi. \u00d8giliga egi\u00f0 forlag. ISBN 9789991880525. Kirsten Brix t\u00fdtt til danskt 2019. Danskt heiti Rejse for livet. forlag Amanda Books. Seld til filmframlei\u00f0slu \u00ed 2018.Hon er \u00ed passandi flogfer\u00f0, skrivingin. Floygd, sum eingin annar tekstur eg n\u00fdligani havi lisi\u00f0. S\u00ed\u00f0st eg kendi meg so v\u00e6l \u00ed felag vi\u00f0 hin skrivandi var, t\u00e1 eg l\u00e6s Bommhjarta hj\u00e1 J\u00f3anesi Nielsen, sum kom \u00ed fj\u00f8r. Ein smittandi respektleys s\u00f8ga, sum hemningsleys gongur s\u00ednar egnu lei\u00f0ir. Men aftanfyri h\u00f3mast ein leitan eftir egnum upphavi. Hv\u00ed bleiv eg sum eg bleiv, er skuggaspurningur h\u00f8vundans \\xa0- Birgir Kruse, umm\u00e6lari.Mohr, H\u00f8gni (2018) Slepp t\u00e6r til heiti fani. \u00d8giliga egi\u00f0 forlag. ISBN 9789991880532. Tekningar: Astrid Andreasen.Ta\u00f0 smakkar bara so v\u00e6l at lesa hasi or\u00f0ini. Ikki t\u00ed eg havi naka\u00f0 \u00edm\u00f3ti Gerhardi ella Javna\u00f0arflokkinum \u00ed Avhaldslosjuni, men bara t\u00ed at eg s\u00edggi sp\u00e6landi or\u00f0alagi\u00f0, sum ikki er eitt st\u00edvrent kv\u00e6\u00f0a\u00f8rindi at f\u00e1a b\u00f3kstavar\u00edm til sk\u00falabr\u00faks, men beint fram br\u00faksf\u00f8royskt loyst \u00far lagdi \\xa0- Birgir Kruse, umm\u00e6lari.Mohr, H\u00f8gni (2019) m\u00e6r d\u00e1mar ikki h\u00f8gna hoydal. \u00d8giliga egi\u00f0 forlag. ISBN 9789991880549\\n\\nT\u00fdtt og ritstj\u00f3rna\u00f0 \\n2006 - Askur og Embla (t\u00fdtt), B\u00f3kadeild F\u00f8roya l\u00e6rarafelags, 204 s\u00ed\u00f0ur.\\n\\n2013 - Sannleikin um \u00e1star\u00e6vint\u00fdri\u00f0 (t\u00fdtt og ritstj\u00f3rna\u00f0), \u00d8giliga egi\u00f0 forlag, 35 s\u00ed\u00f0ur.\\n\\nKeldur',\n    \"question\": 'Hv\u00f8r er \u00fatg\u00e1vandi av b\u00f3kini \"M\u00e6r d\u00e1mar ikki H\u00f8gna Hoydal?\"',\n    \"answers\": {\n        \"answer_start\": array([684]),\n        \"text\": array(['\u00d8giliga egi\u00f0 forlag'], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": '\u00c6vint\u00fdr eru sum skaldskaparslag munnbornar s\u00f8gur um vanlig folk \u00ed einum yvirnat\u00farligum heimi. Heiti\u00f0 ve\u00f0ur n\u00fdtt um fleiri sl\u00f8g av s\u00f8gum, i\u00f0 als ikki \u00f8ll hava sama yivrnat\u00farliga innihald. Antti Aarne og Stith Thompson hava gj\u00f8rt eina skr\u00e1 yvir heimsins \u00e6vint\u00fdr. Har eru tey skift sundur \u00ed 5 h\u00f8vu\u00f0sb\u00f3lkar ella t\u00fdpur. Sum annar munnborin skaldskapur hava \u00e6vint\u00fdrini ongan kendan h\u00f8vund ella upprunaligan form. Tey kennast aftur eftir greining av s\u00f8gugongd og innihaldi, og \u00e1 tann h\u00e1tt hava Aarne og Thompson skift tey sundur \u00ed t\u00fdpur hv\u00f8rja vi\u00f0 s\u00ednum nummari og stavunum AT frammanfyri. Hesar t\u00fdpur og h\u00f8vu\u00f0sb\u00f3lkar eru: I Dj\u00f3ra\u00e6vint\u00fdr (AT 1-299), II Eginlig \u00e6vint\u00fdr (AT 300-1199), III Skemti\u00e6vint\u00fdr (AT 1200-1999), IV Formil\u00e6vint\u00fdr (AT 2000-2399) og V Ymisk \u00e6vint\u00fdr (AT 2400.2499). Hesin seinasti b\u00f3lkurin umfatar tey \u00e6vint\u00fdr, i\u00f0 h\u00f8vundarnir ikki fingu at h\u00f3ska til hinar b\u00f3lkarnar. \\n\\n\u00cd \u00f8llum vanligum br\u00faki ver\u00f0ur oftast hugsa\u00f0 um s\u00f8gurnar \u00ed b\u00f3lki II, t\u00e1 talan er um \u00e6vint\u00fdr. Serstakliga kanska undirb\u00f3lk A, i\u00f0 ver\u00f0ur kalla\u00f0ur Ganda\u00e6vint\u00fdr (AT 300-749). \u00cd hesum b\u00f3lki eru m.a. t\u00e6r v\u00e6l kendu s\u00f8gurnar um ein f\u00e1t\u00e6kan drong, i\u00f0 bjargar eini prinsessu, sum tr\u00f8ll vi\u00f0 n\u00edggju h\u00f8vdum ella onkur onnur yvirnat\u00farlig vera hevur tiki\u00f0; \u00ed endanum giftist drongurin vi\u00f0 prinsessuni og ver\u00f0ur kongur. Ella eina f\u00e1t\u00e6ka gentu, i\u00f0 bjargar einum prinsi, sum ofta er umskaptur til okkurt andskr\u00e6miligt, og s\u00ed\u00f0ani giftist vi\u00f0 honum og gerst drotning. \u00d8ll liva s\u00ed\u00f0ani lukkuliga. \\n\\nH\u00f3ast \u00e6vint\u00fdr sum skaldskaparslag upprunaliga eru munnbornar s\u00f8gur, kenna vit tey n\u00fa \u00ed t\u00ed\u00f0ini best og ivaleyst bert \u00far ritstj\u00f3rna\u00f0um, prenta\u00f0um \u00fatg\u00e1vum. Charles Perrault (1628-1703) var hin fyrsti at geva \u00fat eitt savn vi\u00f0 s\u00f8gum, i\u00f0 eru ritstj\u00f3rna\u00f0 \u00e6vint\u00fdr. B\u00f3kin kom \u00ed 1697 og nenvdist S\u00f8gur og fr\u00e1sagnir \u00far farnum t\u00ed\u00f0um vi\u00f0 undirheitinum \"G\u00e1sam\u00f3\u00f0ir sigur fr\u00e1\" (Les Contes de ma M\u00e8re l\u2019Oye). Millum s\u00f8gurnar \u00ed hesum savni eru so v\u00ed\u00f0agitnar s\u00f8gur sum Rey\u00f0hetta, Tornar\u00f3sa og \u00d8skuf\u00eda. Perrault \u00f3tta\u00f0ist b\u00f3kmentaliga og mentanarliga smakkin \u00ed t\u00ed\u00f0ini, laga\u00f0i s\u00f8gurnar til, sum honum t\u00f3kti best og gav t\u00e6r \u00fat \u00ed navninum \u00e1 10 \u00e1ra gamla syni s\u00ednum. B\u00f3kin gj\u00f8rdist \u00f3metaliga v\u00e6l umt\u00f3kt og var sum fr\u00e1 lei\u00f0 t\u00fddd til flest\u00f8ll fj\u00f8lment evropeisk m\u00e1l. Seinni f\u00f3ru f\u00f3lk a\u00f0rasta\u00f0ni at savna og skriva upp \u00e6vint\u00fdr, og summpart vi\u00f0 beinlei\u00f0is fyrimynd \u00ed s\u00f8gunum hj\u00e1 Perrault komu serliga \u00ed 19. \u00f8ld fleiri kend s\u00f8vn vi\u00f0 ritstj\u00f3rna\u00f0um \u00e6vint\u00fdrum. Kendast eru \u00e6vint\u00fdrini hj\u00e1 t\u00fdskarunum Jacob og Wilhelm Grimm. Eisini \u00ed Nor\u00f0urlondum vaks \u00e1hugin, og millum kendastu \u00fatg\u00e1vur eru t\u00e6r hj\u00e1 Ewald Tang Christensen \u00ed Danmark, Asbj\u00f8rnsen og Moe \u00ed Noregi, og J\u00f3ni \u00c1rnasyni \u00ed \u00cdslandi. \\n\\n\u00cd F\u00f8royum t\u00f3k Jakob Jakobsen tr\u00e1\u00f0in upp, og \u00ed \u00e1runum 1898-1901 gav hann \u00fat savn s\u00edtt vi\u00f0 f\u00f8royskum sagnum og \u00e6vint\u00fdrum. Eisini hann ritstj\u00f3rna\u00f0i s\u00f8gurnar, sum hann savna\u00f0i, so vit kunnu siga, at solei\u00f0is sum vit lesa t\u00e6r hj\u00e1 honum, hava t\u00e6r ikki veri\u00f0 sagdar honum. Hansara ritstj\u00f3rnan er mest av m\u00e1lsligum slag. Hann flytur munnliga fr\u00e1s\u00f8gn \u00ed skrift vi\u00f0 teimum tillagingum, i\u00f0 t\u00e1 eru ney\u00f0ugar, og hartil reinsar hann fr\u00e1s\u00f8gnina fyri \u00fatlendskan m\u00e1lbur\u00f0. Mangt bendir \u00e1, at \u00e6vint\u00fdr valla eru gamal skaldskapur \u00ed F\u00f8royum. Ta\u00f0 tykist, sum tey eru komin \u00ed munnliga fr\u00e1s\u00f8gn \u00ed F\u00f8royum eftir f\u00f3lksligum, einahelst donskum \u00fatg\u00e1vum. Men sum v\u00e6ntandi er \u00ed munnligari s\u00f8gulist, hava f\u00f3lk laga\u00f0 tey til so vi\u00f0 og vi\u00f0, so tey ofta hava f\u00f8royskan d\u00e1m \u00ed mongum lutum. Summi teirra eru t\u00f3 ivaleyst gomul \u00ed F\u00f8royum.\\n\\nKeldur \\n\\n Kirsten Brix: \"Drongurin, i\u00f0 burturtikin var\u00f0 av sj\u00f3tr\u00f8llakonginum\", Var\u00f0anum bd. 59 1992, s. 188-219. \\n Jakob Jakobsen: F\u00e6r\u00f8ske Folkesagn og \u00c6ventyr 1899-1901.\\n\\n\u00c6vint\u00fdr\\nF\u00f3lkaminni',\n    \"question\": 'Hvat var heiti\u00f0 \u00e1 b\u00f3kini eftir Charles Perrault?',\n    \"answers\": {\n        \"answer_start\": array([1743]),\n        \"text\": array(['S\u00f8gur og fr\u00e1sagnir \u00far farnum t\u00ed\u00f0um vi\u00f0 undirheitinum \"G\u00e1sam\u00f3\u00f0ir sigur fr\u00e1\" (Les Contes de ma M\u00e8re l\u2019Oye)'], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": 'Tr\u00f8llakampar (fr\u00f8\u00f0iheiti Asplenium) hoyra til tann b\u00f3lkin av plantum, i\u00f0 ver\u00f0ur kalla\u00f0ur bl\u00f3muleysar plantur. Ta\u00f0 finnast 20.000 sl\u00f8g av tr\u00f8llakampum \u00ed heiminum, og er hetta slagr\u00edkasta fylki, aftan\u00e1 fylki\u00f0 vi\u00f0 bl\u00f3muplantum, i\u00f0 telur 250.000 sl\u00f8g. Flestu sl\u00f8gini av tr\u00f8llakampum finnast \u00ed tropunum og tr\u00edvast best har v\u00e1tt er. Tr\u00f8llakampar ver\u00f0a mettir at vera \"primitivt\" plantuslag, i\u00f0 er n\u00e6r \u00ed \u00e6tt vi\u00f0 upprunaplanturnar. Teir hava ikki bl\u00f3mur og seta ikki fr\u00e6, men n\u00f8rast vi\u00f0 gr\u00f3kornum, i\u00f0 hj\u00e1 summum tr\u00f8llakampum sita \u00ed gr\u00f3h\u00f3pum aftanfyri \u00e1 bla\u00f0num, vardir av einum skj\u00f8ldri, sum opnar seg, t\u00e1 gr\u00f3kornini eru b\u00fagvin, so at tey kunnu spja\u00f0ast. Hj\u00e1 \u00f8\u00f0rum sita teir \u00e1 bla\u00f0kantinum, sum er rulla\u00f0ur inneftir, so leingi gr\u00f3kornini ikki eru b\u00fagvin. \\n\\nSummi tr\u00f8llakampasl\u00f8g hava tvey sl\u00f8g av bl\u00f8\u00f0um, eitt slag i\u00f0 er \u201csterilt\u201d og eitt sum er \u201cfertilt\u201d. Ta\u00f0 \u201cfertila\u201d bla\u00f0i\u00f0 kann hj\u00e1 summum sl\u00f8gum vera heilt ymiskt fr\u00e1 t\u00ed \u201csterila\u201d. Tr\u00f8llakampur kann hava gr\u00f3korn \u00ed milli\u00f3natali, men bert f\u00e1ar n\u00fdggjar plantur koma burtur\u00far. Bl\u00f8\u00f0ini hava ymiskt skap. Tey kunnu ver\u00f0a innskorin eina, tv\u00e6r og fleiri fer\u00f0ir ella als ikki innskorin. Vi\u00f0 s\u00ednum sermerkta vakstrarlagi l\u00edkist tr\u00f8llakampur, \u00e1\u00f0ur enn hann er fullvaksin, einum fi\u00f3lh\u00f8vdi ella t\u00ed evsta \u00e1 fi\u00f3lini.\\n\\n\u00datbrei\u00f0sla\\n\\nTr\u00f8llakampar v\u00f3ru n\u00f3gv vanligari \u00ed F\u00f8royum, \u00e1\u00f0renn f\u00f3lk settu b\u00fagv her. Hetta pr\u00f3gva s\u00e1kornskanningar. V\u00f8ksturin \u00ed F\u00f8royum er sum heild \u00e1virka\u00f0ur av sey\u00f0abiti, og hevur hann veri\u00f0 ta\u00f0, s\u00ed\u00f0an f\u00f3lk settu b\u00fagv her. Sey\u00f0urin leg\u00f0ist beinanvegin eftir t\u00ed fruktag\u00f3\u00f0a gr\u00f3\u00f0ri, sum landi\u00f0 var avvaksi\u00f0 vi\u00f0. Hesin gr\u00f3\u00f0urin hvarv eftir stuttari t\u00ed\u00f0 og broyttist til t\u00e6ttbitna gr\u00f3\u00f0urin, sum vit kenna \u00ed dag.  S\u00e1\u00f0kornskanningar v\u00edsa, at tr\u00f8llakampar sum heild f\u00f3ru n\u00f3gv aftur aftan \u00e1 landn\u00e1m. Teir eru av elstu plantusl\u00f8gum \u00e1 j\u00f8r\u00f0 og vuksu her fyri meira enn 300 mi\u00f3 \u00e1rum s\u00ed\u00f0an. \u00cd kolt\u00ed\u00f0ini vuksu tr\u00f8llakampur, javni og bj\u00f8lluv\u00edsa sum st\u00f3rir sk\u00f3gir.\\n\\nIkki allasta\u00f0ni er sey\u00f0ur sloppin framat at b\u00edta. T\u00ed s\u00e6st enn tann mest upprunaligi gr\u00f3\u00f0urin \u00ed gj\u00e1um og bakkum, har sey\u00f0ur ikki er sloppin framat. Her er gr\u00f3\u00f0urin st\u00f3rur og fj\u00f8lbroyttur, og kanningar bera pr\u00f3gv um, at hann hevur veri\u00f0 st\u00f8\u00f0ugur \u00ed langa t\u00ed\u00f0 av teirri ors\u00f8k, at sey\u00f0ur og f\u00f3lk ikki sluppu framat. Av teimum tr\u00f8llakampum, i\u00f0 eru vanligir \u00ed F\u00f8royum, eru fyrst og fremst tann st\u00f3rvaksni tr\u00f8llakalskampurin, tann heldur f\u00ednari mj\u00faki kvennkampurin og dimmgr\u00f8ni ekstur bl\u00f3\u00f0kampurin. Hesir tr\u00f8llkampar eru n\u00f3gv vanligari \u00ed londunum sunnan fyri enn nor\u00f0an fyri okkum.\\n\\nFleiri sl\u00f8g av tr\u00f8llakampum finnast \u00ed brattlendi. L\u00e6ttast er at f\u00e1a eyga \u00e1 tann st\u00f3rvaksna tr\u00f8llakallskampin og tann n\u00e6stan l\u00edka st\u00f3rvaksna mj\u00faka kvennkampin. S\u00e1\u00f0kornskanningar hava v\u00edst, at \u00fatbrei\u00f0slan av tr\u00f8llakampum minka\u00f0i \u00f3gvuliga n\u00f3gv, t\u00e1 i\u00f0 f\u00f3lk settu b\u00fagv \u00ed F\u00f8royum og h\u00f8vdu h\u00fasdj\u00f3r s\u00edni vi\u00f0 s\u00e6r.\\n\\nFimtan sl\u00f8g av tr\u00f8llakampum finnast \u00ed F\u00f8royum. Flestu av teimum d\u00e1mar best at vaksa \u00ed klettarivum, har v\u00e1tt og skuggi er - men eisini \u00ed gr\u00fdtutum lendi, brattlendi og gj\u00e1um. Ein tann mest vanligi tr\u00f8llakampurin \u00ed F\u00f8royum er f\u00ednur klettakampur, me\u00f0an svartur tr\u00f8llakampur og str\u00e1lh\u00e6rdur tr\u00f8llakampur eru sera sj\u00e1ldsamir og bert finnast \u00e1 einum sta\u00f0. \\n\\n\u00cd 2007 var\u00f0 n\u00fdtt tr\u00f8llakampaslag funni\u00f0 \u00ed brattlendi \u00ed Nor\u00f0uroyggjum. Hetta er tungutr\u00f8llakampur (Asplenium scolopendrium). Hesin tr\u00f8llakampur er eisini sj\u00e1ldsamur \u00ed hinum Nor\u00f0urlondunum.\\n\\nKelda\\n Stamps.fo\\n\\nS\u00ed eisini\\n Plantul\u00edvi\u00f0 \u00ed F\u00f8royum\\n\\nPlantur \u00ed F\u00f8royum\\nPlantur',\n    \"question\": 'Hvussu mong tr\u00f8llakamps sl\u00f8g eru til \u00ed F\u00f8royum?',\n    \"answers\": {\n        \"answer_start\": array([2782]),\n        \"text\": array(['Fimtan'], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Hetta eru tekstir saman vi\u00f0 spurningum og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekstur: {text}\nSpurningur: {question}\nSvara vi\u00f0 \u00ed mesta lagi trimum or\u00f0um: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekstur: {text}\n\nSvara hesum spurninginum um tekstin uppiyvir vi\u00f0 \u00ed mesta lagi trimum or\u00f0um.\n\nSpurningur: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-fo\n</code></pre>"},{"location":"datasets/finnish/","title":"\ud83c\uddeb\ud83c\uddee Finnish","text":"<p>This is an overview of all the datasets used in the Finnish part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/finnish/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/finnish/#scandisent-fi","title":"ScandiSent-fi","text":"<p>This dataset consists of reviews from Trustpilot and was published here. It is a binary sentiment classification dataset, with labels \"positive\" and \"negative\".</p> <p>For the Finnish part of the dataset, there are 10,000 training samples. From these samples, we have created a 1,024 / 256 / 2,048 split for the train, validation and test splits, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Kaikki meni niinkuin piti. Nopea toimitus.\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En pid\u00e4 t\u00e4st\u00e4, kun ei l\u00f6ydy linkki\u00e4 mist\u00e4 p\u00e4\u00e4sis heti maksamaan. En todellakaan pid\u00e4 siit\u00e4, ett\u00e4 joka tieto pit\u00e4\u00e4 kopioida erikseen. Haluaisin p\u00e4\u00e4st\u00e4 suoraan oston j\u00e4lkeen maksamaa mobiilipankkiin. Pari laskua on j\u00e4\u00e4nyt t\u00e4n takia kokonaan huomioimatta. Ja ihan turhaa.... \u00e4rsytt\u00e4\u00e4 sitten se kotiin tuleva muistutuslasku.\",\n  \"label\": \"negative\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Todella hidas toimitus, ja virheellist\u00e4 tietoa tuotteiden saatavuudesta, paketti ja tuotteet perill\u00e4 vasta kuukauden p\u00e4\u00e4st\u00e4 tilauksesta....\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Seuraavassa on arvosteluja ja niiden tunnes\u00e4vy, joka voi olla 'positiivinen' tai 'negatiivinen'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teksti: {text}\nTunnes\u00e4vy: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teksti: {text}\n\nLuokittele arvostelun tunnes\u00e4vy. Vastaa vain 'positiivinen' tai 'negatiivinen', ei muuta.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positiivinen</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negatiivinen</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scandisent-fi\n</code></pre>"},{"location":"datasets/finnish/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/finnish/#turku-ner-fi","title":"Turku-NER-fi","text":"<p>This dataset was published in this paper. The dataset is a manually annotated corpus built on the Universal Dependencies Finnish corpus. The corpus was created by the Turku NLP group.</p> <p>The original dataset contains 12,217 / 1,364 / 1,555 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": [\"Suomalaiset\", \"vaihtoivat\", \"Tukholman\", \"Tallinnaan\"],\n  \"labels\": [\"O\", \"O\", \"B-LOC\", \"B-LOC\"]\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Liuhto', 'nosti', 'Kreikan', 'tapauksen', 'yhteydess\u00e4', 'esille', 'kysymyksen', 'siit\u00e4', ',', 'miten', 'Euroopan', 'unionissa', 'yleisesti', 'sanktioidaan', 'pelis\u00e4\u00e4nt\u00f6jen', 'rikkomisesta', '.'], dtype=object),\n  \"labels\": array(['B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Mithridates', 'oli', 'Pontoksen', 'merkitt\u00e4vin', 'kuningas', 'ja', 'Rooman', 'valtakunnan', 'vaarallisin', 'vihollinen', 'ensimm\u00e4isell\u00e4', 'vuosisadalla', 'eaa.', '.'], dtype=object),\n  \"labels\": array(['B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Seuraavassa on lauseita ja JSON-sanakirjoja, jotka sis\u00e4lt\u00e4v\u00e4t annetussa lauseessa esiintyv\u00e4t nimetyt entiteetit.\n</code></pre></li> <li>Base prompt template:   <pre><code>Lause: {text}\nNimetyt entiteetit: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Lause: {text}\n\nTunnista lauseessa esiintyv\u00e4t nimetyt entiteetit. Tulosta ne JSON-sanakirjana, jonka avaimet ovat 'henkil\u00f6', 'paikka', 'organisaatio' ja 'muut'. Arvojen tulee olla listoja kyseisen tyypin nimetyist\u00e4 entiteeteist\u00e4 t\u00e4sm\u00e4lleen siin\u00e4 muodossa kuin ne esiintyv\u00e4t lauseessa.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diverse</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diverse</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset turku-ner-fi\n</code></pre>"},{"location":"datasets/finnish/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/finnish/#scala-fi","title":"ScaLA-fi","text":"<p>This dataset was published in this paper and was automatically created from the Finnish Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 15,136 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Vuotta aiempaan verrattuna uusia ajoneuvoja rekister\u00f6itiin 17,6 prosenttia enemm\u00e4n.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"20-vuotias sai aiemmin marraskuussa 2006 Helsingin k\u00e4r\u00e4j\u00e4oikeudelta 30 p\u00e4iv\u00e4sakkoa Ta... varastettujen vaatteiden hallussapidosta.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Kun k\u00e4ytt\u00e4j\u00e4 kirjoittaa viestin, se n\u00e4kyy k\u00e4ytt\u00e4j\u00e4n k\u00e4ytt\u00e4j\u00e4listassa.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Seuraavat ovat lauseita ja ovatko ne kieliopillisesti oikein.\n</code></pre></li> <li>Base prompt template:   <pre><code>Lause: {text}\nKieliopillisesti oikein: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Lause: {text}\n\nM\u00e4\u00e4rit\u00e4 onko lause kieliopillisesti oikein vai ei. Vastaa 'kyll\u00e4', jos lause on oikein, ja 'ei', jos se ei ole.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>kyll\u00e4</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>ei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-fi\n</code></pre>"},{"location":"datasets/finnish/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/finnish/#tydiqa-fi","title":"TydiQA-fi","text":"<p>This question-answering dataset was published in this paper. TydiQA is a multilingual dataset covering 11 typologically diverse languages with 204K question-answer pairs collected from native speakers genuinely seeking information. It was designed to evaluate models across languages with varied linguistic features and contains questions written directly in each language without translation.</p> <p>The original Finnish TydiQA dataset contains 6,855 training and 782 validation samples (we use the secondary task subset). We created a 1,024 / 256 / 2,024 split, where the samples from the train and validation split are sampled from the original train and validation splits, respectively. The test set consists of the remaining samples from the original validation split + additional samples from the original train split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"question\": \"Kuka n\u00e4ytteli Dumbledorea Harry Potter elokuvissa?\",\n  \"context\": \"Dumbledorea esitt\u00e4\u00e4 kirjasarjasta tehdyss\u00e4 elokuvasarjassa Richard Harris kahdessa ensimm\u00e4isess\u00e4 elokuvassa. Harrisin kuoltua Michael Gambon esitti hahmoa sarjan lopuissa elokuvissa.\",\n  \"answers\": {\n    \"text\": [\"Richard Harris kahdessa ensimm\u00e4isess\u00e4 elokuvassa. Harrisin kuoltua Michael Gambon\"],\n    \"answer_start\": [59]\n  }\n}\n</code></pre> <pre><code>{\n  \"question\": \"Milloin Cristiano Ronaldo liittyi Juventukseen?\",\n  \"context\": \"Ronaldo siirtyi hein\u00e4kuussa 2018 Juventukseen 105 miljoonalla eurolla. Sopimus on nelivuotinen, ja sen aikana h\u00e4n tienaa verojen j\u00e4lkeen noin 120 miljoonaa euroa.[133]\",\n  \"answers\": {\n    \"text\": [\"hein\u00e4kuussa 2018\"],\n    \"answer_start\": [16]\n  }\n}\n</code></pre> <pre><code>{\n  \"question\": \"Kuka hallitsi Mithridates VI j\u00e4lkeen?\",\n  \"context\": \"Mithridates laajensi valtakuntaansa ymp\u00e4ri Mustanmeren rantoja, ja h\u00e4n ajautui kolmesti sotaan Rooman valtakuntaa vastaan. Ensimm\u00e4isess\u00e4 sodassa (89 eaa.\u201385 eaa.) h\u00e4n valtasi suuren osan V\u00e4h\u00e4\u00e4-Aasiaa ja Rooman valtakunnalle kuuluneet osat, jolloin h\u00e4nen sanotaan teloittaneen 80000 roomalaista. Mithridates valtasi my\u00f6s Kreikan, mutta konsuli Sulla kukisti h\u00e4nen joukkonsa vuonna 85 eaa., ja Mithridateen oli luovuttava valloituksistaan. Toinen sota (83 eaa.\u201381 eaa.) oli suppeampi laajuudeltaan. Kolmannessa sodassa (73 eaa.\u201363 eaa.) roomalaiset sotap\u00e4\u00e4llik\u00f6t Lucullus ja Pompeius kukistivat Mithridateen perusteellisesti. Mithridates surmasi tai surmautti itsens\u00e4 jouduttuaan poikansa Farnakes II:n syrj\u00e4ytt\u00e4m\u00e4ksi.\",\n  \"answers\": {\n    \"text\": [\"Farnakes II\"],\n    \"answer_start\": [687]\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Seuraavassa on tekstej\u00e4 ja niihin liittyvi\u00e4 kysymyksi\u00e4 ja vastauksia.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teksti: {text}\nKysymys: {question}\nVastaa enint\u00e4\u00e4n 3 sanalla: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teksti: {text}\n\nVastaa seuraavaan kysymykseen yll\u00e4 olevasta tekstist\u00e4 enint\u00e4\u00e4n 3 sanalla.\n\nKysymys: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset tydiqa-fi\n</code></pre>"},{"location":"datasets/finnish/#unofficial-belebele-fi","title":"Unofficial: BeleBele-fi","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Toisin kuin muut k\u00e4delliset, isot ihmisapinat eiv\u00e4t en\u00e4\u00e4 k\u00e4yt\u00e4 k\u00e4si\u00e4\u00e4n liikkumiseen, painon kannattelemiseen tai liikkumiseen puissa itse\u00e4\u00e4n heilautellen. Simpanssin k\u00e4si ja jalka ovat samankokoisia ja -pituisia, mik\u00e4 viittaa siihen, ett\u00e4 k\u00e4delle varataan painoa rystyk\u00e4velyss\u00e4. Ihmisen k\u00e4si on lyhyempi kuin jalka, ja sen sormiluut ovat suoremmat. Kahden-kolmen miljoonan vuoden ik\u00e4iset k\u00e4siluiden fossiilit paljastavat k\u00e4den erikoistumisessa t\u00e4m\u00e4n muutoksen liikkumisesta k\u00e4yttelyyn.\\nKysymys: Mik\u00e4 seuraavista kuvaa tarkasti simpanssin sormiluita?\\nVaihtoehdot:\\na. Ne ovat suoremmat kuin ihmisill\u00e4\\nb. Niiden k\u00e4det ja jalat ovat erikokoisia\\nc. Niit\u00e4 k\u00e4ytet\u00e4\u00e4n painon kannattelemiseen\\nd. Niit\u00e4 k\u00e4ytet\u00e4\u00e4n p\u00e4\u00e4asiassa k\u00e4yttelyyn\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Panaman paperit on yl\u00e4k\u00e4site panamalaisen lakiyrityksen Mossack Fonsecan noin kymmenelle miljoonalle asiakirjalle, jotka vuodettiin lehdist\u00f6lle kev\u00e4\u00e4ll\u00e4 2016. Asiakirjoista selvisi, ett\u00e4 nelj\u00e4toista pankkia auttoi varakkaita asiakkaita piilottamaan miljardeja USA:n dollareita verojen ja muiden s\u00e4\u00e4ntelyjen v\u00e4ltt\u00e4miseksi. Brittil\u00e4isen sanomalehden The Guardianin mukaan Deutsche Bank hallitsi t\u00e4m\u00e4n toteuttamiseen k\u00e4ytetyist\u00e4 1 200 postilaatikkoyrityksest\u00e4 suunnilleen kolmasosaa. Seurasi maailmanlaajuisia protesteja ja useita rikossyytteit\u00e4, ja Islannin ja Pakistanin hallitusten johtajat kumpikin erosivat.\\nKysymys: Kuka brittil\u00e4isen lehdist\u00f6n v\u00e4itteen mukaan hallinnoi monia varojen piilottamisessa k\u00e4ytettyj\u00e4 yrityksi\u00e4 tekstikatkelman mukaan?\\nVaihtoehdot:\\na. Eri pankkien varakkaat asiakkaat\\nb. Panamalainen lakiyritys\\nc. Deutsche Bank\\nd. Pakistanin hallitus\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Teksti: Sundarban on maailman suurin mangrovemets\u00e4alue. Se ulottuu 80 kilometri\u00e4 (50 mailia) rannikolta Bangladeshin ja Intian takamaille. Sundarban on julistettu Unescon maailmanperint\u00f6kohteeksi. Mets\u00e4n Intian puolella sijaitsevaa osaa kutsutaan Sundarbanin kansallispuistoksi. Mets\u00e4t eiv\u00e4t kuitenkaan ole pelkki\u00e4 mangrovesoita, vaan niihin kuuluu joitakin viimeisi\u00e4 j\u00e4\u00e4nteit\u00e4 niist\u00e4 mahtavista viidakoista, jotka aikoinaan peittiv\u00e4t koko Gangesin tasangon. Sundarban kattaa 3 850 neli\u00f6kilometrin alueen, josta noin kolmasosa on vesi- tai suoalueiden peitossa. Vuodesta 1966 asti Sundarbans on ollut villiel\u00e4inten suojelualue. Arvioidaan, ett\u00e4 siell\u00e4 on nyky\u00e4\u00e4n 400 intiantiikeri\u00e4 ja suunnilleen 30 000 aksishirve\u00e4.\\nKysymys: Mik\u00e4 mets\u00e4n osa on Intian puolella?\\nVaihtoehdot:\\na. Sundarbanin kansallispuisto\\nb. Villiel\u00e4inten suojelualue\\nc. Maailmanperint\u00f6kohde\\nd. Gangesin tasanko\",\n  \"label\": \"a\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Seuraavat ovat monivalintakysymyksi\u00e4 (vastauksineen).\n</code></pre></li> <li>Base prompt template:   <pre><code>Kysymys: {text}\nVaihtoehdot:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nVastaus: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Kysymys: {text}\nVaihtoehdot:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nVastaa yll\u00e4 olevaan kysymykseen k\u00e4ytt\u00e4m\u00e4ll\u00e4 'a', 'b', 'c' tai 'd', \u00e4l\u00e4k\u00e4 mit\u00e4\u00e4n muuta.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-fi\n</code></pre>"},{"location":"datasets/finnish/#unofficial-multiwikiqa-fi","title":"Unofficial: MultiWikiQA-fi","text":"<p>This dataset will be published in an upcoming paper, and contains Finnish Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Aarne Silvio Heikinheimo (20. maaliskuuta 1894 Tornio \u2013 24. tammikuuta 1938) oli suomalainen j\u00e4\u00e4k\u00e4rikenraalimajuri. H\u00e4nen vanhempansa olivat ylimets\u00e4nhoitaja Johan Henrik Heikel ja Sally Armida Thauv\u00f3n. H\u00e4net vihittiin avioliittoon vuonna 1919 Sylvi Amalia Jurveliuksen kanssa.\\n\\nOpinnot\\nHeikinheimo kirjoitti ylioppilaaksi Oulun suomalaisesta yhteiskoulusta vuonna 1913 ja liittyi Pohjois-Pohjalaiseen Osakuntaan. Opintojaan h\u00e4n jatkoi Teknillisen korkeakoulun koneinsin\u00f6\u00f6riosastolla vuosina 1913\u20131914. H\u00e4n seurasi opetusta Sotakorkeakoulun komentajakurssilla vuonna 1925 ja k\u00e4vi Sotakorkeakoulun yleisen osaston vuosina 1926\u20131927.\\n\\nJ\u00e4\u00e4k\u00e4riaika\\nH\u00e4n liittyi yhten\u00e4 ensimm\u00e4isten vapaaehtoisten joukkoon, jonka p\u00e4\u00e4m\u00e4\u00e4r\u00e4n\u00e4 oli Saksassa sotilaskoulutusta antava Pfadfinder-kurssi, joka j\u00e4rjestettiin Pohjois-Saksassa sijaitsevalla Lockstedter Lagerin harjoitusalueella. Leirille h\u00e4n ilmoittautui 25. helmikuuta 1915. H\u00e4net sijoitettiin joukon 1. komppaniaan. My\u00f6hemmin h\u00e4net sijoitettiin Kuninkaallisen, Preussin J\u00e4\u00e4k\u00e4ripataljoona 27:n 1. komppaniaan. H\u00e4n otti osaa taisteluihin ensimm\u00e4isess\u00e4 maailmansodassa Saksan it\u00e4rintamalla Misse-joella, Riianlahdella ja Aa-joella. H\u00e4n osallistui kes\u00e4ll\u00e4 vuonna 1917 Libaussa j\u00e4rjestetyille moottoriveneenkuljettaja- ja konekiv\u00e4\u00e4riasemestarikursseille ja  elokuussa vuonna 1917 Schaulenissa j\u00e4rjestetylle autokurssille  sek\u00e4 syksyll\u00e4 Libaussa vuonna 1917 j\u00e4rjestetylle r\u00e4j\u00e4ytyskurssille.\\n\\nSuomen sis\u00e4llissota\\n\\nKatso my\u00f6s: Suomen sis\u00e4llissota\\nH\u00e4n saapui Suomeen oberzugf\u00fchrer Friedel Jacobssonin komennuskunnan mukana 30. tammikuuta 1918 ja liittyi Per\u00e4-Pohjolan suojeluskuntajoukkoihin Tervolassa. H\u00e4net komennettiin joukkueenjohtajaksi Tervolaa ja Torniota vastaan taisteleviin joukkoihin. Tervolan ja Tornion valtausten j\u00e4lkeen h\u00e4net nimitettiin Kemin kaupungin komendantiksi 7. helmikuuta, kunnes 5. maaliskuuta h\u00e4net nimitettiin Per\u00e4-Pohjolan pataljoonan komentajaksi. H\u00e4n johdatti pataljoonansa taisteluihin Vilkkil\u00e4ss\u00e4, Haavistolla (Oriveden), Tervaniemess\u00e4, Lemp\u00e4\u00e4l\u00e4ss\u00e4, Vesilahdella, Karkussa ja Tyrv\u00e4\u00e4ll\u00e4. Sis\u00e4llissodan loppuvaiheissa h\u00e4n sai teht\u00e4v\u00e4kseen muodostaa Lahdessa It\u00e4-Uudenmaan rykmentin.\\n\\nSis\u00e4llissodan j\u00e4lkeinen aika\\n\\nSis\u00e4llissodan j\u00e4lkeen Heikinheimo m\u00e4\u00e4r\u00e4ttiin 1. hein\u00e4kuuta 1918 alkaen 1. Divisioonan adjutantiksi ja my\u00f6hemmin v\u00e4liaikaiseksi esikuntap\u00e4\u00e4llik\u00f6ksi, josta h\u00e4net siirrettiin 15. elokuuta 1918 Suomen valkoisen kaartin I pataljoonan komentajaksi ja edelleen komentajaksi 11. syyskuuta 1918 Viipurin rykmentin II pataljoonaan. II Polkupy\u00f6r\u00e4pataljoonan komentajaksi h\u00e4net siirrettiin 27. huhtikuuta 1921 ja Viipurin rykmentin komentajaksi 15. elokuuta 1924. H\u00e4n toimi 12. elokuuta 1926 alkaen komentajana J\u00e4\u00e4k\u00e4riprikaatissa, josta h\u00e4net siirrettiin komentajaksi 3. Divisioonaan 9. kes\u00e4kuuta 1928. Esikuntateht\u00e4viin h\u00e4net siirrettiin 25. elokuuta 1934 ja sijoitettiin Yleisesikuntaan ja m\u00e4\u00e4r\u00e4ttiin jalkav\u00e4en tarkastajaksi. H\u00e4n menehtyi tapaturmaisesti koeammunnoissa Harakan saarella kranaatinheittimen putken r\u00e4j\u00e4hdetty\u00e4 24. tammikuuta 1938. H\u00e4net on haudattu Ouluun Inti\u00f6n hautausmaalle, aivan sankarihautojen viereen.\\n\\nLuottamustoimet\\nHeikinheimo toimi 2. Divisioonan kunniatuomioistuimen puheenjohtajana vuonna 1920 ja  3. Divisioonan kunniatuomioistuimen puheenjohtajana vuosina 1921 ja 1925. Polkupy\u00f6r\u00e4joukkojen erikoiskysymyksi\u00e4 k\u00e4sitelleen komitean j\u00e4senen\u00e4 h\u00e4n toimi vuonna 1922 ja polkupy\u00f6r\u00e4joukkojen ohjes\u00e4\u00e4nt\u00f6komitean puheenjohtajana vuonna 1924 sek\u00e4 pikakiv\u00e4\u00e4rinkokeilukomitean j\u00e4senen\u00e4 vuosina 1924\u20131925. Talvivarustuskomitean j\u00e4senen\u00e4 h\u00e4n toimi vuonna 1924 ja kentt\u00e4varustustoimikunnan puheenjohtajana vuosina 1931\u20131934 sek\u00e4 ohjes\u00e4\u00e4nt\u00f6komitean puheenjohtajana vuonna 1934. Mikkelin kaupunkiseurakunnan lis\u00e4tyn kirkkovaltuuston j\u00e4senen\u00e4 h\u00e4n toimi vuosina 1933\u20131934.\\n\\nL\u00e4hteet \\n Puolustusministeri\u00f6n Sotahistoriallisen toimiston julkaisuja IV, Suomen j\u00e4\u00e4k\u00e4rien el\u00e4m\u00e4kerrasto, WSOY Porvoo 1938.\\n Sotatieteen Laitoksen Julkaisuja XIV, Suomen j\u00e4\u00e4k\u00e4rien el\u00e4m\u00e4kerrasto 1975, Vaasa 1975 ISBN 951-99046-8-9.\\n\\nViitteet \\n\\nJ\u00e4\u00e4k\u00e4rikenraalit\\nVuonna 1894 syntyneet\\nVuonna 1938 kuolleet\",\n    \"question\": \"Milloin Aarne Heikinheimo sai ylioppilastutkinnon suoritettua?\",\n    \"answers\": {\n        \"answer_start\": array([365]),\n        \"text\": array([\"1913\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Peter Costa (s. 17. tammikuuta K\u00edti, Kypros) on englantilainen Las Vegasissa asuva pokeriammattilainen. H\u00e4nen vanhempansa ovat kyproksenkreikkalaisia. Perhe muutti Liverpooliin Peterin ollessa nuori. Perheen yritys myi \\\"fish and chipsej\u00e4\\\" ja yritys laajentui my\u00f6hemmin ketjuksi.\\n\\nBritteinsaarilla Costa tuli tunnetuksi voitettuaan Late Night Pokerin kuudennen tuotantokauden finaalin. Lopun kaksinpeliss\u00e4 Costa kukisti it\u00e4valtalaisen Jin Cai Linin ja ansaitsi 60\\xa0000 puntaa.\\n\\nTammikuussa 2003 Costa voitti Aussie Millions -tapahtuman p\u00e4\u00e4turnauksen ja ansaitsi ykk\u00f6stilastaan 394\\xa0870 Australian dollaria. Costalla on my\u00f6s useita turnausvoittoja Yhdysvalloista: esimerkiksi kes\u00e4kuussa 2002 h\u00e4n voitti kolme turnausta kolmessa viikossa \u2013 kaikissa n\u00e4iss\u00e4 ykk\u00f6spalkinto oli yli 110\\xa0000 dollaria. \\n\\nWorld Series of Pokerissa Costa on parhaimmillaan ollut seitsem\u00e4s (kaksi kertaa). World Poker Tourilta h\u00e4nell\u00e4 on rahasijoja, mutta ei toistaiseksi finaalip\u00f6yt\u00e4sijoituksia.\\n\\nVuosina 2002 ja 2003 Costa oli ehdolla Europaan parhaan pelaajan palkinnon saajaksi. H\u00e4n teki maailmanenn\u00e4tyksen voitettuaan kaikkien aikojen suurimman (1\\xa0166 pelaajaa) limiitti-hold\\'em -turnauksen Orleansin kasinolla hein\u00e4kuussa 2003.\\n\\nKes\u00e4kuussa 2007 Costan pokeriuran turnausansiot ylittiv\u00e4t 1,7 miljoonaa dollaria.\\n\\nL\u00e4hteet\\n\\nAiheesta muualla \\n\\n \\n WPT:n profiili\\n PokerListings.com:n profiili \\n\\nBrittil\u00e4iset pokerinpelaajat\",\n    \"question\": \"Mik\u00e4 on Peter Costan asuinpaikka?\",\n    \"answers\": {\n        \"answer_start\": array([63]),\n        \"text\": array([\"Las Vegasissa\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Sigrid Vaasa (1566\u20131633) oli Ruotsin kuninkaan Eerik XIV:n ja h\u00e4nen puolisonsa Kaarina Maununtytt\u00e4ren tyt\u00e4r.\\n\\nSigrid Vaasa asui lapsuudessaan \u00e4itins\u00e4 Kaarina Maununtytt\u00e4ren kanssa Liuksialan kartanossa ja j\u00e4\u00e4ty\u00e4\u00e4n kahdesti leskeksi palasi asumaan sinne kuolemaansa asti. Vuonna 1597 h\u00e4n avioitui Henrik Klaunpoika Tottin kanssa. Sen j\u00e4lkeen oli Kirkniemen ja Sjundbyn kartanoiden em\u00e4nt\u00e4. Heid\u00e4n lapsistaan merkitt\u00e4vin oli \u00c5ke Tott, joka sai mainetta kuningas Kustaa II Aadolfin johtamissa sodissa. Kaarle-herttuan ja Sigismundin valtataistelun aikana Henrik Tott asettui suomalaisten aatelismiesten ja sit\u00e4 kautta my\u00f6s Sigismundin puolelle, mink\u00e4 vuoksi h\u00e4n joutui pakenemaan maasta ja kuoli ilmeisesti noin vuonna 1603 maanpaossa. Sigrid solmi uuden avioliiton vuonna 1609 Natt och Dag -sukuun kuuluvan Nils Nilsinpojan kanssa, muutti Ruotsiin mutta j\u00e4i nelj\u00e4n vuoden kuluttua leskeksi. Leskeksi j\u00e4\u00e4ty\u00e4\u00e4n h\u00e4n palasi Suomeen ja kuoli Liuksialassa.\\n\\nL\u00e4hteet\\n\\nRuotsin prinsessat\\nVuonna 1566 syntyneet\\nVuonna 1633 kuolleet\",\n    \"question\": \"Mill\u00e4 kartanolla Sigrid Vaasa vietti lapsuusvuotensa?\",\n    \"answers\": {\n        \"answer_start\": array([180]),\n        \"text\": array([\"Liuksialan kartanossa\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Seuraavassa on tekstej\u00e4 ja niihin liittyvi\u00e4 kysymyksi\u00e4 ja vastauksia.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teksti: {text}\nKysymys: {question}\nVastaa enint\u00e4\u00e4n 3 sanalla: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teksti: {text}\n\nVastaa seuraavaan kysymykseen yll\u00e4 olevasta tekstist\u00e4 enint\u00e4\u00e4n 3 sanalla.\n\nKysymys: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-fi\n</code></pre>"},{"location":"datasets/finnish/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/finnish/#hellaswag-fi","title":"HellaSwag-fi","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The dataset was created by Finnish-NLP using Google Translate. The dataset is designed to be used in EuroEval and it therefore already has a 1,024 / 256 / 2,048 split for the train, validation and test splits, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[Otsikko ] Tiikkihuonekalujen tahraus [vaihe] Pyyhi lika, p\u00f6ly ja roskat pois. [vaihe] Voit harjata lian pois kuivalla paperipyyhkeell\u00e4 tai liinalla. Jos puhdistettavia kohtia on sitke\u00e4mpi\u00e4, voit hieroa ne puhtaaksi kostealla rievulla.\\nVastausvaihtoehdot:\\na. [vaihe] Poista tahrat tiikist\u00e4 pyyhkim\u00e4ll\u00e4 ne kuivalla talouspaperilla. [vaihe] Noudata samoja puhdistustoimenpiteit\u00e4, joita k\u00e4ytit tahran kanssa.\\nb. Aja niiden yli puhdistusaineella, kunnes tahra on poissa. [vaihe] Kokeile puupetsin ja \u00f6ljyn yhdistelm\u00e4\u00e4.\\nc. [v\u00e4livaiheet] \u00c4l\u00e4 k\u00e4yt\u00e4 puhdistusaineita. Saatat vahingoittaa puuta, mutta vaikeutat varmasti v\u00e4rj\u00e4ysprosessia.\\nd. Poista mahdollisimman paljon likaa levitt\u00e4m\u00e4ll\u00e4 tahra kevyelle, p\u00f6rr\u00f6iselle liinalle tai k\u00e4delle ja pyyhkim\u00e4ll\u00e4 se pois. [vaihe] K\u00e4yt\u00e4 hankaamiseen valkaisuainetta ja vett\u00e4.\",\n  \"label\": \"c\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Pieni ryhm\u00e4 ihmisi\u00e4 n\u00e4hd\u00e4\u00e4n uimassa altaan ymp\u00e4rill\u00e4 ja johtaa useisiin laukauksiin, joissa uimari heitt\u00e4\u00e4 pallon verkkoon. Maalivahti torjuu muutaman laukauksen ja vaihtaa sitten toisen joukkuetoverinsa kanssa yleis\u00f6n hurraten. ihmisi\u00e4\\nVastausvaihtoehdot:\\na. cheer viel\u00e4 kerran ja palaa uimaan uima-altaan ymp\u00e4rille.\\nb. vaihda jatkuvasti pois ja johtaa siihen, ett\u00e4 yksi joukkue voittaa ja juhlii kaikki yhdess\u00e4 vedess\u00e4.\\nc. Curra ja hypp\u00e4\u00e4 vuorotellen yl\u00f6s ja eteenp\u00e4in pelaamalla biljardia.\\nd. ensimm\u00e4inen video, jossa muut joukkuetoverit sukeltavat altaaseen ja hypp\u00e4\u00e4v\u00e4t yl\u00f6s ja alas ponnahduslaudalla.\",\n  \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Kahden ihmisen n\u00e4hd\u00e4\u00e4n k\u00e4velev\u00e4n p\u00f6yt\u00e4jalkapallop\u00f6yd\u00e4n ymp\u00e4rill\u00e4 pelaamassa. ihmisi\u00e4\\nVastausvaihtoehdot:\\na. pit\u00e4k\u00e4\u00e4 kupit yl\u00f6s ja alakaa pelata peli\u00e4 ja ly\u00f6d\u00e4 toisianne.\\nb. Tartu sauvoista ja ly\u00f6 palloa p\u00f6yd\u00e4n ymp\u00e4rill\u00e4.\\nc. Jatka k\u00e4velemist\u00e4 ja yksi henkil\u00f6 ly\u00f6 pallon verkon yli.\\nd. siirr\u00e4 ymp\u00e4ri p\u00f6yt\u00e4\u00e4 heitt\u00e4en palloa ymp\u00e4riins\u00e4, kun ihmiset katselevat sivuilla.\",\n  \"label\": \"b\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Seuraavat ovat monivalintakysymyksi\u00e4 (vastauksineen).\n</code></pre></li> <li>Base prompt template:   <pre><code>Kysymys: {text}\nVastausvaihtoehdot:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nVastaus: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Kysymys: {text}\nVastausvaihtoehdot:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nVastaa yll\u00e4 olevaan kysymykseen k\u00e4ytt\u00e4m\u00e4ll\u00e4 'a', 'b', 'c' tai 'd', \u00e4l\u00e4k\u00e4 mit\u00e4\u00e4n muuta.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-fi\n</code></pre>"},{"location":"datasets/finnish/#unofficial-goldenswag-fi","title":"Unofficial: GoldenSwag-fi","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Miten auton ulkoinen pesu tehd\u00e4\u00e4n oikein. Ensimm\u00e4inen asia, joka sinun on teht\u00e4v\u00e4 kunnolla, on pest\u00e4 autosi tehokkaasti. Ei ole mit\u00e4\u00e4n j\u00e4rke\u00e4 yritt\u00e4\u00e4 tehd\u00e4 auton ulkoista detaljointia, jos p\u00e4\u00e4dyt vain naarmuttamaan ducosi entist\u00e4 enemm\u00e4n, koska j\u00e4tit autoosi likaa. Sinun on ensin huuhdeltava autosi letkulla kovalla paineella.\\nVastausvaihtoehdot:\\na. T\u00e4m\u00e4 poistaa suurimman osan liasta moottoristasi ja pit\u00e4\u00e4 moottorin moitteettomana. K\u00e4yt\u00e4 autosi pesemiseen korkeapainepesukoneita.\\nb. Sitten sinun on alettava imuroida likaa pois. Kun olet poistanut mahdollisimman paljon likaa, voit palata ajoneuvon luokse ker\u00e4\u00e4m\u00e4\u00e4n roskia.\\nc. Vie letku kaasuttimesta moottorilohkon yl\u00e4osaan, odota viisi minuuttia, sulje sitten vesi ja p\u00e4\u00e4st\u00e4 ilma ulos j\u00e4\u00e4hdyttimest\u00e4. Irrota vanhat tiivisteet ja aloita vedell\u00e4 pesu moottorin kannesta alas.\\nd. \u00c4l\u00e4 k\u00e4yt\u00e4 letkusta lasertyyppist\u00e4 pesua, vaan mieluummin pient\u00e4 suppiloa. Aloita aina ylh\u00e4\u00e4lt\u00e4 ja etene alasp\u00e4in.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Miten kylpe\u00e4 merisuolalla. Varaa itsellesi riitt\u00e4v\u00e4sti aikaa 15-20 minuutin kylpyyn. Kylpy ei ole kuin suihku, jossa usein kiirehdit\u00e4\u00e4n. Sen sijaan niiden on tarkoitus kest\u00e4\u00e4 pidemp\u00e4\u00e4n, jotta keho ja mieli voivat rentoutua.\\nVastausvaihtoehdot:\\na. Ennen kylpy\u00e4 haluat, ett\u00e4 kehosi rentoutuu, ota p\u00e4ivitt\u00e4in noin minuutti rentoutumista. Kylvyst\u00e4 voi saada samoja hy\u00f6tyj\u00e4: suolahoito on helpompaa, mik\u00e4 voi v\u00e4hent\u00e4\u00e4 stressi\u00e4.\\nb. Jotta saisit kylvyst\u00e4si suurimman hy\u00f6dyn, suunnittele, ett\u00e4 viet\u00e4t vedess\u00e4 15-20 minuuttia. Ota suolakylpy illalla, jos haluat hoitaa unettomuutta.\\nc. Jos haluat nopean kylpyl\u00e4kokemuksen, 15-20 minuutin kylpy voi olla hyv\u00e4 valinta. Anna itsellesi muutama tunti aikaa tottua l\u00e4mpim\u00e4\u00e4n, rentouttavaan veteen.\\nd. Jos sinulla on kiire, saatat j\u00e4nnitty\u00e4 niin paljon, ett\u00e4 menet\u00e4t ajantajusi. Jos v\u00e4syt, ota my\u00f6s nopea 15-20 minuutin kylpy.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Kuinka tehd\u00e4 yl\u00f6snousemuss\u00e4mpyl\u00f6it\u00e4. Kaada maito kulhoon. Jotta hiiva aktivoituu, sinun on sekoitettava se l\u00e4mpim\u00e4\u00e4n nesteeseen. Lis\u00e4\u00e4 \u00bd kupillista (118 ml) l\u00e4mmint\u00e4 maitoa tehosekoittimen kulhoon.\\nVastausvaihtoehdot:\\na. Jos haluat pidemm\u00e4n prosessin, voit juoksuttaa hiivan lavuaarissa ennen kuin jatkat.... Sekoita maito ja seos v\u00e4hitellen vispil\u00e4ll\u00e4.\\nb. Sekoita, kunnes maito on hyvin vaaleaa (noin 110 ml). Jos maito on liian pehme\u00e4\u00e4 t\u00e4h\u00e4n reseptiin, lis\u00e4\u00e4 1/2 kupillista (120 ml) smetanaa.\\nc. Maidon l\u00e4mp\u00f6tilan tulisi olla 105 \u00b0f (41 \u00b0c). Voit k\u00e4ytt\u00e4\u00e4 1- tai 2-prosenttista maitoa, mutta t\u00e4ysmaidosta saadaan yleens\u00e4 parhaat s\u00e4mpyl\u00e4t.\\nd. Jos sinulla on sauvasekoitin, voit tehd\u00e4 s\u00e4mpyl\u00f6iden taikinan itse. Tarvitset vain 2 kuppia (500 ml) maitoa.\",\n  \"label\": \"c\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Seuraavat ovat monivalintakysymyksi\u00e4 (vastauksineen).\n</code></pre></li> <li>Base prompt template:   <pre><code>Kysymys: {text}\nVastausvaihtoehdot:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nVastaus: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Kysymys: {text}\nVastausvaihtoehdot:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nVastaa yll\u00e4 olevaan kysymykseen k\u00e4ytt\u00e4m\u00e4ll\u00e4 'a', 'b', 'c' tai 'd', \u00e4l\u00e4k\u00e4 mit\u00e4\u00e4n muuta.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-fi\n</code></pre>"},{"location":"datasets/finnish/#summarization","title":"Summarization","text":""},{"location":"datasets/finnish/#xlsum-fi","title":"XLSum-fi","text":"<p>This dataset is a machine translation of the XL-Sum dataset, which was published in this paper. TurkuNLP has translated the dataset to Finnish using DeepL.</p> <p>The original Finnish XL-Sum dataset contains 54,966 / 1,803 / 1,791 training, validation and test samples, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The new training and validation splits are subsets of the original splits. The test split is the same as the original test split + additional samples from the original validation split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Poliisi kutsuttiin Century Wharfiin keskiviikkona noin kello 14:15 GMT. 66-vuotias mies on pid\u00e4tetty murhasta ep\u00e4iltyn\u00e4, ja h\u00e4nt\u00e4 pidet\u00e4\u00e4n vangittuna. Etel\u00e4-Walesin poliisi ilmoitti, ett\u00e4 se siirt\u00e4\u00e4 asian vapaaehtoisesti riippumattoman poliisin valituslautakunnan k\u00e4sitelt\u00e4v\u00e4ksi.\",\n  \"target_text\": \"Murhatutkinta on aloitettu sen j\u00e4lkeen, kun 65-vuotiaan naisen ruumis l\u00f6ytyi Cardiff Bayn asunnosta.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Yritys on nimitt\u00e4nyt KPMG:n tarkastelemaan uudelleenj\u00e4rjestelyvaihtoehtoja sen j\u00e4lkeen, kun paikallisviranomaisten menojen leikkaukset heikensiv\u00e4t sen liiketoimintan\u00e4kymi\u00e4. Southern tarjoaa hoitoa yli 31 000 ihmiselle, ja suurin osa rahoituksesta tulee NHS:lt\u00e4 ja kunnilta. Yrityksen mukaan budjettileikkaukset merkitsiv\u00e4t sit\u00e4, ett\u00e4 sen vuokrataakka oli 'kest\u00e4m\u00e4t\u00f6n'. Southern kertoi keskustelevansa vuokranantajien kanssa uudelleenj\u00e4rjestelyst\u00e4 ja varoitti my\u00f6s, ett\u00e4 se oli vaarassa j\u00e4tt\u00e4\u00e4 velkansa maksamatta. 'Yhti\u00f6n lainanantajat ovat tietoisia uhkaavasta pankkikovenanttirikkomuksesta, mutta ne tukevat edelleen t\u00e4ysin toimia, joihin yhti\u00f6 ryhtyy ongelmiensa ratkaisemiseksi', Southern sanoi lausunnossaan. Yhti\u00f6 vahvisti my\u00f6s, ettei se en\u00e4\u00e4 keskustele mahdollisten ostajien kanssa. 'Hallitus katsoo, ett\u00e4 yksik\u00e4\u00e4n n\u00e4ist\u00e4 ehdotuksista ei todenn\u00e4k\u00f6isesti johda siihen, ett\u00e4 l\u00e4hitulevaisuudessa teht\u00e4isiin mielek\u00e4s tarjous, ja se on p\u00e4\u00e4tt\u00e4nyt olla jatkamatta niiden k\u00e4sittely\u00e4', Southern totesi. Southernin osakkeet, joiden arvo oli 606 pence\u00e4 vuonna 2007, olivat keskip\u00e4iv\u00e4ll\u00e4 6,3 penni\u00e4.\",\n  \"target_text\": \"Yhdistyneen kuningaskunnan suurimman hoivakotien yll\u00e4pit\u00e4j\u00e4n Southern Cross Healthcaren osakkeet ovat romahtaneet 60 prosenttia, kun on uutisoitu, ett\u00e4 taloudelliset ongelmat ovat lis\u00e4\u00e4ntym\u00e4ss\u00e4.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Pohjois-Walesin palo- ja pelastusviranomainen vahvisti maanantaina talousarvionsa vuosiksi 2015-16. Viranomainen on suostunut leikkaamaan nelj\u00e4 johtoteht\u00e4v\u00e4\u00e4, leikkaamaan joitakin palveluja ja k\u00e4ytt\u00e4m\u00e4\u00e4n vararahastoa, jotta se voi hyv\u00e4ksy\u00e4 32,1 miljoonan punnan talousarvionsa. On pel\u00e4tty, ett\u00e4 sadat palomiehet voivat l\u00e4hte\u00e4 seuraavien viiden vuoden aikana teht\u00e4vien budjettileikkausten seurauksena.\",\n  \"target_text\": \"Pohjois-Walesin palomiehet lopettavat suurten el\u00e4inten pelastamisen ja v\u00e4hent\u00e4v\u00e4t v\u00e4\u00e4rien h\u00e4lytysten m\u00e4\u00e4r\u00e4\u00e4, jotta talous saataisiin tasapainoon.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Seuraavassa on artikkeleita ja niihin liittyvi\u00e4 tiivistelmi\u00e4.\n</code></pre></li> <li>Base prompt template:   <pre><code>Uutisartikkeli: {text}\nTiivistelm\u00e4: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Uutisartikkeli: {text}\n\nKirjoita tiivistelm\u00e4 yll\u00e4 olevasta artikkelista.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset xlsum-fi\n</code></pre>"},{"location":"datasets/french/","title":"\ud83c\uddeb\ud83c\uddf7 French","text":"<p>This is an overview of all the datasets used in the French part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/french/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/french/#allocine","title":"AlloCin\u00e9","text":"<p>This dataset was published in this Github repository and features reviews from the French movie review website AlloCin\u00e9. The reviews range from 0.5 to 5 (inclusive), with steps of 0.5. The negative samples are reviews with a rating of at most 2, and the positive ones are reviews with a rating of at least 4. The reviews in between were discarded.</p> <p>The original full dataset consists of 160,000 / 20,000 / 20,000 samples for training, validation, and testing, respectively. We use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively. All our splits are subsets of the original ones.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Ce 7\u00e8me volet ne m\u00e9rite pas de notre part une grande attention, au vu du pr\u00e9c\u00e9dent New Police Story. \u00c0 la limite du huis clos, Jackie \u00e9volue dans une bo\u00eete de nuit, sorte de pi\u00e8ge du m\u00e9chant cherchant \u00e0 se venger, ou du moins \u00e0 d\u00e9couvrir la v\u00e9rit\u00e9 sur la mort de sa s\u0153ur. Notre cascadeur acteur ne b\u00e9n\u00e9ficie pas d'un d\u00e9cors \u00e0 la hauteur de son potentiel acrobatique et le film d'un sc\u00e9nario \u00e0 la hauteur d'une production, et cette production d'une large distribution, ce qui explique son arriv\u00e9e direct tout \u00e9tag\u00e8re.\",\n  \"label\": \"negative\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Meme pour ceux qui n'aime pas les Chevaliers du Fiel allez voir. 1 il est meilleur que le 1 et cela est rare de voir une suite qui est meilleur que le 1. Des sc\u00e8nes qui peuvent faire rire les petit et les grands. On ne s'ennuie pas. Super film allez le voir. L'interpretation des acteurs sont super. Bonne journ\u00e9e\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Une ambiance envo\u00fbtante, un r\u00e9cit o\u00f9 se m\u00e9langent sorcellerie, croyances indiennes, enqu\u00eate polici\u00e8re sur fond de trafic de drogue, tout est conforme au livre de Tony Hillerman, m\u00eame si ce dernier a \\\"reni\u00e9\\\" le film. Personnellement j'adore. H\u00e9las introuvable en France et diffus\u00e9 seulement sur canal , il y a ..... un certain temps.\",\n  \"label\": \"positive\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Voici des textes et leur sentiment, qui peut \u00eatre 'positif' ou 'n\u00e9gatif'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texte: {text}\nSentiment: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texte: {text}\n\nClassez le sentiment dans le texte. R\u00e9pondez par \u2018positif' ou \u2018n\u00e9gatif'.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset allocine\n</code></pre>"},{"location":"datasets/french/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/french/#eltec","title":"ELTeC","text":"<p>This dataset was published in this paper and consists of sentences from 100 novels in French during the period 1840-1920, all of which are in the public domain. These novels were automatically labelled with named entities using Stanza-NER, and then manually corrected.</p> <p>The original dataset consists of 100 samples, one for each novel. We split the novels into sentences using the French NLTK sentence splitter, resulting in 4,815 samples. We use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003 labelling scheme, which is more common in the NER literature. The mapping is as follows:</p> <ul> <li><code>PERS</code> \u27a1\ufe0f <code>PER</code></li> <li><code>LOC</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>ORG</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>OTHER</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>DEMO</code> \u27a1\ufe0f <code>O</code></li> <li><code>ROLE</code> \u27a1\ufe0f <code>O</code></li> <li><code>EVENT</code> \u27a1\ufe0f <code>O</code></li> </ul> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  'tokens': array(['Jamais', 'ils', 'ne', 'firent', 'de', 'provisions', ',', 'except\u00e9', 'quelques', 'bottes', \"d'ail\", 'ou', \"d'oignons\", 'qui', 'ne', 'craignaient', 'rien', 'et', 'ne', 'co\u00fbtaient', 'pas', \"grand'chose\", ';', 'le', 'peu', 'de', 'bois', \"qu'ils\", 'consommaient', 'en', 'hiver', ',', 'la', 'Sauviat', \"l'achetait\", 'aux', 'fagotteurs', 'qui', 'passaient', ',', 'et', 'au', 'jour', 'le', 'jour', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['I', 'Il', 'y', 'avait', 'plus', 'de', 'soixante', 'ans', 'que', \"l'empereur\", 'Napol\u00e9on', ',', 'press\u00e9', \"d'argent\", ',', 'avait', 'vendu', 'les', 'provinces', 'de', 'la', 'Louisiane', '\u00e0', 'la', 'R\u00e9publique', 'des', '\u00c9tats-Unis', ';', 'mais', ',', 'en', 'd\u00e9pit', 'de', \"l'infiltration\", 'yankee', ',', 'les', 'traditions', 'des', 'cr\u00e9oles', 'fran\u00e7ais', 'se', 'perp\u00e9tuaient', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Les', 'fen\u00eatres', 'de', 'la', 'vieille', 'demeure', 'royale', ',', 'ordinairement', 'si', 'sombres', ',', '\u00e9taient', 'ardemment', '\u00e9clair\u00e9es', ';', 'les', 'places', 'et', 'les', 'rues', 'attenantes', ',', 'habituellement', 'si', 'solitaires', ',', 'd\u00e8s', 'que', 'neuf', 'heures', 'sonnaient', '\u00e0', \"Saint-Germain-l'Auxerrois\", ',', '\u00e9taient', ',', \"quoiqu'il\", 'f\u00fbt', 'minuit', ',', 'encombr\u00e9es', 'de', 'populaire', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Vous trouverez ci-dessous des phrases et des dictionnaires JSON avec les entit\u00e9s nomm\u00e9es qui apparaissent dans la phrase donn\u00e9e.\n</code></pre></li> <li>Base prompt template:   <pre><code>Sentence: {text}\nEntit\u00e9s nomm\u00e9es: {label}\n</code></pre></li> <li> <p>Instruction-tuned prompt template:   <pre><code>Sentence: {text}\n\nIdentifiez les entit\u00e9s nomm\u00e9es dans la phrase. Vous devez produire ceci sous forme de dictionnaire JSON avec les cl\u00e9s 'personne', 'lieu', 'organisation' et 'divers'. Les valeurs doivent \u00eatre des listes des entit\u00e9s nomm\u00e9es de ce type, exactement comme elles apparaissent dans la phrase.\n</code></pre></p> </li> <li> <p>Label mapping:</p> <ul> <li><code>B-PER</code> \u27a1\ufe0f <code>personne</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>personne</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>lieu</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>lieu</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>divers</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>divers</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset eltec\n</code></pre>"},{"location":"datasets/french/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/french/#scala-fr","title":"ScaLA-fr","text":"<p>This dataset was published in this paper and was automatically created from the French Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 16,342 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Le dessert est une part minuscule de g\u00e2teau.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Le trafic international sera normal vendredi sur Eurostar, Thalys, et sur les trains \u00e0 grande vitesse \u00e0 destination de l', a indiqu\u00e9 la SNCF dans un communiqu\u00e9.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Certains craignent qu' un avantage comp\u00e9titif trop net et trop durable favorise les positions dominantes, monopoles et oligopoles, qui limitent la et concurrence finissent par peser sur le consommateur.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Les phrases suivantes indiquent si elles sont grammaticalement correctes.\n</code></pre></li> <li>Base prompt template:   <pre><code>Phrase: {text}\nCorrect du point de vue grammatical: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Phrase: {text}\n\nD\u00e9terminez si la phrase est grammaticalement correcte ou non. R\u00e9pondez par 'oui' si la phrase est correcte et par 'non' si elle ne l'est pas, et rien d'autre.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>oui</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>non</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-fr\n</code></pre>"},{"location":"datasets/french/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/french/#fquad","title":"FQuAD","text":"<p>This dataset was published in this paper, and is a manually annotated dataset of questions and answers from the French Wikipedia.</p> <p>The original full dataset consists of 20,731 / 3,188 / 2,189 samples for training, validation and testing, respectively. Note that the testing split is not publicly accessible, however, so we only use the training and validation split. We use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively. Our training split is a subset of the original training split, and our validation and testing splits are subsets of the original validation split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"Parmi leurs th\u00e8mes r\u00e9currents, on en trouve qui sont communs \u00e0 beaucoup d'autres groupes contemporains ou plus anciens : les Stranglers ont d\u00e9crit, \u00e0 plusieurs reprises, la vie d'un groupe de rock dans toutes ses dimensions (fans, autres groupes, vie en tourn\u00e9e). Le th\u00e8me rebattu - chez les groupes des ann\u00e9es 1960-1970 - de la drogue, est abord\u00e9e sur une demi-douzaine de chansons (Don't Bring Harry), tandis que la vision angoiss\u00e9e du futur, dans le contexte de la guerre froide ou en lien avec les avanc\u00e9es de la science, a donn\u00e9 lieu \u00e0 plusieurs titres (Curfew). On retrouve \u00e9galement chez eux des pr\u00e9occupations \u00e9cologiques (Dreamtime) ou sociales. La guerre, notamment les deux guerres mondiales (Northwinds), mais aussi les guerres contemporaines (I Don't Agree), sont \u00e0 l'origine de divers textes. Mais le th\u00e8me qui les a le plus inspir\u00e9s, c'est de loin les femmes (The Man They Love to Hate).\",\n  \"question\": 'Sur combien de chanson le th\u00e8me de la drogue est il abord\u00e9 ?',\n  \"answers\": {\n    \"answer_start\": array([353]),\n    \"text\": array(['une demi-douzaine'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Au cours de cette p\u00e9riode, Cavour se distingue par son talent de financier. Il contribue de mani\u00e8re pr\u00e9pond\u00e9rante \u00e0 la fusion de la Banque de G\u00eanes et de la nouvelle Banque de Turin au sein de la Banque Nationale des \u00c9tats sardes (Banca Nazionale degli Stati Sardi). Apr\u00e8s le succ\u00e8s \u00e9lectoral de d\u00e9cembre 1849, Cavour devient \u00e9galement une des figures dominantes de la politique pi\u00e9montaise et il prend la fonction de porte-parole de la majorit\u00e9 mod\u00e9r\u00e9e qui vient de se cr\u00e9er. Fort de cette position, il fait valoir que le moment des r\u00e9formes est arriv\u00e9, favoris\u00e9 par le Statut albertin qui a cr\u00e9\u00e9 de r\u00e9elles perspectives de progr\u00e8s. Le Pi\u00e9mont peut ainsi s'\u00e9loigner du front catholique et r\u00e9actionnaire, qui triomphe dans le reste de l'Italie. \",\n  \"question\": \"En quel ann\u00e9e sort-il vainqueur d'une \u00e9lection ?\",\n  \"answers\": {\n    \"answer_start\": array([305]),\n    \"text\": array(['1849'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Pour autant, le ph\u00e9nom\u00e8ne m\u00e9t\u00e9orologique se d\u00e9cline sous d'autres variantes : ocelles du paon, \u00e9voquant les cent yeux d'Argus, fleurs champ\u00eatres et ornant les jardins o\u00f9 s'\u00e9tablit l'osmose entre couleurs compl\u00e9mentaires. La po\u00e9sie tient en main la palette du peintre,, celle de Claude Gell\u00e9e ou de Poussin. Pour autant, il ne s'agit pas l\u00e0 d'une posture habituelle chez lui, qui privil\u00e9gie les paysages quasi-monochromes.\",\n  \"question\": \"Qu'est ce que l'auteur pr\u00e9f\u00e8re d\u00e9crire ?\",\n  \"answers\": {\n    \"answer_start\": array([394]),\n    \"text\": array(['paysages'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Les textes suivants sont accompagn\u00e9s de questions et de r\u00e9ponses.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texte: {text}\nQuestion: {question}\nR\u00e9ponse en 3 mots maximum: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texte: {text}\n\nR\u00e9pondez \u00e0 la question suivante sur le texte ci-dessus en 3 mots maximum.\n\nQuestion: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset fquad\n</code></pre>"},{"location":"datasets/french/#unofficial-belebele-fr","title":"Unofficial: BeleBele-fr","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Texte: Lorsqu\u2019un petit groupe d\u2019\u00eatres vivants (une petite population) est s\u00e9par\u00e9 de la population principale dont il est issu (par exemple, s\u2019il se d\u00e9place au-dessus d\u2019une cha\u00eene de montagnes ou d\u2019une rivi\u00e8re, ou s\u2019il se d\u00e9place vers une nouvelle \u00eele de sorte qu\u2019il ne peut pas facilement revenir en arri\u00e8re), il se retrouve souvent dans un environnement diff\u00e9rent de celui dans lequel il \u00e9tait auparavant. Ce nouvel environnement a des ressources et des concurrents diff\u00e9rents, de sorte que la nouvelle population aura besoin de caract\u00e9ristiques ou d'adaptations nouvelles pour \u00eatre un concurrent puissant par rapport \u00e0 ce dont elle avait besoin auparavant. La population d'origine n'a pas chang\u00e9 du tout,\\xa0elle a toujours besoin des m\u00eames adaptations. Au fil du temps, \u00e0 mesure que la nouvelle population s'adapte \u00e0 son nouvel environnement, elle commence \u00e0 ressembler de moins en moins \u00e0 l'autre population. Enfin, apr\u00e8s des milliers ou m\u00eame des millions d'ann\u00e9es, les deux populations para\u00eetront tellement diff\u00e9rentes qu'elles ne pourront plus \u00eatre consid\u00e9r\u00e9es comme appartenant \u00e0 la m\u00eame esp\u00e8ce. Nous appelons ce processus \u00ab\\u2009sp\u00e9ciation\\u2009\u00bb, ce qui signifie simplement la formation de nouvelles esp\u00e8ces. La sp\u00e9ciation est une cons\u00e9quence in\u00e9vitable et une partie tr\u00e8s importante de l\u2019\u00e9volution.\\nQuestion: D\u2019apr\u00e8s l\u2019extrait et parmi les exemples ci-dessous, qu\u2019est-ce qui g\u00eanerait le processus d\u2019\u00e9volution\\xa0?\\nChoix:\\na. La difficult\u00e9 pour un petit groupe \u00e0 s\u2019\u00e9panouir dans un nouvel endroit\\nb. La migration d\u2019une portion d\u2019une population vers un nouvel environnement\\nc. L\u2019ajustement par une population de son adaptation \u00e0 un nouvel environnement\\nd. Le fait qu\u2019une population finisse par devenir deux populations distinctes\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texte: Le pillage g\u00e9n\u00e9ralis\u00e9 se serait poursuivi pendant la nuit, les forces de l'ordre n'\u00e9tant pas pr\u00e9sentes dans les rues de Bichkek. Un observateur a d\u00e9crit Bichkek comme \u00e9tant en train de sombrer dans un \u00e9tat d\u2019\u00ab anarchie \u00bb, tandis que la population se d\u00e9pla\u00e7ait en bandes dans les rues et pillait les magasins de biens de consommation. Plusieurs habitants de Bichkek ont reproch\u00e9 les manifestants du sud d'\u00eatre responsables de l'anarchie.\\nQuestion: Qui a accus\u00e9 les manifestants du sud de pillage\\xa0?\\nChoix:\\na. Des habitants de Bichkek\\nb. Les forces de l\u2019ordre\\nc. Les anarchistes\\nd. Des bandes de personnes\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texte: Dans de nombreuses r\u00e9gions du monde, faire un signe de la main est un geste amical signifiant \u00ab\\u2009bonjour\\u2009\u00bb. En revanche, en Malaisie, du moins chez les Malais des zones rurales, cela signifie \u00ab viens par ici \u00bb, comme le fait de plier l'index vers soi, geste utilis\u00e9 dans certains pays occidentaux, et il ne devrait \u00eatre utilis\u00e9 qu'en ce sens. De m\u00eame, un voyageur britannique en Espagne pourrait confondre un signe d'adieu fait par une personne qui tourne la paume de sa main vers elle-m\u00eame (plut\u00f4t que vers la personne \u00e0 qui elle adresse le signe) avec une invitation \u00e0 revenir.\\nQuestion: Dans les zones rurales de la Malaisie, quel geste signifie \u00ab viens par ici \u00bb ?\\nChoix:\\na. Plier l\u2019index\\nb. Faire un signe de la main\\nc. Faire un \u00ab high five \u00bb\\nd. Lever le pouce\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Les questions suivantes sont des questions \u00e0 choix multiples (avec r\u00e9ponses).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nR\u00e9ponse: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nR\u00e9pondez \u00e0 la question ci-dessus par 'a', 'b', 'c' ou 'd', et rien d'autre.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-fr\n</code></pre>"},{"location":"datasets/french/#unofficial-multiwikiqa-fr","title":"Unofficial: MultiWikiQA-fr","text":"<p>This dataset will be published in an upcoming paper, and contains French Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"L'advocaat est une liqueur onctueuse d'origine n\u00e9erlandaise, faite de jaune d'\u0153uf, de sucre et d'alcool. Il a un l\u00e9ger go\u00fbt rappelant celui des amandes. Dans les pays anglophones, il contient g\u00e9n\u00e9ralement 15 % d'alcool, tandis qu'en Europe continentale ce taux varie selon les pays, souvent entre 14 et 20 %.\\n\\nOutre le jaune d'\u0153uf, l'alcool et le sucre, l'advocaat peut contenir du miel, de la vanille, de l'eau-de-vie et parfois de la cr\u00e8me fra\u00eeche (ou du lait concentr\u00e9 non sucr\u00e9). Parmi les fabricants, on trouve Warners, Bols, Verpoorten, de Korenaer, \u00c9lixir d'Anvers, Warninks, De Kuyper, Dalkowski et Zwarte Kip.\\n\\nTypes \\n\\nAux Pays-Bas et dans le Tyrol, on vend un advocaat \u00e9pais, souvent consomm\u00e9 \u00e0 la cuill\u00e8re, tandis qu'une version plus liquide est r\u00e9serv\u00e9e \u00e0 l'exportation. Cet advocaat \u00e9pais entre dans la composition de plusieurs desserts, notamment des glaces et des p\u00e2tisseries. Il est aussi servi en ap\u00e9ritif ou en digestif. Traditionnellement, on le sert avec de la cr\u00e8me fouett\u00e9e saupoudr\u00e9e de cacao.\\n\\nLa qualit\u00e9 d'exportation, plus liquide, est particuli\u00e8rement bien adapt\u00e9e \u00e0 la fabrication de cocktails et de long drinks. Le cocktail le plus connu est le Snowball : un m\u00e9lange d'advocaat, de limonade et parfois de jus de citron vert (facultatif). Une autre boisson courante \u00e0 base d'advocaat est le bombardino, servi dans les stations de ski italiennes : c'est un m\u00e9lange d'advocaat, de caf\u00e9 noir et de whisky.\\n\\nHistoire \\nL'advocaat original \u00e9tait une liqueur cr\u00e9\u00e9e par les N\u00e9erlandais du Suriname et de Recife avec des avocats. De retour aux Pays-Bas, o\u00f9 ce fruit n'\u00e9tait pas disponible, ils reconstitu\u00e8rent une texture identique avec du jaune d'\u0153uf \u00e9paissi. Le nom du fruit en nahuatl, ahuacatl, avait \u00e9t\u00e9 transform\u00e9 en espagnol en aguacate, puis en anglais en avocado et en n\u00e9erlandais en advocaatpeer ou advocaat (par analogie avec la profession). De l\u00e0, il se r\u00e9pandit dans les autres pays d'Europe. Le rompope de Puebla, au Mexique, est une liqueur tr\u00e8s similaire, \u00e0 base de jaune d'\u0153uf et de vanille.\\n\\nVoir aussi \\n\\n \\n Gogli\\n Lait de poule\\n Ponche Crema\\n Rompope\\n Sabayon\\n\\nNotes et r\u00e9f\u00e9rences\\n\\nBibliographie \\n \\n \\n\\nLiqueur\\nBoisson \u00e0 base d'\u0153uf\\nBoisson n\u00e9erlandaise\",\n    \"question\": \"Nommez deux marques qui produisent de l'advocaat.\",\n    \"answers\": {\n        \"answer_start\": array([516]),\n        \"text\": array([\"Warners, Bols\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"La Sabine de Gandon est un timbre-poste d'usage courant qui a servi en France de  au retrait de la vente des derniers timbres en . Ce type remplace la Marianne de B\u00e9quet et est remplac\u00e9 en  par la Libert\u00e9 de Gandon d'apr\u00e8s Delacroix.\\n\\nDescription \\n\\nLa Sabine est dessin\u00e9e et grav\u00e9e par Pierre Gandon \u00e0 partir de la t\u00eate de l'h\u00e9ro\u00efne Hersilie, repr\u00e9sent\u00e9e au centre du tableau de Jacques Louis David Les Sabines, sur lequel elle s'interpose entre les Sabins et les Romains. Le mod\u00e8le est Aurore de Bellegarde, une amie du peintre.\\n\\nLes timbres sont imprim\u00e9s en taille-douce en feuille de cent exemplaires.\\n\\nDeux mentions de pays \u00e9metteurs ont figur\u00e9 sur ces timbres. De 1977 \u00e0 1981, la mention est \u00ab FRANCE \u00bb comme sur les timbres comm\u00e9moratifs depuis le d\u00e9but de l'ann\u00e9e 1975, apr\u00e8s le d\u00e9but de la pr\u00e9sidence de Val\u00e9ry Giscard d'Estaing. Apr\u00e8s l'\u00e9lection de Fran\u00e7ois Mitterrand \u00e0 la pr\u00e9sidence de la R\u00e9publique, \u00ab R\u00e9publique fran\u00e7aise \u00bb revient sur les timbres, y compris les derniers \u00e9mis au type Sabine, dans la deuxi\u00e8me partie de l'ann\u00e9e 1981.\\n\\nCarri\u00e8re \\nLa premi\u00e8re \u00e9mission a lieu le  pour les 0,80 franc vert et 1 franc rouge, servant aux tarifs les plus fr\u00e9quents de la lettre \u00e9conomique et prioritaire de moins de 20 grammes. Les valeurs de compl\u00e9ments et les autres valeurs d'usage sont \u00e9mises le  et le .\\n\\nEnsuite, les nouvelles \u00e9missions suivent les changements de tarifs : , . Ce dernier changement de tarif est \u00e9galement \u00e0 l'origine de l'\u00e9mission de six timbres le .\\n\\nLes trois derniers timbres au type Sabine \u00e9mis le sont le  pour correspondre aux tarifs des  ao\u00fbt et  septembre pr\u00e9c\u00e9dents. Ils portent la mention \u00ab REPUBLIQUE FRAN\u00c7AISE \u00bb. Le , paraissent les timbres au type Libert\u00e9 de Gandon d'apr\u00e8s Delacroix.\\n\\nNotes et r\u00e9f\u00e9rences\\n\\nVoir aussi\\n\\nBibliographie \\n Catalogue de cotations de timbres de France, \u00e9d. Dallay, 2005-2006.\\n\\nArticle connexe \\n Timbre de France d'usage courant\\n\\nLiens externes \\n Bibliographie sur le type Sabine sur le site du Cercle des amis de Marianne.\\n Liste des timbres au type Sabine sur le site Phil-Ouest.\\n\\nTimbre de France d'usage courant\",\n    \"question\": \"Quel tableau de Jacques-Louis David a servi de mod\u00e8le au timbre-poste La Sabine, dont le dessin et la gravure sont de Pierre Gandon\\xa0?\",\n    \"answers\": {\n        \"answer_start\": array([399]),\n        \"text\": array([\"Les Sabines\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"(parfois sous-titr\u00e9 Collectible Lennon) est le septi\u00e8me album de John Lennon, sorti en 1975. Il s'agit de la premi\u00e8re compilation de son \u0153uvre , et du dernier album qu'il ait publi\u00e9 avant sa retraite de cinq ans destin\u00e9e \u00e0 s'occuper de son fils Sean.\\n\\nParution \\nL'album reprend onze chansons publi\u00e9es par Lennon en single entre 1969 et 1974. Cinq des chansons, parmi les plus anciennes, n'avaient jusque-l\u00e0 jamais \u00e9t\u00e9 publi\u00e9es sur un 33 tours. Cet aspect a \u00e9t\u00e9 particuli\u00e8rement appr\u00e9ci\u00e9 par la critique qui a g\u00e9n\u00e9ralement bien not\u00e9 l'album. Celui-ci s'est bien vendu et a atteint le huiti\u00e8me rang des ventes au Royaume-Uni, et le douzi\u00e8me rang aux \u00c9tats-Unis, o\u00f9 il est devenu disque d'or.\\n\\nGive Peace a Chance est pr\u00e9sent\u00e9 ici sous forme d'un court extrait tandis qu'une portion de sa version live, enregistr\u00e9e le  au Madison Square Garden \u00e0 New York lors du concert de charit\u00e9 \u00ab One to One \u00bb, est greff\u00e9e au final de Happy Xmas (War Is Over). Cette version augment\u00e9e de la chanson de No\u00ebl est in\u00e9dite \u00e0 cette collection.\\n\\nLe nom du disque fait r\u00e9f\u00e9rence au katsuobushi, une m\u00e9thode japonaise de pr\u00e9paration et de conservation du poisson.\\n\\nLe sous-titre varie selon les \u00e9ditions : absent des premi\u00e8res \u00e9ditions am\u00e9ricaines, il est parfois indiqu\u00e9 Collectible Lennon sur une \u00e9tiquette rouge, parfois Collectable Lennon imprim\u00e9 au dos de la pochette, avant la liste des titres.\\n\\nPochette \\nLe recto de la pochette est compos\u00e9 de douze dessins : onze pour les titres des chansons, plus un pour le titre de l'album qui est illustr\u00e9 d'un disque rouge sur fond blanc semblable au drapeau du Japon, cr\u00e9dit\u00e9 \u00e0 \u00ab Lennon Plastic Ono Band \u00bb. La palette de couleurs, dans des tons pastel, est volontairement limit\u00e9e : un bleu p\u00e2le pr\u00e9domine, formant sur la plupart des vignettes un ciel agr\u00e9ment\u00e9 de nuages blancs ; la palette est compl\u00e9t\u00e9e par des tons de rose et de couleur chair.\\n\\nLes illustrations pour Imagine, Mind Games, et Whatever Gets You Thru the Night rappellent les pochettes des albums dont les chansons sont tir\u00e9es. L'illustration pour Give Peace a Chance est r\u00e9alis\u00e9e \u00e0 partir d'une photo de presse du bed-in de John et Yoko \u00e0 Amsterdam, avec, pos\u00e9e sur le lit, la pochette du second album exp\u00e9rimental du couple, Unfinished Music No.2: Life with the Lions. Pour Happy Xmas (War is Over), un bombardier B29 appara\u00eet suspendu \u00e0 la fa\u00e7on d'une maquette , une boule de No\u00ebl rouge \u00e9tant \u00e0 son tour suspendue \u00e0 l'avion. La chanson Instant Karma! est repr\u00e9sent\u00e9e par un flacon de produit lyophilis\u00e9. Woman is the Nigger of the World est illustr\u00e9e par une femme nue, \u00e0 la t\u00eate couverte, sous une pluie de tubes de rouge \u00e0 l\u00e8vres fusant \u00e0 la fa\u00e7on de balles de fusil, en r\u00e9f\u00e9rence aux paroles  (). L'illustration pour Mother est directement inspir\u00e9e du tableau La M\u00e8re de Whistler, la m\u00e8re ayant ici les traits de Lennon, tandis que le cadre de gauche compte un second portrait de Lennon, en gros plan, laissant \u00e9chapper des larmes. Power to the People est repr\u00e9sent\u00e9 par un texte d\u00e9clarant Lennon admissible \u00e0 une green card et commen\u00e7ant par , rappelant le manuscrit de la constitution des \u00c9tats-Unis. Des dessins de Lennon sont utilis\u00e9s pour illustrer Cold Turkey et #9 Dream.\\n\\nLe dessin au verso repr\u00e9sente un emballage, ouvert, de poisson s\u00e9ch\u00e9 selon la m\u00e9thode japonaise de la compagnie fictive \u00ab Lennon Brand \u00bb. Une citation de Lennon, sous le pseudonyme Dr. Winston O'Boogie,  y est inscrite.\\n\\nLa pochette int\u00e9rieure porte au recto un grand disque rouge sur fond blanc , et au verso les paroles des chansons en blanc sur fond rouge, avec quelques erreurs de transcription.\\n\\nLa direction artistique est confi\u00e9e \u00e0 Roy Kohara, le m\u00eame qui cr\u00e9a les pochettes des deux pr\u00e9c\u00e9dents albums de Lennon, Mind Games et Rock 'n' Roll et celle de la compilation des Beatles Rock 'n' Roll Music l'ann\u00e9e suivante. Les illustrations sont de Michael Bryant.\\n\\nListe des chansons \\nLes titres sont cr\u00e9dit\u00e9s \u00e0 John Lennon sauf indication contraire.\\n\\nClassement\\n\\nNotes et r\u00e9f\u00e9rences\\n\\nNotes\\n\\nR\u00e9f\u00e9rences \\n\\nAlbum de John Lennon\\nCompilation musicale sortie en 1975\\nAlbum publi\u00e9 par Apple Records\\nAlbum publi\u00e9 par EMI Group\\nAlbum produit par Phil Spector\",\n    \"question\": \"Qui est l'illustrateur de la couverture de l'album Shaved Fish?\",\n    \"answers\": {\n        \"answer_start\": array([3828]),\n        \"text\": array([\"Michael Bryant\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Les textes suivants sont accompagn\u00e9s de questions et de r\u00e9ponses.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texte: {text}\nQuestion: {question}\nR\u00e9ponse en 3 mots maximum: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texte: {text}\n\nR\u00e9pondez \u00e0 la question suivante sur le texte ci-dessus en 3 mots maximum.\n\nQuestion: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-fr\n</code></pre>"},{"location":"datasets/french/#knowledge","title":"Knowledge","text":""},{"location":"datasets/french/#mmlu-fr","title":"MMLU-fr","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to French was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"En 2013, la part des personnes en Ethiopie qui pensent que les partis politiques sont corrompus est\\nChoix:\\na. 24%\\nb. 44%\\nc. 64%\\nd. 84%\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Combien de nombres entiers positifs et n\u00e9gatifs $12$ est-il un multiple?\\nChoix:\\na. 3\\nb. 12\\nc. 4\\nd. 6\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Quelle affirmation suivante concernant les r\u00e9actions d\u00e9pendantes de la lumi\u00e8re de la photosynth\u00e8se est correcte?\\nChoix:\\na. Ils fournissent le carbone qui est incorpor\u00e9 dans le sucre.\\nb. Ils produisent du PGA, qui est converti en glucose par la fixation du carbone dans les r\u00e9actions ind\u00e9pendantes de la lumi\u00e8re.\\nc. L'eau est s\u00e9par\u00e9e en fournissant des ions hydrog\u00e8ne et des \u00e9lectrons \u00e0 la NADP pour un stockage temporaire.\\nd. Ils se produisent dans le stroma des chloroplastes.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Les questions suivantes sont des questions \u00e0 choix multiples (avec r\u00e9ponses).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nR\u00e9ponse: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nR\u00e9pondez \u00e0 la question ci-dessus par 'a', 'b', 'c' ou 'd', et rien d'autre.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-fr\n</code></pre>"},{"location":"datasets/french/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/french/#hellaswag-fr","title":"HellaSwag-fr","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[header] Comment dire \u00e0 vos enfants que vous allez divorcer [title] Contr\u00f4lez vos \u00e9motions. [step] Vos enfants seront probablement en col\u00e8re et boulevers\u00e9s lorsque vous leur annoncerez le divorce, essayez donc de ne pas r\u00e9agir de la m\u00eame mani\u00e8re. Attendez de rompre la nouvelle lorsque vous pourrez discuter du sujet de mani\u00e8re efficace et rester ma\u00eetre de vos \u00e9motions.\\nChoix:\\na. Rappelez-vous, le but de la discussion est d'\u00eatre l\u00e0 pour les enfants - ils ne devraient pas avoir \u00e0 vous r\u00e9conforter. [title] Essayez de le faire ensemble, si possible.\\nb. [substeps] Trouvez un moyen d'\u00e9viter que vos enfants ne vous agressent verbalement. Assurez-vous d'\u00eatre calme et pos\u00e9 et ne donnez pas l'impression que la nouvelle du divorce est quelque chose qui vous d\u00e9range.\\nc. [substeps] Si vos enfants ont du mal \u00e0 comprendre la nouvelle \u00e0 distance, posez-leur des questions lors d'une conversation intime et priv\u00e9e. Laissez-les utiliser les questions pour traiter et comprendre ce qu'ils ressentent \u00e0 propos de l'annonce.\\nd. [substeps] Si vous ne voulez pas qu'ils le sachent imm\u00e9diatement, partez en silence et r\u00e9fl\u00e9chissez un peu plus longtemps avant de leur dire. Cherchez un endroit confortable pour vous deux pour parler en priv\u00e9, afin que vous puissiez tous deux prendre du temps pour traiter vos sentiments et accepter la situation.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Certains stands servent des hot-dogs aux gens alors qu'ils p\u00eachent sur la glace. Un petit gar\u00e7on et une petite fille tentent d'attraper un poisson. ils\\nChoix:\\na. attrapent un poisson et continuent de nager.\\nb. sont interview\u00e9s pendant qu'ils p\u00eachent.\\nc. essaient \u00e0 plusieurs reprises, errant tout pr\u00e8s de leur poisson.\\nd. sont rapidement emport\u00e9s par le courant alors qu'ils luttent pour s'\u00e9loigner du banc de la rivi\u00e8re et pagayent pour \u00e9chapper \u00e0 de l\u00e9g\u00e8res infestations de poissons dans l'eau\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] Comment se calmer [title] Respirer. [step] Respirer. Lentement.\\nChoix:\\na. Concentrez-vous sur votre respiration et d\u00e9tendez votre corps. Continuez \u00e0 inspirer et expirer lentement par le nez, en mettant une pression sur votre diaphragme et vos muscles fessiers (vos poumons).\\nb. Si votre c\u0153ur bat vite ou fort, vous pourriez \u00eatre en danger de tachycardie, d'AVC ou de toute autre crise cardiaque. [title] Allongez-vous sur le dos et inspirez et expirez profond\u00e9ment.\\nc. Inspirez pendant 5 secondes; retenez votre souffle pendant 5 secondes, puis expirez pendant 5 secondes. Cela fonctionne parce que vous faites l'oppos\u00e9 de ce qu'une personne excit\u00e9e ferait.\\nd. Inspirez pendant un compte de cinq et abaissez-vous. Expirez, expirez quatre fois de plus, aussi profond\u00e9ment que vous pouvez sentir, et r\u00e9p\u00e9tez pour un total de dix.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Les questions suivantes sont des questions \u00e0 choix multiples (avec r\u00e9ponses).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nR\u00e9ponse: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nR\u00e9pondez \u00e0 la question ci-dessus par 'a', 'b', 'c' ou 'd', et rien d'autre.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-fr\n</code></pre>"},{"location":"datasets/french/#unofficial-goldenswag-fr","title":"Unofficial: GoldenSwag-fr","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Comment r\u00e9parer des lunettes tordues. Prenez une paire de pinces \u00e0 becs en plastique. Les pinces vous permettront d'effectuer des micro-ajustements sur les montures tordues de mani\u00e8re plus s\u00fbre qu'en essayant de les forcer \u00e0 se mettre en forme \u00e0 la main. Si possible, \u00e9quipez-vous d'une paire de pinces dont les pointes sont recouvertes d'un rev\u00eatement en plastique souple.\\nChoix:\\na. Les pinces en m\u00e9tal ordinaires risquent de rayer, voire de casser, les montures en fil m\u00e9tallique fin. Si vous ne disposez pas d'une pince appropri\u00e9e, une pince \u00e0 main en plastique ou une paire de pinces peut \u00e9galement faire l'affaire.\\nb. Sinon, vous pouvez simplement tenir la pince dans votre main et la laisser glisser. Soulevez la lentille avec les pointes de la pince.\\nc. Les bo\u00eetiers m\u00e9talliques sont parmi les mat\u00e9riaux les moins chers disponibles, mais ils rendent la t\u00e2che beaucoup plus difficile. Si vous ne trouvez pas de pince \u00e0 bouts en plastique, votre dentiste optera probablement pour des \u00e9tuis en verre.\\nd. Le plastique souple peut \u00eatre meilleur que le plastique dur. Le but du plastique est d'am\u00e9liorer l'apparence des lentilles, tout en les rendant plus faciles \u00e0 nettoyer et \u00e0 remplacer.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Comment \u00eatre une meilleure personne \u00e0 l'\u00e9cole. D\u00e9veloppez votre sens du bien et du mal. Le monde d'aujourd'hui est rapide et impatient, mais pour devenir une meilleure personne, il faut prendre le temps de travailler sur ses valeurs. D\u00e9cidez quelles sont les valeurs et les vertus les plus importantes pour vous.\\nChoix:\\na. Si vous pratiquez un sport, profitez-en pour vous entra\u00eener. Si vous passez vos journ\u00e9es de gym \u00e0 garder vos muscles immobiles, assurez-vous de prendre le temps de faire cet exercice.\\nb. Efforcez-vous de voir toutes vos situations id\u00e9ales en termes de bonne et de mauvaise situation afin d'avoir une meilleure attitude \u00e0 l'\u00e9gard de ces choses. Pensez \u00e0 la fa\u00e7on dont vous aborderiez la situation dans laquelle vous avez l'intention de faire ce qu'il faut.\\nc. Cr\u00e9ez un syst\u00e8me personnel de moralit\u00e9 en rejoignant des clubs et des organisations qui vous aideront \u00e0 d\u00e9velopper vos vertus, comme une \u00e9quipe sportive, des clubs de service communautaire, une chorale ou un gouvernement \u00e9tudiant. L'empathie, l'honn\u00eatet\u00e9, la patience, l'humour et la pers\u00e9v\u00e9rance ne sont que quelques exemples de bonnes valeurs.\\nd. La derni\u00e8re chose que vous souhaitez, c'est de vous retrouver coinc\u00e9 dans un bar, de passer une mauvaise journ\u00e9e ou de vouloir faire du b\u00e9n\u00e9volat pour votre cause. Pratiquez l'empathie et essayez de vivre votre vie sous un meilleur angle.\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Comment pr\u00e9parer une pommade antibact\u00e9rienne \u00e0 la maison. Choisissez vos huiles. L'huile de coco est naturellement antivirale, antibact\u00e9rienne et antifongique. L'huile de coco devrait \u00eatre le premier ingr\u00e9dient, repr\u00e9sentant environ la moiti\u00e9 de votre base d'huile (environ \u00bd tasse).\\nChoix:\\na. Vous ne devez pas en utiliser trop - 1-1 pour cent est une quantit\u00e9 excessive qui endommage facilement la peau du b\u00e9b\u00e9 et l'irrite. Vous n'avez pas besoin d'utiliser toutes vos huiles, mais essayez-en quelques-unes pour les peaux sensibles.\\nb. Mais l'huile de coco peut aussi \u00eatre rigide et difficile \u00e0 travailler, vous devriez donc envisager d'utiliser \u00bd tasse d'une autre huile. D'excellents choix incluent l'huile d'olive, l'huile de jojoba ou l'huile d'amande.\\nc. Utilisez 1 \u00e0 2 gouttes de votre huile essentielle pr\u00e9f\u00e9r\u00e9e comme antibact\u00e9rien. L'huile de coco est naturellement antibact\u00e9rienne.\\nd. L'huile peut \u00eatre un ingr\u00e9dient irritant pour la peau, provoquant irritation, s\u00e9cheresse et inflammation. Appliquez de l'huile de coco sur la peau s\u00e8che comme rem\u00e8de topique ou \u00e0 domicile.\",\n  \"label\": \"b\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Les questions suivantes sont des questions \u00e0 choix multiples (avec r\u00e9ponses).\n</code></pre></li> <li>Base prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nR\u00e9ponse: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Question: {text}\nChoix:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nR\u00e9pondez \u00e0 la question ci-dessus par 'a', 'b', 'c' ou 'd', et rien d'autre.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-fr\n</code></pre>"},{"location":"datasets/french/#summarization","title":"Summarization","text":""},{"location":"datasets/french/#orange-sum","title":"Orange Sum","text":"<p>This dataset was published in this paper and consists of news articles from Orange Actu. The summaries were written by the journalists themselves (the \"abstract\" field in the original dataset).</p> <p>The original full dataset consists of 21,401 / 1,500 / 1,500 samples for training, validation and testing, respectively. We use 1,024 / 256 / 1,024 samples for training, validation, and testing, respectively. All our splits are subsets of the original ones.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"R\u00e9clam\u00e9 puis annonc\u00e9 par Emmanuel Macron, le d\u00e9bat parlementaire sur l'immigration s'est ouvert ce lundi 7 octobre avec une allocution d'Edouard Philippe devant les d\u00e9put\u00e9s. Le Premier ministre a commenc\u00e9 son discours en empruntant les mots d'un de ses pr\u00e9d\u00e9cesseurs, Michel Rocard. Il a ensuite fait \u00e9tat d'un syst\u00e8me fran\u00e7ais d'asile \\\"satur\u00e9\\\". \\\"En 2018, la France a enregistr\u00e9 le record de 123.000 demandes d'asile\\\", a t-il rappel\u00e9, estimant que la France \\\"n'a pas atteint tous\\\" ses objectifs en mati\u00e8re de politique migratoire et de lutte contre l'immigration irr\u00e9guli\u00e8re. \\\"La question d'un pilotage par objectifs de l'admission au s\u00e9jour n'est pas tabou. Je n'ai pas peur de r\u00e9fl\u00e9chir \u00e0 l'id\u00e9e de quotas. Il nous faut donc regarder sujet apr\u00e8s sujet. On sait depuis longtemps que les quotas ne s'appliquent ni \u00e0 l'asile ni \u00e0 l'immigration familiale. Pour autant, celle-ci ne pourrait \u00e9chapper \u00e0 toute ma\u00eetrise. Il faut lutter contre les abus et les fraudes, et resserrer les crit\u00e8res l\u00e0 o\u00f9 cela s'impose\\\" a t-il poursuivi.Le Premier ministre a en revanche balay\u00e9 l'id\u00e9e de la fin du droit du sol, r\u00e9clam\u00e9e par des \u00e9lus de droite. \\\"Je ne vois pas bien en quoi \u00e0 l'\u00e9chelle du pays, la fin du droit du sol serait une r\u00e9ponse\\\". Il a \u00e9galement adress\u00e9 une critique virulente \u00e0 l'\u00e9gard de la th\u00e9orie de \\\"l'immigration de remplacement\\\", un \\\"vocable d'une laideur certaine qui fait appel aux ressorts les plus d\u00e9testables du complotisme.Ces th\u00e9ories \\\"inspiraient encore r\u00e9cemment des discours dont j'ai eu l'occasion de dire qu'ils \u00e9taient profond\u00e9ment contraires \u00e0 l'id\u00e9e dont nous nous faisons de la France et de la R\u00e9publique\\\" a t-il encore ass\u00e9n\u00e9, en r\u00e9f\u00e9rence \u00e0 la r\u00e9cente \\\"Convention de la droite\\\" organis\u00e9e le 28 septembre dernier autour de Marion Mar\u00e9chal et Eric Zemmour.\",\n  \"target_text\": \"Le Premier ministre a ouvert ce lundi 7 octobre le d\u00e9bat sur l'immigration \u00e0 l'Assembl\u00e9e nationale, d\u00e9clarant que le syst\u00e8me fran\u00e7ais d'asile est aujourd'hui \\\"satur\u00e9\\\". Il a au passage pourfendu la th\u00e9orie de \\\"l'immigration de remplacement\\\", qui fait selon lui appel \\\"aux ressorts les plus d\u00e9testables du complotisme\\\".\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Un supermarch\u00e9 a \u00e9t\u00e9 d\u00e9truit par une explosion, samedi 2 janvier, \u00e0 Grasse, dans les Alpes-Maritimes, a rapport\u00e9 France 3. Aucun bless\u00e9 n'est \u00e0 d\u00e9plorer.L'explosion s'est produite vers 6h du matin dans ce supermarch\u00e9 Aldi de Grasse. Elle a \u00e9t\u00e9 suivie par un violent incendie. Le b\u00e2timent a \u00e9t\u00e9 \\\"totalement d\u00e9truit\\\", selon le maire de la ville, qui a \u00e9voqu\u00e9 une cause \\\"accidentelle\\\" sur sa page Facebook. Une centaine de pompiers, ainsi que des policiers ont \u00e9t\u00e9 mobilis\u00e9s pour lutter contre le sinistre et s\u00e9curiser le p\u00e9rim\u00e8tre.Selon Nice-Matin, deux employ\u00e9es du supermarch\u00e9 ont \u00e9t\u00e9 souffl\u00e9es par l'explosion en allumant la lumi\u00e8re au moment d'arriver sur leur lieu de travail. Aucune des deux n'a \u00e9t\u00e9 bless\u00e9e physiquement, mais elles sont tr\u00e8s choqu\u00e9es.Vers 9h, le feu \u00e9tait ma\u00eetris\u00e9, a indiqu\u00e9 \u00e0 France 3 un porte-parole du Service d'incendie et de secours des Alpes-Maritimes. Soixante pompiers et 40 engins de secours \u00e9taient toujours mobilis\u00e9s sur place.\",\n  \"target_text\": \"Une centaine de pompiers ont \u00e9t\u00e9 mobilis\u00e9s pour lutter contre l'incendie.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Trois ans et demi apr\u00e8s la d\u00e9cision des Britanniques de quitter l'Union europ\u00e9enne, le Brexit est finalement intervenu vendredi 31 janvier. Une mesure qui va s\u00e9rieusement changer la donne pour les Britanniques qui si\u00e8gent aujourd'hui dans les conseils municipaux en France. Comme tous les citoyens europ\u00e9ens, les Britanniques avaient jusqu'\u00e0 pr\u00e9sent le droit de vote et d'\u00e9ligibilit\u00e9 aux \u00e9lections municipales fran\u00e7aises. Actuellement sur 2.493 conseillers \u00e9trangers, 757 viennent du Royaume-Uni, soit environ 30%, selon le R\u00e9pertoire national des \u00e9lus. Ils sont nettement plus nombreux que les Belges (544 \u00e9lus) et les Portugais (357). Ils r\u00e9sident pour la plupart dans un grand quart Sud-Ouest de la France : Charente (70 \u00e9lus), Dordogne (59), Aude (52), Haute-Vienne (40), Lot-et-Garonne (31), H\u00e9rault (30), Deux S\u00e8vres (28), Gers (26), Lot (23)...Or, avec le Brexit, ils ne pourront pas briguer de nouveau mandat, \u00e0 moins d'avoir acquis une autre nationalit\u00e9 europ\u00e9enne depuis les derni\u00e8res \u00e9lections. C'est notamment le cas \u00e0 Poupas, village de 85 habitants dans le Tarn-et-Garonne, o\u00f9 deux des trois conseillers municipaux britanniques, sur les 11 au total que compte la commune, ont obtenu la nationalit\u00e9 fran\u00e7aise. Le droit \\\"de payer et de se taire\\\"Pour certaines petites communes, o\u00f9 il est souvent difficile de trouver des candidats, c'est un vrai casse-t\u00eate. \u00c0 Perriers-en-Beauficel, dans la Manche, Patrick Head , originaire du Wiltshire (sud de l'Angleterre), va ainsi terminer son mandat. Le sexag\u00e9naire avait rafl\u00e9 pas moins de 89,74% des suffrages dans ce petit village normand, o\u00f9 il a \u00e9lu domicile en 2004. Soit le meilleur score de cette commune de 216 habitants, o\u00f9 les \u00e9lecteurs peuvent rayer ou ajouter un nom. \\\"\u00c7a va nous manquer car Patrick nous aidait beaucoup\\\", regrette la maire Lydie Brionne, qui explique que son colistier faisait \\\"le lien\\\" avec la cinquantaine de Britanniques install\u00e9s dans ce coin de campagne normande. \u00c0 Perriers-en-Beauficel, sur les onze \u00e9lus de 2014, deux sont Britanniques. \\\"Il va falloir trouver deux nouveaux candidats. C'est difficile de trouver des gens motiv\u00e9s dans une petite commune\\\", souligne la maire, par ailleurs \u00e9leveuse de vaches laiti\u00e8res. \\\"Depuis 20 ans, beaucoup de Britanniques se sont install\u00e9s, ils ont repeupl\u00e9 la commune, \u00e7a a donn\u00e9 du dynamisme\\\", raconte l'\u00e9lue. Avec le Brexit, \\\"j'ai peur qu'ils soient oblig\u00e9s de repartir.\\\"Loin d'\u00eatre isol\u00e9, le cas de ce village normand se retrouve partout o\u00f9 les Britanniques sont fortement implant\u00e9s. \u00c0 Bellegarde-du-Raz\u00e8s, commune de 240 habitants dans l'Aude, les deux \u00e9lus d'Outre-Manche \\\"apportent une valeur ajout\u00e9e\\\" au village, avec \\\"leur importante implication dans le milieu associatif\\\", estime le maire Gilbert De Paoli. L'\u00c9cossaise Alisson Mackie, 63 ans, install\u00e9e depuis 2011, est d\u00e9pit\u00e9e de ne plus pouvoir se repr\u00e9senter en mars. \\\"On a construit notre maison ici, on paye des imp\u00f4ts ici, on consomme ici mais on a \u00e9t\u00e9 ray\u00e9s des listes \u00e9lectorales\\\", d\u00e9plore-t-elle.\u00c0 Jouac, village de 180 habitants en Haute-Vienne, la maire Virginie Windridge, 39 ans, elle-m\u00eame mari\u00e9e \u00e0 un Britannique, trouve aussi \\\"tr\u00e8s injuste que des gens qui sont l\u00e0 depuis des ann\u00e9es, payent des imp\u00f4ts et contribuent \u00e0 la vie de la commune, aient du jour au lendemain le droit 'de payer et de se taire'\\\". \\\"C'est dur \u00e0 avaler\\\", dit-elle.Les deux \u00e9lus britanniques actuels ont \\\"un apport important\\\", souligne la maire. \\\"D\u00e9j\u00e0 ils sont un relais avec la communaut\u00e9 britannique de la commune. Et puis ils apportent des id\u00e9es diff\u00e9rentes, une autre fa\u00e7on de fonctionner, de voir les choses\\\", d\u00e9crit Mme Windridge. \\\"Ils am\u00e8nent parfois un regard sur ce qui existe ou se fait ailleurs, une autre perspective\\\". \\\"Et, il faut bien le dire, culturellement, quelquefois, les Britanniques sont plus ouverts aux changements que nous, ont un peu moins peur de l'inconnu\\\", ajoute-t-elle en donnant en exemple la d\u00e9cision d'\u00e9teindre l'\u00e9clairage public nocturne. \\\"Les \u00e9lus britanniques \u00e9taient naturellement les plus ouverts sur cette id\u00e9e-l\u00e0, ils voyaient de suite le gagnant-gagnant, pour l'environnement et le budget de la commune\\\", estime-t-elle.\",\n  \"target_text\": \"\u00c0 l'heure actuelle, plus de 750 Britanniques si\u00e8gent dans les conseils municipaux en France. Or, avec la sortie du Royaume-Uni de l'Union europ\u00e9enne, ils ne pourront pas se repr\u00e9senter en mars prochain.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Les articles suivants sont accompagn\u00e9s d'un r\u00e9sum\u00e9.\n</code></pre></li> <li>Base prompt template:   <pre><code>Article de presse: {text}\nR\u00e9sum\u00e9: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Article de presse: {text}\n\nR\u00e9digez un r\u00e9sum\u00e9 de l'article ci-dessus.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset orange-sum\n</code></pre>"},{"location":"datasets/german/","title":"\ud83c\udde9\ud83c\uddea German","text":"<p>This is an overview of all the datasets used in the German part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/german/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/german/#sb10k","title":"SB10k","text":"<p>This dataset was published in this paper and is based on German tweets, which were manually annotated by three annotators.</p> <p>The original full dataset consists of 1,840 / 324 / 870 samples, and we use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively. The splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"ALEMANHA (4-5-1): Neuer; Schmelzer, Hummels, Mertesacker, Lahm; G\u00fcndogan, Khedira, \u00d6zil, M\u00fcller, Reus; Klose\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"@user ok. Bin jetzt dann hernach gleich nochmal weg, aber schreib ruhig.\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"@user Schw\u00fcle 34\u00b0, Tendenz steigend. #schrecklich\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Im Folgenden sind Tweets und ihre Stimmung aufgef\u00fchrt, die 'positiv', 'neutral' oder 'negativ' sein kann.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tweet: {text}\nStimmungslage: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tweet: {text}\n\nKlassifizieren Sie die Stimmung im Tweet. Antworten Sie mit 'positiv', 'neutral' oder 'negativ'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positiv</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutral</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negativ</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset sb10k\n</code></pre>"},{"location":"datasets/german/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/german/#germeval","title":"GermEval","text":"<p>This dataset was published in this paper and is based on German Wikipedia as well as news articles, and was manually annotated. It roughly follows the CoNLL-2003 format, but also allows overlapping entities and derived entities (such as \"English\" for \"England\"). We remove the derived entities and convert the partially overlapping entities to non-overlapping entities (e.g., <code>B-ORGpart</code> to <code>B-ORG</code>).</p> <p>The original full dataset consists of 24,000 / 2,200 / 5,100 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  'tokens': array(['Am', 'Ende', 'der', 'Saison', '2006/07', 'soll', 'es', 'f\u00fcr', 'die', 'L\u00f6wen', 'wieder', 'zu', 'einem', 'Europapokal-Platz', 'reichen', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-LOC', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['In', 'einer', 'Stichwahl', 'gegen', 'seinen', 'Vorg\u00e4nger', 'Georg', 'Kronawitter', 'wurde', 'Erich', 'Kiesl', 'am', '1.', 'April', '1984', 'abgew\u00e4hlt', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Noch', 'im', '13.', 'Jahrhundert', 'wurde', 'sie', 'in', 'manchen', 'Handschriften', 'mit', 'der', 'Christherre-Chronik', 'verschmolzen', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Es folgen S\u00e4tze und JSON-W\u00f6rterb\u00fccher mit den benannten Entit\u00e4ten, die in der angegebenen Phrase vorkommen.\n</code></pre></li> <li>Base prompt template:   <pre><code>Satz: {text}\nBenannte Entit\u00e4ten: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Satz: {text}\n\nIdentifizieren Sie die benannten Entit\u00e4ten im Satz. Sie sollten dies als JSON-W\u00f6rterbuch mit den Schl\u00fcsseln 'person', 'ort', 'organisation' und 'verschiedenes' ausgeben. Die Werte sollten Listen der benannten Entit\u00e4ten dieses Typs sein, genau wie sie im Satz erscheinen.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>ort</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>ort</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>verschiedenes</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>verschiedenes</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset germeval\n</code></pre>"},{"location":"datasets/german/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/german/#scala-de","title":"ScaLA-de","text":"<p>This dataset was published in this paper and was automatically created from the German Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 15,590 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Im In dem Sommer drau\u00dfen zu sitzen ist immer wieder eine \\\"Wonne\\\", so man noch einen Platz bekommt\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Eine 65 m lange Betonmauer tr\u00e4gt nachts einen Leucht - Schriftzug \\\"HOSTAL HOSTILE HOTEL HOSTAGE GOSTIN OSTILE HOSTEL HOSTIL HOST\\\", was in seinem etymologischen Wortspiel so viel bedeutet, dass aus einem feindlichen ein gastfreundlicher Ort geworden ist, in Anspielung auf das auf dem Gel\u00e4nde des ehemaligen Frauenlagers genau gegen\u00fcber liegende Novotel Goldene Bremm (heute Mercure Saarbr\u00fccken - S\u00fcd), das konzeptionell insoweit in die Idee einbezogen ist.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Allerdings wurde nachgewiesen, dass sich der ebenfalls in Extremlebensr\u00e4umen vorkommende Nematode Halicephalobus mephisto im in dem Labor bevorzugt Desulforudis audaxviator ern\u00e4hrt, wenn er eine Wahl hat (Alternative: E. coli).\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Die folgenden S\u00e4tze und ob sie grammatikalisch korrekt sind.\n</code></pre></li> <li>Base prompt template:   <pre><code>Satz: {text}\nGrammatikalisch richtig: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Satz: {text}\n\nBestimmen Sie, ob der Satz grammatikalisch korrekt ist oder nicht. Antworten Sie mit 'ja', wenn der Satz korrekt ist und 'nein', wenn er es nicht ist.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nein</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-de\n</code></pre>"},{"location":"datasets/german/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/german/#germanquad","title":"GermanQuAD","text":"<p>This dataset was published in this paper and is based on German Wikipedia articles, and was manually annotated.</p> <p>The original full dataset consists of 11,518 / 2,204 samples for training and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"Mali\\n\\n=== Verwaltungsgliederung ===\\nDer Staat gliedert sich in zehn Regionen und den Hauptstadtdistrikt. Diese teilen sich in 49 Kreise ''(cercles)'' und 703 Gemeinden ''(communes)''. Die Regionen sind nach ihren Hauptst\u00e4dten benannt. Zwei dieser zehn Regionen, M\u00e9naka und Taoud\u00e9nit, wurden 2012 per Gesetzesbeschluss gebildet. Die Einrichtung ist seit 2016 im Gange.\\nDie Angaben der Regionen Gao und Timbuktu, aus denen die Regionen M\u00e9naka und Taoud\u00e9nit ausgegliedert wurden, spiegeln noch den Stand vor der Aufspaltung wider.\\nUm auch Fl\u00fcchtlinge und vor allem Nomaden in das Verwaltungssystem eingliedern zu k\u00f6nnen, entstanden sogenannte ''Fractions'' (''Fractions Nomades'', ein Begriff, den schon die Kolonialregierung nutzte), die es dementsprechend vor allem im Norden in der N\u00e4he von D\u00f6rfern gibt. Seit den gro\u00dfen Trockenphasen entstanden durch Wanderungsbewegungen solche Verwaltungseinheiten allerdings auch verst\u00e4rkt im S\u00fcden.\",\n  \"question\": 'Wie viele verschiedene Regionen hat Mali? ',\n  \"answers\": {\n    \"answer_start\": array([63], dtype=int32),\n    \"text\": array(['zehn Regionen und den Hauptstadtdistrikt'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Iran\\n\\n=== Automobilindustrie ===\\nIn der Automobilindustrie waren 2010 rund 500.000 Menschen besch\u00e4ftigt, damit ist die Branche der zweitgr\u00f6\u00dfte Arbeitgeber nach der \u00d6lindustrie und der Iran der gr\u00f6\u00dfte Automobilproduzent im Mittleren Osten. 2012 ist die Automobilproduktion des Iran jedoch scharf eingebrochen; es wurden nur noch 989.110 Fahrzeuge produziert \u2013 40 Prozent weniger als 2011. Darunter fallen 848.000 PKW und 141.110 Nutzfahrzeuge.\\nDie beiden gr\u00f6\u00dften Automobilhersteller sind die staatliche SAIPA \u2013 derzeit im Privatisierungsprozess \u2013 und Iran Khodro (IKCO). Die IKCO produziert neben einheimischen Modellen wie Dena und Runna in Lizenz Modelle u.\\xa0a. von Peugeot. SAIPA hat die IKCO im Jahr 2010 das erste Mal in der Rangfolge \u00fcberholt. Nach Ansicht des Business Monitor International\u2019s Iran Autos Report wird sich die Belastbarkeit der iranischen Automobilindustrie erst in den n\u00e4chsten Jahren zeigen, wenn der einheimische Markt ges\u00e4ttigt ist und der Iran zunehmend auf dem internationalen Markt agiert, denn bisher ist der Produktionsanstieg noch \u00fcberwiegend auf die Unterst\u00fctzung der Regierung zur\u00fcckzuf\u00fchren. 12,64 % der zugelassenen Kraftfahrzeuge werden mit Gas betrieben. Der Iran liegt damit weltweit an f\u00fcnfter Stelle der Nutzung von gasbetriebenen Kraftfahrzeugen.\\nDer schwedische LKW-Produzent Scania er\u00f6ffnete 2011 eine neue Produktionslinie in Qazvin und l\u00f6st damit Daimler-Chrysler ab, das seine Gesch\u00e4ftskontakte mit dem Iran abgebrochen hat.',\n  \"question\": 'Wie hei\u00dfen die Automodelle von Iran Khodro?',\n  \"answers\": {\n    \"answer_start\": array([622], dtype=int32),\n    \"text\": array([' Dena und Runna'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Griechenland\\n\\n=== Klima ===\\nGriechenland hat \u00fcberwiegend ein mediterranes Klima mit feucht-milden Wintern und trocken-hei\u00dfen Sommern. An der K\u00fcste ist es im Winter sehr mild und es regnet h\u00e4ufig; Schnee f\u00e4llt nur selten. Die Sommer sind relativ hei\u00df und es gibt nur gelegentlich Sommergewitter. Mit 48\u00b0 wurde 1977 in Griechenland der kontinentaleurop\u00e4ische Hitzerekord gemessen.\\nIm Landesinneren ist es vor allem im Winter deutlich k\u00fchler und es gibt h\u00e4ufig Nachtfrost, manchmal auch starke Schneef\u00e4lle. Der Fr\u00fchling ist kurz, verw\u00f6hnt aber \u201emit einem Feuerwerk aus Lavendel und Anemonen, Klatschmohn und Kamille\u201c. Im Sommer ist es \u00e4hnlich wie an der K\u00fcste hei\u00df und trocken. Die j\u00e4hrlichen Niederschl\u00e4ge schwanken zwischen 400 und 1000\\xa0mm. Da Griechenland sehr gebirgig ist, ist Wintersport durchaus m\u00f6glich, es existieren 19 Wintersportgebiete unterschiedlicher Gr\u00f6\u00dfe. Ein kleiner Teil im Nordwesten des Festlandes liegt in der gem\u00e4\u00dfigten Klimazone.',\n  \"question\": 'Wie oft schneit es in Griechenland?',\n  \"answers\": {\n    \"answer_start\": array([209], dtype=int32),\n    \"text\": array(['nur selten'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Im Folgenden finden Sie Texte mit den dazugeh\u00f6rigen Fragen und Antworten.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nFragen: {question}\nFragen Antwort in maximal 3 W\u00f6rtern: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nBeantworten Sie die folgende Frage zum obigen Text in h\u00f6chstens 3 W\u00f6rtern.\n\nFrage: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset germanquad\n</code></pre>"},{"location":"datasets/german/#unofficial-belebele-de","title":"Unofficial: BeleBele-de","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Text: Es gibt viele Dinge, die Sie vor und w\u00e4hrend einer Reise ber\u00fccksichtigen m\u00fcssen. Erwarten Sie nicht, dass die Dinge beim Reisen genau so sind wie \u201ezuhause\u201c. Umgangsformen, Gesetze, Essen, Verkehr, Unterk\u00fcnfte, Standards, Spache und so weiter werden zu einem gewissen Grad anders sein als dort, wo Sie leben. Dies ist etwas, was man immer im Hinterkopf behalten sollte, um Entt\u00e4uschung oder gar Abneigung \u00fcber lokale Vorgehensweisen zu vermeiden.\\nFragen: Was kann Reisenden dem Abschnitt nach helfen, Entt\u00e4uschung beim Besuch neuer Orte zu vermeiden?\\nAntwortm\u00f6glichkeiten:\\na. \u00c4hnliche Standards wie zuhause erwarten\\nb. Essen probieren, das ungewohnt ist\\nc. Die gleichen Gesetze wie zuhause einhalten\\nd. Nicht vorher nach Unterk\u00fcnften recherchieren\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Text: Genehmigungen m\u00fcssen im Voraus bestellt werden. Sie ben\u00f6tigen eine Genehmigung, um in La Sirena zu \u00fcbernachten. Sirena ist die einzige Rangerstation, die neben Zelten auch \u00dcbernachtung im Schlafsaal und warme Mahlzeiten anbietet. La Leona, San Pedrillo und Los Patos bieten nur Camping ohne Verpflegung an. Es ist m\u00f6glich, eine Parklizenz direkt bei der Rangerstation in Puerto Jim\u00e9nez zu bekommen, aber sie akzeptieren keine Kreditkarten Die Parkverwaltung (MINAE) stellt Genehmigungen  f\u00fcr den Park nicht fr\u00fcher als einen Monat vor der geplanten Ankunft aus. CafeNet El Sol bietet einen Reservierungsservice gegen eine Geb\u00fchr von 30 US-Dollar bzw. 10 US-Dollar f\u00fcr Tageskarten an. Einzelheiten dazu findet man auf deren Corcovado-Seite.\\nFragen: Welche der folgenden Rangerstationen bietet zwei \u00dcbernachtungsm\u00f6glichkeiten an?\\nAntwortm\u00f6glichkeiten:\\na. Sirena\\nb. Los Patos\\nc. La Leona\\nd. San Pedrillo\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Text: Naturnaher Tourismus zieht Leute an, die daran interessiert sind, Naturgebiete zu besuchen, um die Landschaft zu genie\u00dfen, einschlie\u00dflich der wilden Pflanzen und Tiere. Beispiele f\u00fcr Aktivit\u00e4ten vor Ort sind Jagen, Angeln, Fotografie, Vogelbeobachtung, der Besuch von Parks und das Lernen von Informationen \u00fcber das \u00d6kosystem. Ein Beispiel daf\u00fcr ist der Besuch, das Fotografieren und das Studieren von Orangutangs in Borneo.\\nFragen: Welche der folgenden Aktivit\u00e4ten ist kein Beispiel f\u00fcr naturnahen Tourismus?\\nAntwortm\u00f6glichkeiten:\\na. Wandern zu einem Wasserfall\\nb. Fotografieren von Wildblumen\\nc. Besuch eines Wissenschaftsmuseum\\nd. Fliegenfischen\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).\n</code></pre></li> <li>Base prompt template:   <pre><code>Frage: {text}\nAntwort: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frage: {text}\nAntwortm\u00f6glichkeiten:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-de\n</code></pre>"},{"location":"datasets/german/#unofficial-multiwikiqa-de","title":"Unofficial: MultiWikiQA-de","text":"<p>This dataset will be published in an upcoming paper, and contains German Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Claire Patricia Grogan (* 17. M\u00e4rz 1962 in Glasgow, Schottland) ist eine britische Schauspielerin, Pops\u00e4ngerin sowie Kinder- und Jugendbuchautorin.\\n\\nTrotz abweichender Schreibweise ist sie seit Beginn ihrer Karriere unter dem Namen Clare Grogan bekannt. Im Fernsehen trat sie sp\u00e4ter als C.P. Grogan auf, da es in der britischen K\u00fcnstlergewerkschaft Equity eine andere Person gleichen Namens gab.\\n\\nLeben \\nClare Grogan wurde vom schottischen Filmregisseur Bill Forsyth in Glasgow entdeckt, wo sie in einem Restaurant als Kellnerin arbeitete. Im Alter von 19 Jahren spielte sie die Rolle der Susan im Spielfilm Gregory\u2019s Girl. Zu diesem Zeitpunkt feierte sie bereits als S\u00e4ngerin der New-Wave-Band Altered Images erste Erfolge. Mit Titeln wie Happy Birthday und I Could Be Happy wurde die Band Anfang der 1980er-Jahre auch au\u00dferhalb Gro\u00dfbritanniens bekannt. Sie l\u00f6ste sich 1984 nach der Produktion des dritten Albums aufgrund nachlassenden Publikumszuspruchs auf.\\n\\n1987 startete Grogan den Versuch einer Solokarriere, hatte mit ihrer Single Love Bomb jedoch keinen Erfolg. Auch ihr Album Trash Mad wurde nie ver\u00f6ffentlicht. Musikalisch trat sie danach nur noch selten in Erscheinung. 1993 war sie an der Produktion des Musikvideos Young at Heart der Gruppe Bluebells beteiligt. Der Titel stand vier Wochen lang auf dem ersten Platz der britischen Singlecharts. 2000 steuerte sie den Gesang im Song Night Falls Like A Grand Piano aus dem Album Hyacinths and Thistles der Band The 6ths bei. Im zwei Jahre sp\u00e4ter ver\u00f6ffentlichten The Ultimate Celtic Album ist sie mit dem St\u00fcck Her Hooped Dream vertreten. F\u00fcr das 2003 erschienene Album A Tribute to Frankie Miller nahm sie eine neue Version von Angels With Dirty Faces auf. Nach einer 18-j\u00e4hrigen Pause trat sie in den 2000er-Jahren mit wechselnden Musikern mehrmals bei der Here and Now Tour, beim Rewind Festival sowie \u00e4hnlichen Revival-Veranstaltungen in Gro\u00dfbritannien und Irland unter dem Namen Altered Images auf.\\n\\nIm Jahr 1985 setzte sie ihre zweite Karriere als Schauspielerin mit einer kleinen Rolle als Empfangsdame in der sechsteiligen BBC-Produktion Blott on the Landscape fort. In der Science-Fiction-Fernsehserie Red Dwarf spielte sie die Kristine Kochanski, wurde sp\u00e4ter aber durch die Schauspielerin Chlo\u00eb Annett ersetzt. Weitere Auftritte in den Serien Father Ted und EastEnders sowie in den britischen Spielfilmen Bury It und The Penalty King folgten. Grogan war auch Moderatorin im Musiksender VH1 und Gastgeberin einer Talkshow. Zuweilen half sie als Sprecherin beim Radiosender BBC Radio 6 Music aus.\\n\\nAls Autorin deb\u00fctierte Grogan im Oktober 2008 mit dem Kinderbuch Tallulah and the Teenstars. Es erz\u00e4hlt die Geschichte einer Sch\u00fclerin, die eine Popband gr\u00fcndet und den aufkommenden Erfolg bew\u00e4ltigen muss. Ende 2011 erschien eine Fortsetzung mit dem Titel Tallulah on Tour.\\n\\n1994 heiratete Grogan den Produzenten Steve Lironi, fr\u00fcher selbst Gitarrist und Schlagzeuger der Altered Images. Das Paar adoptierte 2005 ein M\u00e4dchen und lebt im Londoner Stadtbezirk London Borough of Haringey.\\n\\nWerke\\n\\nKinofilme und Fernsehproduktionen \\n 1980: Gregory\u2019s Girl\\n 1984: Comfort and Joy\\n 1985: Blott on the Landscape (britische Fernsehserie)\\n 1988: Red Dwarf (britische Fernsehserie), Episoden The End, Balance of Power und Stasis Leak\\n 1993: Red Dwarf, Episode Psirens\\n 1996: Father Ted (britische Fernsehserie), Episode Rock-a-Hula Ted\\n 1997: Jilting Joe\\n 1997: EastEnders (britische Fernsehserie), zwei Episoden\\n 2002: Bury It\\n 2006: The Penalty King\\n 2007: Legit (britische Fernsehserie), Episoden Birthday, Manitoba und Night of the Lobster\\n 2011: Skins \u2013 Hautnah, Episode Mini\\n 2012: Waterloo Road (britische Fernsehserie), Episode Future Proof\\n\\nB\u00fccher \\n 2008: Tallulah and the Teenstars\\n 2011: Tallulah on Tour\\n\\nWeblinks\\n\\nEinzelnachweise \\n\\nFilmschauspieler\\nAutor\\nPops\u00e4nger\\nLiteratur (21. Jahrhundert)\\nLiteratur (Englisch)\\nKinder- und Jugendliteratur\\nMusiker (Vereinigtes K\u00f6nigreich)\\nPerson (Glasgow)\\nSchotte\\nBrite\\nGeboren 1962\\nFrau\",\n    \"question\": \"Was war Clare Grogans T\u00e4tigkeit, bevor sie von Bill Forsyth entdeckt wurde?\",\n    \"answers\": {\n        \"answer_start\": array([519]),\n        \"text\": array([\"Kellnerin\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Claris International Inc. (bis August 2019 FileMaker, Inc.) ist eine hundertprozentige US-amerikanische Tochtergesellschaft des kalifornischen Computerherstellers Apple, die die Datenbanksoftware FileMaker entwickelt. Die Firma FileMaker entstand 1998 als Nachfolgerin von Claris, die ihrerseits 1987 als Ableger von Apple gegr\u00fcndet worden war.\\n\\nGeschichte \\nClaris wurde Anfang 1998 aufgel\u00f6st. Das Programm FileMaker Pro wurde Grundlage des neu gegr\u00fcndeten Unternehmens FileMaker, Inc.\\n\\nProdukte von Claris waren:\\n ClarisCAD, ein CAD-Programm\\n Claris MacDraw, ein Zeichenprogramm\\n Claris Em@iler, ein E-Mail-Programm\\n FileMaker, sp\u00e4ter FileMaker Pro, das dominierende Datenbankprogramm auf der Macintosh-Plattform\\n Claris Home Page, ein HTML-Editor\\n Claris Impact, ein Pr\u00e4sentationsprogramm\\n Claris MacWrite Pro, eine Textverarbeitung\\n Claris Organizer, ein Personal Information Manager\\n Claris Resolve, eine Tabellenkalkulation\\n ClarisWorks, ein B\u00fcropaket, das sp\u00e4ter von Apple als AppleWorks weitergef\u00fchrt wurde\\n Claris MacPaint, ein Bildbearbeitungsprogramm\\n\\nVon 2008 bis 2013 wurde die pers\u00f6nliche Datenbankanwendung Bento verkauft.\\n\\nIm August 2019 gab das Unternehmen bekannt, zum alten Unternehmensnamen Claris zur\u00fcckzukehren.\\n\\nEinzelnachweise \\n\\nApple\\nSoftwarehersteller (Vereinigte Staaten)\\nUnternehmen (Santa Clara, Kalifornien)\\nGegr\u00fcndet 1998\",\n    \"question\": \"Unter welchem Namen war FileMaker, Inc. fr\u00fcher bekannt, bevor es in Claris International Inc. umbenannt wurde?\",\n    \"answers\": {\n        \"answer_start\": array([31]),\n        \"text\": array([\"August 2019\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Augusta Marie Gertrude von Hanau (* 21. September 1829 in Niederdorfelden; \u2020 18. September 1887 in Halle) war die unehelich geborene \u00e4lteste Tochter des Kurf\u00fcrsten Friedrich Wilhelm I. von Hessen-Kassel (1802\u20131875) und seiner erst sp\u00e4teren Ehefrau Gertrude, sp\u00e4tere F\u00fcrstin von Hanau und zu Ho\u0159owitz (1803\u20131882).\\n\\nKurprinz Friedrich Wilhelm lernte seine Frau kennen, als diese noch mit dem Leutnant Karl Michael Lehmann (1787\u20131882) verheiratet war, beging mit ihr Ehebruch, erreichte schlie\u00dflich die Scheidung und heiratete sie 1831. Augusta Marie Gertrude wurde so zu einer Zeit geboren, als ihre Mutter noch eine verheiratete Lehmann war. Sie wurde deshalb zun\u00e4chst vom damaligen Mann ihrer Mutter als ehelich anerkannt. Erst nach der Scheidung und der Heirat von Gertrude Lehmann mit dem Kurprinzen verzichtete Karl Michael Lehmann auf die Vaterschaftsrechte. Augusta Marie Gertrude Lehmann wurde nun von ihrem leiblichen Vater zur Gr\u00e4fin Schaumburg und sp\u00e4ter zur Prinzessin von Hanau erhoben.\\n\\nAm 17. Juli 1849 heiratete sie den Grafen Ferdinand Maximilian zu Ysenburg-B\u00fcdingen (* 24. Oktober 1823; \u2020 5. Mai 1903). Dieser war mental wohl etwas gest\u00f6rt. Nachdem eine Kasseler Zeitung 1853 seine Frau \u201eErlaucht\u201c statt \u201eDurchlaucht\u201c betitelt hatte, griff er den Ersten Minister seines Schwiegervaters, Ludwig Hassenpflug, t\u00e4tlich an und verletzte ihn mit Stockschl\u00e4gen. Er kam darauf vor\u00fcbergehend in eine Klinik. 1865 wurde er durch den Kurf\u00fcrsten in den F\u00fcrstenstand erhoben und nannte sich nun Ferdinand-Maximillian I.\\n\\nF\u00fcrstin Augusta Marie Gertrude hatte ein sehr enges Verh\u00e4ltnis zu ihrem Vater. Als er 1866 nach dem gegen Preu\u00dfen verlorenen Krieg in Stettin als Kriegsgefangener einsa\u00df, besuchte sie ihn.\\n\\nSie starb in Halle, wohin sie ihren Mann begleitet hatte, der sich dort einer Operation unterziehen musste.\\n\\nLiteratur \\n R\u00fcdiger Ham: Ludwig Hassenpflug: Staatsmann und Jurist zwischen Revolution und Reaktion. Eine politische Biographie = Studien zur Geschichtsforschung der Neuzeit 50. Hamburg 2007. ISBN 978-3-8300-2764-5\\nMichel Huberty: L' Allemagne dynastique: Les 15 familles qui ont fait l'empire. Bd. 1: Hesse - Reuss - Saxe. Le Perreux-sur-Marne 1976. ISBN 2-901138-01-2\\n Philipp Losch: Die F\u00fcrstin von Hanau und ihre Kinder. In: Hanauer Geschichtsbl\u00e4tter 13 (1939), S. 33.\\n\\nWeblinks\\n\\nEinzelnachweise \\n\\nFriedrich Wilhelm I. (Hessen-Kassel)\\nTitularf\u00fcrst (Isenburg)\\nFamilienmitglied des Hauses Hanau-Ho\u0159ovice\\n\u26adAugusta Marie Gertrude #Hanau\\nDeutscher\\nGeboren 1829\\nGestorben 1887\\nFrau\",\n    \"question\": \"Wann wurde Ferdinand Maximilian von Ysenburg-B\u00fcdingen F\u00fcrst?\",\n    \"answers\": {\n        \"answer_start\": array([1416]),\n        \"text\": array([\"1865\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Im Folgenden finden Sie Texte mit den dazugeh\u00f6rigen Fragen und Antworten.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nFragen: {question}\nFragen Antwort in maximal 3 W\u00f6rtern: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nBeantworten Sie die folgende Frage zum obigen Text in h\u00f6chstens 3 W\u00f6rtern.\n\nFrage: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <p><pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-de\n\n\n## Knowledge\n\n### MMLU-de\n\nThis dataset is a machine translated version of the English [MMLU\ndataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57\ndifferent topics, such as elementary mathematics, US history and law. The translation to\nGerman was done by the University of Oregon as part of [this\npaper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.\n\nThe original full dataset consists of 269 / 1,410 / 13,200 samples for training,\nvalidation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,\nvalidation and testing, respectively (so 3,328 samples used in total). These splits are\nnew and there can thus be some overlap between the original validation and test sets and\nour validation and test sets.\n\nHere are a few examples from the training split:\n\n```json\n{\n  \"text\": \"Teotihuac\u00e1n wurde im Becken von Mexiko bekannt, nachdem sein Rivale Cuicuilco,\\nAntwortm\u00f6glichkeiten:\\na. von einem Vulkanausbruch gel\u00e4hmt wurde.\\nb. einem B\u00fcrgerkrieg unter seinen herrschenden Familien erlag.\\nc. unter einer Ernteplage litt.\\nd. von einem Hurrikan an der Golfk\u00fcste \u00fcberschwemmt wurde.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Wer von den folgenden ist der industrielle Philanthrop?\\nAntwortm\u00f6glichkeiten:\\na. Frederick Taylor\\nb. Seebohm Rowntree\\nc. Henry Ford\\nd. Max Weber\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Verglichen mit der Varianz der Maximum-Likelihood-Sch\u00e4tzung (MLE) ist die Varianz der Maximum-A-Posteriori (MAP)-Sch\u00e4tzung ________\\nAntwortm\u00f6glichkeiten:\\na. h\u00f6her\\nb. gleich\\nc. niedriger\\nd. es kann jede der obigen Optionen sein\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).\n</code></pre></li> <li>Base prompt template:   <pre><code>Frage: {text}\nAntwort: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frage: {text}\nAntwortm\u00f6glichkeiten:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-de\n</code></pre>"},{"location":"datasets/german/#unofficial-arc-de","title":"Unofficial: ARC-de","text":"<p>This dataset is a machine translated version of the English ARC dataset and features US grade-school science questions. The translation to German was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Callahan zitiert die Ergebnisse des Oregon Death with Dignity Legal Defense and Education Center, wonach es \\\"nach vier vollen Jahren keine Missteps, Missbr\u00e4uche oder Zwangstendenzen\\\" bez\u00fcglich der Gesetze zur Euthanasie gab. Er argumentiert dagegen, dass\\nAntwortm\u00f6glichkeiten:\\na. sie dies ohne eine anonyme Umfrage nicht sicher wissen k\u00f6nnen.\\nb. andere Studien haben widerspr\u00fcchliche Ergebnisse gefunden.\\nc. selbst wenn das Ergebnis wahr ist, ist es irrelevant f\u00fcr den moralischen Status der Euthanasie.\\nd. die Ergebnisse sind verd\u00e4chtig, weil die Studie von Bef\u00fcrwortern der Euthanasie durchgef\u00fchrt wurde.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>  \"text\": \"Eine Frau besa\u00df ein Land im absoluten Besitz. Die Frau \u00fcbertrug das Land an einen Freund \u201cauf Lebenszeit\u201d und als der Freund starb, sollte das Land an den Nachbarn der Frau \\\"und ihre Erben\\\" weitergegeben werden. Der Nachbar starb und in ihrem ordnungsgem\u00e4\u00df beglaubigten Testament vermachte sie ihre gesamte Hinterlassenschaft an eine \u00f6rtliche Wohlt\u00e4tigkeitsorganisation. Wenn sie intestat gestorben w\u00e4re, w\u00e4re ihre Tochter ihre einzige Erbin gewesen. Ein Jahr nach dem Tod des Nachbarn \u00fcbertrug dessen Tochter durch eine Quitclaims-Erkl\u00e4rung jegliches Interesse, das sie an dem Land haben k\u00f6nnte, an die Freundin der Frau. Das Common Law Rule Against Perpetuities ist in der Gerichtsbarkeit unver\u00e4ndert. Es gibt keine weiteren anwendbaren Gesetze. Wer hat welches Interesse an dem Land?\\nAntwortm\u00f6glichkeiten:\\na. Der Freund hat einen absoluten Besitz, weil sein Lebensbesitz mit dem verbleibenden Teil verschmolzen ist, den ihm die Tochter \u00fcbertragen hat.\\nb. Der Freund hat einen Lebensbesitz und die Wohlt\u00e4tigkeitsorganisation hat einen unverfallbaren Rest, weil das Interesse des Nachbarn \u00fcbertragbar war.\\nc. Der Freund hat einen Lebensbesitz und die Tochter hat einen unverfallbaren Rest, weil die Erkl\u00e4rung der Frau ein Interesse an den Erben des Nachbarn schuf.\\nd. Der Freund hat einen Lebensbesitz und die Frau hat einen R\u00fcckfall, weil das Restinteresse des Nachbarn gem\u00e4\u00df dem Rule Against Perpetuities ung\u00fcltig war.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"F\u00fcr welches dieser beiden Szenarien tut der Hauptcharakter (der ich/mich/mein verwendet) etwas, das nach den gew\u00f6hnlichen moralischen Standards in den USA im Jahr 2020 eindeutig moralisch falsch ist? Szenario 1 | Ich gehe gerne in die Kirche, weil es mich in h\u00f6chstem Ma\u00dfe Gott nahe f\u00fchlen l\u00e4sst. Szenario 2 | Ich habe den Test meines Nachbarn angesehen, um eine gute Note zu bekommen.\\nAntwortm\u00f6glichkeiten:\\na. Falsch, Falsch\\nb. Falsch, Nicht falsch\\nc. Nicht falsch, Falsch\\nd. Nicht falsch, Nicht falsch\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).\n</code></pre></li> <li>Base prompt template:   <pre><code>Frage: {text}\nAntwort: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frage: {text}\nAntwortm\u00f6glichkeiten:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset arc-de\n</code></pre>"},{"location":"datasets/german/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/german/#hellaswag-de","title":"HellaSwag-de","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[header] Wie man sich trennt, wenn Kinder involviert sind [title] Erstellen Sie einen Trennungsplan mit Ihrem Partner. [step] Sie sollten sich auch auf das Gespr\u00e4ch mit Ihren Kindern vorbereiten, indem Sie vorher mit Ihrem Partner einen Plan f\u00fcr die Zukunft erstellen. Sie sollten gemeinsam besprechen, wer wo leben wird, wer f\u00fcr bestimmte t\u00e4gliche Bed\u00fcrfnisse und Aktivit\u00e4ten der Kinder verantwortlich sein wird und wann der offizielle Scheidungsprozess beginnen wird.\\nAntwortm\u00f6glichkeiten:\\na. Indem Sie hier\u00fcber klare Vorstellungen haben, k\u00f6nnen Sie Ihre Kinder besser beruhigen und einheitlich auftreten. [substeps] Zum Beispiel, k\u00f6nnten Sie vereinbaren, dass Ihr Partner auszieht und in einer nahegelegenen Wohnung oder einem anderen Haus lebt.\\nb. Sie beide sollten Ihre Aktionen in den Monaten bis zur Eheschlie\u00dfung sowie dar\u00fcber, wie Sie alles tun werden, planen, sobald das Kind wieder mit seinem Vater vereint ist. [title] Entscheiden Sie, was Sie mit dem Kind machen werden.\\nc. Stellen Sie sicher, dass Ihr Partner einverstanden ist und zustimmt, immer Pausen zu machen. [substeps] Sie sollten sich nun auf die Urlaubsdaten und Reisepl\u00e4ne einigen, zu denen Ihre Kinder gehen werden.\\nd. Der erste Schritt zu diesem Plan ist, ein Telefongespr\u00e4ch zu vereinbaren, damit Sie mit Ihrem Partner pers\u00f6nlich sprechen k\u00f6nnen. Sprechen Sie ruhig und deutlich, um den Ton f\u00fcr dieses Gespr\u00e4ch zu setzen.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] Wie man Festival-Make-up macht [title] Bereiten Sie Ihr Gesicht vor. [step] Bevor Sie Ihr Augen-Make-up auftragen, m\u00fcssen Sie eine Basis schaffen. Dies hilft sicherzustellen, dass Ihr Augen-Make-up den ganzen Tag h\u00e4lt.\\nAntwortm\u00f6glichkeiten:\\na. [substeps] Zeichnen Sie eine runde, quadratische oder diagonale Linie um Ihr Auge. Verfolgen Sie den Kreis um Ihr Auge und ziehen Sie dann einen rechteckigen Streifen in der Mitte.\\nb. [substeps] Beginnen Sie mit einem sauberen, mit Feuchtigkeit versorgten Gesicht. Reinigen Sie Ihr Gesicht zun\u00e4chst mit einem sanften Reinigungsmittel und tragen Sie dann einen leichten Feuchtigkeitsspender auf Ihr Gesicht und Ihren Hals auf, um das Erscheinungsbild feiner Linien zu reduzieren.\\nc. Bevor Sie Lidschatten auftragen, w\u00e4hlen Sie einen einzelnen Lidschatten aus und messen Sie ihn so aus, dass er etwas gr\u00f6\u00dfer ist als das Auge, das Sie verblenden m\u00f6chten. Tragen Sie den Lidschatten auf die Spitze jedes Auges auf und streichen Sie mit einem Verblendpinsel dar\u00fcber.\\nd. Make-up am fr\u00fchen Morgen zu tragen ist nicht immer eine Option, aber Sie k\u00f6nnen es am Abend tun. [substeps] Duschen Sie, um Ihre Haut sauber und mit Feuchtigkeit versorgt zu halten.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Wir sehen einen Mann in einem Orchester Grimassen schneiden. Der Mann steht dann auf und spielt die Violine. Wir sehen Menschen an Spinden. wir\\nAntwortm\u00f6glichkeiten:\\na. sehen Menschen in einem Bus.\\nb. sehen Menschen beim \u00dcben von Kampfsport und Musik spielen.\\nc. kehren zum Mann zur\u00fcck, der die Violine spielt.\\nd. sehen den Mann am Keyboard wieder.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).\n</code></pre></li> <li>Base prompt template:   <pre><code>Frage: {text}\nAntwort: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frage: {text}\nAntwortm\u00f6glichkeiten:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-de\n</code></pre>"},{"location":"datasets/german/#unofficial-goldenswag-de","title":"Unofficial: GoldenSwag-de","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Wie man Rouge auftr\u00e4gt. Verwenden Sie die richtige Art von Pinsel. Die Art des Pinsels h\u00e4ngt davon ab, wo Sie das Rouge auftragen wollen. Da Sie das Rouge nicht nur auf die Wangen\u00e4pfel auftragen werden, sollten Sie f\u00fcr kleinere Bereiche einen kleineren Pinsel verwenden.\\nAntwortm\u00f6glichkeiten:\\na. F\u00fcr die Wangen k\u00f6nnen Sie einen normalen Rougepinsel verwenden. Manche empfehlen, f\u00fcr die kleineren Gesichtspartien einen Abdeckpinsel zu verwenden.\\nb. Je kleiner der Pinsel ist, desto mehr Rouge m\u00fcssen Sie auf Ihre Wangen auftragen. \u00dcberpr\u00fcfen Sie auf der Verpackung die richtige Pinselgr\u00f6\u00dfe f\u00fcr diesen Bereich.\\nc. W\u00e4hlen Sie den Pinsel, der am besten zu Ihrem Haartyp passt. Bei lockigem Haar verwenden Sie einen gr\u00f6\u00dferen Pinsel f\u00fcr d\u00fcnneres Haar und einen kleineren Pinsel f\u00fcr d\u00fcnnes Haar.\\nd. F\u00fcr gr\u00f6\u00dfere Fl\u00e4chen k\u00f6nnen Sie einen Tubenpinsel oder einen Pinsel in einer anderen Farbe verwenden, um ein Zusammenfallen zu vermeiden. Verwenden Sie einen Pinsel mit Borsten in der Farbe Ihrer Grundierung, damit die abgerundeten Borsten weniger auffallen.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Wie Sie einen Redakteur auf sich aufmerksam machen k\u00f6nnen. Lesen und befolgen Sie die Einreichungsrichtlinien der Publikation. Publikationen erstellen Einreichungsrichtlinien, um es sowohl den Autoren als auch den Redakteuren leichter zu machen. Wenn Sie die Richtlinien lesen und befolgen, erstellen Sie einen Beitrag, der den Anforderungen der Publikation entspricht, was es f\u00fcr Sie als Autor einfacher macht, und zwar in einem Format, das die Redakteure leichter auf Eignung und Qualit\u00e4t pr\u00fcfen k\u00f6nnen.\\nAntwortm\u00f6glichkeiten:\\na. Vermeiden Sie es, den Namen und die Ver\u00f6ffentlichungsseite der Publikation vollst\u00e4ndig zu blockieren. Wenn die Publikation nicht sehr k\u00fcnstlerisch ist, wird sie vielleicht gar nicht ver\u00f6ffentlicht.\\nb. Vergewissern Sie sich, dass Ihr Artikel diesen Richtlinien entspricht, wenn Sie sich um eine Stelle als Redakteur bewerben. Bei einigen Stellen m\u00fcssen Sie eine bestimmte Menge an Arbeit leisten, um eine Redakteursstelle zu erhalten, w\u00e4hrend bei anderen ein Minimum von 30 Arbeitsstunden erforderlich ist.\\nc. Die meisten Publikationen mit Internetpr\u00e4senz bieten ihre Richtlinien f\u00fcr die Einreichung von Beitr\u00e4gen auf ihren Websites an. Wenn dies nicht der Fall ist, k\u00f6nnen Sie die Richtlinien erhalten, indem Sie an die angegebene Adresse der Publikation schreiben.\\nd. Bitten Sie die Autoren am Ende der Ver\u00f6ffentlichung, Ihre Arbeit regelm\u00e4\u00dfig zu ver\u00f6ffentlichen. Heben Sie in Ihrem Beitrag wichtige Aspekte hervor, damit Sie nicht von der Publikation ausgeschlossen werden.\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Wie Sie Hundegeruch aus Ihrem Auto entfernen. Waschen Sie alle abnehmbaren Teile Ihres Autos. Alle Teile Ihres Autos, die Sie abnehmen k\u00f6nnen, sollten Sie in der Waschmaschine waschen. Dadurch wird der Hundegeruch entfernt und Ihr Auto riecht wieder frischer.\\nAntwortm\u00f6glichkeiten:\\na. Wenn Sie feststellen, dass Ihr Auto nach Ihnen riecht, wenn Sie es ausstecken, sollten Sie die Teile 5 Minuten in warmem Wasser und 20 Minuten in kaltem Wasser einweichen. Wenn Sie ein Stra\u00dfenfest veranstalten, verwenden Sie einen Trichter, um Plastikteile in die Waschmaschine zu bef\u00f6rdern, w\u00e4hrend die \u00e4u\u00dferen Teile weggeworfen werden.\\nb. Gummimatten, Autositzbez\u00fcge und alle Decken, die Sie f\u00fcr Ihren Hund aufbewahren, k\u00f6nnen entfernt und gewaschen werden. Waschen Sie die Teile Ihres Autos sicherheitshalber bei einer k\u00fchlen Temperatur.\\nc. Eine Schicht Antitranspirant hingegen entfernt nur das Produkt, und Ihr Auto riecht wahrscheinlich schon nach Urin. Wenn Ihr Auto mit Ledersitzen ausgestattet ist, wischen Sie das Produkt, das sich dort angesammelt hat, ab.\\nd. Am sichersten ist es, alle abnehmbaren Teile Ihres Autos zu entfernen, einschlie\u00dflich der \"Fifflers\". Diese Teile k\u00f6nnen bei hei\u00dfem Wetter leicht stinken, aber sie k\u00f6nnen auch schwitzen und den Eigengeruch Ihres Hundes produzieren.\",\n  \"label\": \"b\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).\n</code></pre></li> <li>Base prompt template:   <pre><code>Frage: {text}\nAntwort: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frage: {text}\nAntwortm\u00f6glichkeiten:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBeantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-de\n</code></pre>"},{"location":"datasets/german/#summarization","title":"Summarization","text":""},{"location":"datasets/german/#mlsum-de","title":"MLSum-de","text":"<p>This dataset was published in this paper and features news articles and their summaries in five languages, including German. The German part of the dataset is based on news articles from S\u00fcddeutsche Zeitung, with human-written summaries.</p> <p>The original full dataset consists of 221,000 / 11,400 / 10,700 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Jede neue Schlagzeile ein Stich ins Herz: F\u00fchrende Muslime beklagen in einem offenen Brief die wachsende \\\"Feindseligkeit\\\" gegen Migranten in Deutschland. Sie fordern Bundespr\u00e4sident Wulff auf, Stellung zu beziehen. In einem offenen Brief haben 15 namhafte deutsche Muslime Bundespr\u00e4sident Christian Wulff aufgefordert, in der schwelenden Debatte um Integrationsprobleme Stellung zu beziehen. Ausl\u00f6ser der Kontroverse war das Buch Deutschland schafft sich ab des SPD-Politikers und scheidenden Bundesbankvorstandes Thilo Sarrazin. Detailansicht \u00f6ffnen In der von SPD-Politiker und Noch-Bundesbanker Thilo Sarrazin ausgel\u00f6sten Integrationsdebatte fordern namhafte deutsche Muslime nun von Bundespr\u00e4sident Christian Wulff, Stellung zu beziehen. (Foto: dpa) Intellektuelle wie der Regisseur Fatih Akin und der Schriftsteller Feridun Zaimoglu beklagten in dem in der taz ver\u00f6ffentlichten Brief wachsende \\\"Feindseligkeit\\\" gegen Muslime in Deutschland. W\u00f6rtlich hei\u00dft es: \\\"F\u00fcr Musliminnen und Muslime ist derzeit nicht einmal der Gang zum Zeitungsh\u00e4ndler leicht, weil sie nie wissen, welche Schlagzeile, welches stereotype Bild sie dort erwartet.\\\" Die Unterzeichner erinnerten Wulff an seine Antrittsrede, in der er die Chancen der Integration betont hatte. \\\"Wir bitten Sie, gerade in der derzeitigen angespannten Stimmung f\u00fcr die Leits\u00e4tze einer offenen, von gegenseitigem Respekt gepr\u00e4gten demokratischen Kultur einzustehen und \u00f6ffentlich f\u00fcr sie zu werben\\\", hei\u00dft es in dem Appell an Wulff. Ausl\u00f6ser f\u00fcr den offenen Brief sei der Aufruf der Bild-Zeitung gewesen, an Pr\u00e4sident Wulff zu schreiben, sagte Shermin Langhoff, Intendantin des Berliner Theaters Ballhaus Naunynstra\u00dfe. \\\"Wir dachten uns, das k\u00f6nnen wir nicht so stehen lassen\\\", sagte die Mitunterzeichnerin zur SZ. Sie sprach von \\\"biologistischen Wahnthesen\\\" Sarrazins und hofft auf ein \\\"Wort der Vernunft\\\" aus Bellevue. Auch andere Unterzeichnerinnen setzen darauf, dass sich das Staatsoberhaupt in die Debatte einschaltet. Aylin Selcuk, Initiatorin des Vereins Deukische Generation, w\u00fcnscht sich ein starkes Zeichen Wulffs. Der Pr\u00e4sident m\u00f6ge zeigen, dass die Muslime in Deutschland dazugeh\u00f6ren. \\\"Wir bitten Sie: Bekennen Sie sich zu uns.\\\" Lamya Kaddor vom Liberal-Islamischen Bund sprach von einem \\\"\u00f6ffentlichen Bekenntnis\\\" des Pr\u00e4sidenten. In der laufenden Debatte gehe es nicht nur um Muslime, sondern um den \\\"Zusammenhalt in der Gesellschaft\\\", warnte Selcuk. Die Studentin hatte Sarrazin nach seinen \u00c4u\u00dferungen zur vererbten Intelligenz wegen Volksverhetzung angezeigt. Seitdem erreichten sie unz\u00e4hlige E-Mails, in denen sie geschm\u00e4ht und bedroht werde, sagte Selcuk. Nun hofft sie auf Wulff. \\\"Wir werden dieses Land nicht aufgeben\\\", hei\u00dft es in dem Brief an Christian Wulff. \\\"Dieses Land ist unsere Heimat und Sie sind unser Pr\u00e4sident.\\\"\",\n  \"target_text\": \"Jede neue Schlagzeile ein Stich ins Herz: F\u00fchrende Muslime beklagen in einem offenen Brief die wachsende \\\"Feindseligkeit\\\" gegen Migranten in Deutschland. Sie fordern Bundespr\u00e4sident Wulff auf, Stellung zu beziehen.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hoch flog der erste Schl\u00e4ger in die Luft, und viele andere Gegenst\u00e4nde folgten ihm. \u00dcberall auf dem Eis lag die Ausr\u00fcstung der deutschen Mannschaft zerstreut, Handschuhe, Helme, Schl\u00e4ger, weg damit, wer braucht so etwas schon, wenn er hemmungslos jubeln kann? In einer Ecke des Eises versammelten sich die Spieler der deutschen Eishockey-Mannschaft. Sie h\u00fcpften und tanzten und schrien, und wenn es nicht zu den Gepflogenheiten des Sports z\u00e4hlen w\u00fcrde, irgendwann zum H\u00e4ndesch\u00fctteln mit dem Gegner in der Mitte des Feldes zu erscheinen, dann h\u00e4tten sie wahrscheinlich noch eine ganze Weile so weitergemacht. Es war nun wirklich ein sporthistorischer Moment, den das Team des Deutschen Eishockey-Bundes (DEB) dort zelebrierte. Mit 4:3 (1:0, 3:1, 0:2) hatte es in einem ph\u00e4nomenalen Spiel den Rekord-Olympiasieger Kanada bezwungen und sich damit f\u00fcr das Finale des Turniers gegen die Olympischen Athleten aus Russland (5.10 Uhr MEZ) qualifiziert. Zum ersten Mal \u00fcberhaupt kann eine deutsche Mannschaft Olympiasieger werden, es ist der gr\u00f6\u00dfte Erfolg in der Geschichte des deutschen Eishockeys. \\\"Verr\u00fcckt, ne, verr\u00fcckt, verr\u00fcckte Welt\\\", sagte Bundestrainer Marco Sturm: \\\"Das ist einmalig.\\\" Ein ohnehin schon irres Turnier kulminiert in diesem 4:3 im Halbfinale Ja, einmalig war es in der Tat, was seine Mannschaft da geleistete hatte. Und es war interessant mitzuerleben, wie nach dem Spiel ein Akteur nach dem anderen in die Kabine trottete und sich unterwegs kurz den Journalisten stellte. Da war etwa der Torwart Danny aus den Birken, der v\u00f6llig ausgelaugt war. Oder Defensivspieler Moritz M\u00fcller, der seine Tr\u00e4nen kaum halten konnte. Oder die NHL-gest\u00e4hlten Routiniers Christian Erhoff und Marcel Goc, die schon so viel erlebt haben, aber so etwas wie an diesem Abend dann doch noch nicht. Keiner hatte schon so recht begriffen, was da geschehen war, und keiner wollte zu gro\u00dfen sportfachlichen Analysen ansetzen, als es um die Gr\u00fcnde f\u00fcr den Erfolg ging. Ein jeder sagte nur: Team. Mannschaft. Teamgeist. Mannschaftsgeist. Diese W\u00f6rter fallen oft im Sport, aber soweit sich das von au\u00dfen beurteilen l\u00e4sst, trifft das bei den Eishockey-Spielern tats\u00e4chlich zu. Sturm hat in den drei Jahren eine bemerkenswerte Mannschaft geformt, die ohnehin ein irres Turnier spielt. Das knappe 0:1 gegen Schweden in der Vorrunde, der Penalty-Sieg \u00fcber Norwegen, der Erfolg nach Verl\u00e4ngerung gegen die Schweiz, das denkw\u00fcrdige 4:3 gegen Schweden im Viertelfinale. Aber all das kulminierte jetzt in diesem 4:3 gegen Kanada im Halbfinale. In einem \\\"Jahrhundertspiel\\\", wie Alfons H\u00f6rmann, Pr\u00e4sident des Deutschen Olympischen Sportbundes, nicht ganz zu Unrecht schw\u00e4rmte.\",\n  \"target_text\": \"Nach dem sensationellen 4:3-Sieg gegen Kanada kann das deutsche Eishockey-Team erstmals Olympiasieger werden. Im Finale ist der Gegner der Favorit - doch die Mannschaft von Marco Sturm glaubt an sich.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Monatelang haben Sicherheitsbeh\u00f6rden nach Salah Abdeslam gefahndet. Jetzt ist der 26-j\u00e4hrige Terrorverd\u00e4chtige festgenommen worden. Er soll an den Anschl\u00e4gen von Paris beteiligt gewesen sein, bei denen am 13. November drei Killerkommandos 130 Menschen get\u00f6tet hatten. Was man bisher \u00fcber den Mann wei\u00df Salah Abdeslam ist in Br\u00fcssel geboren, aber franz\u00f6sischer Staatsb\u00fcrger. Er ist der Bruder des Selbstmordattent\u00e4ters Brahim, der ebenfalls bei den Anschl\u00e4gen dabei war. Die verst\u00fcmmelte Leiche des 31-j\u00e4hrigen Brahim Abdeslam hatte die Polizei am Tag des Anschlags am Boulevard Voltaire in der N\u00e4he des Konzertsaals Bataclan gefunden, wo er sich in die Luft gesprengt hatte. Salah wohnte im Br\u00fcsseler Vorort Molenbeek, der als eine Hochburg von gewaltbereiten Islamisten in Belgien gilt. Abdeslam soll in Deutschland gewesen sein Laut Recherchen des SWR soll sich Abdeslam Anfang Oktober 2015 kurzzeitig in Baden-W\u00fcrttemberg aufgehalten und dort wom\u00f6glich Komplizen abgeholt haben. Demnach fuhr er in der Nacht vom 2. auf den 3. Oktober 2015 mit einem auf seinen Namen angemieteten Wagen nach Ulm und offenbar nach etwa einer Stunde wieder zur\u00fcck. Er k\u00f6nnte in Ulm laut SWR drei M\u00e4nner, die sich als Syrer ausgegeben hatten, aus einer Fl\u00fcchtlingsunterkunft abgeholt haben. Bei einer Anwesenheitskontrolle am 3. Oktober wurde festgestellt, dass die drei M\u00e4nner in der Unterkunft fehlten. Ihre Identit\u00e4t werde vom Bundeskriminalamt gemeinsam mit franz\u00f6sischen und belgischen Sicherheitsbeh\u00f6rden gepr\u00fcft, hie\u00df es. Die deutschen Beh\u00f6rden wollten sich nicht zu dem Vorgang \u00e4u\u00dfern. Familie bat ihn, sich zu stellen Wie andere Islamisten auch ist Abdeslam im Br\u00fcsseler Stadtteil Molenbeek aufgewachsen. Er war der Polizei wegen Drogendelikten bekannt. Seinen Job als Mechaniker verlor er 2011 wegen h\u00e4ufiger Abwesenheit. Ab 2013 betrieb er eine Bar in Molenbeek, die schlie\u00dflich von den Beh\u00f6rden geschlossen wurde, weil G\u00e4ste dort Drogen genommen haben sollen. Mit Abdelhamid Abaaoud, der die Anschl\u00e4ge von Paris vermutlich geplant hat, war Salah Abdeslam seit seiner Kindheit befreundet. Nach den Anschl\u00e4gen in Frankreich wurde er per internationalem Haftbefehl gesucht. Fahnder beschrieben ihn als \\\"gef\u00e4hrlich\\\" und m\u00f6glicherweise \\\"schwer bewaffnet\\\". Zwischenzeitlich war auch \u00fcber einen Aufenthalt in Syrien spekuliert worden. Salahs Bruder Mohamed hatte in Fernsehinterviews an den Gesuchten appelliert, sich zu stellen. Er selbst war nach den Anschl\u00e4gen kurzzeitig festgenommen, aber bald wieder freigelassen worden. Seine Anw\u00e4ltin sagte, er habe \\\"nicht das gleiche Leben gew\u00e4hlt\\\" wie seine Br\u00fcder. Mohamed berichtete, dass Brahim und Salah in den Monaten vor den Anschl\u00e4gen im November in Paris ges\u00fcnder gelebt, gebetet, keinen Alkohol mehr getrunken h\u00e4tten und hin und wieder in die Moschee gegangen seien. Er wollte darin aber \\\"nicht direkt ein Zeichen f\u00fcr Radikalisierung\\\" sehen. Zur Rolle seines Bruders bei den Anschl\u00e4gen in Paris sagte Mohamed: \\\"Salah ist sehr intelligent. Er hat in letzter Minute kehrtgemacht\\\". Salah sollte angeblich in Paris auch ein Selbstmordattentat ver\u00fcben. Er z\u00fcndete die Bombe aber nicht, sondern warf seinen Sprengstoffg\u00fcrtel in einem Pariser Vorort in einen M\u00fclleimer.\",\n  \"target_text\": \"Dort soll der Terrorist drei Komplizen aus einer Fl\u00fcchtlingsunterkunft abgeholt haben. Die belgischen Beh\u00f6rden haben den 26-J\u00e4hrigen jetzt wegen Mordes angeklagt.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Im Folgenden finden Sie Nachrichtenartikel mit den dazugeh\u00f6rigen Zusammenfassungen.\n</code></pre></li> <li>Base prompt template:   <pre><code>Nachrichtenartikel: {text}\nZusammenfassung: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Nachrichtenartikel: {text}\n\nSchreiben Sie eine Zusammenfassung des obigen Artikels.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mlsum-de\n</code></pre>"},{"location":"datasets/icelandic/","title":"\ud83c\uddee\ud83c\uddf8 Icelandic","text":"<p>This is an overview of all the datasets used in the Icelandic part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/icelandic/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/icelandic/#hotter-and-colder-sentiment","title":"Hotter and Colder Sentiment","text":"<p>This dataset was published in this paper, and consists of texts from Icelandic blog post, annotated with sentiment labels (and many others) via a crowdsourcing platform.</p> <p>The original full dataset consists of 2,901 samples, and we use a 1,021 / 255 / 1,607 split for training, validation and testing, respectively (so all samples are used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Til hamingju me\u00f0 gott framtak. \u00deetta eru g\u00f3\u00f0ir \u00fatgangspunktar me\u00f0 stj\u00f3rnarskr\u00e1na, \u00fe\u00f3 margt fleira \u00feurfi a\u00f0 laga svo h\u00fan \u00fej\u00f3ni vel\u00a0 n\u00fdju l\u00fd\u00f0veldi framt\u00ed\u00f0arinnar.\u00c9g sty\u00f0 heils hugar \u00feetta framtak ykkar.\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"J\u00fa, j\u00fa, au\u00f0vita \u00e1 hann ekki a\u00f0 vera\u00a0samstarfsma\u00f0ur e\u00f0a einu sinni \u00ed sama h\u00fasi og s\u00e9rstakir r\u00edkissaks\u00f3knarar \u00ed \u00feessu m\u00e1li. S\u00e9rstakir r\u00edkissaks\u00f3knarar fyrir \u00feetta m\u00e1l\u00a0eiga a\u00f0 liggja\u00a0liggja beint undir r\u00e1\u00f0uneytinu og vera algerlega sj\u00e1lfst\u00e6\u00f0ir, \\\"untouchables\\\". \u00c9g hef ekki enn s\u00e9\u00f0 nein r\u00f6k fyrir \u00fev\u00ed a\u00f0\u00a0Valt\u00fdr \u00feurfi a\u00f0 v\u00edkja \u00far s\u00ednu starfi ef \u00feessi lei\u00f0 ver\u00f0ur valin? Best v\u00e6ri ef s\u00e9rstakir r\u00edkissaks\u00f3knarar \u00ed \u00feessu m\u00e1li v\u00e6ri \u00ferepinu h\u00e6rri \u00ed valdastiganum en Valt\u00fdr, ef \u00fea\u00f0 er h\u00e6gt a\u00f0 koma \u00fev\u00ed \u00ed gegn me\u00f0 sn\u00f6ggum lagabreytingum? Varla er \u00feetta Stj\u00f3rnarskr\u00e1rm\u00e1l?\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Meira a\u00f0 segja h\u00f6r\u00f0ustu klappst\u00fdrur \u00de\u00f3r\u00f3lfs hlj\u00f3ta a\u00f0 hugsa, \u00fe\u00f3 ekki v\u00e6ri \u00ed nema augnablik: Miki\u00f0 er skr\u00fdti\u00f0 a\u00f0 hann s\u00e9 ekki me\u00f0 \u00e1 hreinu af hverju f\u00e1ir handleggir eru a\u00f0 bj\u00f3\u00f0a sig \u00ed \u00feri\u00f0ju sprautuna!Annars er bara sama handriti\u00f0 a\u00f0 fara spilast aftur: N\u00fa er hausti\u00f0 komi\u00f0 og \u00e1rst\u00ed\u00f0arbundnar pestir munu rj\u00faka upp, allar sem ein, og \u00fe\u00e1 ver\u00f0ur skellt \u00ed l\u00e1s og tala\u00f0 um a\u00f0 hafa opna\u00f0 of snemma.\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru yfirfer\u00f0ir \u00e1samt lyndisgildi \u00feeirra, sem getur veri\u00f0 'j\u00e1kv\u00e6tt', 'hlutlaust' e\u00f0a 'neikv\u00e6tt'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Yfirfer\u00f0: {text}\nLyndi: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texti: {text}\n\nFlokka\u00f0u tilfinninguna \u00ed textanum. Svara\u00f0u me\u00f0 'j\u00e1kv\u00e6tt', 'hlutlaust' e\u00f0a 'neikv\u00e6tt'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>j\u00e1kv\u00e6tt</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>hlutlaust</code></li> <li><code>negative</code> \u27a1\ufe0f <code>neikv\u00e6tt</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hotter-and-colder-sentiment\n</code></pre>"},{"location":"datasets/icelandic/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/icelandic/#mim-gold-ner","title":"MIM-GOLD-NER","text":"<p>This dataset was published in this paper and is based on the Tagged Icelandic Corpus (MIM), which consists of Icelandic books, news articles, periodicals, parliament speeches, legal texts, adjudications and government websites. It has been annotated with named entities in a semi-automated fashion, where each labels has been manually verified. The entity types in the dataset is a superset of the CoNLL-2003 tags, with the following additional labels: <code>DATE</code>, <code>TIME</code>, <code>MONEY</code>, <code>PERCENT</code>. These labels have been removed.</p> <p>The original full dataset consists of 1,000,000 tokens. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  'tokens': array(['Sj\u00e1lfsagt', 'er', 'a\u00f0', 'mi\u00f0a', 'endurgrei\u00f0sluna', 'ver\u00f0i', 'n\u00faverandi', 'heimild', 'framlengd', 'vi\u00f0', 'EUROIII', '\u00ed', 'sta\u00f0', 'EUROII', 'eins', 'og', 'n\u00fa', 'er', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['\u00dea\u00f0', 'var', 'br\u00f3\u00f0ir', 'Sandlers', 'sem', 'hvatti', 'hann', 'til', 'a\u00f0', 'leggja', 'gr\u00edni\u00f0', 'fyrir', 'sig', '\u00feegar', 'hann', 'var', '17', '\u00e1ra', 'a\u00f0', 'aldri', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['2.-', 'Erla', 'Gu\u00f0n\u00fd', 'Gylfad.', ',', 'Smyrill', 'fr\u00e1', 'Stokkh\u00f3lma', ',', '7,01', '.'], dtype=object),\n  'labels': array(['O', 'B-PER', 'I-PER', 'I-PER', 'O', 'B-PER', 'O', 'B-LOC', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru setningar \u00e1samt JSON lyklum me\u00f0 nefndum einingum sem koma fyrir \u00ed setningunum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nNefndar einingar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nGreini\u00f0 nefndu einingarnar \u00ed setningunni. \u00de\u00fa \u00e6ttir a\u00f0 skila \u00feessu sem JSON or\u00f0ab\u00f3k me\u00f0 lyklunum 'einstaklingur', 'sta\u00f0setning', 'stofnun' og '\u00fdmislegt'. Gildin \u00e6ttu a\u00f0 vera listi yfir nefndu einingarnar af \u00feeirri ger\u00f0, n\u00e1kv\u00e6mlega eins og \u00fe\u00e6r koma fram \u00ed setningunni.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>einstaklingur</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>einstaklingur</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sta\u00f0setning</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sta\u00f0setning</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>stofnun</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>stofnun</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>\u00fdmislegt</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>\u00fdmislegt</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mim-gold-ner\n</code></pre>"},{"location":"datasets/icelandic/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/icelandic/#scala-is","title":"ScaLA-is","text":"<p>This dataset was published in this paper and was automatically created from the Icelandic Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 3,535 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Utanrrh.: \u00c9g hef \u00c9g hef\u00f0i \u00f3ska\u00f0 \u00feess a\u00f0 h\u00e6stv. utanr\u00edkisr\u00e1\u00f0herra hef\u00f0i meiri \u00e1hrif \u00e1 fors\u00e6tisr\u00e1\u00f0herra en raun ber vitni Gripi\u00f0 fram \u00ed. \u00fev\u00ed a\u00f0 hann er sem betur fer ekki a\u00f0 tala ni\u00f0ur \u00fe\u00e1 atvinnugrein sem tengist sj\u00e1var\u00fatveginum eins og h\u00e6stv. fors\u00e6tisr\u00e1\u00f0herra gerir alla jafna.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"\u00dea\u00f0 v\u00e6ri mun sk\u00e1rra, \u00fea\u00f0 hef\u00f0i veri\u00f0 h\u00e6gt a\u00f0 gera \u00fea\u00f0 meiri me\u00f0 s\u00e1tt, en \u00fea\u00f0 var einfaldlega ekki gert.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Mig l\u00edka a\u00f0 koma a\u00f0, \u00e9g gleymdi \u00fev\u00ed \u00e1\u00f0an og kom \u00fev\u00ed heldur ekki a\u00f0, komugj\u00f6ldunum eins og \u00feau heita v\u00edst n\u00fana, ekki legugj\u00f6ld lengur.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru setningar og hvort \u00fe\u00e6r eru m\u00e1lfr\u00e6\u00f0ilega r\u00e9ttar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nM\u00e1lfr\u00e6\u00f0ilega r\u00e9tt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nGreini\u00f0 hvort setningin er m\u00e1lfr\u00e6\u00f0ilega r\u00e9tt e\u00f0a ekki. Svari\u00f0 skal vera 'j\u00e1' ef setningin er r\u00e9tt og 'nei' ef h\u00fan er ekki.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>j\u00e1</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-is\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-iceec","title":"Unofficial: IceEC","text":"<p>This dataset was published here and consists of texts in modern Icelandic from student essays, online news texts and Wikipedia articles, annotated for mistakes related to spelling, grammar, and other issues.</p> <p>The original full dataset consists of 58,200 / 5,270 samples for training and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, where the training and testing splits are subsets of the original training and testing splits, and the validation split is a disjoint subset of the training split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Kannski erum vi\u00f0 me\u00f0 meiri s\u00f6lu \u00ed \u00f6\u00f0rum skrokkhlutum en s\u00ed\u00f0um t.d., \u201c segir Stein\u00fe\u00f3r.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"\u00de\u00f3 svo a\u00f0 hann s\u00e9 lei\u00f0inlegur og ekkert t\u00edvol\u00ed gaman, \u00fe\u00e1 er mi\u00f0lar hann \u00feekkingu til okkar og \u00e1n hans mundi enginn menntun vera.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"S\u00edminn er hvers manns \u00e1byrg\u00f0.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru setningar og hvort \u00fe\u00e6r eru m\u00e1lfr\u00e6\u00f0ilega r\u00e9ttar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nM\u00e1lfr\u00e6\u00f0ilega r\u00e9tt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nGreini\u00f0 hvort setningin er m\u00e1lfr\u00e6\u00f0ilega r\u00e9tt e\u00f0a ekki. Svari\u00f0 skal vera 'j\u00e1' ef setningin er r\u00e9tt og 'nei' ef h\u00fan er ekki.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>j\u00e1</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset ice-ec\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-icelinguistic","title":"Unofficial: IceLinguistic","text":"<p>This dataset was published here, with the source of the documents unknown. It consists of Icelandic sentences annotated with whether they are grammatically correct or not (along with other linguistic properties).</p> <p>The original full dataset consists of 382 samples, and we use a 94 / 32 / 256 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"\u00c9g afla\u00f0i uppl\u00fdsinganna og \u00fe\u00fa peninganna.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Af hverju f\u00f3r \u00fe\u00fa ekki heim?\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"\u00de\u00fa bor\u00f0a\u00f0ir k\u00f6kuna og \u00e9g kleinuhringurinn.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru setningar og hvort \u00fe\u00e6r eru m\u00e1lfr\u00e6\u00f0ilega r\u00e9ttar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nM\u00e1lfr\u00e6\u00f0ilega r\u00e9tt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nGreini\u00f0 hvort setningin er m\u00e1lfr\u00e6\u00f0ilega r\u00e9tt e\u00f0a ekki. Svari\u00f0 skal vera 'j\u00e1' ef setningin er r\u00e9tt og 'nei' ef h\u00fan er ekki.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>j\u00e1</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset ice-linguistic\n</code></pre>"},{"location":"datasets/icelandic/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/icelandic/#nqii","title":"NQiI","text":"<p>This dataset was published in this paper and is based on articles from the Icelandic Wikipedia. Annotators were asked to write both questions (only seeing the beginning of the article) as well as answers as they appear in the article.</p> <p>The original full dataset consists of 2,234 / 259 / 244 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively. Our splits are new, and there can thus be some overlap between the new test split and the old training and validation splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": 'Gr\u00f3\u00f0urh\u00fasalofttegund er lofttegund , \u00ed lofthj\u00fapi sem drekkur \u00ed sig og gefur fr\u00e1 s\u00e9r innrau\u00f0a geislun . \u00dea\u00f0 ferli er a\u00f0al \u00e1st\u00e6\u00f0a gr\u00f3\u00f0urh\u00fasa\u00e1hrifa . Helstu gr\u00f3\u00f0urh\u00fasalofttegundirnar \u00ed lofthj\u00fapi jar\u00f0ar eru vatnsgufa , kold\u00edox\u00ed\u00f0 , metan , tv\u00edk\u00f6fnunarefnisox\u00ed\u00f0 og \u00f3son . \u00c1n gr\u00f3\u00f0urh\u00fasalofttegunda v\u00e6ri me\u00f0alhiti yfirbor\u00f0s jar\u00f0ar \u2212 18 \u00b0 C , n\u00faverandi me\u00f0altals 15 \u00b0 C . \u00cd s\u00f3lkerfinu , eru Venus , Mars og T\u00edtan einnig me\u00f0 lofthj\u00fap sem veldur gr\u00f3\u00f0urh\u00fasa\u00e1hrifum .',\n  \"question\": 'Hverjar eru gr\u00f3\u00f0urh\u00fasalofttegundirnar ?',\n  \"answers\": {\n    \"answer_start\": array([202], dtype=int32),\n    \"text\": array([' vatnsgufa , kold\u00edox\u00ed\u00f0 , metan , tv\u00edk\u00f6fnunarefnisox\u00ed\u00f0 og \u00f3son'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Hvannadalshn\u00fakur e\u00f0a Hvannadalshnj\u00fakur er h\u00e6sti tindur eldkeilunnar undir \u00d6r\u00e6faj\u00f6kli og jafnframt h\u00e6sti tindur \u00cdslands . Samkv\u00e6mt n\u00fdjustu m\u00e6lingu er h\u00e6\u00f0 hans 2.109,6 metrar yfir sj\u00e1varm\u00e1li . Tindurinn er sta\u00f0settur innan Vatnaj\u00f6kuls\u00fej\u00f3\u00f0gar\u00f0s og er vins\u00e6ll hj\u00e1 fjallg\u00f6nguf\u00f3lki , reyndu sem og \u00f3reyndu . Tindurinn er ekki fl\u00f3kinn uppg\u00f6ngu og \u00fearfnast ekki mikillar reynslu e\u00f0a t\u00e6kni \u00ed fjallg\u00f6ngum , gangan krefst samt mikils \u00fathalds \u00fear sem oftast er gengi\u00f0 \u00e1 tindinn og ni\u00f0ur aftur \u00e1 sama deginum . H\u00e6kkunin er r\u00famir 2000 metrar , gangan tekur oftast 12 - 14 klst \u00ed heild .',\n  \"question\": 'Hvert er h\u00e6sta fjall \u00e1 \u00cdslandi ?',\n  \"answers\": {\n    \"answer_start\": array([20,  0, 20], dtype=int32),\n    \"text\": array([' Hvannadalshnj\u00fakur', 'Hvannadalshn\u00fakur', ' Hvannadalshnj\u00fakur er h\u00e6sti tindur eldkeilunnar undir \u00d6r\u00e6faj\u00f6kli og jafnframt h\u00e6sti tindur \u00cdslands'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Falklandseyjar er l\u00edtill eyjaklasi \u00fat af Su\u00f0ur-Amer\u00edku , um 500 km til su\u00f0austurs fr\u00e1 Argent\u00ednu . \u00de\u00e6r eru undir stj\u00f3rn Bretlands en Argent\u00edna hefur einnig gert tilkall til \u00feeirra og olli \u00fea\u00f0 Falklandseyjastr\u00ed\u00f0inu milli \u00fej\u00f3\u00f0anna 1982 .',\n  \"question\": 'Hvar eru Falklandseyjar ?',\n  \"answers\": {\n    \"answer_start\": array([34, 34], dtype=int32),\n    \"text\": array([' \u00fat af Su\u00f0ur-Amer\u00edku', ' \u00fat af Su\u00f0ur-Amer\u00edku , um 500 km til su\u00f0austurs fr\u00e1 Argent\u00ednu'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru textar me\u00f0 tilheyrandi spurningum og sv\u00f6rum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texti: {text}\nSpurning: {question}\nSvara\u00f0u me\u00f0 a\u00f0 h\u00e1marki 3 or\u00f0um: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texti: {text}\n\nSvara\u00f0u eftirfarandi spurningu um textann a\u00f0 h\u00e1marki \u00ed 3 or\u00f0um.\n\nSpurning: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset nqii\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-icelandicqa","title":"Unofficial: IcelandicQA","text":"<p>This dataset was published here and consists of an automatically created Icelandic question-answering dataset based on the Icelandic Wikipedia as well as Icelandic news articles from the R\u00daV corpus.</p> <p>Both questions and answers were generated automatically, meaning that the answers might not appear in the context. To remedy this, we used GPT-4o to rephrase the answers to ensure that they appear in the context.</p> <p>The original full dataset consists of 2,000 samples, and we use a 531 / 128 / 1,024 split for training, validation and testing, respectively. These are all the samples where the (rephrased) answer appears in the context.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": '\u00d3mar Ragnarsson - Syngur fyrir b\u00f6rnin  er 33 sn\u00faninga LP hlj\u00f3mplata gefin \u00fat af SG - hlj\u00f3mpl\u00f6tum \u00e1ri\u00f0 1981. \u00c1 henni syngur \u00d3mar Ragnarsson \u00ferett\u00e1n barnal\u00f6g. Platan er safnplata af \u00e1\u00f0ur \u00fatgefnum \"hit\" l\u00f6gum af 45 sn\u00faninga pl\u00f6tum.\\n\\nLagalisti \\n \u00c9g er a\u00f0 baka - Lag - texti: E. Shuman/B. Bower - \u00d3mar Ragnarsson\\n Br\u00f3\u00f0ir minn - Lag - texti: W. Holt -\u00d3mar Ragnarsson\\n Eitthva\u00f0 \u00fat \u00ed lofti\u00f0 - Lag - texti: P. McCartney - \u00d3mar Ragnarsson \\n Lok, lok og l\u00e6s - Lag - texti: Brezkt \u00fej\u00f3\u00f0lag - \u00d3mar Ragnarsson\\n Aha, sei-sei, j\u00e1-j\u00e1 - Lag - texti: \u00d3mar Ragnarsson\\n Ligga, ligga l\u00e1 - Lag - texti: \u00d3mar Ragnarsson \\n Hl\u00e1turinn lengir l\u00edfi\u00f0 - Lag - texti: Ortega - \u00d3mar Ragnarsson\\n Sumar og s\u00f3l - Lag - texti: \u00d3mar Ragnarsson\\n J\u00f3i \u00fatherji - Lag - texti: \u00c1stralskt \u00fej\u00f3\u00f0lag - \u00d3mar Ragnarsson\\n \u00d3li drj\u00f3li - Lag - texti: \u00d3mar Ragnarsson)\\n Minkurinn \u00ed h\u00e6nsnakofanum - Lag - texti: Norskt \u00fej\u00f3\u00f0lag - \u00d3mar Ragnarsson \\n Kenni\u00f0 m\u00e9r krakkar - Lag - texti: A. Johansen - \u00d3mar Ragnarsson\\n H\u00ed \u00e1 \u00feig - Lag - texti: Amer\u00edskt \u00fej\u00f3\u00f0lag - \u00d3mar Ragnarsson\\n\\nSG-hlj\u00f3mpl\u00f6tur\\nHlj\u00f3mpl\u00f6tur gefnar \u00fat \u00e1ri\u00f0 1981\\n\u00d3mar Ragnarsson',\n  \"question\": 'Hva\u00f0a \u00e1r var LP-hlj\u00f3mplatan \u201e\u00d3mar Ragnarsson - Syngur fyrir b\u00f6rnin\u201c gefin \u00fat?',\n  \"answers\": {\n    \"answer_start\": 102,\n    \"text\": array(['1981'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Tj\u00f6rn er kirkjusta\u00f0ur \u00ed Dalv\u00edkurbygg\u00f0 \u00ed Svarfa\u00f0ardal. B\u00e6rinn stendur a\u00f0 vestanver\u00f0u \u00ed dalnum um 5 km innan vi\u00f0 Dalv\u00edk. \u00de\u00f3rarinn Kr. Eldj\u00e1rn l\u00e9t reisa n\u00faverandi \u00edb\u00fa\u00f0arh\u00fas 1931. Tjarnartj\u00f6rn er l\u00edti\u00f0 og grunnt st\u00f6\u00f0uvatn \u00e1 flatlendinu ne\u00f0an vi\u00f0 b\u00e6inn. Tj\u00f6rnin er innan Fri\u00f0lands Svarfd\u00e6la sem teygir sig allt til strandar. \u00dear er miki\u00f0 fuglal\u00edf. Tj\u00f6rn er me\u00f0 st\u00e6rri j\u00f6r\u00f0um \u00ed Svarfa\u00f0ardal og a\u00f0 l\u00edkindum landn\u00e1msj\u00f6r\u00f0 \u00fe\u00f3tt b\u00e6jarins s\u00e9 ekki geti\u00f0 \u00ed Landn\u00e1mu. \u00dear hafa veri\u00f0 stunda\u00f0ar \u00farkomum\u00e6lingar \u00e1 vegum Ve\u00f0urstofunnar fr\u00e1 \u00e1rinu 1970. \u00cd hl\u00ed\u00f0inni ofan vi\u00f0 Tj\u00f6rn eru volgrur og \u00ed framhaldi af \u00feeim er jar\u00f0hitinn \u00ed Laugahl\u00ed\u00f0 \u00fear sem Sundsk\u00e1li Svarfd\u00e6la f\u00e6r vatn sitt.\\nKristj\u00e1n Eldj\u00e1rn forseti f\u00e6ddist \u00e1 Tj\u00f6rn 1916 og \u00f3lst \u00fear upp.\\nS\u00f6ngh\u00f3purinn Tjarnarkvartettinn var kenndur vi\u00f0 Tj\u00f6rn \u00ed Svarfa\u00f0ardal.\\n\\nTjarnarb\u00e6ndur \u00e1 20. \u00f6ld:\\n Sr. Kristj\u00e1n Eldj\u00e1rn \u00de\u00f3rarinsson og Petr\u00edna Soff\u00eda Hj\u00f6rleifsd\u00f3ttir\\n \u00de\u00f3rarinn Kr. Eldj\u00e1rn og Sigr\u00fan Sigurhjartard\u00f3ttir\\n Hj\u00f6rtur Eldj\u00e1rn \u00de\u00f3rarinsson og Sigr\u00ed\u00f0ur Hafsta\u00f0\\n Kristj\u00e1n Eldj\u00e1rn Hjartarson og Kristjana Arngr\u00edmsd\u00f3ttir\\n\\nTjarnarkirkja \\n\\nKirkja hefur l\u00edklega veri\u00f0 reist \u00e1 Tj\u00f6rn flj\u00f3tlega eftir a\u00f0 kristni var l\u00f6gleidd \u00ed landinu. Hennar er \u00fe\u00f3 ekki geti\u00f0 me\u00f0 beinum h\u00e6tti \u00ed heimildum fyrr en \u00ed Au\u00f0unarm\u00e1ldaga fr\u00e1 1318. \u00dear segir a\u00f0 kirkjan s\u00e9 helgu\u00f0 Mar\u00edu gu\u00f0sm\u00f3\u00f0ur, Mikj\u00e1li erkiengli, J\u00f3hannesi sk\u00edrara og Andr\u00e9si postula. Kirkjan \u00e1tti \u00fe\u00e1 h\u00e1lft heimalandi\u00f0, Ingvarasta\u00f0aland og h\u00f3lminn \u00d6rgumlei\u00f0a. \u00c1 16. \u00f6ld er Tj\u00f6rn or\u00f0in beneficium, \u00fe.e. \u00f6ll komin \u00ed eigu kirkjunnar og \u00feannig h\u00e9lst \u00fear til sr. Kristj\u00e1n Eldj\u00e1rn \u00de\u00f3rarinsson (1843-1917) keypti j\u00f6r\u00f0ina \u00e1ri\u00f0 1915. Sr. Kristj\u00e1n var s\u00ed\u00f0asti prestur \u00e1 Tj\u00f6rn. \u00cd Svarfa\u00f0ardal voru lengi fj\u00f3rar s\u00f3knir en \u00fer\u00edr prestar \u00fev\u00ed Ur\u00f0akirkja var annex\u00eda fr\u00e1 Tj\u00f6rn. Upsas\u00f3kn var s\u00ed\u00f0an l\u00f6g\u00f0 undir Tjarnarprest 1859 en 1917 var Tjarnarprestakall me\u00f0 s\u00ednum \u00feremur s\u00f3knum sameina\u00f0 Vallaprestakalli. Eftir a\u00f0 prestssetri\u00f0 var flutt fr\u00e1 V\u00f6llum 1969 hefur Tjarnarkirkju veri\u00f0 \u00fej\u00f3na\u00f0 af fr\u00e1 Dalv\u00edk. Tjarnars\u00f3kn n\u00e6r fr\u00e1 Steindyrum a\u00f0 Ytraholti.\\n\\nN\u00faverandi kirkja var reist 1892. H\u00fan er \u00far timbri \u00e1 hl\u00f6\u00f0num grunni og tekur 60-70 manns \u00ed s\u00e6ti. \u00cd henni eru steindir gluggar teikna\u00f0ir af Valger\u00f0i Hafsta\u00f0 listm\u00e1lara. Kirkjugar\u00f0ur er umhverfis kirkjuna. Kirkjan skemmdist nokku\u00f0 \u00ed Kirkjurokinu svokalla\u00f0a, miklu \u00f3ve\u00f0ri sem gekk yfir landi\u00f0 \u00feann 20. september \u00e1ri\u00f0 1900. \u00de\u00e1 ey\u00f0il\u00f6g\u00f0ust kirkjurnar \u00e1 Ur\u00f0um og Upsum og Vallakirkja var\u00f0 fyrir skemmdum. Tjarnarkirkja snara\u00f0ist \u00e1 grunni s\u00ednum og halla\u00f0ist mj\u00f6g til nor\u00f0urs en j\u00e1rnkr\u00f3kar miklir, sem h\u00e9ldu timburverkinu vi\u00f0 hla\u00f0inn grunninn, v\u00f6rnu\u00f0u \u00fev\u00ed a\u00f0 verr f\u00e6ri. Nokkru eftir f\u00e1rvi\u00f0ri\u00f0 ger\u00f0i hvassvi\u00f0ri af nor\u00f0ri sem f\u00e6r\u00f0i hana til \u00e1 grunninum og r\u00e9tti hana a\u00f0 mestu vi\u00f0 \u00e1 n\u00fd. M\u00f6rgum \u00fe\u00f3ttu \u00feetta st\u00f3rmerki. Gert var vi\u00f0 kirkjuna eftir \u00feetta og m.a. voru \u00fatb\u00fain \u00e1 hana j\u00e1rnst\u00f6g sem lengi settu skemmtilegan svip \u00e1 bygginguna og minntu \u00e1 hi\u00f0 mikla f\u00e1rvi\u00f0ri sem h\u00fan haf\u00f0i sta\u00f0i\u00f0 af s\u00e9r. Kirkjan st\u00f3\u00f0 einnig af s\u00e9r Dalv\u00edkurskj\u00e1lftann 1934 en \u00fe\u00f3 ur\u00f0u skemmdir \u00e1 grunni hennar.\\n\\nHeimildir \\n \\n \\n Kirkjur \u00cdslands 9. bindi. Tjarnarkirkja bls. 271-307. Reykjav\u00edk 2007\\n\\nTenglar\\nTjarnarkirkja \u00e1 kirkjukort.net \\n\\n\u00cdslenskir sveitab\u00e6ir\\nKirkjusta\u00f0ir \u00ed Eyjafjar\u00f0ars\u00fdslu\\nKirkjur \u00e1 \u00cdslandi\\nSvarfa\u00f0ardalur',\n  \"question\": '\u00c1 hva\u00f0a b\u00e6 \u00ed Svarfa\u00f0ardal hafa veri\u00f0 stunda\u00f0ar \u00farkomum\u00e6lingar \u00e1 vegum Ve\u00f0urstofunnar fr\u00e1 \u00e1rinu 1970?',\n  \"answers\": {\n    \"answer_start\": 0,\n    \"text\": array(['Tj\u00f6rn'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Fyrir greinina um \u00fe\u00e1ttinn sem er \u00ed gangi \u00ed dag, sj\u00e1 Kastlj\u00f3s (d\u00e6gurm\u00e1la\u00fe\u00e1ttur)\\nKastlj\u00f3s var fr\u00e9ttask\u00fdringa\u00fe\u00e1ttur sem var \u00e1 dagskr\u00e1 R\u00edkis\u00fatvarpsins fr\u00e1 1974 til 1998. Hann h\u00f3f g\u00f6ngu s\u00edna sem fr\u00e9ttask\u00fdringa\u00fe\u00e1ttur um innlendar fr\u00e9ttir \u00e1ri\u00f0 1974 og t\u00f3k \u00fe\u00e1 vi\u00f0 af \u00fe\u00e6tti sem nefndist Landshorn. \u00de\u00e1tturinn var um fj\u00f6rut\u00edu m\u00edn\u00fatna langur, \u00ed umsj\u00f3n fr\u00e9ttastofunnar og s\u00fdndur \u00e1 f\u00f6stud\u00f6gum \u00e1 besta t\u00edma. Umsj\u00f3narmenn voru mismunandi fr\u00e9ttamenn \u00ed hvert skipti. Annar \u00fe\u00e1ttur \u00e1 mi\u00f0vikud\u00f6gum fjalla\u00f0i \u00fe\u00e1 um erlendar fr\u00e9ttir. 1980 var \u00fe\u00e1ttunum tveimur slegi\u00f0 saman \u00ed eitt Kastlj\u00f3s \u00e1 f\u00f6stud\u00f6gum \u00ed umsj\u00f3n tveggja stj\u00f3rnenda. 1987 var \u00fe\u00e6ttinum aftur breytt \u00ed fr\u00e9ttask\u00fdringa\u00fe\u00e1tt um innlend m\u00e1lefni stutt skei\u00f0. 1988 h\u00e9t \u00fe\u00e1tturinn Kastlj\u00f3s \u00e1 sunnudegi og 1990 Kastlj\u00f3s \u00e1 \u00feri\u00f0judegi eftir breyttum \u00fatsendingart\u00edma en 1992 var \u00fe\u00e1tturinn aftur fluttur \u00e1 besta t\u00edma \u00e1 f\u00f6studegi. 1993 var Kastlj\u00f3s teki\u00f0 af dagskr\u00e1 um skei\u00f0 \u00feegar d\u00e6gurm\u00e1la\u00fe\u00e1tturinn Dagslj\u00f3s h\u00f3f g\u00f6ngu s\u00edna. \\n\\n\u00cdslenskir sj\u00f3nvarps\u00fe\u00e6ttir',\n  \"question\": '\u00c1 hva\u00f0a \u00e1rum var fr\u00e9ttask\u00fdringa\u00fe\u00e1tturinn Kastlj\u00f3s upphaflega \u00e1 dagskr\u00e1 R\u00edkis\u00fatvarpsins?',\n  \"answers\": {\n    \"answer_start\": 147,\n    \"text\": array(['Fr\u00e1 1974 til 1998'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru textar me\u00f0 tilheyrandi spurningum og sv\u00f6rum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texti: {text}\nSpurning: {question}\nSvara\u00f0u me\u00f0 a\u00f0 h\u00e1marki 3 or\u00f0um: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texti: {text}\n\nSvara\u00f0u eftirfarandi spurningu um textann a\u00f0 h\u00e1marki \u00ed 3 or\u00f0um.\n\nSpurning: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset icelandic-qa\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-belebele-is","title":"Unofficial: BeleBele-is","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Texti: \u00cd Frelsisstr\u00ed\u00f0inu myndu\u00f0u r\u00edkin \u00ferett\u00e1n veikbur\u00f0a r\u00edkisstj\u00f3rn \u2013 me\u00f0 \u00dej\u00f3\u00f0\u00feingi\u00f0 sem eina \u00fe\u00e1tt \u00feess \u2013 skv. fyrstu stj\u00f3rnarskr\u00e1nni. \u00deingi\u00f0 var ekki me\u00f0 n\u00e6gar valdheimildir til a\u00f0 leggja \u00e1 skatta, og vegna \u00feess a\u00f0 ekki var neinn alr\u00edkisstj\u00f3ri e\u00f0a d\u00f3msvald til sta\u00f0ar, treysti \u00fea\u00f0 \u00e1 yfirv\u00f6ld \u00ed hverju r\u00edki fyrir sig, sem voru oft og t\u00ed\u00f0um \u00f3samvinnu\u00fe\u00fd\u00f0, til a\u00f0 framfylgja l\u00f6gum \u00feess. \u00dea\u00f0 haf\u00f0i heldur engar valdheimildir til a\u00f0 fella ni\u00f0ur skattal\u00f6g og tolla \u00e1 milli r\u00edkja. Greinarnar ger\u00f0u kr\u00f6fu um samhlj\u00f3\u00f0a sam\u00feykki allra r\u00edkjanna \u00e1\u00f0ur en h\u00e6gt var a\u00f0 breyta \u00feeim og r\u00edkin s\u00fdndu r\u00edkisvaldinu svo mikla l\u00edtilsvir\u00f0ingu a\u00f0 fulltr\u00faar \u00feeirra voru oft fjarverandi.\\nSpurning: Samkv\u00e6mt \u00fev\u00ed sem fram kemur \u00ed kaflanum, hva\u00f0a fullyr\u00f0ing \u00e1 n\u00e1kv\u00e6mlega vi\u00f0 um \u00e1stand r\u00edkisvaldsins \u00ed frelsisstr\u00ed\u00f0inu?\\nSvarm\u00f6guleikar:\\na. Skattar voru innheimtir af \u00feinginu og r\u00edkisstofnunum\\nb. Breytingar \u00e1 stj\u00f3rnarskr\u00e1nni \u00feurftu sam\u00feykki \u00feingsins\\nc. Fulltr\u00faar r\u00edkjanna voru oft fjarverandi\\nd. Hin mi\u00f0l\u00e6ga r\u00edkisstj\u00f3rn var myndu\u00f0 \u00ed kringum tvo megin\u00fe\u00e6tti\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texti: \u0130zmir er \u00feri\u00f0ja st\u00e6rsta borg Tyrklands me\u00f0 um 3,7 millj\u00f3nir \u00edb\u00faa, n\u00e6stst\u00e6rstu h\u00f6fnina \u00e1 eftir Istanb\u00fal og er mj\u00f6g g\u00f3\u00f0 samg\u00f6ngumi\u00f0st\u00f6\u00f0. Hin forna borg Smyrna er n\u00fana n\u00fat\u00edmaleg, \u00fer\u00f3u\u00f0 og i\u00f0andi vi\u00f0skiptami\u00f0st\u00f6\u00f0 sem sta\u00f0sett er vi\u00f0 gr\u00ed\u00f0arst\u00f3ran fl\u00f3a og umkringd er fj\u00f6llum. Hinar brei\u00f0u brei\u00f0g\u00f6tur, byggingar me\u00f0 framhli\u00f0um \u00far gleri og n\u00fat\u00edmalegar verslunarmi\u00f0st\u00f6\u00f0var me\u00f0 hef\u00f0bundnum rau\u00f0um \u00feaksk\u00edfum, 18. aldar marka\u00f0urinn og gamlar moskur og kirkjur, \u00fe\u00f3 a\u00f0 andr\u00famsloft borgarinnar tengist meira Mi\u00f0jar\u00f0arhafssv\u00e6\u00f0i Evr\u00f3pu en hef\u00f0bundnu Tyrklandi.\\nSpurning: Hvert eftirfarandi einkennir Izmir er fr\u00e1 fornri t\u00ed\u00f0?\\nSvarm\u00f6guleikar:\\na. Brei\u00f0ar brei\u00f0g\u00f6tur\\nb. Byggingar me\u00f0 framhli\u00f0um \u00far gleri\\nc. Verslanami\u00f0st\u00f6\u00f0var\\nd. rau\u00f0ar \u00feaksk\u00edfur\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texti: D\u00e6migert fyrir \u00fea\u00f0 t\u00edmabil er Kirby Muxloe Castle sem er frekar v\u00edggirt h\u00fas en raunverulegur kastali. St\u00f3ru glj\u00e1\u00f0u gluggarnir og \u00feunnu veggirnir hef\u00f0u ekki geta\u00f0 sta\u00f0ist st\u00f3r\u00e1r\u00e1s \u00ed langan t\u00edma. \u00c1ri\u00f0 1480, \u00feegar Hastings l\u00e1var\u00f0ur h\u00f3f byggingarframkv\u00e6mdirnar, r\u00edkti fri\u00f0ur \u00ed n\u00e1nast \u00f6llu landinu og a\u00f0eins var \u00fe\u00f6rf \u00e1 varnarm\u00farum gegn litlum r\u00e6ningjah\u00f3pum.\\nSpurning: Hvert af eftirt\u00f6ldu hef\u00f0i veri\u00f0 tali\u00f0 \u00f3venjulegt vi\u00f0 byggingu Kirby Muxloe kastala \u00e1 \u00feeim t\u00edma sem tala\u00f0 er um \u00ed kaflanum?\\nSvarm\u00f6guleikar:\\na. St\u00f3rir gluggar\\nb. Grunnur sem \u00e1 a\u00f0 standast \u00e1r\u00e1sir\\nc. Minna af varnar\u00fatb\u00fana\u00f0i en \u00ed \u00f6\u00f0rum k\u00f6stulum\\nd. \u00deunnir veggir\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fj\u00f6lvalsspurningar (me\u00f0 sv\u00f6rum).\n</code></pre></li> <li>Base prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvara: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nSvara\u00f0u eftirfarandi spurningum me\u00f0 'a', 'b', 'c' e\u00f0a 'd', og engu \u00f6\u00f0ru.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-is\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-multiwikiqa-is","title":"Unofficial: MultiWikiQA-is","text":"<p>This dataset will be published in an upcoming paper, and contains Icelandic Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Eldfell er r\u00e9tt r\u00famlega 200 m h\u00e1tt eldfjall \u00e1 Heimaey \u00ed Vestmannaeyjaklasanum. \u00dea\u00f0 mynda\u00f0ist \u00ed eldgosi sem h\u00f3fst 23. jan\u00faar 1973 en lauk 3. j\u00fal\u00ed 1973, \u00feetta eldgos er kalla\u00f0 Heimaeyjargosi\u00f0.\\n\\nHeimaeyjargosi\u00f0 \\n\u00cd upphafi gossins opna\u00f0ist st\u00f3r sprunga fr\u00e1 nor\u00f0ri til su\u00f0urs \u00e1 austasta hluta Heimaeyjar, og n\u00e1\u00f0i h\u00fan a\u00f0 h\u00f6fninni  \u00ed nor\u00f0ri en ni\u00f0ur a\u00f0 Skarfatanga \u00ed su\u00f0ri. Flj\u00f3tlega minnka\u00f0i sprungan \u00fe\u00f3 og megineldvarpi\u00f0 var\u00f0 \u00fear sem n\u00fa stendur Eldfell. Gosefni\u00f0 \u00ed upphafi gossins var n\u00e1nast \u00eds\u00fart, en \u00fe\u00f3 var\u00f0 \u00fea\u00f0 flj\u00f3tlega bas\u00edskt (SiO2 &gt; 52%). Efnainnihald kvikunnar bendir til a\u00f0 kvikuh\u00f3lf og megineldst\u00f6\u00f0 s\u00e9u a\u00f0 myndast \u00e1 \u00feessum sl\u00f3\u00f0um. \\n\\nStrax og tilkynning barst um a\u00f0 eldgos v\u00e6ri hafi\u00f0 h\u00f3fst brottflutningur f\u00f3lks af eynni. Af 5.500 \u00edb\u00faum eyj\u001b[48;55;272;1980;3808tarinnar voru um 4.000 fluttir burt um n\u00f3ttina, mestmegnis me\u00f0 skipum. \u00c1 n\u00e6stu vikum voru b\u00fasl\u00f3\u00f0ir f\u00f3lks fluttar burt a\u00f0 mestu, en h\u00fas t\u00f3ku mj\u00f6g flj\u00f3tlega a\u00f0 hverfa undir hraun.\\n\\nEinn ma\u00f0ur d\u00f3 \u00ed gosinu og var \u00fea\u00f0 af v\u00f6ldum kold\u00edox\u00ed\u00f0eitrunar - miki\u00f0 af l\u00edfsh\u00e6ttulegum lofttegundum kom upp \u00far j\u00f6r\u00f0inni me\u00f0 vikrinum og gj\u00f3skunni. Mikil mildi \u00fe\u00f3tti a\u00f0 ekki skyldi hafa fari\u00f0 verr, \u00fear sem a\u00f0 sprungan kom upp r\u00e9tt austan vi\u00f0 austasta h\u00fas b\u00e6jarins (\u00fe\u00f3 muna\u00f0i ekki nema nokkrum metrum). \\n\\nUm helmingur h\u00fasa b\u00e6jarins \u00fdmist lenti undir hrauni e\u00f0a \u00e1 annan h\u00e1tt ey\u00f0ilag\u00f0ist \u00ed gosinu, en uppbyggingin eftir gosi\u00f0 var mj\u00f6g sn\u00f6gg.\\n\\nGosi\u00f0 \u00ed Heimaey byrja\u00f0i 23. jan\u00faar 1973 og lauk 3. j\u00fal\u00ed sama \u00e1r. \u00deetta er fyrsta gos sem hefst vi\u00f0 \u00fe\u00e9ttb\u00fdli \u00e1 \u00cdslandi. \u00dea\u00f0 var loftskeytama\u00f0urinn Hj\u00e1lmar Gu\u00f0nason og vinur hans, \u00d3laf Granz, sem voru \u00ed s\u00ednum vanalega mi\u00f0n\u00e6turg\u00f6ngut\u00far \u00feegar hinn tilkomumikla s\u00fdn birtist \u00feeim \u00feegar \u00feeir sko\u00f0u\u00f0u b\u00e6inn fr\u00e1 Helgafellstoppi. \u00dear s\u00e1u \u00feeir j\u00f6r\u00f0ina opnast og eldtungurnar st\u00f3\u00f0u marga metra upp \u00ed lofti\u00f0. Strax var haft samband vi\u00f0 l\u00f6greglu \u00fear sem tilkynnt var a\u00f0 jar\u00f0eldur v\u00e6ri kominn upp austan vi\u00f0 Kirkjub\u00e6. L\u00f6greglan t\u00f3k uppl\u00fdsingarnar ekki tr\u00faanlegar \u00ed fyrstu en f\u00f3r strax a\u00f0 athuga hva\u00f0 v\u00e6ri \u00ed gangi og \u00feegar \u00e1 sta\u00f0inn var komi\u00f0 s\u00e1u \u00feeir a\u00f0 gos var hafi\u00f0 \u00e1 1600 metra langri sprungu og magna\u00f0ist hratt \u00e1 fyrstu m\u00edn\u00fatunum. Kveikt var \u00e1 brunal\u00fa\u00f0rum og \u00e1 mj\u00f6g sk\u00f6mmum t\u00edma var allur b\u00e6rinn vakna\u00f0ur og f\u00f3lk streymdi \u00far h\u00fasum s\u00ednum og ni\u00f0ur \u00e1 bryggju. Flestir \u00feeir sem upplif\u00f0u gosi\u00f0 eru samm\u00e1la um a\u00f0 klukkuna hafi vanta\u00f0 fimm m\u00edn\u00fatur \u00ed tv\u00f6 \u00feegar a\u00f0 gosi\u00f0 h\u00f3fst.\\n\\nEldfellshraun er um 2,5 ferk\u00edl\u00f3metrar og st\u00e6kka\u00f0i Heimaey um 20%.\\n\\nTenglar \\n \u00c1tta t\u00edmar \u00ed eyjum; greinar \u00ed Morgunbla\u00f0inu 1973\\n kort af g\u00f6tum sem f\u00f3ru undir hraun\\nVestmannaeyjar\\nEldfj\u00f6ll \u00e1 \u00cdslandi\\nEldgos \u00e1 \u00cdslandi\",\n    \"question\": \"Hva\u00f0 er Eldfell h\u00e1tt?\",\n    \"answers\": {\n        \"answer_start\": array([11]),\n        \"text\": array([\"r\u00e9tt r\u00famlega 200 m\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Edduver\u00f0launin 2007 eru afhending Edduver\u00f0launa \u00cdslensku kvikmynda- og sj\u00f3nvarpsakadem\u00edunnar sem f\u00f3r fram \u00e1 H\u00f3tel Hilton Nordica sunnudaginn 11. n\u00f3vember 2007. A\u00f0alkynnar kv\u00f6ldsins voru \u00deorsteinn Gu\u00f0mundsson og \u00d3laf\u00eda Hr\u00f6nn J\u00f3nsd\u00f3ttir.\\n\\n\u00de\u00e6r breytingar ur\u00f0u \u00e1 ver\u00f0launaflokkum a\u00f0 flokknum \u201eLeikari/leikkona \u00ed a\u00f0alhlutverki\u201c var skipt \u00ed tvennt og \u00fer\u00edr tilnefndir \u00ed hvorum flokknum \u201eleikari \u00ed a\u00f0alhlutverki\u201c og \u201eleikkona \u00ed a\u00f0alhlutverki\u201c. Fyrir sj\u00f3nvarpsefni var flokknum \u201esj\u00f3nvarps\u00fe\u00e1ttur \u00e1rsins\u201c skipt \u00ed \u201efr\u00e9tta- og/e\u00f0a vi\u00f0tals\u00fe\u00e1ttur\u201c \u00e1rsins annars vegar og \u201emenningar- og/e\u00f0a l\u00edfst\u00edls\u00fe\u00e1ttur \u00e1rsins\u201c sem \u00e1samt flokknum \u201eskemmti\u00fe\u00e1ttur \u00e1rsins\u201c gera \u00ferj\u00e1 flokka fyrir sj\u00f3nvarps\u00fe\u00e6tti \u00ed sta\u00f0 tveggja \u00e1\u00f0ur. Flokkurinn \u201emyndataka og klipping\u201c sem haf\u00f0i veri\u00f0 me\u00f0 \u00e1ri\u00f0 2005 var aftur tekinn upp. Alls voru \u00fev\u00ed veitt ver\u00f0laun \u00ed sext\u00e1n flokkum, auk hei\u00f0ursver\u00f0launa \u00cdKSA. \\n\\nSigurmynd h\u00e1t\u00ed\u00f0arinnar var kvikmyndin Foreldrar eftir Ragnar Bragason me\u00f0 sex ver\u00f0laun. Tv\u00e6r myndir me\u00f0 tilv\u00edsun \u00ed Brei\u00f0av\u00edkurm\u00e1li\u00f0 voru tilnefndar \u00feetta \u00e1ri\u00f0, heimildarmyndin Syndir fe\u00f0ranna og kvikmynd Gu\u00f0n\u00fdjar Halld\u00f3rsd\u00f3ttur, Ve\u00f0ram\u00f3t. Tveir sj\u00f3nvarps\u00fe\u00e6ttir fengu ver\u00f0laun sem besti fr\u00e9tta-/vi\u00f0tals\u00fe\u00e1ttur \u00e1rsins; Komp\u00e1s \u00e1 St\u00f6\u00f0 2 og \u00dat og su\u00f0ur \u00e1 R\u00daV. Egill Helgason var b\u00e6\u00f0i valinn sj\u00f3nvarpsma\u00f0ur \u00e1rsins og b\u00f3kmennta\u00fe\u00e1ttur hans, Kiljan, var valinn menningar-/l\u00edfst\u00edls\u00fe\u00e1ttur \u00e1rsins.\\n\\nTilnefningar og handhafar Edduver\u00f0launa 2007\\nHandhafar Edduver\u00f0launanna \u00ed hverjum flokki eru feitletra\u00f0ir og gulllita\u00f0ir.\\n\\nKvikmynd \u00e1rsins\\n\\nLeiki\u00f0 sj\u00f3nvarpsefni \u00e1rsins\\n\\nStuttmynd \u00e1rsins\\n\\nLeikstj\u00f3ri \u00e1rsins\\n\\nHandrit \u00e1rsins\\n\\nLeikkona \u00ed a\u00f0alhlutverki\\n\\nLeikari \u00ed a\u00f0alhlutverki\\n\\nLeikari/leikkona \u00ed aukahlutverki\\n\\nHeimildarmynd \u00e1rsins\\n\\nFr\u00e9tta- og/e\u00f0a vi\u00f0tals\u00fe\u00e1ttur \u00e1rsins\\n\\nMenningar- og/e\u00f0a l\u00edfst\u00edls\u00fe\u00e1ttur \u00e1rsins\\n\\nSkemmti\u00fe\u00e1ttur \u00e1rsins\\n\\nSj\u00f3nvarpsma\u00f0ur \u00e1rsins\\n\\nMyndataka og klipping\\n\\nHlj\u00f3\u00f0 og t\u00f3nlist\\n\\n\u00datlit myndar\\n\\nHei\u00f0ursver\u00f0laun \u00cdKSA 2007\\n\\nFramlag \u00cdslands til forvals \u00d3skarsins\\n\\nEdduver\u00f0launin\",\n    \"question\": \"Undir hva\u00f0a nafni er b\u00f3kmennta\u00fe\u00e1ttur Egils Helgasonar \u00feekktur, sem hlaut vi\u00f0urkenningu sem menningar- e\u00f0a l\u00edfst\u00edls\u00fe\u00e1ttur \u00e1rsins?\",\n    \"answers\": {\n        \"answer_start\": array([1294]),\n        \"text\": array([\"Kiljan\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Edinborgarh\u00fasi\u00f0 er fri\u00f0a\u00f0 h\u00fas og menningarmi\u00f0st\u00f6\u00f0 \u00e1 \u00cdsafir\u00f0i. H\u00fasi\u00f0 var byggt af Edinborgarversluninni sem var kringum aldam\u00f3tin 1900 eitt st\u00e6rsta verslunarfyrirt\u00e6ki landsins um aldam\u00f3tin 1900. Edinborgarverslunin var stofnu\u00f0 \u00ed Reykjav\u00edk \u00e1ri\u00f0 1895 og var \u00ed eigu  \u00c1sgeirs Sigur\u00f0sson sem \u00e6tta\u00f0ur var fr\u00e1 \u00cdsafir\u00f0i og  skoska verslunarfyrirt\u00e6kisins Copland and Berrie \u00ed Leith. Edinborgarverslunin f\u00e6r\u00f0i \u00fat kv\u00edarnar og opna\u00f0i verslunarb\u00fa\u00f0 \u00e1 \u00cdsafir\u00f0i \u00e1ri\u00f0 1902. \u00c1ri\u00f0 1903 var\u00f0 Karl Olgeirsson, verslunarstj\u00f3ri Edinborgarverslunar \u00e1 \u00cdsafir\u00f0i og me\u00f0eigandi f\u00e1um \u00e1rum s\u00ed\u00f0ar. \\n\\nBygging Edinborgarh\u00fassins h\u00f3fst eftir a\u00f0 fengin var byggingarl\u00f3\u00f0 fyrir h\u00fasi\u00f0 \u00e1ri\u00f0 1907  vi\u00f0 Pollinn. \u00dear var byggt h\u00fas eftir teikningu R\u00f6gnvald \u00c1g\u00fast \u00d3lafsson og bryggja og bryggjuh\u00fas. Edinborgarh\u00fasi\u00f0 og bryggjan voru lengi ein mesta mannvirki \u00e1 \u00cdsafir\u00f0i. Edinborgarverslun h\u00e6tti starfsemi \u00e1 \u00cdsafir\u00f0i \u00e1ri\u00f0 1917 og seldi hlut sinn til Karls verslunarstj\u00f3ra. \u00c1ri\u00f0 1918 var\u00f0 J\u00f3hann E. \u00deorsteinsson me\u00f0eigandi og var verslunin rekin undir nafninu Karl &amp; J\u00f3hann til  1923 en \u00fe\u00e1 seldi Karl sinn hluta og Sigurj\u00f3n \u00de. J\u00f3nsson  kom inn og r\u00e1ku Sigurj\u00f3n og J\u00f3hann E. \u00deorsteinson verslunina til \u00e1rsins 1926.\\n\\nTogaraf\u00e9lag \u00cdsfir\u00f0inga h.f. sem var stofna\u00f0 1925  var til h\u00fasa \u00ed Edinborgarh\u00fasinu. F\u00e9lagi\u00f0 keypti og rak togarann H\u00e1var\u00f0 \u00cdsfir\u00f0ing fr\u00e1 1925 til 1939. \u00c1 kreppu\u00e1runum gekk reksturinn illa og \u00e1ri\u00f0 1935 t\u00f3k Landsbankinn yfir reksturinn, hlutaf\u00e9 var auki\u00f0 og nafni breytt \u00ed h.f. H\u00e1var\u00f0ur. \u00c1ri\u00f0 1938 var\u00f0 \u00fear f\u00e9lag gjald\u00ferota og stofna\u00f0 n\u00fdtt hlutaf\u00e9lag me\u00f0 a\u00f0komu Kaupf\u00e9lags \u00cdsfir\u00f0inga. N\u00fdja hlutaf\u00e9lagi\u00f0 var nefnt Valur og var togarinn H\u00e1var\u00f0ur endursk\u00edr\u00f0ur og nefndur Skutull.\\n\\nKaupf\u00e9lag \u00cdsfir\u00f0inga elfdist mj\u00f6g \u00e1 millistr\u00ed\u00f0s\u00e1runum og keypti upp \u00fdmsar eignir. \u00c1ri\u00f0 1937 eigna\u00f0ist kaupf\u00e9lagi\u00f0 eignir sem h\u00f6f\u00f0u tilheyrt Edinborgarversluninni  og \u00fear \u00e1 me\u00f0al Edinborgarh\u00fasi\u00f0 og fiskreiti \u00e1 l\u00f3\u00f0 h\u00fassins. Kaupf\u00e9lagi\u00f0 \u00e1tti st\u00f3ran hlut \u00ed \u00fatger\u00f0arf\u00e9laginu Nir\u00f0i en \u00fea\u00f0 f\u00e9lag ger\u00f0i \u00fat b\u00e1ta sem kalla\u00f0ir voru D\u00edsirnar. Kaupf\u00e9lagi\u00f0 verka\u00f0i fisk fr\u00e1 Nir\u00f0i \u00e1 fiskreitunum  og sk\u00f6mmu eftir \u00e1ri\u00f0 1945 var settur upp \u00feurrklefi fyrir fisk \u00ed Edinborgarh\u00fasinu. \u00deessi \u00feurrklefi ger\u00f0i m\u00f6gulegt a\u00f0 \u00feurrka fisk innan dyra \u00e1 veturna. Kaupf\u00e9lag \u00cdsfir\u00f0inga \u00e1tti Edinborgarh\u00fasi\u00f0 \u00ed r\u00famlega 50 \u00e1r e\u00f0a \u00feanga\u00f0 til S\u00cdS t\u00f3k yfir eigur \u00feess.\\n\\nStofna\u00f0 var  einkahlutaf\u00e9lag um menningarmi\u00f0st\u00f6\u00f0 \u00ed Edinborgarh\u00fasinu 9. september 1992.\\n\\nHeimild \\n Saga h\u00fassins (af vefnum edinborg.is)\\n\\nTenglar \\n Gl\u00e6sileg menningarmi\u00f0st\u00f6\u00f0 \u00ed Edinborgarh\u00fasi, Morgunbla\u00f0i\u00f0 B, 11. jan\u00faar 1998, bls. 6-7\\n Stefnt a\u00f0 opnun fj\u00f6lnotasalar eftit eitt \u00e1r, Morgunbla\u00f0i\u00f0, 20. ma\u00ed 2006, bls. 22\\n Formleg opnun Edinborgarh\u00fassins, B\u00e6jarins besta, 31. ma\u00ed 2007, bls. 2\\n\\n\u00cdsafj\u00f6r\u00f0ur\\nByggingar \u00e1 \u00cdslandi\",\n    \"question\": \"Hver gegndi st\u00f6\u00f0u verslunarstj\u00f3ra hj\u00e1 Edinborgarversluninni \u00e1 \u00cdsafir\u00f0i \u00e1ri\u00f0 1903?\",\n    \"answers\": {\n        \"answer_start\": array([471]),\n        \"text\": array([\"Karl Olgeirsson\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru textar me\u00f0 tilheyrandi spurningum og sv\u00f6rum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texti: {text}\nSpurning: {question}\nSvara\u00f0u me\u00f0 a\u00f0 h\u00e1marki 3 or\u00f0um: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texti: {text}\n\nSvara\u00f0u eftirfarandi spurningu um textann a\u00f0 h\u00e1marki \u00ed 3 or\u00f0um.\n\nSpurning: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-is\n</code></pre>"},{"location":"datasets/icelandic/#knowledge","title":"Knowledge","text":""},{"location":"datasets/icelandic/#icelandicknowledge","title":"IcelandicKnowledge","text":"<p>This dataset was published here and consists of an automatically created Icelandic question-answering dataset based on the Icelandic Wikipedia as well as Icelandic news articles from the R\u00daV corpus.</p> <p>The dataset was converted into a multiple-choice knowledge dataset by removing the contexts and using GPT-4o to generate 3 plausible wrong answers for each correct answer, using the following prompt for each <code>row</code> in the original dataset:</p> <pre><code>messages = [\n    {\n        \"role\": \"user\",\n        \"content\": f\"For the question: {row.question} where the correct answer is: {row.answer}, please provide 3 plausible alternatives in Icelandic. You should return the alternatives in a JSON dictionary, with keys 'first', 'second', and 'third'. The values should be the alternatives only, without any numbering or formatting. The alternatives should be unique and not contain the correct answer.\"\n    }\n]\n\ncompletion = client.beta.chat.completions.parse(\n    model=\"gpt-4o\", messages=messages, response_format=CandidateAnswers\n)\n</code></pre> <p>where <code>CandidateAnswers</code> is a Pydantic model that is used to ensure structured outputs.</p> <p>The original dataset has 2,000 samples, but only 1,994 unique questions, and the total length of this dataset is therefore 1,994. The split is given by 842 / 128 / 1024 for train, val, and test, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hver var talinn heilagur ma\u00f0ur eftir dau\u00f0a sinn, er t\u00e1kngervingur al\u00fe\u00fd\u00f0uhreyfingar vestanlands og talinn g\u00f3\u00f0ur til \u00e1heita?\\nSvarm\u00f6guleikar:\\na. \u00de\u00f3r\u00f0ur J\u00f3nsson helgi\\nb. Gu\u00f0mundur Arason\\nc. Snorri \u00deorgr\u00edmsson\\nd. J\u00f3n Hreggvi\u00f0sson\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"\u00cd kringum hva\u00f0a \u00e1r h\u00f3fst verslun \u00e1 Arnger\u00f0areyri?\\nSvarm\u00f6guleikar:\\na. 1895\\nb. 1884\\nc. 1870\\nd. 1902\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hven\u00e6r var \u00e1kve\u00f0i\u00f0 a\u00f0 uppstigningardagur skyldi vera kirkjudagur aldra\u00f0ra \u00e1 \u00cdslandi?\\nSvarm\u00f6guleikar:\\na. \u00c1ri\u00f0 1975\\nb. \u00c1ri\u00f0 1985\\nc. \u00c1ri\u00f0 1982\\nd. \u00c1ri\u00f0 1990\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fj\u00f6lvalsspurningar (me\u00f0 sv\u00f6rum).\n</code></pre></li> <li>Base prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvara: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nSvara\u00f0u eftirfarandi spurningum me\u00f0 'a', 'b', 'c' e\u00f0a 'd', og engu \u00f6\u00f0ru.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset icelandic-knowledge\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-arc-is","title":"Unofficial: ARC-is","text":"<p>This dataset is a machine translated version of the English ARC dataset and features US grade-school science questions. The dataset was translated by Mi\u00f0eind using the Claude 3.5 Sonnet model.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"L\u00edkamar manna hafa fl\u00f3kna uppbyggingu sem sty\u00f0ur v\u00f6xt og l\u00edfsl\u00edkur. Hver er grundvallaruppbygging l\u00edkamans sem stu\u00f0lar a\u00f0 vexti og l\u00edfsl\u00edkum?\\nSvarm\u00f6guleikar:\\na. fruma\\nb. vefur\\nc. l\u00edff\u00e6ri\\nd. l\u00edff\u00e6rakerfi\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ve\u00f0urfr\u00e6\u00f0ingur skr\u00e1ir g\u00f6gn fyrir borg \u00e1 \u00e1kve\u00f0num degi. G\u00f6gnin innihalda hitastig, sk\u00fdjahulu, vindhra\u00f0a, loft\u00fer\u00fdsting og vind\u00e1tt. Hva\u00f0a a\u00f0fer\u00f0 \u00e6tti ve\u00f0urfr\u00e6\u00f0ingurinn a\u00f0 nota til a\u00f0 skr\u00e1 \u00feessi g\u00f6gn fyrir flj\u00f3tlega tilv\u00edsun?\\nSvarm\u00f6guleikar:\\na. skriflega l\u00fdsingu\\nb. t\u00f6flu\\nc. st\u00f6\u00f0varl\u00edkan\\nd. ve\u00f0urkort\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hva\u00f0a breytingar ur\u00f0u \u00feegar reikistj\u00f6rnurnar hitnnu\u00f0u \u00e1 me\u00f0an \u00fe\u00e6r myndu\u00f0ust?\\nSvarm\u00f6guleikar:\\na. Massi \u00feeirra j\u00f3kst.\\nb. \u00de\u00e6r t\u00f6pu\u00f0u meirihluta geislavirkra sams\u00e6ta sinna.\\nc. Uppbygging \u00feeirra a\u00f0greindist \u00ed mismunandi l\u00f6g.\\nd. \u00de\u00e6r byrju\u00f0u a\u00f0 sn\u00faast \u00ed kringum s\u00f3lina.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fj\u00f6lvalsspurningar (me\u00f0 sv\u00f6rum).\n</code></pre></li> <li>Base prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvara: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nSvara\u00f0u eftirfarandi spurningum me\u00f0 'a', 'b', 'c' e\u00f0a 'd', og engu \u00f6\u00f0ru.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset arc-is\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-mmlu-is","title":"Unofficial: MMLU-is","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The dataset was translated using Mi\u00f0eind's Greynir translation model.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Af hverju er \u00f6ruggara a\u00f0 horfa \u00e1 tungli\u00f0 en a\u00f0 horfa \u00e1 s\u00f3lina?\\nSvarm\u00f6guleikar:\\na. Tungli\u00f0 er minna bjart.\\nb. Tungli\u00f0 er n\u00e6r j\u00f6r\u00f0inni.\\nc. Tungli\u00f0 sk\u00edn a\u00f0allega \u00e1 n\u00f3ttunni.\\nd. Tungli\u00f0 er a\u00f0eins fullt einu sinni \u00ed m\u00e1nu\u00f0i.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hva\u00f0a l\u00f6g jar\u00f0ar eru a\u00f0allega ger\u00f0 \u00far f\u00f6stu efni?\\nSvarm\u00f6guleikar:\\na. innri kjarni og ytri kjarni\\nb. skorpu og innri kjarni\\nc. skorpu og m\u00f6ttli\\nd. m\u00f6ttli og ytri kjarni\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Bekkur er a\u00f0 rannsaka \u00fe\u00e9ttleika bergs\u00fdna. Hva\u00f0a v\u00edsindalegan b\u00fana\u00f0 \u00feurfa \u00feau til a\u00f0 \u00e1kvar\u00f0a \u00fe\u00e9ttleika bergs\u00fdnanna?\\nSvarm\u00f6guleikar:\\na. sm\u00e1sj\u00e1 og vog\\nb. bikar og m\u00e6ligl\u00f6s\\nc. m\u00e6ligl\u00f6s og vog\\nd. sm\u00e1sj\u00e1 og m\u00e6ligl\u00f6s\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fj\u00f6lvalsspurningar (me\u00f0 sv\u00f6rum).\n</code></pre></li> <li>Base prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvara: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nSvara\u00f0u eftirfarandi spurningum me\u00f0 'a', 'b', 'c' e\u00f0a 'd', og engu \u00f6\u00f0ru.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-is\n</code></pre>"},{"location":"datasets/icelandic/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/icelandic/#winogrande-is","title":"Winogrande-is","text":"<p>This dataset was published in this paper and is a manually translated and adapted version of the English WinoGrande dataset. The samples are sentences containing two nouns and an ambiguous pronoun, and the task is to determine which of the two nouns the pronoun refers to.</p> <p>The original full dataset consists of 1,095 samples, and we use a 64 / 128 / 896 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Eiginma\u00f0urinn hennar Myrru keypti handa henni h\u00e1lsmen me\u00f0 perlu og h\u00fan h\u00e9lt a\u00f0 \u00fea\u00f0 v\u00e6ri ekki ekta. _ var of gyllt.\\nSvarm\u00f6guleikar:\\na. perlan\\nb. h\u00e1lsmeni\u00f0\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Bergfinnur l\u00e9t sem hann heyr\u00f0i ekki \u00ed lekanum \u00ed krananum en hann haf\u00f0i ekkert um a\u00f0 velja \u00feegar hundurinn gelti. _ er h\u00e1v\u00e6rari.\\nSvarm\u00f6guleikar:\\na. lekinn\\nb. hundurinn\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Dan\u00eda var spenntari fyrir \u00fev\u00ed a\u00f0 heims\u00e6kja ritstj\u00f3rann en \u00deorl\u00e1ks\u00edna vegna \u00feess a\u00f0 _ fannst n\u00fdja b\u00f3kin geggju\u00f0.\\nSvarm\u00f6guleikar:\\na. \u00deorl\u00e1ks\u00ednu\\nb. Dan\u00edu\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fj\u00f6lvalsspurningar (me\u00f0 sv\u00f6rum).\n</code></pre></li> <li>Base prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvara: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nSvara\u00f0u eftirfarandi spurningum me\u00f0 'a', 'b', 'c' e\u00f0a 'd', og engu \u00f6\u00f0ru.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset winogrande-is\n</code></pre>"},{"location":"datasets/icelandic/#unofficial-hellaswag-is","title":"Unofficial: HellaSwag-is","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated using Mi\u00f0eind's Greynir translation model.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[h\u00f6f.] Hvernig finna m\u00e1 samr\u00e6mi \u00ed l\u00edfinu [titill] Skuldbinda \u00feig til breytinga. [skref] Fyrsta skrefi\u00f0 til a\u00f0 n\u00e1 fram breytingum \u00ed l\u00edfinu er a\u00f0 skuldbinda sig til breytinga. Me\u00f0 \u00fev\u00ed a\u00f0 gefa me\u00f0vita\u00f0a, viljasetta yfirl\u00fdsingu til sj\u00e1lfs s\u00edns um a\u00f0 \u00fe\u00fa munir halda \u00feig vi\u00f0 efni\u00f0 og n\u00e1 settum \u00e1rangri getur \u00fea\u00f0 hj\u00e1lpa\u00f0 \u00fe\u00e9r a\u00f0 halda \u00fe\u00e9r vi\u00f0 efni\u00f0 og \u00fdtt \u00fe\u00e9r \u00e1fram \u00ed \u00e1tt a\u00f0 \u00fev\u00ed markmi\u00f0i.\\nSvarm\u00f6guleikar:\\na. \u00de\u00e1 \u00e6ttir \u00fe\u00fa a\u00f0 vera a\u00f0 skuldbinda \u00feig til a\u00f0 lifa st\u00f6\u00f0ugra og samr\u00e6mdara l\u00edfi. [Undirskrefi] Hugsa\u00f0u um \u00e1st\u00e6\u00f0urnar fyrir \u00fev\u00ed a\u00f0 \u00fe\u00fa vilt lifa samr\u00e6mdara l\u00edfi.\\nb. [undirefni] Byrja\u00f0u \u00e1 \u00fev\u00ed a\u00f0 skuldbinda \u00feig til a\u00f0 breyta einhverju sem kemur \u00fe\u00e9r \u00far jafnv\u00e6gi. Ef \u00fe\u00fa gerir \u00fea\u00f0 ekki \u00fe\u00e1 situr\u00f0u uppi me\u00f0 eitthva\u00f0 sem lo\u00f0ir vi\u00f0 \u00feig heima hj\u00e1 \u00fe\u00e9r, sem ver\u00f0ur ekki au\u00f0veldara a\u00f0 koma \u00ed sta\u00f0inn fyrir \u00fe\u00e1 tilfinningu.\\nc. [Undirefni] Ekki l\u00e1ta sko\u00f0anir \u00fe\u00ednar e\u00f0a sko\u00f0anir stangast \u00e1 vi\u00f0 sj\u00e1lfsvir\u00f0ingu \u00fe\u00edna. Vi\u00f0urkenndu a\u00f0 \u00fe\u00fa s\u00e9rt fullor\u00f0inn og \u00fev\u00ed \u00f3hr\u00e6ddur vi\u00f0 a\u00f0 taka \u00fe\u00ednar eigin \u00e1kvar\u00f0anir var\u00f0andi \u00fea\u00f0 sem \u00fe\u00fa vilt \u00ed l\u00edfinu.\\nd. [Efnisor\u00f0] \u00deegar einhver annar hvetur \u00feig til a\u00f0 breyta, \u00fe\u00e1 skaltu ver\u00f0launa \u00feig fyrir \u00fea\u00f0 g\u00f3\u00f0a sem \u00fe\u00fa n\u00e6r\u00f0 fram \u00fe\u00f3 a\u00f0 \u00fea\u00f0 hafi kannski ekki liti\u00f0 \u00fat \u00e1 einhvern h\u00e1tt. [Titill] Ekki \u00e6tlast til \u00feess a\u00f0 f\u00f3lk breyti s\u00e9r af skyldur\u00e6kni.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ma\u00f0ur er a\u00f0 vinna \u00e1 spor\u00f6skjulaga v\u00e9l. \u00fea\u00f0\\nSvarm\u00f6guleikar:\\na. gr\u00edpur og st\u00fdrir t\u00e6kinu.\\nb. s\u00fdnir skj\u00e1inn \u00e1 v\u00e9linni.\\nc. er s\u00fdnd \u00ed tveimur hlutum, sem hver um sig er festur af manneskju.\\nd. vir\u00f0ist vera vins\u00e6ll eftir \u00fev\u00ed sem hann vinnur sig upp.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Sle\u00f0ast\u00falka \u00e1 uppbl\u00e1snum b\u00e1t heldur \u00e1 streng framan \u00e1 mann, allt \u00ed einu dettur h\u00fan \u00ed holu. F\u00f3lk ber sle\u00f0ab\u00e1ta og sle\u00f0ast\u00falkan er \u00e1 sle\u00f0ab\u00e1ti. eftir h\u00f3p af f\u00f3lki\\nSvarm\u00f6guleikar:\\na. sle\u00f0a saman kan\u00f3um, svo sle\u00f0a a\u00f0rir \u00ed vatninu.\\nb. sle\u00f0a hli\u00f0ar vatnsvatn \u00e1 hestum vi\u00f0 hli\u00f0ina \u00e1 br\u00fa b\u00e1ta.\\nc. sle\u00f0a ni\u00f0ur brekkuna \u00feanga\u00f0 til hitta a\u00f0ra einstaklinga.\\nd. Sle\u00f0amenn ganga \u00e1 torgi, \u00e1 milli annarra og s\u00ed\u00f0an hlaupa allir um.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fj\u00f6lvalsspurningar (me\u00f0 sv\u00f6rum).\n</code></pre></li> <li>Base prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvara: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Spurningar: {text}\nSvarm\u00f6guleikar:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nSvara\u00f0u eftirfarandi spurningum me\u00f0 'a', 'b', 'c' e\u00f0a 'd', og engu \u00f6\u00f0ru.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-is\n</code></pre>"},{"location":"datasets/icelandic/#summarization","title":"Summarization","text":""},{"location":"datasets/icelandic/#rrn","title":"RRN","text":"<p>This dataset was published in this paper and consists of news articles and their summaries from R\u00daV, the Icelandic National Broadcasting Service, from years 2021 and 2022.</p> <p>The original full dataset consists of 3,960 samples, and we use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Vi\u00f0 erum a\u00f0 sj\u00e1 \u00f3tta um truflanir \u00e1 framlei\u00f0sluke\u00f0jum og efnahagsstarfsemi eitthva\u00f0 \u00ed l\u00edkingu vi\u00f0 \u00fea\u00f0 sem var fyrr \u00e1 \u00e1rinu.\\nsegir J\u00f3n Bjarki Bentsson a\u00f0alhagfr\u00e6\u00f0ingur \u00cdslandsbanka. \u00c1hrif Delta afbrig\u00f0isins sj\u00e1st v\u00ed\u00f0a. Eftirspurn hefur ekki haldist \u00ed hendur vi\u00f0 v\u00e6ntingar sem me\u00f0al annars hefur orsaka\u00f0 mikla ver\u00f0l\u00e6kkun \u00e1 ol\u00edu \u00e1 heimsmarka\u00f0i undanfarnar vikur. Hefur ver\u00f0i\u00f0 \u00e1 ekki veri\u00f0 l\u00e6gra \u00ed \u00ferj\u00e1 m\u00e1nu\u00f0i.\\nB\u00edlaframlei\u00f0eindur eru einnig \u00ed vanda, en \u00fear er vandam\u00e1li\u00f0 ekki skortur \u00e1 eftirspurn heldur skortur \u00e1 a\u00f0f\u00f6ngum, \u00e1 svok\u00f6llu\u00f0um h\u00e1lflei\u00f0urum n\u00e1nar tilteki\u00f0. \u00deeir eru a\u00f0allega framleiddir \u00ed As\u00edu og hefur \u00fatbrei\u00f0sla Delta afbrig\u00f0isins raska\u00f0 framlei\u00f0slu og framkalla\u00f0 skort. Margir af st\u00e6rstu b\u00edlaframlei\u00f0endum heims hafa tilkynnt um a\u00f0 \u00feeir ney\u00f0ist til a\u00f0 draga \u00far framlei\u00f0slu og \u00fearf Toyota, st\u00e6rsti b\u00edlaframlei\u00f0andi heims, a\u00f0 minnka framlei\u00f0slu s\u00edna um 40 pr\u00f3sent.\\n\u00c1standi\u00f0 hefur s\u00f6mulei\u00f0is valdi\u00f0 mikilli styrkingu dollars. Mi\u00f0gengi se\u00f0labanka \u00cdslands \u00ed dag er 128 kr\u00f3nur en var \u00ed byrjun sumars 121 kr\u00f3na. \u00c1 sama t\u00edma hefur kr\u00f3nan haldist st\u00f6\u00f0ug gagnvart \u00f6\u00f0rum myntum. Auk \u00fatbrei\u00f0slu Delta afbrig\u00f0isins hafa atbur\u00f0ir li\u00f0inna vikna \u00ed Afganistan \u00fer\u00fdst \u00e1 styrkingu dollarsins.\\n\u00deetta hefur allt \u00e1hrif til \u00feess a\u00f0 hvetja til \u00f3tta \u00ed \u00f6ryggi eins og svo er kalla\u00f0 og dollarinn n\u00fdtur oft g\u00f3\u00f0s af svolei\u00f0is \u00f3tta. \u00deykir n\u00e1tt\u00farlega gr\u00ed\u00f0arlega \u00f6rugg eign a\u00f0 hafa og seljanleiki hans er n\u00e1tt\u00farlega meiri en nokkurs annars eigna flokks.\",\n  \"target_text\": \"\u00datbrei\u00f0sla Delta afbrig\u00f0is k\u00f3r\u00f3nuveirunnar \u00f3gnar bata heimshagkerfisins. Ol\u00eduver\u00f0 hefur hr\u00ed\u00f0falli\u00f0 \u00e1 undanf\u00f6rnum vikum, b\u00edlaframlei\u00f0endur f\u00e1 ekki a\u00f0f\u00f6ng og fj\u00e1rfestar flykkjast \u00ed bandar\u00edkjadollar. \"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ve\u00f0urfar hefur veri\u00f0 \u00f3venjulegt \u00e1 su\u00f0vesturhorni landsins. L\u00edti\u00f0 snj\u00f3a\u00f0i \u00ed vetur og s\u00ed\u00f0ustu vikur hefur \u00farkoma veri\u00f0 me\u00f0 allra minnsta m\u00f3ti. J\u00f3n \u00de\u00f3r \u00d3lason, forma\u00f0ur Stangvei\u00f0if\u00e9lags Reykjav\u00edkur, segir a\u00f0 vei\u00f0imenn s\u00e9u vissulega or\u00f0nir langeygir eftir rigningunni, en b\u00e6tir vi\u00f0 a\u00f0 eitt helsta einkenni \u00edslenskra vei\u00f0imanna s\u00e9 \u00f3bilandi bjarts\u00fdni.\\nJ\u00f3n \u00de\u00f3r segir a\u00f0 nor\u00f0an- og austanlands s\u00e9u horfurnar betri. \u00deurrkat\u00ed\u00f0in hefur \u00fe\u00f3 ekki haft \u00e1hrif \u00e1 s\u00f6lu vei\u00f0ileyfa. \u00d3vissan um ve\u00f0urfar fylgi me\u00f0 \u00ed kaupunum og n\u00fa \u00feegar eru margar af \u00e1m f\u00e9lagsins uppseldar. \u00de\u00e1 er von \u00e1 fleiri \u00fatlendingum \u00ed \u00e1r en \u00ed fyrra, en k\u00f3r\u00f3nuveirufaraldurinn haf\u00f0i mj\u00f6g mikil \u00e1hrif \u00e1 s\u00f6lu vei\u00f0ileyfa \u00ed fyrra.\",\n  \"target_text\": \"Forma\u00f0ur Stangavei\u00f0if\u00e9lags Reykjav\u00edkur segir vei\u00f0imenn \u00e1 su\u00f0vesturhorni landsins dansa n\u00fa regndans \u00ed von um a\u00f0 langvarandi \u00feurrkat\u00ed\u00f0 s\u00e9 senn \u00e1 enda.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"\u00cd morgun fjarl\u00e6g\u00f0u b\u00e6jarstarfsmenn \u00e1berandi kosningabor\u00f0a frambo\u00f0sins Vina K\u00f3pavogs \u00e1 horni Digranesvegar og Gr\u00e6nutungu. J\u00f3hann Sigurbj\u00f6rnsson, sem er \u00ed18. s\u00e6ti \u00e1 lista Vina K\u00f3pavogs, setti bor\u00f0ana upp og er afar \u00f3s\u00e1ttur vi\u00f0 \u00feeir hafi veri\u00f0 fjarl\u00e6g\u00f0ir. Hann segir a\u00f0 vegi\u00f0 s\u00e9 a\u00f0 tj\u00e1ningarfrelsi s\u00ednu.\\n\u00c9g hengi upp bor\u00f0a vegna \u00feess a\u00f0 \u00e9g tel mig vera \u00ed fullum r\u00e9tti til a\u00f0 tj\u00e1 mig um \u00fe\u00e6r framkv\u00e6mdir sem eru \u00ed gangi h\u00e9rna \u00e1 m\u00f3ti m\u00e9r. \u00c9g hengi upp \u00feessa bor\u00f0a \u00e1 grindverki\u00f0 sem er r\u00e9tt fyrir innan l\u00f3\u00f0am\u00f6rk s\u00ed\u00f0an koma hinga\u00f0 menn \u00ed gulum f\u00f6tum \u00ed morgun fr\u00e1 b\u00e6num sem fjarl\u00e6gja bor\u00f0ana.\\nB\u00e6jarstarfsmenn hafa undanfari\u00f0 veri\u00f0 \u00ed samskiptum vi\u00f0 frambo\u00f0i\u00f0 um a\u00f0 broti\u00f0 hafi veri\u00f0 gegn l\u00f6greglusam\u00feykkt og byggingarregluger\u00f0 me\u00f0 \u00fev\u00ed a\u00f0 setja upp augl\u00fdsingabor\u00f0a \u00e1 l\u00f3\u00f0am\u00f6rkum og utan \u00feeirra, og einnig svo st\u00f3ra augl\u00fdsingabor\u00f0a a\u00f0 s\u00e9rstakt leyfi \u00feurfi.\\nSigr\u00ed\u00f0ur Bj\u00f6rg T\u00f3masd\u00f3ttir uppl\u00fdsingafulltr\u00fai K\u00f3pavogsb\u00e6jar segir \u00ed samtali vi\u00f0 fr\u00e9ttastofu a\u00f0 sk\u00fdrar reglur gildi um uppsetningu augl\u00fdsingaskilta. Reglur um sl\u00edka uppsetningu hafi veri\u00f0 sendar a\u00f0 gefnu tilefni \u00e1 alla frambo\u00f0sflokka \u00ed K\u00f3pavogi fyrir helgi. \u00de\u00e1 hafi st\u00f3rt augl\u00fdsingaskilti \u00e1 vegum Frams\u00f3knarflokksins \u00ed Sk\u00f3garlind veri\u00f0 fjarl\u00e6gt af b\u00e6jaryfirv\u00f6ldum \u00ed s\u00ed\u00f0ustu viku. Sigr\u00ed\u00f0ur segir a\u00f0 skiltin ver\u00f0i a\u00f0 vera undir tveimur fermetrum til a\u00f0 mega vera uppi - annars \u00feurfi a\u00f0 s\u00e6kja um leyfi fr\u00e1 byggingarfulltr\u00faa K\u00f3pavogsb\u00e6jar. Reglurnar s\u00e9u sk\u00fdrar.\\nHelga, Oddviti Vina K\u00f3pavogsb\u00e6jar segist hissa yfir framgangi b\u00e6jaryfirvalda, \u00feetta geti ekki sta\u00f0ist sko\u00f0un og a\u00f0 frambo\u00f0i\u00f0 muni leita r\u00e9ttar s\u00edns.\",\n  \"target_text\": \"Augl\u00fdsingaskilti og frambo\u00f0sbor\u00f0ar hafa veri\u00f0 fjarl\u00e6g\u00f0 af b\u00e6jaryfirv\u00f6ldum \u00ed K\u00f3pavogi v\u00ed\u00f0s vegar um b\u00e6inn s\u00ed\u00f0ustu daga. \"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Eftirfarandi eru fr\u00e9ttagreinar me\u00f0 tilheyrandi samantektum.\n</code></pre></li> <li>Base prompt template:   <pre><code>Fr\u00e9ttagrein: {text}\nSamantekt: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Fr\u00e9ttagrein: {text}\n\nSkrifa\u00f0u samantekt um ofangreindu grein.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset rrn\n</code></pre>"},{"location":"datasets/italian/","title":"\ud83c\uddee\ud83c\uddf9 Italian","text":"<p>This is an overview of all the datasets used in the Italian part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/italian/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/italian/#sentipolc-16","title":"Sentipolc-16","text":"<p>This dataset was published in this paper and slightly modified in this paper. It is based on Italian tweets, which were manually annotated by three annotators.</p> <p>The original full dataset consists of 1,839 / 324 / 870 samples, and we use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively. The splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"RT @user: Siamo dei falsi. I ragazzi vogliono le ragazze timide e poi stanno con le troie. Le ragazze vogliono i dolci e poi amano con\u2026\",\n  \"label\": \"negative\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ho aggiunto un video a una playlist di @user: http ROMA PRESENTAZIONE LIBRO SVIMEZ SULL\u2019ECONOMIA DEL\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"RT @user: @user te lo auguro di cuore e far\u00f2 il possibile affinch\u00e9 sia cos\u00ec. Un abbraccio\",\n  \"label\": \"positive\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Di seguito sono riportati i testi e il loro sentimento, che pu\u00f2 essere 'positivo', 'neutro' o 'negativo'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tweet: {text}\nSentimento: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tweet: {text}\n\nClassificare il sentimento nel Tweet. Rispondete con 'positivo', 'neutro' o 'negativo', e nient'altro.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset sentipolc16\n</code></pre>"},{"location":"datasets/italian/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/italian/#multinerd-it","title":"MultiNERD IT","text":"<p>This dataset was published in this paper and consists of sentences from Wikipedia and Wikinews in 10 different languages. It is an extension of the combination of WikiNEuRal and NER4EL. The original test set was created from manual annotations, while the training set is based on an automatic annotation pipeline.</p> <p>The Italian part of the original dataset consists of 181,927 sentences, split into 145,520 / 18,190 / 18,217 for training, validation, and testing respectively. We use given splits, and use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>We have furthermore converted their fine-grained labelling scheme to the CoNLL-2003 labelling scheme, which is more common in the NER literature. The mapping is as follows:</p> <ul> <li><code>PERS</code> \u27a1\ufe0f <code>PER</code></li> <li><code>LOC</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>ORG</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>MISC</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>TIME</code> \u27a1\ufe0f <code>O</code></li> <li><code>ANIM</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>BIO</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>CEL</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>DIS</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>EVE</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>FOOD</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>INST</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>MEDIA</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>MYTH</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>PLANT</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>VEHI</code> \u27a1\ufe0f <code>MISC</code></li> </ul> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['Alcune' 'statue' 'che' 'la' 'rappresentano' 'vennero' 'ritrovate' 'non' 'lontano' 'da' 'Tani' ',' 'anche' 'se' 'in' 'nessuna' 'di' 'queste' 'si' '\u00e8' 'conservato' 'il' 'volto' ',' 'mentre' 'nella' 'seconda' 'cateratta' '\u00e8' 'registrata' 'una' 'piena' 'del' 'Nilo' 'datata' 'al' 'suo' '3\u00ba' 'anno' 'di' 'regno' '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Nella' 'seconda' 'met\u00e0' 'del' 'XX' 'secolo' 'gli' 'infinitesimi' 'sono' 'stati' 'recuperati' ',' 'in' 'una' 'prospettiva' 'rigorosa' ',' 'da' 'Abraham' 'Robinson' ',' 'nella' 'formulazione' 'di' 'quella' 'che' 'lui' 'chiam\u00f2' 'analisi' 'non' 'standard' '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Il' 'monumento' 'a' 'Carlo' 'Emanuele' 'III' 'di' 'Savoia' '\u00e8' 'ubicato' 'nella' 'piazza' 'omonima' 'sul' 'lungomare' '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Di seguito sono riportate le frasi e i dizionari JSON con le entit\u00e0 denominate presenti nella frase data.\n</code></pre></li> <li>Base prompt template:   <pre><code>Frase: {text}\nEntit\u00e0 denominate: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frase: {text}\n\nIdentificare le entit\u00e0 nominate nella frase. Il risultato dovrebbe essere un dizionario JSON con le chiavi 'persona', 'posizione', 'organizzazione' e 'varie'. I valori devono essere elenchi di entit\u00e0 nominate di quel tipo, esattamente come appaiono nella frase.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>posizione</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>posizione</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organizzazione</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organizzazione</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>varie</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>varie</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multinerd-it\n</code></pre>"},{"location":"datasets/italian/#unofficial-wikineural-it","title":"Unofficial: WikiNEuRal IT","text":"<p>This dataset was published in this paper and consists of sentences from Wikipedia in 9 different languages. The annotations are automatic but at the time novel and state-of-the-art methodologies.</p> <p>The Italian part of the original dataset consists of 110,519 sentences, split into 88,400 / 11,050 / 11,069 for training, validation, and testing respectively. We use given splits, and use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['Comunque' ',' 'il' 'poema' 'sarebbe' 'stato' 'influenzato' 'da' 'una' '\"' 'tematica' 'di' 'regime' '\"' 'voluta' 'dalla' 'politica' 'culturale' 'di' 'Domiziano' 'nella' 'quale' 'rientrano' 'anche' 'i' '\"' 'Punica' '\"' 'di' 'Silio' 'Italico' '.']),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-PER', 'I-PER', 'O'])\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['\u00c8' 'stato' 'uno' 'degli' 'artisti' 'pi\u00f9' 'importanti' \"dell'\" 'etichetta' 'discografica' 'di' 'musica' 'soul' 'Stax' 'Records' 'che' 'negli' 'anni' 'sessanta' 'e' 'settanta' 'era' 'la' 'principale' 'antagonista' 'della' 'Motown' 'nel' 'campo' 'della' 'black' 'music' '.']),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O'])\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Decise' 'di' 'scrivere' 'una' 'serie' 'di' 'saggi' 'e' 'presentarli' 'in' 'un' 'periodico' 'intitolato' '\"' 'The' 'Rambler' '\"' 'che' 'sarebbe' 'stato' 'messo' 'in' 'vendita' 'per' 'pochi' 'centesimi' 'ogni' 'marted\u00ec' 'e' 'sabato' '.']),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Di seguito sono riportate le frasi e i dizionari JSON con le entit\u00e0 denominate presenti nella frase data.\n</code></pre></li> <li>Base prompt template:   <pre><code>Frase: {text}\nEntit\u00e0 denominate: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frase: {text}\n\nIdentificare le entit\u00e0 nominate nella frase. Il risultato dovrebbe essere un dizionario JSON con le chiavi 'persona', 'posizione', 'organizzazione' e 'varie'. I valori devono essere elenchi di entit\u00e0 nominate di quel tipo, esattamente come appaiono nella frase.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>posizione</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>posizione</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organizzazione</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organizzazione</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>varie</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>varie</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset wikineural-it\n</code></pre>"},{"location":"datasets/italian/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/italian/#scala-it","title":"ScaLA-it","text":"<p>This dataset was published in this paper is automatically created from the Italian Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original full dataset consists of 13,121 / 564 / 482 samples for training, validation and testing, respectively. We use 512 / 128 / 1,024, sampled from a combination of all the splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Il Presidente della di la Repubblica non \u00e8 responsabile degli di gli atti compiuti nell' in l' esercizio delle di le sue funzioni, tranne che per alto tradimento o per attentato alla a la Costituzione.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Ottimamente ha retto invece il cuore nuovo di Saverio Pallucca - alle a le spalle tre infarti, quattro by-pass, un trapianto cardiaco meno di due anni fa - nell' in l' ultima edizione della di la famosa maratona di New York.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Un secondo gruppo di problemi riguarda la necessit\u00e0 di garantire che il sistema economico venga percepito come fondamentalmente equo, che rappresenta la chiave della la di sua sostenibilit\u00e0 politica.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Di seguito sono riportate le frasi e la loro correttezza grammaticale.\n</code></pre></li> <li>Base prompt template:   <pre><code>Frase: {text}\nGrammaticalmente corretto: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frase: {text}\n\nStabilite se la frase \u00e8 grammaticalmente corretta o meno. Rispondete con 'si' se la frase \u00e8 corretta e con 'no' se non lo \u00e8, e nient'altro.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>si</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>no</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-it\n</code></pre>"},{"location":"datasets/italian/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/italian/#squad-it","title":"SQuAD-it","text":"<p>This dataset is derived from the SQuAD 1.1 dataset and was published in this paper. The questions and answers were obtained through \"semi-automatic\" translation, using DeepL, of the SQuAD dataset to Italian. The dataset consists of 54,159 / 7,609 question/answer pairs for training and test respectively. We use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively. Our training split is a subset of the original training split, and our validation and testing splits are subsets of the original test split.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"Lo studio del Corano e dell' Hadith prosper\u00f2 in un' atmosfera cos\u00ec studiosa. Filosofia, Fiqh e teologia (kalaam) sono stati ulteriormente sviluppati, in particolare da Avicenna e dai suoi avversari. Al-Razi e Al-Farabi avevano fornito metodologie e conoscenze in medicina e filosofia. Avicenna ha avuto accesso alle grandi biblioteche di Balkh, Khwarezm, Gorgan, Rey, Isfahan e Hamadan. Vari testi (come il' Ahd con Bahmanyar') mostrano che egli ha dibattuto punti filosofici con i pi\u00f9 grandi studiosi del tempo. Aruzi Samarqandi descrive come prima che Avicenna lasciasse Khwarezm aveva conosciuto Al-Biruni (un famoso scienziato e astronomo), Abu Nasr Iraqi (un famoso matematico), Abu Sahl Masihi (un illustre filosofo) e Abu al-Khayr Khammar (un grande medico).\",\n  \"question\": \"Che cosa \u00e8 stato un tema che Avicenna ha ulteriormente sviluppato?\",\n  \"answers\": {\n    \"answer_start\":  array([95]),\n    \"text\": array(['teologia'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Florida Alta Velocit\u00e0 ferroviaria \u00e8 stata proposta ferroviaria ad alta velocit\u00e0 sostenuta dal governo che avrebbe collegato Miami, Orlando e Tampa. La prima fase \u00e8 stata pianificata per collegare Orlando e Tampa ed \u00e8 stato offerto un finanziamento federale, ma \u00e8 stato respinto dal governatore Rick Scott nel 2011. La seconda fase della linea \u00e8 stata prevista per collegare Miami. Entro il 2014, un progetto privato conosciuto come All Aboard Florida da parte di una societ\u00e0 della storica Florida East Coast Railway ha iniziato la costruzione di una linea ferroviaria ad alta velocit\u00e0 nel sud della Florida che dovrebbe terminare all' aeroporto internazionale di Orlando.\",\n  \"question\": \"In quale anno ha iniziato All Aboard Florida?\",\n  \"answers\": {\n    \"answer_start\": array([390]),\n    \"text\": array(['2014'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": \"Gli insetti sociali, come le termiti, le formiche e molte api e vespe, sono la specie pi\u00f9 familiare di animali eusociali. Vivono insieme in grandi colonie ben organizzate che possono essere cos\u00ec strettamente integrate e geneticamente simili che le colonie di alcune specie sono talvolta considerate superorganismi. Talvolta si sostiene che le varie specie di api da miele siano gli unici invertebrati (e addirittura uno dei pochi gruppi non umani) ad aver evoluto un sistema di comunicazione simbolica astratta in cui un comportamento viene utilizzato per rappresentare e trasmettere informazioni specifiche su qualcosa nell' ambiente. In questo sistema di comunicazione, chiamato linguaggio dance, l' angolo in cui una danza d' ape rappresenta una direzione relativa al sole, e la lunghezza della danza rappresenta la distanza da volare. 309-311 Anche se forse non cos\u00ec avanzato come le api mellifere, anche i bombi hanno potenzialmente alcuni comportamenti di comunicazione sociale.\",\n  \"question\": \"Termiti, api, vespe e quali altri insetti sono insetti sociali?\",\n  \"answers\": {\n    \"answer_start\": array([41]),\n    \"text\": array(['formiche'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>I testi che seguono sono accompagnati da domande e risposte.\n</code></pre></li> <li>Base prompt template:   <pre><code>Testo: {text}\nDomanda: {question}\nRispondere in massimo 3 parole: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Testo: {text}\n\nRispondi alla seguente domanda sul in un massimo di 3 parole.\n\nDomanda: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset squad-it\n</code></pre>"},{"location":"datasets/italian/#unofficial-belebele-it","title":"Unofficial: BeleBele-it","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Testo: Con la decisione del signor Rudd di firmare l\u2019accordo sul clima di Kyoto, gli Stati Uniti, che ora saranno l\u2019unica nazione sviluppata a non averlo ratificato, rimangono isolati. Il precedente governo conservatore australiano aveva rifiutato di ratificare gli accordi di Kyoto asserendo che avrebbero danneggiato l'economia, data la pesante dipendenza dalle esportazioni di carbone, mentre gli obiettivi sulle emissioni non sarebbero stati vincolanti per Paesi come l'India e la Cina.\\nDomanda: Il precedente governo australiano pensava che la ratifica di Kyoto avrebbe causato danni a cosa?\\nOpzioni:\\na. Stati Uniti\\nb. Economia del Paese\\nc. Esportazioni di carbone\\nd. Gli obiettivi di emissione del Paese\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Testo: \"I commenti, in diretta televisiva, hanno rappresentato la prima occasione per autorevoli fonti iraniane per ammettere che le sanzioni sono efficaci. Esse comprendono limitazioni finanziarie e il divieto dell\\'Unione europea all\\'esportazione di petrolio greggio, che rappresenta l\\'80% del reddito estero nell\\'economia dell\\'Iran. Secondo l\\'ultimo rapporto mensile dell\u2019OPEC, il volume delle esportazioni di greggio \u00e8 sceso al livello pi\u00f9 basso degli ultimi vent\\'anni, con 2,8 milioni di barili al giorno. Il leader supremo del Paese, l\u2019Ayatollah Ali Khamenei, ha parlato della dipendenza dal petrolio paragonandola ad \"\"una trappola\"\" che risale al periodo precedente la rivoluzione islamica iraniana del 1979 e dalla quale il Paese si dovrebbe liberare.\"\\nDomanda: Secondo il passaggio, chi ha ammesso gli effetti delle sanzioni sull\\'economia iraniana?\\nOpzioni:\\na. Autorevoli fonti\\nb. OPEC\\nc. Ayatollah Ali Khamenei\\nd. L\\'Unione Europea\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Testo: Il dottor Lee si \u00e8 detto preoccupato anche in merito ai rapporti che rivelano che i bambini in Turchia ora sono stati contagiati dal virus dell'influenza aviaria A(H5N1) senza ammalarsi. Ha sottolineato che secondo alcuni studi la malattia diventer\u00e0 meno mortale prima che possa causare un'epidemia globale. Si teme che se permangono sintomi influenzali di lieve entit\u00e0, i pazienti possano continuare a contagiare pi\u00f9 persone durante la loro routine quotidiana.\\nDomanda: Secondo il brano, cosa dovrebbe accadere alla malattia prima di causare un'epidemia globale?\\nOpzioni:\\na. Deve diventare meno letale\\nb. I sintomi devono rimanere lievi\\nc. Occorre che pi\u00f9 pazienti vengano infettati\\nd. I bambini devono manifestare i sintomi\",\n  \"label\": \"a\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Le seguenti sono domande a scelta multipla (con relative risposte).\n</code></pre></li> <li>Base prompt template:   <pre><code>Domanda: {text}\nOpzioni:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRisposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Domanda: {text}\nOpzioni:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nRispondete alla domanda precedente con 'a', 'b', 'c' o 'd', e nient'altro.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-it\n</code></pre>"},{"location":"datasets/italian/#unofficial-multiwikiqa-it","title":"Unofficial: MultiWikiQA-it","text":"<p>This dataset will be published in an upcoming paper, and contains Italian Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"I Campionati canadesi di sci alpino 2015 si sono svolti a Mont-Sainte-Anne e Nakiska dal 24 febbraio al 29 marzo. Il programma ha incluso gare di supergigante, slalom gigante, slalom speciale e combinata, tutte sia maschili sia femminili; tuttavia le gare di combinata sono state annullate.\\n\\nTrattandosi di competizioni valide anche ai fini del punteggio FIS, vi hanno partecipato anche sciatori di altre federazioni, senza che questo consentisse loro di concorrere al titolo nazionale canadese.\\n\\nRisultati\\n\\nUomini\\n\\nSupergigante \\n\\nData: 24 febbraio\\nLocalit\u00e0: Nakiska\\nOre: 11.00 (UTC-5)\\nPista: \\nPartenza: 2\\xa0255\\xa0m\\xa0s.l.m.\\nArrivo: 1\\xa0790\\xa0m\\xa0s.l.m.\\nDislivello: 465\\xa0m\\nTracciatore: Richard Jagger\\n\\nSlalom gigante \\n\\nData: 26 marzo\\nLocalit\u00e0: Mont-Sainte-Anne\\n1\u00aa manche:\\nOre: \\nPista: \\nPartenza: 615\\xa0m\\xa0s.l.m.\\nArrivo: 265\\xa0m\\xa0s.l.m.\\nDislivello: 350\\xa0m\\nTracciatore: John Kucera\\n\\n2\u00aa manche:\\nOre: \\nPista: \\nPartenza: 615\\xa0m\\xa0s.l.m.\\nArrivo: 265\\xa0m\\xa0s.l.m.\\nDislivello: 350\\xa0m\\nTracciatore: Mathieu Roy\\n\\nSlalom speciale \\n\\nData: 28 marzo\\nLocalit\u00e0: Mont-Sainte-Anne\\n1\u00aa manche:\\nOre: \\nPista: \\nPartenza: 515\\xa0m\\xa0s.l.m.\\nArrivo: 315\\xa0m\\xa0s.l.m.\\nDislivello: 200\\xa0m\\nTracciatore: Johnny Crichton\\n\\n2\u00aa manche:\\nOre: \\nPista: \\nPartenza: 515\\xa0m\\xa0s.l.m.\\nArrivo: 315\\xa0m\\xa0s.l.m.\\nDislivello: 200\\xa0m\\nTracciatore: Duane Baird\\n\\nCombinata \\nLa gara, originariamente in programma il 26 marzo a Mont-Sainte-Anne, \u00e8 stata annullata.\\n\\nDonne\\n\\nSupergigante \\n\\nData: 24 febbraio\\nLocalit\u00e0: Nakiska\\nOre: 9.30 (UTC-5)\\nPista: \\nPartenza: 2\\xa0255\\xa0m\\xa0s.l.m.\\nArrivo: 1\\xa0790\\xa0m\\xa0s.l.m.\\nDislivello: 465\\xa0m\\nTracciatore: Richard Jagger\\n\\nSlalom gigante \\n\\nData: 27 marzo\\nLocalit\u00e0: Mont-Sainte-Anne\\n1\u00aa manche:\\nOre: \\nPista: \\nPartenza: 615\\xa0m\\xa0s.l.m.\\nArrivo: 265\\xa0m\\xa0s.l.m.\\nDislivello: 350\\xa0m\\nTracciatore: Peter Ryb\u00e1rik\\n\\n2\u00aa manche:\\nOre: \\nPista: \\nPartenza: 615\\xa0m\\xa0s.l.m.\\nArrivo: 265\\xa0m\\xa0s.l.m.\\nDislivello: 350\\xa0m\\nTracciatore: Martin Durocher\\n\\nSlalom speciale \\n\\nData: 28 marzo\\nLocalit\u00e0: Mont-Sainte-Anne\\n1\u00aa manche:\\nOre: \\nPista: \\nPartenza: 515\\xa0m\\xa0s.l.m.\\nArrivo: 315\\xa0m\\xa0s.l.m.\\nDislivello: 200\\xa0m\\nTracciatore: Pierre-Luc Dumoulin\\n\\n2\u00aa manche:\\nOre: \\nPista: \\nPartenza: 515\\xa0m\\xa0s.l.m.\\nArrivo: 315\\xa0m\\xa0s.l.m.\\nDislivello: 200\\xa0m\\nTracciatore: Brett Zagazowski\\n\\nCombinata \\nLa gara, originariamente in programma il 27 marzo a Mont-Sainte-Anne, \u00e8 stata annullata.\\n\\nNote\\n\\nCollegamenti esterni \\n \\n \\n\\nCanadesi\\n2015\\nSport a Beaupr\u00e9\",\n    \"question\": \"Qual \u00e8 stato l'autore del tracciato della prima manche dello slalom speciale maschile a Mont-Sainte-Anne?\",\n    \"answers\": {\n        \"answer_start\": array([1134]),\n        \"text\": array([\"Johnny Crichton\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"\\n\\nCarriera\\nTra il 1991 ed il 1995 \u00e8 tesserato del , club della prima divisione inglese: nelle prime 2 stagioni gioca nelle giovanili, mentre dal 1993 al 1995 \u00e8 aggregato alla prima squadra, in cui comunque gioca solamente una partita ufficiale, il 14 agosto 1994, quando subentra dalla panchina al 64' nel Charity Shield perso per 2-0 contro il  a Wembley. Nell'arco di queste stagioni trascorre anche un breve periodo in prestito al , club di quarta divisione, con cui nella parte finale della stagione 1993-1994 gioca 11 partite di campionato. Nella seconda parte della stagione 1994-1995 viene ceduto a titolo definitivo allo , con cui realizza 9 reti in 20 partite di campionato, non riuscendo comunque ad evitare la retrocessione in terza divisione del club, con cui in compenso raggiunge le semifinali di Coppa di Lega, risultato a cui contribuisce realizzando 2 reti in altrettante presenze nella competizione. L'anno seguente con 10 reti in 26 presenze contribuisce all'immediato ritorno del club in seconda divisione, categoria nella quale nella stagione 1996-1997 mette a segno 8 reti in 31 presenze.\\n\\nNell'estate del 1997 passa allo , altro club di seconda divisione, con cui mette a segno 12 reti in 36 partite nel campionato 1997-1998, che si conclude con la retrocessione in terza divisione delle Potteries; l'anno seguente realizza 9 reti in 34 presenze in questa categoria, mentre nella stagione 1999-2000 oltre a vincere un Football League Trophy realizza 24 reti in 45 partite di campionato, a cui aggiunge 16 reti in 38 partite nel campionato successivo. Nella stagione 2000-2001 realizza invece 4 reti in 5 presenze per poi essere ceduto al , altro club di terza divisione, con cui nella rimanente parte della stagione mette a segno 8 reti in 26 presenze. Nella stagione 2002-2003 vince invece i play-off di terza divisione, dopo aver segnato 13 reti in 46 partite di campionato; nella stagione 2003-2004 torna quindi nuovamente a giocare in seconda divisione, categoria nella quale va a segno per 13 volte in 23 presenze. L'anno seguente, che \u00e8 anche il suo ultimo nel Cardiff City, gioca con maggior regolarit\u00e0 e va nuovamente in doppia cifra di reti segnate: chiude infatti il campionato con 31 presenze e 12 reti. Tra il 2005 ed il 2007 gioca ancora in seconda divisione, con la maglia del , ma con un ruolo da comprimario: nell'arco di 2 stagioni segna infatti solamente una rete in complessive 36 partite di campionato. Al termine della stagione 2006-2007 scende di categoria e si accasa al , in quarta divisione: qui, nelle stagioni 2007-2008 e 2008-2009 gioca stabilmente da titolare e torna a segnare con regolarit\u00e0 (31 reti in 70 partite di campionato nell'arco del biennio), mentre nella stagione 2009-2010, la sua ultima in carriera, perde il posto in squadra e gioca in totale solamente 9 partite fra tutte le competizioni (7 in campionato e 2 nel Football League Trophy) senza mai segnare.\\n\\nIn carriera ha totalizzato complessivamente 495 presenze e 174 reti nei campionati professionistici inglesi (play-off inclusi), pi\u00f9 25 presenze e 2 reti in FA Cup, 27 presenze e 14 reti in Coppa di Lega, una presenza nel Community Shield e 13 presenze e 7 reti nel Football League Trophy, per un totale complessivo di 561 presenze e 197 reti in carriera in partite ufficiali.\\n\\nPalmar\u00e8s\\n\\nClub\\n\\nCompetizioni nazionali\\n\\nStoke: 1999-2000\\n\\nNote\\n\\nCollegamenti esterni\",\n    \"question\": \"In quale torneo ha disputato l'unico incontro ufficiale il calciatore con il Manchester City?\",\n    \"answers\": {\n        \"answer_start\": array([306]),\n        \"text\": array([\"Charity Shield\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"HD 56779 \u00e8 una stella bianco-azzurra nella sequenza principale di magnitudine 5,01 situata nella costellazione della Poppa. Dista 959 anni luce dal sistema solare.\\n\\nOsservazione\\nSi tratta di una stella situata nell'emisfero celeste australe. La sua posizione moderatamente australe fa s\u00ec che questa stella sia osservabile specialmente dall'emisfero sud, in cui si mostra alta nel cielo nella fascia temperata; dall'emisfero boreale la sua osservazione risulta invece pi\u00f9 penalizzata, specialmente al di fuori della sua fascia tropicale. La sua magnitudine pari a 5 fa s\u00ec che possa essere scorta solo con un cielo sufficientemente libero dagli effetti dell'inquinamento luminoso.\\n\\nIl periodo migliore per la sua osservazione nel cielo serale ricade nei mesi compresi fra dicembre e maggio; nell'emisfero sud \u00e8 visibile anche all'inizio dell'inverno, grazie alla declinazione australe della stella, mentre nell'emisfero nord pu\u00f2 essere osservata limitatamente durante i mesi della tarda estate boreale.\\n\\nCaratteristiche fisiche\\nLa stella \u00e8 una bianco-azzurra nella sequenza principale; possiede una magnitudine assoluta di -2,33 e la sua velocit\u00e0 radiale positiva indica che la stella si sta allontanando dal sistema solare.\\n\\nVoci correlate\\nStelle principali della costellazione della Poppa\\n\\nCollegamenti esterni\\n\\nStelle di classe spettrale B\\nStelle bianco-azzurre di sequenza principale\",\n    \"question\": \"Quanto \u00e8 distante HD 56779 dal nostro sistema solare?\",\n    \"answers\": {\n        \"answer_start\": array([130]),\n        \"text\": array([\"959 anni luce\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>I testi che seguono sono accompagnati da domande e risposte.\n</code></pre></li> <li>Base prompt template:   <pre><code>Testo: {text}\nDomanda: {question}\nRispondere in massimo 3 parole: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Testo: {text}\n\nRispondi alla seguente domanda sul in un massimo di 3 parole.\n\nDomanda: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-it\n</code></pre>"},{"location":"datasets/italian/#knowledge","title":"Knowledge","text":""},{"location":"datasets/italian/#mmlu-it","title":"MMLU-it","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Italian was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Quale delle seguenti situazioni \u00e8 meglio modellata dalla distribuzione binomiale?\\nScelte:\\na. Il numero di minuti in un'ora in cui la media Dow-Jones \u00e8 superiore alla sua media iniziale del giorno.\\nb. Il numero di citt\u00e0 tra le 10 pi\u00f9 grandi dello Stato di New York in cui il tempo \u00e8 nuvoloso per la maggior parte di un determinato giorno.\\nc. Il numero di conducenti che indossano le cinture di sicurezza se 10 conducenti consecutivi vengono fermati in un posto di blocco della polizia.\\nd. Nessuna delle precedenti.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Il 'nuovo razzismo' si riferisce a:\\nScelte:\\na. una forma pi\u00f9 sottile di pregiudizio, mascherata dall'orgoglio nazionale\\nb. una decostruzione post-moderna delle idee razziste per rivelarne la mancanza di profondit\u00e0\\nc. pratiche razziste riscontrabili in aree sociali di recente emergenza, come il cyberspazio\\nd. un movimento antifascista che sfida le politiche nazionaliste\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tutti i seguenti possono agire come messaggeri intracellulari, TRANNE\\nScelte:\\na. ioni di calcio\\nb. cAMP\\nc. acetilcolina\\nd. inositolo 1,4,5-trifosfato\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Le seguenti sono domande a scelta multipla (con relative risposte).\n</code></pre></li> <li>Base prompt template:   <pre><code>Domanda: {text}\nScelte:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRisposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Domanda: {text}\nScelte:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nRispondete alla domanda precedente con 'a', 'b', 'c' o 'd' e nient'altro.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-it\n</code></pre>"},{"location":"datasets/italian/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/italian/#hellaswag-it","title":"HellaSwag-it","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,193 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"[header] Come pulire il tappeto stainmaster [title] Aspirare lo sporco. [step] In primo luogo, si pu\u00f2 rimuovere molta della sporcizia con un aspirapolvere. Poi, si possono affrontare le macchie rimanenti con sapone e acqua.\\nScelte:\\na. Quindi, iniziare a spolverare e aspirare. Non usare prodotti chimici aggressivi, come detergenti abrasivi, poich\u00e9 questi possono causare la formazione di muffe sul tappeto.\\nb. [substeps] Fai spolverare la superficie prima di aspirare. Puoi farlo con un panno in microfibra o una spazzola.\\nc. [title] Usare sapone e acqua sulla macchia. [step] Mescolare acqua e \u00bc di tazza (21 grammi) di sapone liquido in una bottiglia spray e poi spruzzare direttamente questa miscela sulla macchia.\\nd. Cerca fango o macchie nere che puoi pulire localmente. [substeps] Se il tuo tappeto stainmaster non \u00e8 pulito, potrebbe essere necessario pulirlo da un professionista.\",\n    \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"[header] Come sapere perch\u00e9 un bambino (sotto i 2 anni) sta piangendo [title] Ascolta il pianto forte, quasi un lamento. [step] Questo di solito significa \\\"ho dolore\\\" o \\\"sono malato\\\". Il bambino far\u00e0 una pausa, poi urler\u00e0 di nuovo e ripeter\u00e0 il processo.\\nScelte:\\na. Questo tipo di pianto \u00e8 di solito solo un segnale di avvertimento della fame. Un bambino pianger\u00e0 anche leggermente di pi\u00f9 se ha fame.\\nb. Questo pu\u00f2 essere molto sconvolgente da guardare, quindi fai venire un genitore ad aiutare il bambino. [substeps] Solo un genitore pu\u00f2 giudicare l'et\u00e0 del loro bambino.\\nc. Questo di solito finir\u00e0 dopo circa tre minuti. [title] Fai attenzione agli occhi chiusi del bambino.\\nd. \u00c8 persistente, penetrante e inequivocabile. Se senti questo pianto, vai immediatamente dal bambino.\",\n    \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Una donna mostra come asciugare la superficie del bancone e il lavandino dall'acqua schizzata dal rubinetto con un asciugamano di carta. una donna\\nScelte:\\na. mostra il suo metodo preparatorio meticoloso per il bancone e il pavimento sui quali applicher\u00e0 un asciugamano.\\nb. sta in cucina accanto al lavandino e parla alla telecamera.\\nc. impugna un asciugamano di carta e inizia a pulire una bevanda appoggiata sulla superficie del bancone e del lavandino.\\nd. sta di fronte ad un set di utensili sul bancone, prende un asciugacapelli con le sue parti accessorie fissate e sicure con una barra sul lavandino asciutto.\",\n    \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Le seguenti sono domande a scelta multipla (con relative risposte).\n</code></pre></li> <li>Base prompt template:   <pre><code>Domanda: {text}\nScelte:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRisposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Domanda: {text}\nScelte:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nRispondete alla domanda precedente con 'a', 'b', 'c' o 'd' e nient'altro.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-it\n</code></pre>"},{"location":"datasets/italian/#unofficial-goldenswag-it","title":"Unofficial: GoldenSwag-it","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Come sapere cosa indossare. Identificate la vostra tonalit\u00e0 di pelle. Ci sono molti termini usati per descrivere la tonalit\u00e0 della pelle, da quella chiara o scura, a quella pallida o olivastra. Il modo pi\u00f9 accurato per capire quali colori vi stanno bene \u00e8 capire il sottotono della vostra pelle.\\nScelte:\\na. Questa \u00e8 la chiave numero uno per identificare il colore della vostra pelle. Se avete un misto di pelle olivastra e sottotono caldo (come una pelle avorio), il vostro tono di pelle \u00e8 probabilmente a met\u00e0 tra il caldo e il freddo.\\nb. Se avete una corporatura media o calda, in genere avete sottotoni evidenti. Ecco alcuni sottotoni comuni: la pelle calda e i sottotoni caldi comprendono tutti e tre i toni medi, tutti e tre i toni freddi, tutti e quattro i toni caldi e tutti e quattro i toni caldi.\\nc. La vostra pelle sar\u00e0 del colore delle vostre spalle, dal collo alle dita, alle unghie dei piedi. Il sottotono \u00e8 un colore di base per il vostro aspetto generale, come espressione primaria della vostra carnagione.\\nd. Ne esistono tre tipi: caldo, freddo e neutro. Poich\u00e9 si cercano i sottotoni della pelle, non basta guardarsi allo specchio per averne conferma.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Come fare la treccia. Spazzolare i capelli. Spazzolate i capelli in modo che siano leggeri e soffici. Dovete eliminare tutti i nodi in modo che la treccia sia liscia come la seta! Questa operazione facilita anche il processo di intreccio, quindi assicuratevi di farlo.\\nScelte:\\na. Prendete tre o quattro pollici (da 5 a 10 cm) di capelli dalla nuca, pettinateli e metteteli in un porta-treccia. Legateli e rimetteteli nel supporto.\\nb. Se i capelli sono molto aggrovigliati, potrebbero gocciolare e potreste non riuscire a intrecciarli in modo cos\u00ec ordinato! Avvolgere i capelli. Con i capelli raccolti in rulli, arricciateli intorno al dito in modo che tutti i rulli siano infilati.\\nc. Decidete dove fare la treccia. Sar\u00e0 dietro la testa in una coda di cavallo? Sar\u00e0 laterale o pi\u00f9 bassa, vicino al collo? Decidete questo per determinare dove e come sar\u00e0 pi\u00f9 bella.\\nd. Inumidite i capelli e scompigliateli delicatamente con le dita, in modo da ottenere un risultato bello e soffice. Probabilmente sar\u00e0 facile separarli tirandoli un po', ma fate attenzione a non farlo.\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Come mettere la carta velina in un sacchetto regalo. Raccogliete i materiali. Avrete bisogno di carta velina, del regalo, di nastri o abbellimenti, di un sacchetto regalo e di un biglietto. Avrete bisogno di diversi colori di carta velina che si abbinino al colore del sacchetto regalo.\\nScelte:\\na. Acquistate o realizzate un sacchetto di carta velina bianco o crema in un negozio di artigianato. La carta velina vi dar\u00e0 un colore rosa pastello e si completer\u00e0 con il colore del sacchetto regalo.\\nb. La carta velina colorata rende il regalo pi\u00f9 festoso! Assicuratevi che il vostro sacchetto regalo sia adatto all'occasione. Se avete intenzione di arricciare il nastro per aggiungerlo come decorazione, avrete bisogno di forbici per arricciare il nastro o di un nastro gi\u00e0 arricciato.\\nc. Potreste aver bisogno di andare in un negozio di antiquariato o in un negozio dell'usato per trovare tutti i colori che vi servono. Considerate la possibilit\u00e0 di utilizzare diversi colori per il biglietto, tra cui carta commestibile, carta da regalo o carta da costruzione.\\nd. Potete utilizzare carta di scarto, carta in rotoli, carta riciclata o carta da costruzione. Prendete un pezzo di carta velina, di carta igienica o di qualsiasi altro foglio di carta colorata.\",\n  \"label\": \"b\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Le seguenti sono domande a scelta multipla (con relative risposte).\n</code></pre></li> <li>Base prompt template:   <pre><code>Domanda: {text}\nScelte:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRisposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Domanda: {text}\nScelte:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nRispondete alla domanda precedente con 'a', 'b', 'c' o 'd' e nient'altro.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-it\n</code></pre>"},{"location":"datasets/italian/#summarization","title":"Summarization","text":""},{"location":"datasets/italian/#ilpost-sum","title":"IlPost-Sum","text":"<p>This dataset was published in this paper and consists of news articles from Il Post. The summaries were written by the journalists themselves (the \"target\" field in the original dataset).</p> <p>The original dataset consists of 35,201 / 4,400 / 4,400 samples for training, validation and testing, respectively. We use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively. All our splits are subsets of the original ones.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Mai come nel 2013 abbiamo riflettuto sulla quantit\u00e0 di dati e informazioni su ciascuno di noi che nel corso degli anni hanno immagazzinato le grandi societ\u00e0 di Internet. Ne eravamo consapevoli anche prima, ma soprattutto in seguito alle rivelazioni sui sistemi usati dalla National Security Agency statunitense per spiare le attivit\u00e0 di centinaia di milioni di persone in giro per il mondo abbiamo iniziato a farci qualche domanda in pi\u00f9 su che fine facciano le email, le foto e gli aggiornamenti sui social network quando li carichiamo online. Sappiamo meglio di prima che tutte queste cose vengono consegnate alla rete \u201cper sempre\u201d e che continueranno a esistere su qualche server, anche se faremo clic sull\u2019icona di un cestino o su un tasto rosso con scritto sopra \u201cCancella\u201d. E forse proprio per questo motivo, in molti iniziano a provare sollievo nell\u2019avere a disposizione servizi e applicazioni che fanno l\u2019esatto contrario: che rendono effimera e del tutto temporanea l\u2019esistenza di qualcosa di nostro online. Come spiega Farhad Manjoo sul Wall Street Journal, la cosa pi\u00f9 rilevante in campo tecnologico nel 2013 \u00e8 stata probabilmente Snapchat, un\u2019applicazione basata su comunicazioni temporanee. In pochi anni ha ottenuto un successo considerevole, soprattutto negli Stati Uniti, attirando l\u2019attenzione di alcune grandi societ\u00e0 come Facebook e Google che si dice abbiano offerto diversi miliardi di dollari per acquisirla. Le offerte sono state fin qui rifiutate da quelli di Snapchat, che per ora sembrano essere solo interessati a migliorare e rendere ancora pi\u00f9 diffusa la loro applicazione.\",\n  \"target_text\": \"Snapchat e l\u2019Internet \u201ctemporanea\u201d. Come funziona \u2013 e cosa implica, per gli utenti \u2013 la popolare applicazione per mandarsi messaggi e foto che spariscono dopo pochi secondi, contesa a colpi di offerte miliardarie.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Con trovata da entertainer, nel suo discorso da sconfitto al ballottaggio delle primarie del centrosinistra, Matteo Renzi ha citato Bersani, \u201cma non Pierluigi, Samuele\u201d. \u00e8 sempre bellissima la cicatrice che mi ricorder\u00e0 di esser stato felice\",\n  \"target_text\": \"Pesce d\u2019aprile, Samuele Bersani. La canzone citata da Matteo Renzi nel suo \\\"concession speech\\\".\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Questa mattina i carabinieri hanno arrestato pi\u00f9 di 50 persone accusate di essere a capo o affiliate al clan mafioso D\u2019Abramo-Sforza. Gli arresti sono avvenuti a Bari, Altamura (Bari), Foggia, Cerignola (Foggia), Matera, Lecce e Roma. Le accuse contro gli arrestati sono di associazione armata di tipo mafioso, detenzione e porto d\u2019armi anche da guerra, traffico di sostanze stupefacenti, omicidio, tentato omicidio, estorsione, turbativa d\u2019asta. L\u2019operazione \u00e8 stata disposta dal gip di Bari su richiesta della Direzione distrettuale antimafia; le indagini sono state condotte dal nucleo investigativo del Comando provinciale Carabinieri di Bari.\",\n  \"target_text\": \"Sono state arrestate pi\u00f9 di 50 persone accusate di far parte del clan mafioso D\u2019Abramo-Sforza.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Di seguito sono riportati gli articoli con i relativi riassunti.\n</code></pre></li> <li>Base prompt template:   <pre><code>Articolo di cronaca: {text}\nSintesi: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Articolo di cronaca: {text}\n\nScrivete un riassunto dell'articolo sopra citato.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset ilpost-sum\n</code></pre>"},{"location":"datasets/latvian/","title":"\ud83c\uddf1\ud83c\uddfb Latvian","text":"<p>This is an overview of all the datasets used in the Latvian part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/latvian/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/latvian/#latvian-twitter-sentiment","title":"Latvian Twitter Sentiment","text":"<p>This dataset was published in this paper and consists of sentiment-annotated Latvian tweets from the food and drinks domain, collected over an 8-year period.</p> <p>The original dataset contains 5,059 / 743 samples for the training and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. Our test split includes all 743 original test samples plus 1,305 additional samples drawn from the original training data to reach 2,048 total test samples. Both the validation split and final training split are sampled exclusively from the original training data.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"@ChiuljuPussala @nahimovs Tu \u0113d savus konservat\u012bvos draugus?\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"@komako66 @elitaveidemane N\u0113. Nav. Vi\u0146am ir \u0113tisks pien\u0101kums \u0113st sardeli iepriek\u0161\u0113j\u0101 ieslodz\u012bjuma vietn\u0113, saukt\u0101 \\\"sept\u012bt\u0101s Debesis\\\". Bez matra\u010da. Ar pl\u0101nu sedzi\u0146u.\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"@selmuushh @GMeluskans Es k\u0101du laiku ga\u013cu \u0113du \u013coti reti, bet no \u0161\u012b gada s\u0101kuma p\u0101rst\u0101ju \u0113st pavisam. Labpr\u0101t pam\u0113\u0123in\u0101tu soj\u0161liku.\",\n  \"label\": \"positive\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>T\u0101l\u0101k ir dokumenti un to noska\u0146ojums, kas var b\u016bt 'pozit\u012bvs', 'neitr\u0101ls' vai 'negat\u012bvs'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Dokuments: {text}\nNoska\u0146ojums: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Dokuments: {text}\n\nKlasific\u0113jiet noska\u0146ojumu dokument\u0101. Atbildiet ar 'pozit\u012bvs', 'neitr\u0101ls' vai 'negat\u012bvs', un neko citu.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>pozit\u012bvs</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neitr\u0101ls</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negat\u012bvs</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset latvian-twitter-sentiment\n</code></pre>"},{"location":"datasets/latvian/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/latvian/#fullstack-ner-lv","title":"FullStack-NER-lv","text":"<p>This dataset was published in this paper and is part of a multilayered syntactically and semantically annotated text corpus for Latvian. The corpus text sources include approximately 60% news, 20% fiction, 10% legal texts, 5% spoken language transcripts, and 5% miscellaneous content from a balanced 10-million-word corpus.</p> <p>The original full dataset consists of 11,425 samples. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"tokens\": array([\"'\", \"T\u0113rvetes\", \"AL\", \"'\", \"re\u0123istr\u0113ts\", \"2012.\", \"gad\u0101\", \"Kro\u0146auc\u0113\", \",\", \"p\u0101r\u0146emot\", \"\u0161o\", \"biznesu\", \"no\", \"AS\", \"'\", \"Agrofirma\", \"T\u0113rvete\", \"'\", \"ar\", \"m\u0113r\u0137i\", \"moderniz\u0113t\", \"ra\u017eo\u0161anu\", \",\", \"ieguldot\", \"att\u012bst\u012bb\u0101\", \"vair\u0101k\", \"nek\u0101\", \"piecus\", \"miljonus\", \"eiro\", \".\"], dtype=object),\n    \"labels\": [\"B-ORG\", \"I-ORG\", \"I-ORG\", \"I-ORG\", \"O\", \"B-MISC\", \"I-MISC\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"I-ORG\", \"I-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n}\n</code></pre> <pre><code>{\n    \"tokens\": array([\"Lieldienas\", \"aktrise\", \"Torija\", \"Spelinga\", \"pavad\u012bja\", \"kop\u0101\", \"ar\", \"\u0123imeni\", \"\u0136\u012bnie\u0161u\", \"restor\u0101n\u0101\", \",\", \"sv\u0113tki\", \"tika\", \"izboj\u0101ti\", \"mirkl\u012b\", \",\", \"kad\", \"vi\u0146a\", \"darbinieku\", \"nev\u012b\u017e\u012bbas\", \"d\u0113\u013c\", \"pasl\u012bd\u0113ja\", \"un\", \"iekrita\", \"gril\u0101\", \".\"], dtype=object),\n    \"labels\": [\"B-MISC\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"],\n}\n</code></pre> <pre><code>{\n    \"tokens\": array([\"Mani\", \"pamodin\u0101jis\", \"Patr\u012bcijas\", \"zvans\", \".\"], dtype=object),\n    \"labels\": [\"O\", \"O\", \"B-PER\", \"O\", \"O\"],\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>T\u0101l\u0101k ir teikumi un JSON v\u0101rdn\u012bcas ar nosauktajiem objektiem, kas par\u0101d\u0101s dotaj\u0101 teikum\u0101.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teikums: {text}\nNosauktie objekti: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teikums: {text}\n\nIdentific\u0113jiet nosauktos objektus teikum\u0101. Jums j\u0101izvada \u0161\u012b inform\u0101cija k\u0101 JSON v\u0101rdn\u012bcu ar atsl\u0113g\u0101m 'persona', 'vieta', 'organiz\u0101cija' un 'da\u017e\u0101di'. V\u0113rt\u012bb\u0101m j\u0101b\u016bt \u0161\u012b tipa nosaukto objektu sarakstiem, tie\u0161i t\u0101, k\u0101 tie par\u0101d\u0101s teikum\u0101.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>vieta</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>vieta</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organiz\u0101cija</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organiz\u0101cija</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>da\u017e\u0101di</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>da\u017e\u0101di</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset fullstack-ner-lv\n</code></pre>"},{"location":"datasets/latvian/#unofficial-wikiann-lv","title":"Unofficial: WikiANN-lv","text":"<p>This dataset was published in this paper and is part of a cross-lingual named entity recognition framework for 282 languages from Wikipedia. It uses silver-standard annotations transferred from English through cross-lingual links and performs both name tagging and linking to an english Knowledge Base.</p> <p>The original full dataset consists of 10,000 / 10,000 / 10,000 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"tokens\": array([\"Iez\u012bm\u0113\", \"robe\u017eu\", \"starp\", \"Greiema\", \"Zemi\", \"zieme\u013cos\", \"un\",\n       \"P\u0101lmera\", \"Zemi\", \"Antarkt\u012bdas\", \"pussalas\", \"dienvidos\", \",\",\n       \"k\u0101\", \"ar\u012b\", \"starp\", \"Falj\u0113ra\", \"krastu\", \"zieme\u013cos\", \"un\",\n       \"Raimila\", \"krastu\", \"dienvidos\", \".\"], dtype=object),\n       \"labels\": [\"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"B-LOC\", \"I-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\", \"O\"]\n}\n</code></pre> <pre><code>{\n    \"tokens\": array([\"'\", \"''\", \"x-\", \"''\", \"Detroitas\", \"``\", \"Pistons\", \"''\"],\n      dtype=object),\n      \"labels\": [\"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"I-ORG\", \"I-ORG\"]\n}\n</code></pre> <pre><code>{\n    \"tokens\": array([\"K\u0101rlis\", \"Gustavs\", \"J\u0113kabs\", \"Jakobi\"], dtype=object),\n    \"labels\": [\"B-PER\", \"I-PER\", \"I-PER\", \"I-PER\"]\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>T\u0101l\u0101k ir teikumi un JSON v\u0101rdn\u012bcas ar nosauktajiem objektiem, kas par\u0101d\u0101s dotaj\u0101 teikum\u0101.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teikums: {text}\nNosauktie objekti: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teikums: {text}\n\nIdentific\u0113jiet nosauktos objektus teikum\u0101. Jums j\u0101izvada \u0161\u012b inform\u0101cija k\u0101 JSON v\u0101rdn\u012bcu ar atsl\u0113g\u0101m 'persona', 'vieta', 'organiz\u0101cija' un 'da\u017e\u0101di'. V\u0113rt\u012bb\u0101m j\u0101b\u016bt \u0161\u012b tipa nosaukto objektu sarakstiem, tie\u0161i t\u0101, k\u0101 tie par\u0101d\u0101s teikum\u0101.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>vieta</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>vieta</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organiz\u0101cija</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organiz\u0101cija</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>da\u017e\u0101di</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>da\u017e\u0101di</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset wikiann-lv\n</code></pre>"},{"location":"datasets/latvian/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/latvian/#scala-lv","title":"ScaLA-lv","text":"<p>This dataset was published in this paper and was automatically created from the Latvian Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original full dataset consists of 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"Gult\u0101 vi\u0146am nav j\u0101dara piln\u012bgi nekas, lai es non\u0101ktu l\u012bdz orgasmam.\",\n    \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Ar savu puiku, kur\u0161 parasts.\",\n    \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"1992. v\u0113l gad\u0101 Latvij\u0101 atrad\u0101s no 50 000 l\u012bdz 80 000 padomju milit\u0101rpersonu.\",\n    \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>\u0160ie ir teikumi un to gramatiskie pareizumi.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teikums: {text}\nGramatiski pareizs: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teikums: {text}\n\nNoteiciet, vai teikums ir gramatiski pareizs vai n\u0113. Atbildiet ar 'j\u0101', ja teikums ir pareizs, un 'n\u0113', ja tas nav.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>j\u0101</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>n\u0113</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-lv\n</code></pre>"},{"location":"datasets/latvian/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/latvian/#multiwikiqa-lv","title":"MultiWikiQA-lv","text":"<p>This dataset will be published in an upcoming paper, and contains Latvian Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro. The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Zvjahe\u013ca (, l\u012bdz 2022. gadam \u2014 Novohrada-Volinska) ir pils\u0113ta Ukrainas zieme\u013crietumos, \u017ditomiras apgabala rietumos, Slu\u010das upes krast\u0101. T\u0101 ir Zvjahe\u013cas rajona administrat\u012bvais centrs. Att\u0101lums l\u012bdz apgabala centram \u017ditomirai ir .\\n\\nZvjahe\u013ca ir ukrai\u0146u tautas dzejnieces Lesjas Ukrainkas dzimt\u0101 pils\u0113ta.\\n\u0160eit ir dzimis Ukrainas armijas virspav\u0113lnieks \u0123ener\u0101lis Valerijs Zalu\u017enijs.\\n\\nV\u0113sture \\nV\u0113stures avtos apdz\u012bvot\u0101 vieta pirmoreiz min\u0113ta 1256. gad\u0101 Slu\u010das labaj\u0101 krast\u0101 k\u0101 Vozvjahe\u013ca (\u0412\u043e\u0437\u0432\u044f\u0433\u0435\u043b\u044c) Gal\u012bcijas-Vol\u012bnijas hronik\u0101. Gadu v\u0113l\u0101k to par nepaklaus\u012bbu nodedzin\u0101ja Gal\u012bcijas karalis Danila. N\u0101kamo reizi apdz\u012bvot\u0101 vieta min\u0113ta 1432. gad\u0101 jau Slu\u010das kreisaj\u0101 krast\u0101 k\u0101 Vzvjaho\u013cas (\u0412\u0437\u0432\u044f\u0433\u043e\u043b\u044c) miests, bet 1499. gad\u0101\\xa0\u2014 Zvjaho\u013ca (\u0417\u0432\u044f\u0433\u043e\u043b\u044c). 1507. gad\u0101 miests ieguva ties\u012bbas b\u016bv\u0113t pili un veidot pils\u0113tu. P\u0113c \u013bub\u013cinas \u016bnijas 1569. gad\u0101 miests saukts par Zvjahe\u013cu (\u0417\u0432\u044f\u0433\u0435\u043b\u044c, ).\\n\\n1793. gad\u0101 Zvjahe\u013ca non\u0101ca Krievijas Imp\u0113rijas sast\u0101v\u0101. 1795. gad\u0101 miests ieguva Novohradas-Volinskas nosaukumu un pils\u0113tas ties\u012bbas, un k\u013cuva par jaunizveidot\u0101s Vol\u012bnijas guber\u0146as centru (l\u012bdz 1804. gadam).\\n\\n2022. gada 16. j\u016bnij\u0101 Novohradas-Volinskas domes deput\u0101ti nobalsoja par pils\u0113tas p\u0101rd\u0113v\u0113\u0161anu t\u0101s v\u0113sturiskaj\u0101 nosaukum\u0101 \u2014 Zvjahe\u013ca. V\u0113l\u0101k \u0161o l\u0113mumu apstiprin\u0101ja \u017ditomiras apgabala dome. Ar Ukrainas Augst\u0101k\u0101s Radas dekr\u0113tu 2022. gada 16. novembr\u012b pils\u0113ta tika p\u0101rd\u0113v\u0113ta par Zvjahe\u013cu.\\n\\nAtsauces\\n\\n\u0100r\u0113j\u0101s saites\",\n    \"question\": \"K\u0101ds Ukrainas bru\u0146oto sp\u0113ku komandieris n\u0101k no Zvjahe\u013cas?\",\n    \"answers\": {\n        \"answer_start\": array([349]),\n        \"text\": array([\"\u0123ener\u0101lis Valerijs Zalu\u017enijs\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Bogota (), saukta ar\u012b Santafe de Bogota (Santa Fe de Bogot\u00e1), ir pils\u0113ta Kolumbijas centr\u0101laj\u0101 da\u013c\u0101, 2640 metri virs j\u016bras l\u012bme\u0146a. Kolumbijas galvaspils\u0113ta, galvenais valsts politiskais, ekonomiskais un kult\u016bras centrs. Kaut ar\u012b pils\u0113ta atrodas tropiskaj\u0101 josl\u0101, augstkalnu apst\u0101k\u013cu d\u0113\u013c pils\u0113t\u0101 nav karsts (vid\u0113j\u0101 gaisa temperat\u016bra visu gadu - apm\u0113ram +15 gr\u0101di).\\n\\nV\u0113sture \\n\\nPirms konkistadoru iera\u0161an\u0101s Bogotas viet\u0101 bija \u010dib\u010du indi\u0101\u0146u galvenais centrs, kuru sauca par Bakatu (Bacat\u00e1).\\n\\nM\u016bsdienu pils\u0113tu nodibin\u0101ja konkistadors Gonsalo Himeness de Kvesada (Gonzalo Jim\u00e9nez de Quesada) 1538. gad\u0101.\\n\\n1718. gad\u0101 Bogota k\u013cuva par sp\u0101\u0146u Jaun\u0101s Gran\u0101das vicekaralistes (Virreinato de Nueva Granada) centru.\\n\\n1810. gad\u0101 iedz\u012bvot\u0101ji sac\u0113l\u0101s pret sp\u0101\u0146u varu, tom\u0113r sacel\u0161an\u0101s tika apspiesta. 1819. gad\u0101 Bogotu ie\u0146\u0113ma Simona Boliv\u0101ra karasp\u0113ks.\\n\\n1819. gad\u0101 vicekaraliste ieguva neatkar\u012bbu no Sp\u0101nijas un Bogota k\u013cuva par Lielkolumbijas (Gran Colombia) galvaspils\u0113tu. Tom\u0113r 1830. gad\u0101 Lielkolumbija sabruka un izveidoj\u0101s Jaun\u0101 Gran\u0101da (m\u016bsdienu Kolumbija), Ekvadora un Venecu\u0113la. 1903. gad\u0101 ar ASV atbalstu pret sol\u012bjumiem at\u013caut b\u016bv\u0113t Panamas kan\u0101lu, neatkar\u012bbu no Kolumbijas ieguva Panama.\\n\\n1948. gad\u0101 Bogot\u0101 tika nogalin\u0101ts popul\u0101rais kolumbie\u0161u polti\u0137is Horhe Gaitans. Pils\u0113t\u0101 izc\u0113l\u0101s pla\u0161i nemieri un ielu kaujas. S\u0101k\u0101s politisk\u0101s nestabilit\u0101tes periods (La Violencia), kur\u0161 turpin\u0101j\u0101s 10 gadus, g\u0101ja boj\u0101 no 180 000 l\u012bdz 300 000 kolumbie\u0161u.\\n\\nCilv\u0113ki \\n\\nBogot\u0101 dzimu\u0161i:\\n\\n Egans Bernals (Egan Bernal, 1997) \u2014 rite\u0146brauc\u0113js;\\n Ingr\u012bda Betank\u016bra (\u00cdngrid Betancourt, 1961) \u2014 politi\u0137e;\\n Huans Pablo Montoija (Juan Pablo Montoya, 1975) \u2014 Formula 1 pilots;\\n Katalina Sandino Moreno (Catalina Sandino Moreno, 1981) \u2014 aktrise;\\n Kamilo Toress Restrepo (Camilo Torres Restrepo, 1929-1966) \u2014 revolucion\u0101rs.\\n\\n\u0100r\u0113j\u0101s saites \\n\\nDienvidamerikas galvaspils\u0113tas\\nKolumbijas pils\u0113tas\",\n    \"question\": \"Kad Bogata tika iecelta par Jaun\u0101s Gran\u0101das vicekaralistes centru Sp\u0101nijas pak\u013caut\u012bb\u0101?\",\n    \"answers\": {\n        \"answer_start\": array([599]),\n        \"text\": array([\"1718. gad\u0101\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"D\u017eastins \u0160ulcs (; dzimis ) ir kan\u0101die\u0161u hokejists, aizsargs. Pa\u0161laik (2020) \u0160ulcs sp\u0113l\u0113 Nacion\u0101l\u0101s hokeja l\u012bgas kluba Va\u0161ingtonas \"Capitals\" sast\u0101v\u0101.\\n\\nSp\u0113l\u0113t\u0101ja karjera \\nP\u0113c vair\u0101k\u0101m NCAA \u010dempion\u0101t\u0101 aizvad\u012bt\u0101m sezon\u0101m, profesion\u0101\u013ca karjeru \u0160ulcs s\u0101ka 2012.\u201413. gada sezon\u0101, taj\u0101 sp\u0113les laiku dalot starp NHL klubu Edmontonas \"Oilers\" un AHL vien\u012bbu Oklahomsitijas \"Barons\". \"Oilers\" \u0160ulcs aizvad\u012bja 48 sp\u0113les, savuk\u0101rt AHL k\u013cuva par l\u012bgas rezultat\u012bv\u0101ko aizsargu, tiekot atz\u012bts ar\u012b par l\u012bgas lab\u0101ko aizsargu. 2013.\u201414. gada sezonu \u0160ulcs jau piln\u012bb\u0101 aizvad\u012bja \"Oilers\" sast\u0101v\u0101.\\n\\nP\u0113c neveiksm\u012bga 2015.\u201416. gada sezonas ievada \u0160ulcs tika aizmain\u012bts uz Pitsburgas \"Penguins\". T\u0101s sast\u0101v\u0101 2016. un 2017. gad\u0101 vi\u0146\u0161 izc\u012bn\u012bja Stenlija kausu. \"Penguins\" sast\u0101v\u0101 sp\u0113l\u0113ja l\u012bdz 2020. gadam, kad pievienoj\u0101s Va\u0161ingtonas \"Capitals\".\\n\\n\u0100r\u0113j\u0101s saites \\n\\n1990. gad\u0101 dzimu\u0161ie\\nKan\u0101das hokejisti\\nEdmontonas \"Oilers\" sp\u0113l\u0113t\u0101ji\\nPitsburgas \"Penguins\" sp\u0113l\u0113t\u0101ji\\nVa\u0161ingtonas \"Capitals\" sp\u0113l\u0113t\u0101ji\\nStenlija kausa ieguv\u0113ji\\nBritu Kolumbij\u0101 dzimu\u0161ie\",\n    \"question\": \"Kad D\u017eastins \u0160ulcs uzs\u0101ka savu profesion\u0101lo karjeru?\",\n    \"answers\": {\n        \"answer_start\": array([251]),\n        \"text\": array([\"2012.\u201413. gada sezon\u0101\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Turpm\u0101k seko teksti ar atbilsto\u0161iem jaut\u0101jumiem un atbild\u0113m.\n</code></pre></li> <li>Base prompt template:   <pre><code>Teksts: {text}\nJaut\u0101jums: {question}\nAtbild\u0113t ar maksim\u0101li 3 v\u0101rdiem:\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Teksts: {text}\n\nAtbildiet uz \u0161o jaut\u0101jumu par iepriek\u0161 min\u0113to tekstu ar maksim\u0101li 3 v\u0101rdiem.\n\nJaut\u0101jums: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-lv\n</code></pre>"},{"location":"datasets/latvian/#knowledge","title":"Knowledge","text":""},{"location":"datasets/latvian/#mmlu-lv","title":"MMLU-lv","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Latvian was done by the Latvian Language Technology Initiative and is available in the VTI-Data repository.</p> <p>The full Latvian MMLU dataset consists of 13,941 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Atrodiet skaitli, kas padara apgalvojumu patiesu: 48 m = lodzi\u0146\u0161 mm.\\nIzv\u0113les:\\na. 48,000\\nb. 480\\nc. 4,800\\nd. 5\",\n  \"label\": \"a\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Darbinieks sagaida liel\u0101ku konsekvenci sava priek\u0161nieka uzved\u012bb\u0101, nek\u0101 tas ir pamatoti. Kur\u0161 no \u0161iem faktoriem vislab\u0101k izskaidro darbinieka gaidas?\\nIzv\u0113les:\\na. p\u0101rm\u0113r\u012bgas attaisno\u0161anas hipot\u0113ze\\nb. pa\u0161labuma aizspriedumain\u012bba\\nc. fundament\u0101lais atrib\u016bcijas aizspriedums\\nd. pa\u0161p\u0101rbaudes teorija\",\n  \"label\": \"c\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Kur\u0101 no \u0161iem diviem scen\u0101rijiem galvenais varonis (kur\u0161 lieto es/j\u0113/man) dara kaut ko, kas ir ac\u012bmredzami mor\u0101li nepareizs, saska\u0146\u0101 ar parastaj\u0101m mor\u0101les norm\u0101m ASV no 2020. gada? scen\u0101rijs | Es atsl\u0113dzu automa\u0161\u012bnas kru\u012bza kontroli. scen\u0101rijs | Es izsaucu policiju savam biju\u0161ajam m\u012b\u013cotajam, jo vi\u0146\u0161 mani piek\u0101va.\\nIzv\u0113les:\\na. Nepareizi, nepareizi\\nb. Nepareizi, nav nepareizi\\nc. Nav nepareizi, nepareizi\\nd. Nav nepareizi, nav nepareizi\",\n  \"label\": \"d\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>T\u0101l\u0101k seko jaut\u0101jumi ar vair\u0101k\u0101m atbil\u017eu izv\u0113l\u0113m (ar atbild\u0113m).\n</code></pre></li> <li>Base prompt template:   <pre><code>Jaut\u0101jums: {text}\nIzv\u0113les:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nAtbilde: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Jaut\u0101jums: {text}\nIzv\u0113les:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nAtbildiet uz iepriek\u0161\u0113jo jaut\u0101jumu, atbildot ar 'a', 'b', 'c' vai 'd', un nekas cits.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-lv\n</code></pre>"},{"location":"datasets/latvian/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/latvian/#copa-lv","title":"COPA-lv","text":"<p>This dataset was published in this paper and is a translated version of the English COPA dataset, which was created from scratch by the authors. The dataset was machine translated using the Tilde Translation service, and the test samples were manually post-edited.</p> <p>The original full dataset consists of 214 / 57 / 132 samples, and we keep the splits as-is.</p> <p>Here are a few examples from the training split (which have not been post-edited):</p> <p><pre><code>{\n  \"text\": \"\u012arnieki tika izlikti no dz\u012bvok\u013ca.\\nIzv\u0113les:\\na. Vi\u0146i savu \u012bri nemaks\u0101ja.\\nb. Vi\u0146i saprat\u0101s ar savu saimnieku.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Sve\u0161inieks man sve\u0161valod\u0101 kliedza.\\nIzv\u0113les:\\na. ES truli blenzu uz vi\u0146u.\\nb. ES apst\u0101jos, lai pap\u013c\u0101p\u0101tu ar vi\u0146u.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Pagriezu gaismas sl\u0113dzi uz aug\u0161u un uz leju.\\nIzv\u0113les:\\na. Gaisma izdzisa.\\nb. Gaisma mirgoja.\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>T\u0101l\u0101k seko jaut\u0101jumi ar vair\u0101k\u0101m atbil\u017eu izv\u0113l\u0113m (ar atbild\u0113m).\n</code></pre></li> <li>Base prompt template:   <pre><code>Jaut\u0101jums: {text}\nIzv\u0113les:\na. {option_a}\nb. {option_b}\nAtbilde: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Jaut\u0101jums: {text}\nIzv\u0113les:\na. {option_a}\nb. {option_b}\n\nAtbildiet uz iepriek\u0161\u0113jo jaut\u0101jumu, atbildot ar 'a' vai 'b', un nekas cits.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset copa-lv\n</code></pre>"},{"location":"datasets/latvian/#summarisation","title":"Summarisation","text":""},{"location":"datasets/latvian/#lsm","title":"LSM","text":"<p>This dataset contains news articles and their corresponding summaries from the Latvian public media news portal LSM.lv.</p> <p>Samples were collected using the lsm_scraper. We use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"FOTO: Raimonda Paula un El\u012bnas Garan\u010das satik\u0161an\u0101s koncert\u0101 \u00abJa tevis neb\u016btu...\u00bb\\n\\nIdeja svin\u0113t apa\u013co jubileju uz vienas skatuves ar izcilo operdzied\u0101t\u0101ju El\u012bnu Garan\u010du Maestro radusies, kop\u0101 uzst\u0101joties jau pirms pieciem gadiem. Maestro nesl\u0113pj gandar\u012bjumu, ka pand\u0113mijas d\u0113\u013c p\u0101rceltais koncerts beidzot notiks. Raimonds Pauls koncertprogramm\u0101 \u201cJa tevis neb\u016btu...\u201d dzied\u0101t\u0101jai velt\u012bjis divus jaunus dziesmu ciklus ar kop\u012bgi atlas\u012btu Vizmas Bel\u0161evicas un Oj\u0101ra V\u0101cie\u0161a dzeju. Savuk\u0101rt koncerta otraj\u0101 da\u013c\u0101 iek\u013cautas Paula dziesmas no kinofilm\u0101m un te\u0101tra izr\u0101d\u0113m. Kameror\u0137estra \u201cSimfonietta R\u012bga\u201d pavad\u012bjum\u0101 popul\u0101ras melodijas at\u0161\u0137ir\u012bg\u0101s noska\u0146\u0101s izskan\u0113s jaunos aran\u017e\u0113jumos, ko veidoju\u0161i t\u0101di izcili komponisti k\u0101 Lolita Ritmane, Rihards Dubra, J\u0113kabs Jan\u010devskis un Raimonds Macats. \u201cMan \u0161\u012b otr\u0101 da\u013ca ar kino un te\u0101tra m\u016bziku ir t\u0101ds sapnis, kas ir piepild\u012bjies. Jo \u0161is \u017eanrs mani vienm\u0113r ir \u013coti interes\u0113jis. Var\u0113tu teikt, ka es operas \u017eanr\u0101 esmu nok\u013cuvusi faktiski nejau\u0161i, jo sirds aicin\u0101jums no pa\u0161a s\u0101kuma bija tie\u0161i te\u0101tris,\u201d atkl\u0101j El\u012bna Garan\u010da. Oj\u0101rs Rubenis atz\u012bst: \u201cEs varu tikai apbr\u012bnot gan Maestro 85 gados \u2013 iztur\u012bbu un to darbu, ko vi\u0146\u0161 var izdar\u012bt. Un, protams, ar\u012b El\u012bnu Garan\u010du, kura vienk\u0101r\u0161i ir apbr\u012bnojama sav\u0101 neambiciozit\u0101t\u0113 pret visu p\u0101r\u0113jo un ambiciozit\u0101t\u0113 pret m\u0101kslu. Tas ir tas lielm\u0101kslinieku kods!\u201d Maestro un El\u012bnas Garan\u010das atkalsatik\u0161an\u0101s Nacion\u0101laj\u0101 te\u0101tr\u012b b\u016bs skat\u0101ma piektdien un sestdien, savuk\u0101rt Latvijas Telev\u012bzij\u0101 \u0161o koncertu var\u0113s v\u0113rot \u0161\u012b gada ruden\u012b.\",\n  \"target_text\": \"Vi\u0146iem bija iecer\u0113ts tikties jau \u0161\u012b gada s\u0101kum\u0101, bet pand\u0113mijas d\u0113\u013c Raimonda Paula 85. jubilejai velt\u012btais koncerts ar pasaulslaven\u0101s operdzied\u0101t\u0101jas El\u012bnas Garan\u010das piedal\u012b\u0161anos tika p\u0101rcelts. \u0160aj\u0101 ned\u0113\u013cas nogal\u0113 Nacion\u0101lo te\u0101tri beidzot pieskandin\u0101s abu izcilo m\u016bzikas person\u012bbu atkalsatik\u0161an\u0101s ar skat\u012bt\u0101jiem koncert\u0101 \u201cJa tevis neb\u016btu...\u201d.\"\n}\n</code></pre> <pre><code>{\n\"text\": \"Ukrain\u0101 t\u016bksto\u0161iem cilv\u0113ku protest\u0113 pret korupcijas apkarot\u0101ju v\u0101jin\u0101\u0161anu; Zelenskis sola jaunu likumu\\n\\nCilv\u0113ki pau\u017e neapmierin\u0101t\u012bbu par\\xa0korupcijas apkarot\u0101ju v\u0101jin\u0101\u0161anu Tre\u0161dienas vakar\u0101 Kijiv\u0101\\xa0bija pilns\\xa0Ivana Franka laukums, kas ir tuv\u0101k\u0101 vieta pie prezidenta Volodimira Zelenska darba vietas, kur var br\u012bvi piek\u013c\u016bt cilv\u0113ki. P\u0101rsvar\u0101 gados jauni cilv\u0113ki bija san\u0101ku\u0161i, lai paustu protestu, no\u017e\u0113lu un neapmierin\u0101t\u012bbu ar Augst\u0101k\u0101s Radas pie\u0146emto likumprojektu, kas paredz atcelt Ukrainas Korupcijas apkaro\u0161anas biroja un specializ\u0113t\u0101s pretkorupcijas prokurat\u016bras neatkar\u012bbu, iest\u0101\u017eu p\u0101rraudz\u012bbu nododot \u0123ener\u0101lprokuroram, kas ir politiski izraudz\u012bts. Cilv\u0113ki skand\u0113ja visda\u017e\u0101d\u0101kos sauk\u013cus \u2013 ar\u012b \\\"Rokas nost no NABU!\\\", \\\"Neklus\u0113!\\\", \\\"Kauns!\\\", \\\"Slava Ukrainai!\\\", \\\"Varo\u0146iem slava!\\\" un daudzus citus. T\u0101 k\u0101 pamat\u0101 tie bija jaunie\u0161i, vi\u0146i bija \u013coti ska\u013ci un akt\u012bvi. Rok\u0101s daudziem bija pa\u0161darin\u0101ti plak\u0101ti. Piem\u0113ram, \\\"Augst\u0101k\u0101 nodev\u012bba\\\" \u2013 sp\u0113l\u0113joties ar Augst\u0101k\u0101s Radas jeb parlamenta nosaukumu. K\u0101ds jaunietis ar\u012b bija izveidojis plak\u0101tu, kur puse sejas bija no prezidenta Zelenska, otra puse \u2013 no b\u0113d\u012bgi slaven\u0101 prokrievisk\u0101 eksprezidenta Viktora Janukovi\u010da, kur\u0161 2014.\\xa0gad\u0101 p\u0113c Eiromaidana jeb Pa\u0161cie\u0146as revol\u016bcijas asi\u0146ainajiem notikumiem aizb\u0113ga no Ukrainas un \u0161obr\u012bd sl\u0113pjas Krievij\u0101. Akt\u012bvisti Ukrainas protest\u0101 pret korupcijas apkarot\u0101ju v\u0101jin\u0101\u0161anu 00:00 / 01:09 Lejupl\u0101d\u0113t Indra Sprance Latvijas Radio parun\u0101j\u0101s ar da\u017eiem no akt\u012bvistiem. Marina: Esmu \u0161eit, jo esmu \u013coti sa\u0161utusi par pa\u0161reiz\u0113jo situ\u0101ciju ar likumprojektu. Ir pie\u0146emts likums, kas piln\u012bb\u0101 neatbilst Eiropas Savien\u012bbas un tautas pras\u012bb\u0101m. M\u0113s atgrie\u017eamies pie t\u0101 st\u0101vok\u013ca, k\u0101ds bija 2013. gad\u0101, kad m\u016bsu tauta c\u012bn\u012bj\u0101s par savu ce\u013cu uz Eiropas Savien\u012bbu. Mans br\u0101lis pa\u0161laik karo Pokrovskas tuvum\u0101. Visa \u0161\u012b situ\u0101cija man \u0161\u0137iet k\u0101 sp\u013c\u0101viens sej\u0101 visiem tiem karav\u012briem, kas m\u016bs sarg\u0101, risk\u0113jot ar dz\u012bv\u012bb\u0101m,\\xa0\u2013 vara vi\u0146iem demonstr\u0113, ka esam tuv\u0101k nevis Eiropas Savien\u012bbai un m\u016bsu Rietumu partneriem, bet Krievijai. Ihors: Man gandr\u012bz visi v\u012brie\u0161u k\u0101rtas radinieki \u0161obr\u012bd karo, un man nav ties\u012bbu \u0161obr\u012bd st\u0101v\u0113t mal\u0101. Aleksa: Ukrain\u0101 \u0161obr\u012bd notiek \u013coti briesm\u012bgas lietas \u2013 kam\u0113r da\u017ei cilv\u0113ki atdod savas dz\u012bv\u012bbas, lai m\u0113s var\u0113tu \u0161eit norm\u0101li dz\u012bvot, k\u0101ds sagrauj valsti. Un tas nav labi. Mums \u0161eit ir j\u0101b\u016bt.\\xa0 Tas ir svar\u012bgi. Tre\u0161dienas vakar\u0101 protesta akcija notika ar\u012b Ukrainas otr\u0101 liel\u0101kaj\u0101 pils\u0113t\u0101 Harkiv\u0101, tur p\u0113c \\\"Radio Br\u012bv\u012bba\\\" apl\u0113s\u0113m bijis l\u012bdz pust\u016bkstotim cilv\u0113ku. Protesti notiku\u0161i ar\u012b \u010cernihiv\u0101, Zapori\u017ej\u0101, \u013bviv\u0101, D\u0146ipro, Krivijrih\u0101, Ivanofrankivsk\u0101, Ternopi\u013c\u0101, Odes\u0101 un citur. \u0160\u012b ir jau otr\u0101 diena, kad cilv\u0113ki iziet iel\u0101s. Iepriek\u0161 tie bija spont\u0101ni protesti, rea\u0123\u0113jot uz Augst\u0101k\u0101s Radas l\u0113mumu, bet tre\u0161dien jau daudzviet cilv\u0113kus iel\u0101s aicin\u0101ju\u0161as da\u017e\u0101das sabiedrisk\u0101s organiz\u0101cijas. Zelenskis sola jaunu likumu Prezidents Volodimirs Zelenskis tre\u0161dien bija noorganiz\u0113jis tik\u0161anos ar visu Ukrainas ties\u012bbu aizsardz\u012bbas iest\u0101\u017eu vad\u012bt\u0101jiem, taj\u0101 skait\u0101 abu pretkorupcijas iest\u0101\u017eu \u2013 NABU un specializ\u0113t\u0101s prokurat\u016bras vad\u012bt\u0101jiem. Saruna bijusi atkl\u0101ta un v\u0113rt\u012bga. N\u0101kamned\u0113\u013c notik\u0161ot dzi\u013c\u0101ka darba tik\u0161an\u0101s saist\u012bb\u0101 ar kop\u012bgajiem darbiem. P\u0113c\u0101k videouzrun\u0101 Zelenskis sac\u012bja, ka ir sadzird\u0113jis cilv\u0113ku ba\u017eas. Zelenskis pied\u0101v\u0101s Augst\u0101kajai Radai savu \u2013 prezidenta likumprojektu, kas nodro\u0161in\u0101s ties\u012bbu aizsardz\u012bbas sist\u0113mas sp\u0113ku un to, ka neb\u016bs nek\u0101da Krievijas iejauk\u0161an\u0101s iest\u0101\u017eu darb\u0101. Jau v\u0113l\u0101k Zelenskis likumprojektu iesniedzis. V\u0113l gan nav skaidrs, kas tie\u0161i \u0161aj\u0101 likumprojekt\u0101 ir un kad tie\u0161i par to balsos parlaments. K\u0101 likumprojektu koment\u0113jis Zelenskis, tas paredz piln\u012bgas korupcijas apkaro\u0161anas iest\u0101\u017eu neatkar\u012bbas garantijas. Tas ar\u012b paredzot re\u0101las iesp\u0113jas p\u0101rliecin\u0101ties, ka iest\u0101\u017eu darb\u012bb\u0101 neiejaucas Krievija. Ikvienam, kam ir pieeja valsts nosl\u0113pumiem - ne tikai Nacion\u0101lajam pretkorupcijas birojam un Specializ\u0113tajai pretkorupcijas prokurat\u016brai, bet ar\u012b Valsts izmekl\u0113\u0161anas birojam un Valsts policijai - ir j\u0101veic melu detektora p\u0101rbaudes un t\u0101m j\u0101b\u016bt regul\u0101r\u0101m, likumprojekta saturu koment\u0113ja Zelenskis. Likumprojekt\u0101 ir iek\u013cauti ar\u012b noteikumi, kas aizsarg\u0101 pret da\u017e\u0101diem p\u0101rk\u0101pumiem, piebilda prezidents. P\u0113c jaun\u0101 likumprojekta p\u0101rskat\u012b\u0161anas Nacion\u0101lais pretkorupcijas birojs pazi\u0146ojum\u0101 nor\u0101d\u012bja, ka ierosin\u0101tais likumprojekts patiesi atjaunos visas procesu\u0101l\u0101s pilnvaras un neatkar\u012bbas garantijas gan biroj\u0101, gan Specializ\u0113taj\u0101 pretkorupcijas prokurat\u016br\u0101. Ar\u012b Ukrainas Korupcijas apkaro\u0161anas r\u012bc\u012bbas centrs, kas ir uzraudz\u012bbas iest\u0101de, atbalst\u012bja iniciat\u012bvu, sakot, ka t\u0101 atjaunos principus, ko iepriek\u0161 bija nojaukusi Augst\u0101k\u0101 Rada. Centrs gan br\u012bdin\u0101ja, ka pat vienas ned\u0113\u013cas kav\u0113\u0161an\u0101s var b\u016bt pietiekama, lai izn\u012bcin\u0101tu virkni ab\u0101s pretkorupcijas iest\u0101d\u0113s eso\u0161\u0101s tiesved\u012bbas pret augst\u0101kaj\u0101m korump\u0113taj\u0101m amatperson\u0101m. KONTEKSTS: Ukrainas parlaments 22. j\u016blij\u0101 apstiprin\u0101ja likuma groz\u012bjumus, kas mazina Ukrainas korupcijas apkaro\u0161anas iest\u0101\u017eu neatkar\u012bbu. Ukrainas Nacion\u0101lais pretkorupcijas birojs (NABU) un specializ\u0113t\u0101 prokurat\u016bra turpm\u0101k b\u016bs pak\u013cauti Ukrainas \u0123ener\u0101lprokuroram, kas ir Ukrainas prezidenta Volodimira Zelenska izvirz\u012bta amatpersona. Tas izrais\u012bjis ba\u017eas par korupcijas apkaro\u0161anas dienestu pak\u013cau\u0161anu Zelenska komandas interes\u0113m. Ukrainas Dro\u0161\u012bbas dienests iepriek\u0161 veicis pla\u0161a m\u0113roga krat\u012b\u0161anas pie NABU un specializ\u0113t\u0101s prokurat\u016bras darbiniekiem. \u0160ie so\u013ci izrais\u012bju\u0161i protestus Ukrainas iek\u0161ien\u0113, k\u0101 ar\u012b kritiku no Ukrainas partneriem, kas raiz\u0113jas par demokr\u0101tijas standartu v\u0101jin\u0101\u0161anu un nepietiekamo aktivit\u0101ti korupcijas apkaro\u0161an\u0101. Tas var\u0113tu apgr\u016btin\u0101t Ukrainas izredzes k\u013c\u016bt par Eiropas Savien\u012bbas dal\u012bbvalsti.\",\n\"target_text\": \"Ukrain\u0101 tre\u0161dienas vakar\u0101, rea\u0123\u0113jot uz \u0161oned\u0113\u013c liel\u0101 steig\u0101 pie\u0146emto likumu, kas atce\u013c pretkorupcijas iest\u0101\u017eu neatkar\u012bbu, t\u016bksto\u0161iem cilv\u0113ku izg\u0101ja iel\u0101s. Latvijas Radio bija kl\u0101t Kijiv\u0101, kur pulc\u0113j\u0101s liels skaits cilv\u0113ku.\"\n}\n</code></pre> <pre><code>{\n\"text\": \"Norv\u0113\u0123ijas dziesma Eirov\u012bzij\u0101 \u2013 folkm\u016bzikas, elektronikas un viduslaiku est\u0113tikas sint\u0113ze\\n\\nAlessandro ir sp\u0101\u0146u izcelsmes, vi\u0146\u0161 run\u0101 \u010detr\u0101s valod\u0101s, iedvesmojas no da\u017e\u0101du pasaules tautu m\u016bzikas, k\u0101 ar\u012b ir labs dejot\u0101js. Alessandro dziesma \\\"Lighter\\\" ietur\u0113ta popm\u016bzikas stilistik\u0101, kur\u0101 iev\u012bti daudz da\u017e\u0101di elementi. Te var sadzird\u0113t gan norv\u0113\u0123u folkm\u016bzikas, gan elektronisk\u0101s deju m\u016bzikas notis, gan Balk\u0101nu popm\u016bzikai rakstur\u012bgos ritmus un pat viduslaiku est\u0113tiku. Dziesma aicina notic\u0113t sev un b\u016bt pa\u0161am savai dzirkstij. Dziesmas \\\"Lighter \\\" v\u0101rdi Golden girl dressed in ice A heart as dark as night You got me to dim my light No more, (no more) I really think I bought your lies Did anything to keep you mine You kept me hooked on your line No more, (no more) Somewhere along the way I lost my mind I had to walk a hundred thousand miles I\u2019m not afraid to set it all on fire I won\u2019t fall again, I\u2019ll be my own lighter (Eh-Eh-Eh-Eh) Nothing can burn me now (Eh-Eh-Eh-Eh) I\u2019ll be my own lighter I feel a spark inside me I don\u2019t need saving (No way, no way) \u2018Cause I\u2019m my own, I\u2019m my own lighter I\u2019m tired of a million tries To fight, the signs And when everybody tried to tell me I should\u2019ve known that it was time to break free Your reigns that kept me at your mercy I\u2019ll burn them to the ground No more, no more Ignite the fire Somewhere along the way I lost my mind I had to walk a hundred thousand miles I\u2019m not afraid to set it all on fire I won\u2019t fall again, I\u2019ll be my own lighter (Eh-Eh-Eh-Eh) Nothing can burn me now (Eh-Eh-Eh-Eh) I\u2019ll be my own lighter I feel a spark inside me I don\u2019t need saving (No way, no way) \u2018Cause I\u2019m my own, I\u2019m my own lighter Silence fills the room And I\u2019ve taken off my jewels I wish none of this was true But there\u2019s a fire growing too Yeah! (Eh-Eh-Eh-Eh) Nothing can burn me now (Eh-Eh-Eh-Eh) I\u2019ll be my own lighter I feel a spark inside me I don\u2019t need saving (No way, no way) \u2018Cause I\u2019m my own, I\u2019m my own lighter (Eh-Eh-Eh-Eh) Nothing can burn me down (Eh-Eh-Eh-Eh) I\u2019m my own, I\u2019m my own lighter Eirov\u012bzija\\xa02025 \u2013 dal\u012bbnieki Vair\u0101k KONTEKSTS: 2025. gada Eirov\u012bzijas dziesmu konkurss notiks \u0160veic\u0113, B\u0101zel\u0113, un savu dal\u012bbu taj\u0101 apstiprin\u0101ju\u0161as 37 valstis. 31 no vis\u0101m dal\u012bbvalst\u012bm sacent\u012bsies pusfin\u0101los\\xa013. maij\u0101 un 15. maij\u0101. Desmit\\xa0lab\u0101kie no katra pusfin\u0101la kvalific\u0113sies lielajam fin\u0101lam 17. maij\u0101, pievienojoties p\u0113rn\u0101 gada uzvar\u0113t\u0101jai \u0160veicei un \\\"lielajam piecniekam\\\" \u2013 Sp\u0101nijai, Apvienotajai\\xa0Karalistei, V\u0101cijai, It\u0101lijai un Francijai. Eirov\u012bzijas konkursa pusfin\u0101li un fin\u0101li \u0161ogad s\u0101ksies pulksten 22.00 p\u0113c Latvijas laika. Tie\u0161raides b\u016bs skat\u0101mas Latvijas Sabiedrisk\u0101 medija port\u0101l\u0101 LSM.lv un satura atska\u0146ot\u0101j\u0101 REplay.lv, k\u0101 ar\u012b LTV1. \u0160\u012b gada Latvijas nacion\u0101laj\u0101 atlas\u0113 \\\"Supernova\\\" uzvar\u0113ja un uz Eirov\u012bziju dosies grupa \\\"Tautumeitas\\\" . \\\"Tautumeitas\\\" k\u0101ps uz skatuves Eirov\u012bzijas konkursa otraj\u0101 pusfin\u0101l\u0101. Taj\u0101 kop\u0101 ar Latviju piedal\u012bsies ar\u012b Arm\u0113nija, Austr\u0101lija, Austrija, Grie\u0137ija, \u012arija, Lietuva, Melnkalne, \u010cehija, D\u0101nija, Somija, Gruzija, Izra\u0113la, Luksemburga, Malta un Serbija.\",\n\"target_text\": \"Norv\u0113\u0123iju Eirov\u012bzijas dziesmu konkurs\u0101 p\u0101rst\u0101v jaunais dzied\u0101t\u0101js Kails Alessandro ( Kyle Alessandro ). Pla\u0161\u0101ka auditorija dzied\u0101t\u0101ju iepazina jau 10 gadu vecum\u0101, kad vi\u0146\u0161 veiksm\u012bgi piedal\u012bj\u0101s\\xa0TV \u0161ov\u0101 \\\"Norway\u2019s Got Talent\\\".\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>T\u0101l\u0101k ir dokumenti ar pievienot\u0101m kopsavilkumiem.\n</code></pre></li> <li>Base prompt template:   <pre><code>Dokuments: {text}\nKopsavilkums: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Dokuments: {text}\n\nUzrakstiet kopsavilkumu par iepriek\u0161 min\u0113to dokumentu.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset lsm\n</code></pre>"},{"location":"datasets/norwegian/","title":"\ud83c\uddf3\ud83c\uddf4 Norwegian","text":"<p>This is an overview of all the datasets used in the Norwegian part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/norwegian/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/norwegian/#norec","title":"NoReC","text":"<p>This dataset was published in this paper and is based on reviews from three different media organisations: Schibsted Media Group, Aller Media and NRK.</p> <p>The original full dataset consists of 680,792 / 101,106 / 101,594 samples for training, validation and test, respectively. We use a split of 1,024 / 256 / 2,048 samples for training, validation and test, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Den som ikke blir rystende ber\u00f8rt av \u00ab De utvalgte \u00bb , m\u00e5 v\u00e6re forherdet til det immune .\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Under er noen av funksjonene som er dels unike for LG G3 :\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tilsvarende f\u00e5r vi ogs\u00e5 lavere score i 3DMark enn hva tilfellet er for f.eks . Xperia Z2 og Galaxy S5 .\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er anmeldelser og deres sentiment, som kan v\u00e6re 'positiv', 'n\u00f8ytral' eller 'negativ'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Anmeldelse: {text}\nSentiment: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Anmeldelse: {text}\n\nKlassifiser sentimentet i anmeldelsen. Svar med 'positiv', 'n\u00f8ytral' eller 'negativ'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positiv</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>n\u00f8ytral</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negativ</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset norec\n</code></pre>"},{"location":"datasets/norwegian/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/norwegian/#norne-nb","title":"NorNE-nb","text":"<p>This dataset was published in this paper and is a manually NER annotated version of the Bokm\u00e5l Universal Dependencies treebank. The NER labels almost follow the CoNLL-2003 standard, but with some additional labels.</p> <p>The original full dataset consists of 15,696 / 2,410 / 1,939 samples for training, validation and test, respectively. We use a split of 1,024 / 256 / 2,048 samples for training, validation and test, respectively. The splits we use are new, so there might be some samples from the training split in the validation or test splits.</p> <p>We have mapped the labels into the CoNLL-2003 standard as follows:</p> <ul> <li><code>LOC</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>PER</code> \u27a1\ufe0f <code>PER</code></li> <li><code>ORG</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>MISC</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>GPE_LOC</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>GPE_ORG</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>PROD</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>DRV</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>EVT</code> \u27a1\ufe0f <code>MISC</code></li> </ul> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['Det', 'fremkommer', 'av', '\u00e5rsmeldingene', 'fra', 'Bergen', 'helser\u00e5d', 'i', '\u00e5rene', '1952', '-', '66', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Viktig', 'var', 'det', 'ogs\u00e5', 'at', 'Kina', 'allerede', 'var', 'blitt', 's\u00e5', 'avhengig', 'av', 'det', 'amerikanske', 'markedet', 'og', 'av', 'dollaren', ',', 'at', 'en', 'nedgang', 'i', 'USA', 'ogs\u00e5', 'ville', 'ramme', 'Kina', 'hardt', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-ORG', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  'tokens': array(['Han', 'tok', 'fram', 'pistolen', 'og', 'dro', 'tilbake', 'til', 'Skaregata', '2', '.'], dtype=object),\n  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er fraser og JSON-ordb\u00f8ker med de navngitte enhetene som forekommer i den gitte frasen.\n</code></pre></li> <li>Base prompt template:   <pre><code>Frase: {text}\nNavngitte enheter: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frase: {text}\n\nIdentifiser de navngitte enhetene i frasen. Du b\u00f8r outputte dette som en JSON-ordbok med n\u00f8klene 'person', 'sted', 'organisasjon' og 'diverse'. Verdiene skal v\u00e6re lister over de navngitte enhetene av den typen, akkurat som de vises i frasen.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisasjon</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisasjon</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diverse</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diverse</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset norne-nb\n</code></pre>"},{"location":"datasets/norwegian/#norne-nn","title":"NorNE-nn","text":"<p>This dataset was published in this paper and is a manually NER annotated version of the Nynorsk Universal Dependencies treebank. The NER labels almost follow the CoNLL-2003 standard, but with some additional labels.</p> <p>The original full dataset consists of 14,174 / 1,890 / 1,511 samples for training, validation and test, respectively. We use a split of 1,024 / 256 / 2,048 samples for training, validation and test, respectively. The splits we use are new, so there might be some samples from the training split in the validation or test splits.</p> <p>We have mapped the labels into the CoNLL-2003 standard as follows:</p> <ul> <li><code>LOC</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>PER</code> \u27a1\ufe0f <code>PER</code></li> <li><code>ORG</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>MISC</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>GPE_LOC</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>GPE_ORG</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>PROD</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>DRV</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>EVT</code> \u27a1\ufe0f <code>MISC</code></li> </ul> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['-', 'Ulfr', 'provoserer', 'kjapt', 'fram', 'eit', 'slagsm\u00e5l', ',', 'og', 'han', 'drep', 'hovdingen', '.'], dtype=object),\n  \"labels\": array(['O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['I', 'haust', 'blei', 'det', 'avsl\u00f8rt', 'at', 'minst', 'to', 'tolv\u00e5ringar', 'p\u00e5', 'mellomtrinnet', 'ved', 'Gimle', 'skule', 'hadde', 'med', 'seg', 'alkohol', 'p\u00e5', 'ein', 'skuletur', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['Krigen', 'mot', 'Irak', 'skulle', 'aldri', 'ha', 'vore', 'gjennomf\u00f8rd', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er fraser og JSON-ordb\u00f8ker med de navngitte enhetene som forekommer i den gitte frasen.\n</code></pre></li> <li>Base prompt template:   <pre><code>Frase: {text}\nNavngitte enheter: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frase: {text}\n\nIdentifiser de navngitte enhetene i frasen. Du b\u00f8r outputte dette som en JSON-ordbok med n\u00f8klene 'person', 'sted', 'organisasjon' og 'diverse'. Verdiene skal v\u00e6re lister over de navngitte enhetene av den typen, akkurat som de vises i frasen.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>sted</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisasjon</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisasjon</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diverse</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diverse</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset norne-nn\n</code></pre>"},{"location":"datasets/norwegian/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/norwegian/#scala-nb","title":"ScaLA-nb","text":"<p>This dataset was published in this paper and was automatically created from the Bokm\u00e5l Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 20,044 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"En vellykket gjennomf\u00f8ring av denne reformen vil bli en avgj\u00f8rende pr\u00f8ve p\u00e5 Regjeringens handlekraft.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Lunde var ikke blant, mener Andreassen.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"72 kjoler g\u00e5r hver med sesong.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er setninger og hvorvidt de er grammatisk korrekte.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nGrammatisk korrekt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nBestem om setningen er grammatisk korrekt eller ikke. Svar med 'ja' hvis setningen er korrekt og 'nei' hvis den ikke er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-nb\n</code></pre>"},{"location":"datasets/norwegian/#scala-nn","title":"ScaLA-nn","text":"<p>This dataset was published in this paper and was automatically created from the Nynorsk Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 17,575 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Dersom Noreg snart g\u00e5r forbi Danmark i folketal, slik framskrivingane tilseier, kan ogs\u00e5 dette langt p\u00e5 veg forklarast med naturressursar.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Eg kan ikkje sj\u00e5 at det er grunn til \u00e5 ha ei slik grense i lova, det kan vurderast i, seier ho.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"SV har elles levert og i dag framsett ei gode forslag som kan bidra til \u00e5 gjera noko med straumprisproblematikken og straumforbruket, om viljen v\u00e5r er der.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er setninger og hvorvidt de er grammatisk korrekte.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nGrammatisk korrekt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nBestem om setningen er grammatisk korrekt eller ikke. Svar med 'ja' hvis setningen er korrekt og 'nei' hvis den ikke er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-nn\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-nocola","title":"Unofficial: NoCoLA","text":"<p>This dataset was published in this paper and is based on the annotated language learner corpus ASK. Notably, the individual types of errors are also annotated in this dataset. We use the error types to ensure that there is an equal representation of each error type, but then collapse the error types into <code>correct</code> and <code>incorrect</code>.</p> <p>The original dataset consists of 116,199 / 14,293 / 14,387 samples for training, validation and test, respectively. We use 1,024 / 256 / 2,048 samples for training, validation and test, respectively, where we sample each error type equally. All splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Vi har hatt krig i nesten ti \u00e5r. Jeg f\u00f8ler meg noen ganger trist fordi jeg har mistet flere venner og min far p\u00e5 grunn av krigen.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvis jeg ikke sier in n genting, kan han spille hele dagen.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"De f\u00f8ler at samfunnet trenger ikke dem.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er setninger og hvorvidt de er grammatisk korrekte.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nGrammatisk korrekt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nBestem om setningen er grammatisk korrekt eller ikke. Svar med 'ja' hvis setningen er korrekt og 'nei' hvis den ikke er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset no-cola-binary\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-jentoft","title":"Unofficial: Jentoft","text":"<p>This dataset was published in this Master's thesis by Matias Jentoft.</p> <p>The original dataset consists of 85,771 / 10,827 / 10487 samples for training, validation and test, respectively. We use a split of 1,024 / 256 / 2,048 samples for training, validation and test, respectively. In each split, the distribution of <code>correct</code> and <code>incorrect</code> is 50/50.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"For to uker siden var jeg p\u00e5 en fotoutstilling om Erytrea.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Det viser seg at folk ikke kan leve uten mobiltelefonen.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Mobiltelefoner dominerer mange av oss, og vi bruker dem over alt, p\u00e5 gatene 'hvert hj\u00f8rne', i gatene, holdeplasser, kaffeteriaene og i parken, der folk burde tilbringe koselig tid sammen i naturen.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er setninger og hvorvidt de er grammatisk korrekte.\n</code></pre></li> <li>Base prompt template:   <pre><code>Setning: {text}\nGrammatisk korrekt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Setning: {text}\n\nBestem om setningen er grammatisk korrekt eller ikke. Svar med 'ja' hvis setningen er korrekt og 'nei' hvis den ikke er.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nei</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset jentoft\n</code></pre>"},{"location":"datasets/norwegian/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/norwegian/#norquad","title":"NorQuAD","text":"<p>This dataset was published in this paper and is a manually annotated dataset based on data from the Bokm\u00e5l Wikipedia.</p> <p>The original full dataset consists of 3,810 / 472 / 472 samples for training, validation and test, respectively. We use a split of 1,024 / 256 / 2,048 samples for training, validation and test, respectively. When creating the splits, we only select samples that contain an answer in the associated context. The splits we use are new, so there might be some samples from the training split in the validation or test splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": 'Sprekpodden: Denne treningen gj\u00f8r deg smartere og lykkeligere\\nHJERNEFORSKER: \u2013 Hjernen er i utgangspunktet programmert for latskap. Derfor m\u00e5 vi i st\u00f8rre grad tvinge oss selv til \u00e5 v\u00e6re mer aktive, sier forsker Ole Petter Hjelle. Foto: Tor Stenersen (arkiv)\\nSPREKPODDEN: Denne uken har programleder Daniel R\u00f8ed-Johansen og Malene Indreb\u00f8-Langlo bes\u00f8k av Ole Petter Hjelle. Foto: Morten Uglum\\n\u2013 Vi var rett og slett lei av \u00e5 sitte og fortelle pasientene v\u00e5re at de m\u00e5tte v\u00e6re i fysisk aktivitet, uten at noe skjedde.\\nFor noen \u00e5r siden startet hjerneforsker og fastlege Ole Petter Hjelle, og de andre legene p\u00e5 \u00c5sg\u00e5rdstrand legekontor, en treningsgruppe for pasientene sine. Det ble stor suksess.\\n\u2013 Folk vet at det er bra \u00e5 trene for den fysiske helsen, men at fysisk aktivitet ogs\u00e5 er bra for den mentale helse, er et underkommunisert tema, sier han.\\nBedre enn sudoku og kryssord\\n\u2013 Er fysisk aktivitet bedre hjernetrim enn sudoku og kryssord?\\n\u2013 L\u00f8ser du masse kryssord, s\u00e5 blir du veldig til \u00e5 l\u00f8se kryssord. Men det har ikke de store ringvirkningene p\u00e5 v\u00e5re kognitive funksjoner, som det \u00e5 huske, planlegge og gjennomf\u00f8re, sier Hjelle.\\nHan forklarer at n\u00e5r pulsen v\u00e5r \u00f8ker, skilles det ut vekstfaktorer i hjernen som beskytter hjernecellene v\u00e5re og gj\u00f8r at cellene kommuniserer bedre.\\nForskning viser ogs\u00e5 at det dannes nye hjerneceller i enkelte deler av hjernen, under aktivitet.\\n\u2013 Men skal man f\u00e5 denne effekten, m\u00e5 man rett og slett v\u00e6re i aktivitet.\\nF\u00e5 opp pulsen\\nForskning viser ogs\u00e5 at fysisk aktivitet reduserer risiko for depresjon og demens, \u00f8ker intelligensen, bedrer hukommelsen, gj\u00f8r deg mer kreativ og gir deg et lengre og bedre liv.\\nHjelle forteller at det viktigste for \u00e5 hente ut disse fordelene er \u00e5 f\u00e5 opp pulsen.\\n\u2013 Men dersom du skulle valgt en aktivitet \u2013 som i st\u00f8rst mulig grad stimulerte flest mulig hjerneomr\u00e5der \u2013 pleier jeg \u00e5 si ballspill. Da f\u00e5r du opp pulsen, du samarbeider, har taktikk, koordinasjon, balanse og strategi, sier Hjelle.\\nH\u00f8r mer fra \u00abtreningslegen\u00bb i ukens Sprekpodden her.',\n  \"question\": 'Hva jobber Daniel som?',\n  \"answers\": {\n    \"answer_start\": array([286]),\n    \"text\": array(['programleder'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Litauiske medier: En utvekslingsavtale skal v\u00e6re p\u00e5 plass for Frode Berg\\nFrode Berg ble d\u00f8mt til 14 \u00e5rs fengsel i Russland. Foto: Tore Meek / NTB scanpix\\nRussland og Litauen er enige om \u00e5 utveksle en spiond\u00f8mt russer mot to litauere og en nordmann, opplyser kilder i den litauiske sikkerhetstjenesten til den litauiske nyhetstjenesten Baltic News Service (BNS).\\n\u2013 Utvekslingsavtalen inkluderer ogs\u00e5 en norsk statsborger som er d\u00f8mt i Russland, sier en anonym tjenestemann i den litauiske sikkerhetstjenesten.\\nAvisen navngir ikke Frode Berg, men Berg er den eneste nordmannen som soner en slik dom i Russland.\\nAftenposten og en rekke norske medier omtalte saken onsdag ettermiddag. Flere russiske medier melder ogs\u00e5 om det samme, alle med BNS som kilde\\n\u2013 H\u00e5per en avtale foreligger\\nFrode Bergs norske advokat Brynjulf Risnes kan ikke bekrefte opplysningene.\\n\u2013 Jeg har ikke informasjon som verken bekrefter eller avkrefter en slik avtale. Vi h\u00e5per selvsagt at en slik avtale foreligger, sier Risnes til NTB.\\nUD vil ikke kommentere saken.\\n\u2013 Norske myndigheter \u00f8nsker \u00e5 f\u00e5 Frode Berg hjem. Vi h\u00e5ndterer saken p\u00e5 den m\u00e5ten som vi mener er best for \u00e5 ivareta hans interesser. Utover det kommenterer vi ikke saken, sier underdirekt\u00f8r Ane Haavardsdatter Lunde i Utenriksdepartementet til NTB.\\nBergs russiske forsvarer, advokat Ilja Novikov, ikke vil kommentere saken, if\u00f8lge NRK.\\nSt\u00f8ttegruppen for Frode Berg h\u00e5per opplysningene stemmer.\\n\u2013 Dersom det viser seg at dette er riktig, er det en ufattelig god nyhet som vi har ventet p\u00e5 skulle skje, sier st\u00f8ttegruppemedlem Thorbj\u00f8rn Brox Webber til NTB.\\n\u2013 En slik avtale m\u00e5 bety at Frode kan komme tilbake til Norge og Kirkenes, legger han til.\\nD\u00f8mt for spionasje\\nBerg er d\u00f8mt til 14 \u00e5rs fengsel for spionasje. Han ble p\u00e5grepet i Moskva i desember 2017 og har sittet fengslet siden.\\nNRK meldte i august at UD er i forhandlinger med Russland om \u00e5 f\u00e5 Berg hjem og har informert hans n\u00e6rmeste familie om dette.\\nMuligheten for en utvekslingsavtale har v\u00e6rt antydet, men et problem har v\u00e6rt hvem den i s\u00e5 fall skal omfatte.',\n  \"question\": 'Hvilken norske advokat representerer Frode Berg?',\n  \"answers\": {\n    \"answer_start\": array([808]),\n    \"text\": array(['Brynjulf Risnes'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Ny nedtur for Ruud\\nCasper Ruud r\u00f8k torsdag ut av challengerturneringen i Koblenz. Bildet er fra en tidligere turnering.\\nAv Ole Henrik Tveten\\nDet ble en frustrerende kamp mot nederlandske Tallpon Griekspoor torsdag. Casper Ruud vant f\u00f8rste sett 6-4, men etter det var det lite som stemte for nordmannen i Tyskland.\\nI andre sett ble Ruud utspilt og tapte 1-6, mens feilene fortsatte \u00e5 florere ogs\u00e5 i tredje sett og Ruud tapte settet 2-6.\\nDen norske 20-\u00e5ringen gikk rett inn i 2. runde i Koblenz-turneringen etter \u00e5 ha f\u00e5tt walkover i den f\u00f8rste. Der slet han seg til seier mot italienske Raul Brancaccio onsdag. Torsdagens motstander, Tallpon Griekspoor, er nummer 233 p\u00e5 verdensrankingen.\\nDet startet bra for Snar\u00f8ya-gutten da han i f\u00f8rste sett br\u00f8t nederlenderens serve og tok ledelsen 4-3. Servebruddet ble avgj\u00f8rende for settet som Ruud vant 6-4, etter blant annet \u00e5 ha reddet en breakball etter en lengre ballveksling.\\nI andre sett begynte problemene for Casper Ruud. Griekspoor br\u00f8t Ruuds serve ved f\u00f8rste anledning og gikk opp i 2-0-ledelse. Deretter vant han egen serve, br\u00f8t Ruuds serve p\u00e5 ny og vant s\u00e5 egen serve. Da ledet plutselig nederlenderen 5-0.\\nNordmannen servet inn til 5-1, men det var dessverre ikke starten p\u00e5 noen snuoperasjon. Nederlenderen vant settet 6-1.\\nNordmannen hadde ikke ristet av seg problemene i pausen, og ble feid av banen av Griekspoor. Ruud kom under 0-4 i tredje sett f\u00f8r han omsider reduserte til 1-4. Men da var det for sent.\\nNederlenderen servet inn 5-1, Ruud reduserte, f\u00f8r Griekspoor servet seieren i land. Dermed tapte Ruud tredje sett 6-2 og r\u00f8k ut av turneringen.\\n\u00c5 ryke ut i Tyskland hjelper ikke nordmannens jakt p\u00e5 rankingpoeng for \u00e5 komme seg inn i topp 100 i verden. Han risikerer \u00e5 falle flere plasser ettersom han mister de 70 rankingpoengene han skaffet seg da han tok seg til 2. runde i Australian Open i fjor. Ruud er akkurat n\u00e5 nummer 112 p\u00e5 verdensrankingen. (NTB)',\n  \"question\": 'Hvordan endte 1. sett mellom Ruud og Griekspoor?',\n  \"answers\": {\n    \"answer_start\": array([244]),\n    \"text\": array(['6-4'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 2</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger tekster med tilh\u00f8rende sp\u00f8rsm\u00e5l og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nSp\u00f8rsm\u00e5l: {question}\nSvar p\u00e5 maks 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l om teksten ovenfor med maks 3 ord.\n\nSp\u00f8rsm\u00e5l: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset norquad\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-norglm-multi-qa","title":"Unofficial: NorGLM Multi QA","text":"<p>This dataset was released in this paper and features a manually annotated reading comprehension dataset based on Norwegian news articles. This dataset is an abstractive question answering dataset, meaning that the answers do not always feature in the context. To fix this, they were rephrased using this script, which utilised the <code>gpt-4o-2024-05-13</code> model.</p> <p>The original dataset contains 2,406 samples, which we split into 1,024 / 256 / 1,126 samples for training, validation and test, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": ' Kommer det melding om at ansatte kj\u00f8per aksjer i eget selskap, kan det v\u00e6re gode grunner til at du ogs\u00e5 b\u00f8r gj\u00f8re det. \u2013 V\u00e6r p\u00e5 lag med innsiderne, er ekspertens r\u00e5d.Har du lyst til \u00e5 pr\u00f8ve deg som aksjeinvestor helt gratis og uten reell risiko? Meld deg p\u00e5 Aksje-NM her!Mange assosierer innsidehandel med kj\u00f8p og salg av aksjer basert p\u00e5 tilgang p\u00e5 selskapsnyheter f\u00f8r de blir offentliggjort i markedet. Slik handel kan gi stor \u00f8konomisk gevinst, og er ulovlig.Det finnes derimot ogs\u00e5 en lovlig form for innsidehandel, og denne kan det v\u00e6re lurt \u00e5 f\u00f8lge med p\u00e5, skal vi tro forskningssjef Geir Linl\u00f8kken i Investtech. Aksjeskolen er en del av E24s Aksje-NM. En tidligere versjon av denne artikkelserien ble publisert i 2020.N\u00e5r man snakker om \u00abinnsidehandel\u00bb i b\u00f8rssammenheng, siktes det som regel til handler som direkt\u00f8rer, styremedlemmer og andre n\u00f8kkelmedarbeidere gj\u00f8r. Disse handlene m\u00e5 rapporteres inn til Oslo B\u00f8rs, og kj\u00f8pet eller salget blir offentlig informasjon. Denne informasjonen kan v\u00e6re gull verdt, skal vi tro forskningen til Investtech.\u2013 N\u00f8kkelpersoner som direkt\u00f8rer og styremedlemmer sitter p\u00e5 veldig mye kunnskap om bedriften. N\u00e5r disse enten selger eller kj\u00f8per aksjer i eget selskap, kan det ses p\u00e5 som et signal til andre akt\u00f8rer, sier Linl\u00f8kken. Linl\u00f8kken har forsket p\u00e5 innsidehandel og tatt utgangspunkt i over 11.000 rapporterte innsidekj\u00f8p i norske og svenske selskaper. Han har sett n\u00e6rmere p\u00e5 hvordan kursen utviklet seg i tiden etter innsidekj\u00f8pet. \u2013 Vi fant at disse selskapene p\u00e5 \u00e5rlig basis steg med 7,1 prosentpoeng mer enn andre selskaper. Det kan alts\u00e5 v\u00e6re et godt tips \u00e5 f\u00f8lge med p\u00e5 innsidekj\u00f8p.Dersom det tikker inn meldinger om at innsidere selger aksjene sine, er det ogs\u00e5 lurt \u00e5 f\u00f8lge n\u00f8ye med. Investtech har tatt utgangspunkt i over 6.900 slike tilfeller i Norge og Sverige, og gjorde spennende funn. \u2013 I snitt gjorde disse aksjene det 3,0 prosentpoeng svakere enn b\u00f8rsen, sier han. Linl\u00f8kken forteller at noen av aksjene kan ha falt for eksempel 50 prosent etter innsidesalg, mens det kan ha g\u00e5tt ganske bra i andre selskaper med innsidesalg.\u2013 Men i gjennomsnitt har disse aksjene gjort det d\u00e5rlig, fastsl\u00e5r han.Linl\u00f8kken sier at Investtech anser innsidehandelanalyse som en forenklet fundamental analyse, alts\u00e5 en analyse av om aksjen er billig eller dyr i forhold til verdiene i selskapet. Har man ikke tid eller kunnskap til \u00e5 gj\u00f8re slik analyse selv, er det et godt alternativ \u00e5 se til innsiderne. \u2013 Historisk og statistisk sett, har det v\u00e6rt riktig \u00e5 f\u00f8lge innsiderne og v\u00e6re p\u00e5 lag med dem, svarer Linl\u00f8kken.',\n  \"question\": 'Hva kan man gj\u00f8re dersom man ikke har tid eller kunnskap til \u00e5 gj\u00f8re en analyse av aksjene til et selskap?',\n  \"answers\": {\n    \"answer_start\": 2434,\n    \"text\": array(['Se til innsiderne.'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": ' Alt om pubertet, penis, psyken og livet sj\u00e6l. Nok en fullkommen bok fra duoen bak et par av de st\u00f8rste boksuksessene de siste \u00e5rene. \u00abDe har gjort det igjen\u00bb, skrev jeg i VG for ganske n\u00f8yaktig to \u00e5r siden, da jeg satt her og leste og anmeldte \u00abJenteboka\u00bb av legene Nina Brochmann og Ellen St\u00f8kken Dahl. Da hadde det g\u00e5tt to \u00e5r siden de brak-debuterte med \u00abGleden med skjeden\u00bb. Jeg gav \u00abJenteboka\u00bb terningkast 6. Vel, vel. Du har kanskje gjettet det n\u00e5, men n\u00e5 har de alts\u00e5 gjort det enda en gang: Laget en knallgod, fullkommen bok vi f\u00e5r h\u00e5pe mange leser.For jeg t\u00f8r p\u00e5st\u00e5 at guttene trenger sin Guttebok vel s\u00e5 mye som jentene trenger sin. For selv om det er jentene vi har snakket mest om, er det mange unge gutter som sliter. Unge gutter faller oftere ut av skolen, er mer deprimerte og har mindre fremtidsoptimisme enn f\u00f8r. Det finnes dyster statistikk, kort fortalt: De opplever ogs\u00e5 stress og press og uhelse. Og s\u00e5 er de ikke s\u00e5 flinke til \u00e5 snakke om det. I \u00abGutteboka\u00bb tar Brochmann og Dahl for seg alt man m\u00e5 vite og forst\u00e5 n\u00e5r man er p\u00e5 vei inn i eller st\u00e5r midt i puberteten. (Eller senere i livet, for den saks skyld, jeg plukket opp noen gode tips selv, jeg.) De skriver om kroppsh\u00e5r, kviser, stemmeskifte,  legning, penisst\u00f8rrelse, pung, kj\u00f8nn, s\u00e6d, k\u00e5thet, ereksjonsknipe (!) og svettelukt, for \u00e5 nevne noen av mange h\u00f8ydepunkter.  Legeduoen havnet p\u00e5 denne lista: De ti heteste norske forfatterne i utlandet! Foruten alle de rent kroppslige og fysiske forandringene man kan oppleve p\u00e5 veien fra gutt til mann, inneholder boka gode kapitler om de psykiske aspektene og livet sj\u00e6l. Grensesetting, samtykke, nettvett, om \u00e5 trenge en pornopause, om psykisk uhelse, stress og press. \u00abAlle har det vondt iblant, men ingen har det vondt for alltid. Du kommer til \u00e5 bli glad igjen!\u00bb Det er noe med tonen i boka, som er s\u00e5 fin. Lett, \u00e5pen, sympatisk, avv\u00e6pnende. Smart, kul og og med faglig tyngde. Men aldri formanende, ingen pekefinger. \u00abOnani er godt og sunt. Onani er ikke bare ufarlig \u2013 det er bra for deg.\u00bb \u00abKroppen din er laget for \u00e5 brukes og nytes.\u00bb  \u00abDet er synd at trening ender opp med \u00e5 handle om bare utseendet. \u00c5 trene er nemlig bra for deg. Det er ikke jakten p\u00e5 \u00abdr\u00f8mmekroppen\u00bb.\u00bb Selv de mer alvorlige og kliniske temaene er dessuten en forn\u00f8yelse \u00e5 bla om til, ogs\u00e5 takket v\u00e6re de fantastiske illustrasjonene til Magnhild Wisnes. De er fargerike og morsomme, og gj\u00f8r boka komplett. S\u00e5 mange peniser har jeg ikke sett siden vi fniste og lo av \u00abPenisatlaset\u00bb p\u00e5 et nachspiel i studietiden. S\u00e5 kan man jo stille seg sp\u00f8rsm\u00e5let, om denne boka n\u00e5r frem til dem som trenger \u00e5 lese den. Den burde egentlig v\u00e6rt pensum, tenker jeg, eller i alle fall utgangspunkt for et prosjekt p\u00e5 skolen. \u00c5 sette seg ned med en bok, som attp\u00e5til handler om puberteten, st\u00e5r vel ikke h\u00f8yest p\u00e5 lista over hva ten\u00e5ringsgutter flest vil bruke fritiden sin p\u00e5. Pr\u00f8v likevel.  Jeg vet ikke, kanskje betale gutten noen kroner for \u00e5 lese den, om det er det som skal til. Jeg f\u00f8ler meg sikker p\u00e5 at det vil v\u00e6re verdt det. For hvis de unge guttene v\u00e5re leser denne boka, er jeg sikker p\u00e5 at livet blir lettere \u00e5 leve og verden et morsommere sted. Anmeldt av: Trine Saugestad Hatlen',\n  \"question\": 'Hvem st\u00e5r for illustrasjonene i \u00abGutteboka\u00bb?',\n  \"answers\": {\n    \"answer_start\": 2321,\n    \"text\": array(['illustrasjonene til Magnhild Wisnes'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": ' Regjeringen lanserer ny handlingsplan for \u00e5 beskytte den truede villaksen. \u2013 Altfor slapt, sier SV-politiker.Regjeringen lanserer n\u00e5 en handlingsplan for \u00e5 bevare den truede villaksen.\u2013 Villaksen kan n\u00e5 bli r\u00f8dlistet i Norge for f\u00f8rste gong. Det er helt klart at det trengs konkrete tiltak for \u00e5 snu denne utviklingen, sier Sveinung Rotevatn i pressemeldingen fra regjeringen.Handlingsplanen inneholder tiltak mot blant annet lakselus, r\u00f8mt oppdrettsfisk, lakseparasitten Gyro, vannkraftregulering, forsuring, overbeskatning og fremmende fiskearter som pukkellaks.Regjeringen viser til at lakselus utgj\u00f8r den st\u00f8rste risikoen for \u00e5 gj\u00f8re ytterligere skade p\u00e5 vill atlantisk laks, if\u00f8lge Vitenskapelig r\u00e5d for lakseforvaltning.\u2013 Lakselus utgj\u00f8r en stor risiko for villaksen. Regjeringen vil blant annet utrede krav om nullutslipp av lakselus fra oppdrettsanlegg fra og med 2030, sier Rotevatn.Det vil i s\u00e5 fall inneb\u00e6re krav om lukkede anlegg.Lakselus finnes naturlig i alle havomr\u00e5der p\u00e5 den nordlige halvkule, og er den vanligste parasitten p\u00e5 laksefisk.Blir forekomsten av lus h\u00f8y, kan det v\u00e6re en utfordring b\u00e5de for oppdrettsfisk og vill laksefisk.Havbruk medf\u00f8rer at antall fisk i sj\u00f8en \u00f8ker, og dermed \u00f8ker ogs\u00e5 antall verter for lakselus. Niv\u00e5ene med lakselus i anleggene m\u00e5 derfor holdes lavest mulig, slik at de samlede lusemengdene i sj\u00f8en ikke blir for store.Som f\u00f8lge av omfattende resistens hos lusen mot kjemiske behandlingsmidler, har n\u00e6ringen de siste \u00e5rene v\u00e6rt tvunget til \u00e5 ta i bruk mekaniske metoder for \u00e5 fjerne lusen, med negative konsekvenser for fiskens velferd.Kilde: Lusedata, MattilsynetDagens trafikklyssystem som regulerer veksten i n\u00e6ringen i forhold til luseutviklingen, skal ogs\u00e5 utvikles og forbedres.Planen inneholder ogs\u00e5 tiltak mot en rekke andre p\u00e5virkningsfaktorer. Utfisking av r\u00f8mt oppdrettslaks skal \u00f8kes, og det skal vurderes nye metoder for \u00e5 spore og merke oppdrettslaks og hindre at r\u00f8mt oppdrettslaks gyter.Hele 80 prosent av villaksbestandene i Norge n\u00e5r for tiden ikke minstem\u00e5let for god kvalitet. R\u00f8mt oppdrettslaks og lakselus er regnet som de to st\u00f8rste truslene, skriver regjeringen.Fremmende fiskearter utgj\u00f8r ogs\u00e5 en risiko for b\u00e5de biologisk mangfold, produktiviteten til lokal laksefisk og akvakultur.I \u00e5r har Norge hatt den st\u00f8rste invasjonen av pukkellaks noensinne, og regjeringen vil derfor opprette en nasjonal kompetansegruppe for \u00e5 koordinere arbeidet med dette.SVs nestleder Torgeir Knag Fylkesnes er ikke forn\u00f8yd med tiltakene.\u2013 Dette er altfor, altfor slapt. Regjeringen tar ikke tak i elefanten i rommet, nemlig den lite b\u00e6rekraftige forvaltningen av oppdrettsn\u00e6ringa. Vi m\u00e5 stille strengere milj\u00f8krav til alle nye oppdrettstillatelser, og fase inn disse kravene hos de med eksisterende tillatelser, skriver han i en kommentar til E24.Han p\u00e5peker at det i dag tildeles oppdrettstillatelser til den h\u00f8ystbydende, og ikke til de med den mest milj\u00f8vennlige teknologien. \u2013 Skal vi redde villaksen og sikre en b\u00e6rekraftig vekst for oppdrettsn\u00e6ringen, m\u00e5 vi legge om systemet slik at vi gjennom \u00e5 gi billigere tillatelser, men med krav om nullutslipp, null r\u00f8mming og null ressurser p\u00e5 avveie.Fylkesnes understreker videre at teknologien finnes, og at n\u00e6ringen har god r\u00e5d.\u2013 N\u00e5r man for eksempel ser p\u00e5 Salmars investeringsaktivitet de siste ukene, s\u00e5 ser vi at n\u00e6ringen b\u00e5de kan betale for ny teknologi og skatt p\u00e5 formue og grunnrente.Fylkesnes gikk tidligere denne uken hardt ut mot Salmar-eier Gustav Witz\u00f8e, etter at laksemilliard\u00e6ren uttalte seg kritisk mot \u00f8kning i formuesskatten tidligere i sommer.',\n  \"question\": 'Hva inneholder regjeringens nye handlingsplan for villaksen?',\n  \"answers\": {\n    \"answer_start\": 377,\n    \"text\": array(['Handlingsplanen inneholder tiltak mot blant annet'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 2</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger tekster med tilh\u00f8rende sp\u00f8rsm\u00e5l og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nSp\u00f8rsm\u00e5l: {question}\nSvar p\u00e5 maks 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l om teksten ovenfor med maks 3 ord.\n\nSp\u00f8rsm\u00e5l: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset norglm-multi-qa\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-belebele-no","title":"Unofficial: BeleBele-no","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Tekst: Det kinesiske nyhetsbyr\u00e5et Xinhua meldte tidligere fra om at et fly var kapret. Det ble senere rapportert at flyet fikk en bombetrussel og ble veiledet mot retur til Afghanistan med landing i Kandahar. If\u00f8lge de f\u00f8rste rapportene ble flyet dirigert tilbake til Afghanistan etter \u00e5 ha blitt nektet n\u00f8dlanding i \u00dcr\u00fcmqi.\\nSp\u00f8rsm\u00e5l: Hva ble ikke sagt i den nyeste rapporten fra nyhetsbyr\u00e5et Xinhua?\\nSvaralternativer:\\na. Flyet fikk en bombetrussel\\nb. Flyet landet i \u00dcr\u00fcmqi\\nc. Flyet ble dirigert til Afghanistan\\nd. Flyet landet i Kandahar\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tekst: Tyskland begynte \u00e5 gj\u00f8re seg klare til \u00e5 invadere Storbritannia da kampen om Frankrike var over. Tyskland gav angrepet kodenavnet \u00aboperasjon sj\u00f8l\u00f8ve\u00bb. Mesteparten av den britiske h\u00e6rens tunge v\u00e5pen og forsyninger hadde g\u00e5tt tapt da den flyktet fra Dunkirk, s\u00e5 de var sv\u00e6rt s\u00e5rbar. Den britiske marinen var imidlertid fremdeles mye kraftigere enn den tyske (\u00abKriegsmarine\u00bb) og kunne ha \u00f8delagt en eventuell invasjonsfl\u00e5te sendt over den engelske kanal. Det var likevel sv\u00e6rt f\u00e5 skip fra Royal Navy som ble stasjonert n\u00e6r de sannsynlige invasjonsrutene siden admiralene var engstelige for at de kom til \u00e5 bli senket av tyske luftangrep.\\nSp\u00f8rsm\u00e5l: Hva kalte Tyskland angrepet p\u00e5 Storbritannia?\\nSvaralternativer:\\na. Dunkirk\\nb. Operasjon sj\u00f8l\u00f8ve\\nc. Kriegsmarine\\nd. Royal Navy\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Tekst: Det italienske og det tyske landslaget er de nest beste lagene i verden og var FIFA World Cup-mestere i 2006. Fotball, basketball, volleyball, vannpolo, fekting, rugby, sykling, ishockey, rullehockey og Formel-1 bilsport er godt likte sportsgrener. Vintersport er mest popul\u00e6rt i nordlige omr\u00e5der, der italienere deltar i internasjonale konkurranser og OL-arrangementer.\\nSp\u00f8rsm\u00e5l: Hvilke av f\u00f8lgende sporter vant et verdensmesterskap for Italia, basert p\u00e5 informasjonen i avsnittet?\\nSvaralternativer:\\na. Fotball\\nb. Vannpolo\\nc. Basketball\\nd. Sykling\",\n  \"label\": \"a\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c' eller 'd', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-no\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-multiwikiqa-nb","title":"Unofficial: MultiWikiQA-nb","text":"<p>This dataset will be published in an upcoming paper, and contains Norwegian Bokm\u00e5l Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Cabaret Marzipan er et musikkalbum med Lumbago, innspilt i Nidaros Studios i Trondheim og utgitt i 1981 p\u00e5 Polydor Records. Produsent er Nils B. Kvam. Dette er bandets andre og siste album.\\n\\nSporliste\\n \u00abTanta mi rapper i supermarkedet\u00bb (Thanasis Zlatanos/Morten J\u00f8rgensen)\\n \u00abPene jenter\u00bb (Thanasis Zlatanos/Stein Gulbrandsen/Morten J\u00f8rgensen)\\n \u00abBare deg jeg tenker p\u00e5\u00bb (Stein Gulbrandsen/Trond Armand Larsen/Morten J\u00f8rgensen)\\n \u00abNatt\u00bb (Thanasis Zlatanos/Stein Gulbrandsen/Trond Armand Larsen/Morten J\u00f8rgensen)\\n \u00abEn god dag idag\u00bb (Thanasis Zlatanos/Morten J\u00f8rgensen)\\n \u00abI gata der du bor\u00bb (Thanasis Zlatanos/Stein Gulbrandsen/Morten J\u00f8rgensen)\\n \u00abSammen igjen\u00bb (Thanasis Zlatanos/Marilena Zlatanou/Stein Gulbrandsen/Morten J\u00f8rgensen)\\n \u00abLumbagoid\u00bb (Thanasis Zlatanos/Stein Gulbrandsen/Trond Armand Larsen/Morten J\u00f8rgensen)\\n \u00abEva\u00bb (Thanasis Zlatanos/Stein Gulbrandsen/Morten J\u00f8rgensen)\\n \u00abTotalklaustrofobi\u00bb (Thanasis Zlatanos/Stein Gulbrandsen/Morten J\u00f8rgensen)\\n\\nMedvirkende\\n\\nLumbago\\n Morten J\u00f8rgensen - sang, flersang, orgel, flakse, casio vi-tone, l\u00e5tskriver\\n Thanasis Zlatanos - vokal p\u00e5 Sammen igjen, gitarer, synthesizer, kor, emt-bombe, l\u00e5tskriver, fotograf, coverdesign\\n Stein Gulbrandsen - bass, kontrabass, piano, synthesizer, kor, l\u00e5tskriver\\n Trond Armand Larsen - trommer, perkusjon, marimba, vibrafon, casio vi-tone, orgel, programmering, kor, l\u00e5tskriver\\n\\n\u00d8vrige\\n Trygve Mathiesen - flersang p\u00e5 Pene jenter og I gata der du bor, coverdesign \\n Anne Sandborg, Carl Otto Platou, Eva Storevik Tveit, Hilde Norrgr\u00e8n, Ivar Eidem, Mona Eggehagen, Tom Trussel, Cecilie, Geir, Ida, Ina, Ivan, Joachim, K. Udzen, Katja, Maijana, Mala og Martin - bakgrunnvokal p\u00e5 I gata der du bor\\n Marilena Zlatanou - gresk oversettelse p\u00e5 Sammen igjen\\n Nils Bjarne Kvam - produsent, miksing\\n Hans Petter Danielsen - tekniker\\n Tore Tambs Lyche - tekniker \\n Ivar Finsen - tekniker\\n Rune Nordal - miksing \\n Bitte Petersen - fotograf\\n Gunnhild Bakke - fotograf\\n Jan Walaker - fotograf\\n Trond Davidsen - fotograf\\n Ole Sch\u00f8ning - coverdesign\\n\\nEksterne lenker \\n\\nMusikkalbum fra 1981\\nLumbago-album\",\n    \"question\": \"N\u00e5r kom Cabaret Marzipan ut?\",\n    \"answers\": {\n        \"answer_start\": array([99]),\n        \"text\": array([\"1981\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Dagligvarehandelen er en frittst\u00e5ende ukeavis for dagligvarebransjen og distribueres til alle landets dagligvareforretninger og kjedekontorer samt kiosker og bensinstasjoner med dagligvarer i sortimentet.\\n\\nLesere er ledere og mellomledere hos leverand\u00f8rer, agenter og kjedekontorer i dagligvarebransjen, samt PR- og informasjonsr\u00e5dgivere og reklame- og formidlingsbyr\u00e5er. Nettutgaven er et verkt\u00f8y for alle leverand\u00f8rer av produkter og tjenester til dagligvarebransjen. M\u00e5lgruppen er alle som driver butikk, enten de er selvstendige, ansatte eller franchisetakere. Dagligvarehandelen er et av Nordens mest leste fagtidsskrifter.\\n\\nUtgiver er Medier og Ledelse AS, og ansvarlig redakt\u00f8r er Are Knudsen. Daglig leder er Magne Ler\u00f8.\\n\\nPublikasjoner\\n\\nHvem er hvem gir en oversikt over hovedkontorer og kjeder i de sentrale grupperingene i dagligvare detalj i Norge og Norden, samt de viktigste akt\u00f8rene i kiosk, \u2013 bensin og servicemarkedet. Her finner man adresser, telefonnummer etc. samt aktuelle kontaktpersoner i de ulike kjedene. Hvem er hvem benyttes som oppslagsverk i alle ledd i bransjen.\\n\\nTemanumre tar opp aktuelle saker i bransjen og varierer fra \u00e5r til \u00e5r. De distribueres sammen med Dagligvarehandelen til alle dagligvareforretninger, kjedekontorer samt kiosker og bensinstasjoner med dagligvarer i sortimentet.\\n\\nReferanser\\n\\nEksterne lenker\\n Dagligvarehandelens hjemmeside\\n\\nNorske tidsskrifter\\nDagligvarehandel\",\n    \"question\": \"Hvem har den daglige ledelsen av Dagligvarehandelen?\",\n    \"answers\": {\n        \"answer_start\": array([717]),\n        \"text\": array([\"Magne Ler\u00f8\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Timothy Evans (f\u00f8dt 20. november 1924 i Merthyr Tydfil i South Wales, d\u00f8d 9. mars 1950 ved henging) var en waliser anklaget for mordet p\u00e5 sin kone og datter under et opphold i Notting Hill, London i november 1949. I januar 1950 ble Evans d\u00f8mt for drapet p\u00e5 datteren sin, og han ble d\u00f8mt til d\u00f8den ved henging p\u00e5 grunn av dette. \\n\\nUnder rettssaken, hadde Evans anklaget naboen, John Christie, for \u00e5 v\u00e6re ansvarlig for begge drapene. Tre \u00e5r etter Evans sin rettssak og henging, ble det oppdaget at Christie var en seriemorder som hadde myrdet en rekke kvinner p\u00e5 hans egen eiendom, inkludert hans egen kone, og disse oppdagelsene kastet alvorlig tvil om dommen mot at Timothy Evans var riktig. En offisiell unders\u00f8kelse som ble foretatt seksten \u00e5r etter at Evans ble hengt bekreftet at Evans sin datter var blitt myrdet av Christie, og Evans ble deretter gitt en posthumt ben\u00e5dning. Denne saken genererte mye kontrovers og ble senere anerkjent som et justismord. Dette spilte en stor rolle i avskaffelsen av endelig d\u00f8dsstraff i Storbritannia. \\n\\nHans biologiske far forlot familien i 1924 kort tid f\u00f8r Evans ble f\u00f8dt. Evans hadde en eldre s\u00f8ster Eileen og en yngre halvs\u00f8ster Maureen, som ble f\u00f8dt etter at Evans mor giftet seg for andre gang i 1929. Som barn, hadde Evans problemer med \u00e5 l\u00e6re \u00e5 snakke og han slet p\u00e5 skolen. Etter en ulykke da han var \u00e5tte \u00e5r, utviklet Evans en tuberkul\u00f8s verucca p\u00e5 hans h\u00f8yre fot som aldri ble helt bra igjen, og som gjorde at han gikk glipp av betydelige mengder tid fra skolen p\u00e5 grunn av flere omfattende behandlinger. Derfor klarte han verken \u00e5 lese eller skrive noe utover hans eget navn som voksen. Som barn, ble Evans ansett for \u00e5 ha et d\u00e5rlig temperament og han hadde flere raserianfall. \\n\\nDen 20. september 1947 giftet Evans seg med Beryl Susanna Thorley, som han hadde m\u00f8tt gjennom en felles venn av dem. Timothy og Beryl fikk datteren Geraldine som ble f\u00f8dt 10. oktober 1948. Deres ekteskap var preget av flere store krangler, forsterket av Beryl sitt d\u00e5rlige renhold og manglende evne til \u00e5 h\u00e5ndtere familiens \u00f8konomi. Timothy fikk etter hvert st\u00f8rre og st\u00f8rre problemer hans tunge drikking som forverret hans allerede korte temperament. \\n\\nP\u00e5 slutten av 1949, ble Beryl ut at hun var gravid med deres andre barn. Siden familien allerede slet \u00f8konomisk, bestemte Beryl seg for at det eneste valget var \u00e5 ta abort, og etter noe motvilje, godtok Evans denne beslutningen. Flere uker senere, 30. november 1949, informerte Evans politiet at han hadde drept sin kone. Hans f\u00f8rste tilst\u00e5else var at han hadde ved et uhell hadde drept henne ved \u00e5 gi henne noe i en flaske som en mann hadde gitt til ham for \u00e5 avbryte graviditeten. Deretter skal han ha kastet liket i en kloakk i n\u00e6rheten av hjemmet deres, men politiet fant ingenting p\u00e5 det angitte stedet i kloakk-systemet og forklaringen ble ikke godtatt som ekte. Til tross for flere svake indisier brukte juryen bare 40 minutter p\u00e5 \u00e5 finne Evans skyldig i drapene p\u00e5 hans kone og barn.\\n\\nReferanser \\n\\nBriter d\u00f8mt for forbrytelser\\nWalisere\\nPersoner som har blitt ben\u00e5det\\nPersoner d\u00f8mt for drap\\nPersoner utsatt for justismord\\nHenrettede personer\",\n    \"question\": \"Hvem var den seriemorderen som bodde i Evans' nabolag?\",\n    \"answers\": {\n        \"answer_start\": array([377]),\n        \"text\": array([\"John Christie\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 2</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger tekster med tilh\u00f8rende sp\u00f8rsm\u00e5l og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nSp\u00f8rsm\u00e5l: {question}\nSvar p\u00e5 maks 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l om teksten ovenfor med maks 3 ord.\n\nSp\u00f8rsm\u00e5l: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-nb\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-multiwikiqa-nn","title":"Unofficial: MultiWikiQA-nn","text":"<p>This dataset will be published in an upcoming paper, and contains Norwegian Nynorsk Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Peter H\u00f8eg () er ein dansk forfattar, som vart verdskjend med romanen Fr\u00f8ken Smillas fornemmelse for sne (1992).\\n\\nLiv og forfattarskap \\nH\u00f8eg er oppvaksen i K\u00f8benhavn, kor han i 1984 vart ferdigutdanna som mag. art. i litteraturvitskap. Etter ein omflakkande periode som m.a. globetrotter, idrettsl\u00e6rar og dansar debuterte H\u00f8eg i 1988 med Forestilling om det tyvende \u00e5rhundret p\u00e5 Rosinante forlag. Romanen, som er ein sterkt fabulerande slektskr\u00f8nike, ber tydelege spor av s\u00f8ramerikansk magisk realisme og tiltrekte seg relativt stor merksemd allereie ved utgjevinga. I 1990 kom Fort\u00e6llinger om natten ut, 9 noveller med tematisk samanheng, og med denne utgjevinga vart H\u00f8eg snart omtalt som eit forfattartalent med internasjonalt potensiale. Det endelege nybrottet lot ikkje venta p\u00e5 seg.\\n\\nI 1992 kom kriminalromanen Fr\u00f8ken Smillas fornemmelse for sne ut, eit portrett av den dansk-gr\u00f8nlandske glasiologen Smilla. Romanen sementerer H\u00f8egs f\u00f8retrekte tema og understrekar sympatiane i forfattarskapen for det kvinnelege prinsippet, for barnet og dei marginaliserte, samtidig som han byr p\u00e5 ein god del kritikk av den vestlege sivilisasjon sin imperialisme og vitskapen sin maktmisbruk.\\n\\nH\u00f8eg vart rost til skyane for sin store fortellerevne, sin spr\u00e5klege evne og selde no uh\u00f8yrt mange b\u00f8ker samanlikna med danske standardar, men s\u00e6rleg med utgjevinga av De m\u00e5ske egnede (1993) begynte kritikken \u00e5 dukka opp. Omtalarar anklaga H\u00f8egs forfattarskap for politisk korrektheit, f\u00f8reseieleg sivilisasjonskritikk og lettkj\u00f8pt frelstheit. Med n\u00e6rskyld sivilisasjonskritisk tematikk kunne romanen Kvinnen og aben (1996) alt anna enn retta opp i dette, samtidig som stiftinga av fondet Lolwe til st\u00f8tte for kvinner og born i Den tredje verda ikkje just fekk kritikken til \u00e5 tagna. Etter Kvinnen og aben lot forfattaren ikkje h\u00f8yra meir fr\u00e5 seg utanom eit enkelt, personleg dikt med tittelen F\u00f8rste og siste kapitel i antologien Trykt - og godt (1998) til H\u00f8egs forleggar og n\u00e6re ven, Merethe Riis. I staden trekte H\u00f8eg seg heilt tilbake fr\u00e5 det offentlege rampelyset. I ei \u00e5rrekke budde han ved Vekstsenteret i N\u00f8rre Snede, eit spirituelt treningssenter med undervisning i meditativ praksis og sj\u00f8lvutvikling.\\n\\nTrass kritikken vert forfattarskapen hans end\u00e5 stadig rekna for vesentleg, og noko tyder p\u00e5 at det m\u00f8ter fornya interesse. S\u00e5leis kom forfattarskapsportrett Apa si poetikk ut v\u00e5ren 2005, ein kronologisk litteraturvitskapleg kritikk av H\u00f8egs tekstar. Sj\u00f8lv gav forfattaren, etter 10 \u00e5rs skj\u00f8nnlitter\u00e6r tagnad, ut romanen Den stille jenta i mai 2006.\\n\\nI 2010 gav Peter H\u00f8eg ut romanen Elefantpassernes b\u00f8rn.\\n\\nN\u00e6rframtidsromanen Effekten av Susan (2014) trekker, med sin bruk av ei sterk kvinne med spesielle evnar som hovudfigur, linjer tilbake til 'Smilla'.\\n\\nPrisar \\nPeter H\u00f8eg har teke i mot mange litter\u00e6re prisar, mellom dei: \\n Weekendavisens litteraturpris (1988)\\n Kritikarprisen (1993)\\n Herman Bangs Mindelegat (1993) \\n De Gyldne Laurb\u00e6r (1994).\\n Glassn\u00f8kkelen for Smillas fornemmelse for sne\\n\\nFilmatisering \\nI 1997 filmatiserte Bille August Fr\u00f8ken Smillas fornemmelse for sne. Filmen vart ein fiasko, b\u00e5de i omtalene og i salstala.\\n\\nBibliografi \\n Forestilling om det tyvende \u00e5rhundre (1988)\\n Fortellinger om natten (1990)\\n Fr\u00f8ken Smillas fornemmelse for sne (1992)\\n De m\u00e5ske egnede (1993)\\n Kvinnen og apen (1996)\\n Den stille piken (2006)\\n Elefantpassernes b\u00f8rn (2010)\\n Effekten af Susan (2014)\\n Gennem dine \u00f8jne (2018)\\n\\nKjelder \\n\\nDanske romanforfattarar\\nStatens Kunstfonds h\u00e6dersydelse\\nFolk fr\u00e5 K\u00f8benhavn\\nVinnarar av Glassn\u00f8kkelen\",\n    \"question\": \"Kven laga filmen basert p\u00e5 Fr\u00f8ken Smillas kjensle for sn\u00f8?\",\n    \"answers\": {\n        \"answer_start\": array([3033]),\n        \"text\": array([\"Bille August\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"For den tidlegare kyrkja i Eidsberg, sj\u00e5 Hen kyrkje i Eidsberg\\nHen kyrkje ligg sentralt i bygda Isfjorden i Rauma kommune.\\n\\nKyrkja vart bygd i 1831 av gr\u00e5stein, tak-konstruksjonen og klokket\u00e5rnet er av treverk.\\n\\nKyrkja er bygd p\u00e5 den same plassen der ei eldre kyrkje stod f\u00f8r. Denne var i s\u00e5 d\u00e5rleg tilstand at ho m\u00e5tte rivast. Ei gammal kyrkjeklokke fr\u00e5 1200-talet er bevart og er i dag p\u00e5 Romsdalsmuseet p\u00e5 Molde.\\n\\nInteri\u00f8ret\\nPreikestolen som vert brukt i dag er fr\u00e5 1930-\u00e5ra.\\n\\nAltertavla vart laga til kyrkja i 1831. Ein eldre preikestol, som ikkje er i bruk, er plassert midt i altertavla. D\u00e5 kyrkja vart restaurert i 1931, m\u00e5la Halvard Hatlen eitt nytt bilde i altertavla. \\n\\nElles finst det eit rosem\u00e5la skap fr\u00e5 1788. Halvard Hatlen har m\u00e5la seks portrett av tidlegare prestar. Desse heng langs langveggane. Han har \u00f2g m\u00e5la et m\u00e5leri (1942), som heng i koret.\\n\\nKjelde\\n Thaule, John Ove; Ubostad, Ingar; Pedersen, Bj\u00f8rn. 1990. Kyrkjene v\u00e5re i Ei bok om Rauma, Rauma Kommune. s 207-210\\n\\nBakgrunnsstoff\\n \\n\\nKyrkjer i Rauma\\nKyrkjer i Indre Romsdal prosti\\nKulturminne i Rauma\\nNorske kyrkjer fr\u00e5 1831\\nLangkyrkjer i M\u00f8re bisped\u00f8mme\",\n    \"question\": \"N\u00e5r vart rosem\u00e5lingane i Hen kyrkje laga?\",\n    \"answers\": {\n        \"answer_start\": array([718]),\n        \"text\": array([\"1788\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Christophorus Clavius (f\u00f8dd Christoph Klau 1537/38 i Bamberg i Tyskland, d\u00f8d 1612 i Roma) var ein tysk matematikar, astronom og jesuittpater p\u00e5 1500-talet. I samtida vart han kalla \u00abkongen av matematikken\u00bb, og vart framf\u00f8rt alt kjend for arbeidet sitt ved det vatikanske stjerneobservatoriet som f\u00f8rte til utviklinga av det nye kalendersystemet som vart kalla opp etter pave Gregor XIII, den gregorianske kalenderen. \\n\\nClavius tredde inn i jesuittordenen i 1555 og fekk utdanninga si i ordenen. Ved jesuittane sitt Collegio Romano i Roma studerte han teologi og underviste deretter matematikk der i ein lang periode. Clavius forfatta fleire matematikkb\u00f8ker og medverka slik til utviklinga av matematikken. Ein vidt utbreidd kommentar til euklidsk geometri stammer fr\u00e5 han. Clavius medverka \u00f2g til teorien for prostaferese, ein reknemetode som var ein forl\u00f8par for logaritmane. Verka hans kom ut i 1612 i Mainz i fem band.\\n\\nM\u00e5nekrateret Clavius er kalla opp etter han.\\n\\nKjelder\\nDenne artikkelen bygger p\u00e5 \u00abChristophorus Clavius\u00bb fr\u00e5 ,  den 1. november 2011.  \\n \\n\\nF\u00f8dde i 1530-\u00e5ra\\nD\u00f8de i 1612\\nFolk fr\u00e5 Bamberg\\nTyske katolske prestar\\nTyske matematikarar\\nTyske astronomar\\nTyske jesuittar\\nMatematikarar p\u00e5 1500-talet\\nMatematikarar p\u00e5 1600-talet\",\n    \"question\": \"Kva f\u00f8dsels\u00e5r hadde Clavius?\",\n    \"answers\": {\n        \"answer_start\": array([43]),\n        \"text\": array([\"1537/38\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 2</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger tekster med tilh\u00f8rende sp\u00f8rsm\u00e5l og svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Tekst: {text}\nSp\u00f8rsm\u00e5l: {question}\nSvar p\u00e5 maks 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Tekst: {text}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l om teksten ovenfor med maks 3 ord.\n\nSp\u00f8rsm\u00e5l: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-nn\n</code></pre>"},{"location":"datasets/norwegian/#knowledge","title":"Knowledge","text":""},{"location":"datasets/norwegian/#nrk-quiz-qa","title":"NRK Quiz QA","text":"<p>This dataset was published in this paper and is a multiple-choice question answering (QA) dataset designed for evaluation of the Norwegian language and culture, including both Bokm\u00e5l and Nynorsk. The dataset consists of quizzes from NRK, the national public broadcaster in Norway.</p> <p>The original dataset contains 4,930 samples, spread across 549 quizzes. We keep the top-256 quizzes, allowing us to create splits stratified across all the remaining quizzes. We 635 / 256 / 2048 samples for training, validation and test, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Gunnar har hatt plutselige og sterke smerteanfall siden han var liten gutt. Det var vondt \u00e5 tisse og det gjorde vondt i ryggen og magen. Det hjalp litt \u00e5 drikke vann. Reseptbelagte medisiner kan v\u00e6re n\u00f8dvendig under anfall.\\nSvaralternativer:\\na. Nyrestein, kronisk\\nb. Irritabel tarmsyndrom\\nc. Angst\\nd. Urinveisinfeksjon\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"80 \u00e5r gamle Harrison Ford er nok ein gong aktuell i rolla som Indiana Jones. Kva heiter filmen?\\nSvaralternativer:\\na. Indiana Jones and the Nasty Nazis\\nb. Indiana Jones and the Dial of Destiny\\nc. Indiana Jones and the Hunt for Power\\nd. Indiana Jones Forever\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"I 1980 m\u00e5tte denne bassisten overnatte ni netter i fengsel i Japan fordi han pr\u00f8vde \u00e5 f\u00e5 med seg ca. 200 gram marihuana inn i landet. Hvem var det?\\nSvaralternativer:\\na. Sting\\nb. Lemmy Kilmister\\nc. Paul McCartney\\nd. Bootsy Collins\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c', eller 'd', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset nrk-quiz-qa\n</code></pre>"},{"location":"datasets/norwegian/#idioms-no","title":"Idioms-no","text":"<p>This dataset was published here and consists of 3,553 Norwegian idioms and phrases that appear more than 100 times in the online library of the National Library of Norway.</p> <p>We have reformulated the dataset as a multiple-choice question format with 4 options, where the alternative answers have been generated using GPT-4o. Based on 3,232 samples (3,144 Bokm\u00e5l, 88 Nynorsk) from the original dataset, we use a 928 (27 Nynorsk) / 256 (11 Nynorsk) / 2,048 (50 Nynorsk) split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Complete the Nynorsk idiom:\\nalle gode ting er _____\\n\\nSvaralternativer::\\na. s\u00f8te\\nb. tre\\nc. fire\\nd. vennlege\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Complete the Bokm\u00e5l idiom:\\ndet er ikke bare , _____\\n\\nSvaralternativer::\\na. moro\\nb. bare\\nc. lett\\nd. enkelt\",\n  \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Complete the Bokm\u00e5l idiom:\\ndet f\u00e5r st\u00e5 sin _____\\n\\nSvaralternativer::\\na. pr\u00f8ve\\nb. vegg\\nc. sak\\nd. greie\",\n  \"label\": \"a\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c' eller 'd', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset idioms-no\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-mmlu-no","title":"Unofficial: MMLU-no","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Norwegian was conducted using the DeepL translation API.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hvorfor er Mahavira en viktig person i jainatradisjonene?\\nSvaralternativer:\\na. Han er den siste av de asketiske profetene.\\nb. Han er den f\u00f8rste av de asketiske profetene\\nc. Han er den mest l\u00e6rde av de asketiske profetene\\nd. Han er den helligste av de asketiske profetene\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En enfaset fullbroomformer kan drives i lastkommuteringsmodus hvis belastningen best\u00e5r av\\nSvaralternativer:\\na. RL.\\nb. RLC underdempet.\\nc. RLC overdempet.\\nd. RLC kritisk dempet.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En professor, som var eneeier av en boligblokk, skrev et skj\u00f8te med f\u00f8lgende ordlyd: \\\"Jeg overdrar herved min boligblokk til min s\u00f8nn og datter som leietakere i fellesskap.\\\" I skj\u00f8tet, som var korrekt utferdiget, forbeholdt professoren seg en livsvarig eiendomsrett. Professoren fortalte deretter barna sine om overdragelsen og la den i familiehvelvet i biblioteket for oppbevaring. Deretter giftet s\u00f8nnen seg med en lege. Professoren, som mislikte legen, utferdiget deretter et nytt skj\u00f8te som han kalte \\\"et korreksjonsskj\u00f8te\\\". I \\\"korreksjonsskj\u00f8tet\\\" overf\u00f8rte professoren byg\u00e5rden \\\"til min s\u00f8nn og datter som sameiere med overlevelsesrett.\\\" If\u00f8lge det nye skj\u00f8tet forbeholdt professoren seg igjen livsvarig eiendomsrett. Begge barna aksepterte overdragelsen av \\\"korreksjonsskj\u00f8tet.\\\" Et halvt \u00e5r senere d\u00f8de s\u00f8nnen, og etterlot seg legen som eneste arving. Eiendomsretten til boligblokken er i datterens og\\nSvaralternativer:\\na. datteren og legen som sameiere.\\nb. datteren med forbehold om professorens livstidsarv.\\nc. datteren og legen som sameiere, med forbehold om professorens livsarvinger.\\nd. datteren og legen som sameiere med overlevelsesrett, med forbehold for professorens livsarvinger.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c' eller 'd', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-no\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-arc-no","title":"Unofficial: ARC-no","text":"<p>This dataset is a machine translated version of the English ARC dataset and features US grade-school science questions. The translation to Norwegian was conducted using the DeepL translation API.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hvorfor er det tryggere \u00e5 se p\u00e5 m\u00e5nen enn p\u00e5 solen?\\nSvaralternativer:\\na. M\u00e5nen er mindre lyssterk.\\nb. M\u00e5nen er n\u00e6rmere jorden.\\nc. M\u00e5nen skinner mest om natten.\\nd. M\u00e5nen er full bare \u00e9n gang i m\u00e5neden.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvilket av f\u00f8lgende er et biprodukt av celle\u00e5nding hos dyr?\\nSvaralternativer:\\na. oksygen\\nb. varme\\nc. sukker\\nd. protein\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Big Bang-teorien sier at universet\\nSvaralternativer:\\na. trekker seg sammen.\\nb. ikke har noen begynnelse.\\nc. startet som \u00e9n enkelt masse.\\nd. hele tiden danner hydrogen.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c' eller 'd', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset arc-no\n</code></pre>"},{"location":"datasets/norwegian/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/norwegian/#norcommonsenseqa","title":"NorCommonSenseQA","text":"<p>This dataset was published in this paper and is a manually translated and localised version of the English CommonSenseQA dataset. There are samples in both Bokm\u00e5l and Nynorsk, but with the vast majority being Bokm\u00e5l.</p> <p>The original dataset contains 1,093 samples. We use a 128 / 128 / 787 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Hvor er det sannsynlig at en fugl lager hjemmet sitt?\\nSvaralternativer:\\na. I skogen\\nb. I et rede\\nc. P\u00e5 taket\\nd. P\u00e5 blader\\ne. I himmelen\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hvis et hjem har et abonnoment, hva f\u00e5r de sannsyneligvis hver dag i posten?\\nSvaralternativer:\\na. Delestykker\\nb. En avis\\nc. En gate\\nd. En vaskemaskin\\ne. Jordas overflate\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"N\u00e5r du ikke klarer \u00e5 gj\u00f8re noe ferdig, hva feilet du i da?\\nSvaralternativer:\\na. \u00c5 vinne\\nb. \u00c5 best\u00e5\\nc. \u00c5 fullf\u00f8r\\nd. \u00c5 gj\u00f8re det bra\\ne. \u00c5 lykkes\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\ne. {option_e}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\ne. {option_e}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c', 'd' eller 'e', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset nor-common-sense-qa\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-hellaswag-no","title":"Unofficial: HellaSwag-no","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated to Norwegian using the DeepL translation API.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[header] Slik holder du deg kj\u00f8lig og f\u00f8ler deg frisk om sommeren [title] Dusj hver dag. [step] Bruk en eksfolierende dusjs\u00e5pe for \u00e5 fjerne smuss. Sett vannet p\u00e5 varmt i starten av dusjen (fordi det rengj\u00f8r deg mer effektivt), men mot slutten av dusjen setter du vannet p\u00e5 lunkent eller kj\u00f8lig.\\nSvaralternativer:\\na. Dette senker kroppstemperaturen slik at du f\u00f8ler deg kj\u00f8ligere (og v\u00e5kner opp om morgenen!). [Sm\u00f8r deg med fuktighetskrem rett etter at du har g\u00e5tt ut av dusjen.\\nb. P\u00e5f\u00f8r denne gelen p\u00e5 svetten under armene eller p\u00e5 kroppen. Tenk p\u00e5 det som \u00e5 spyle den ene armhulen med vann (du kan lage din egen dusjs\u00e5pe med armene eller bena, og du kan vaske av deg litt med en gang).\\nc. Alternativt kan du \u00e5pne d\u00f8ren og la kj\u00f8lig vann str\u00f8mme gjennom det \u00e5pne vinduet i minst en time. [Bruk en ansiktsmaske mens du dusjer.\\nd. Vannet skal v\u00e6re varmt nok til \u00e5 skylle ut smuss og d\u00f8d hud som henger over ansiktet. P\u00e5f\u00f8r kroppss\u00e5pe (eller la den v\u00e6re \u00e5pen for lufting) p\u00e5 hudoverflaten i korte riller.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En l\u00f8per l\u00f8per p\u00e5 en bane foran en folkemengde. en mann\\nSvaralternativer:\\na. kaster en ball som hunden skal fange.\\nb. snakker til kameraet.\\nc. l\u00f8per ikke n\u00e5r han hopper ned i en sandkasse.\\nd. gir en kort introduksjon f\u00f8r han fortsetter og konkurrerer mot mannen i svart.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] Slik vet du om hunden din liker deg best [title] Legg merke til at hunden din f\u00f8lger mye etter deg. [En m\u00e5te \u00e5 bevise at en hund liker deg best, er n\u00e5r den er mye sammen med deg. S\u00e5 hold \u00f8ye med om hunden din liker \u00e5 v\u00e6re i n\u00e6rheten av deg.\\nSvaralternativer:\\na. [Hold \u00f8ye med eventuell fysisk atferd. [Et godt eksempel p\u00e5 denne atferden er hvis den presser rumpa opp mot l\u00e5ret ditt og sjekker hva du har p\u00e5 deg.\\nb. [Se etter tegn p\u00e5 at hunden din kan v\u00e6re fl\u00f8rtende. [Et godt tegn p\u00e5 at hunden din liker deg er at den klapper deg mye eller stirrer p\u00e5 deg i intime \u00f8yeblikk.\\nc. [Finn ut om hunden din liker \u00e5 leke med deg. [Hvis det er en hund som elsker leker, kan du leke med dem, og hvis den er veldig glad i \u00e5 leke, s\u00e5 liker den at du leker med den.\\nd. Legg merke til at hunden din f\u00f8lger deg rundt i huset hver dag n\u00e5r du er ute og g\u00e5r. Selv om du kanskje ikke har lyst til det, kan det \u00e5 tilbringe mye tid sammen med en hund f\u00e5 den til \u00e5 f\u00f8le seg komfortabel med deg.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f8lgende er flervalgssp\u00f8rsm\u00e5l (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Sp\u00f8rsm\u00e5l: {text}\nSvaralternativer:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvar f\u00f8lgende sp\u00f8rsm\u00e5l med 'a', 'b', 'c' eller 'd', og ikke noe annet.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-no\n</code></pre>"},{"location":"datasets/norwegian/#summarization","title":"Summarization","text":""},{"location":"datasets/norwegian/#nosammendrag","title":"NoSammendrag","text":"<p>This dataset is a combination of the SNL and VG summarisation datasets as well as a translated version of the English XSum dataset, based on British BBC news articles. The SNL dataset is based on the Norwegian encyclopedia Store Norske Leksikon, while the VG dataset is based on the Norwegian articles from the newspaper VG. The translation of the XSum dataset was done using the NLLB model.</p> <p>The original full dataset consists of 472,000 samples, and we use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"P\u00e5 Akvariet i Bergen har pingvinene f\u00e5tt et ekstra fristende sommertilbud denne uken. \u2013 Vi fikk en litt artig id\u00e9, og bestemte oss for \u00e5 gi pingvinene v\u00e5re en slags \u00abslush-is\u00bb i g\u00e5r. Det ble til en morsom aktivisering for pingvinene, og det falt virkelig i god smak hos dem, sier dyrepasser Jannicke Johannessen. Hun forteller at de eldre pingvinene f\u00f8rst var litt skeptiske, og at det var de yngste som ledet an i isleken. \u2013 Ett- og to\u00e5ringene var veldig interesserte da vi kom ut med isen, og hoppet opp p\u00e5 den og storkoste seg. En av pingvinene ble faktisk liggende opp\u00e5 isen helt til den smeltet, ler hun. Hun forteller at isen falt i s\u00e5 god smak, at de skal gjenta suksessen l\u00f8rdag, slik at flere gjester i parken ogs\u00e5 kan f\u00e5 med seg aktiviteten.Selv om sommeren har satt flere varmerekorder i hele landet, forteller Johannessen at dyrene i Akvariet slettes ikke har lidd noen n\u00f8d. \u2013 Vi har California-sj\u00f8l\u00f8ver, som overhodet ikke har hatt noen problemer med varmen. Tvert imot, de elsker \u00e5 ligge \u00e5 sole seg. Vi har ogs\u00e5 europeiske otere, som takler klimaet godt, da det er dyr man finner naturlig i s\u00f8rlige deler av Europa. Dessuten er vi ekstremt heldige her p\u00e5 Akvariet, og pumper opp nytt saltvann hele tiden, og dyrene har mange muligheter til \u00e5 kj\u00f8le seg ned p\u00e5. Hun gir imidlertid et viktig r\u00e5d til dyreeiere som vil kj\u00f8le ned dyrene sine: \u2013 Jeg har f\u00e5tt med meg at folk gir is som hundene kan spise for eksempel, og det er ikke akkurat et sjakktrekk. N\u00e5r man kj\u00f8ler ned dyrene fra innsiden samtidig som det er veldig varmt ute, tuller det med kroppstemperaturen. Kroppen jobber for \u00e5 varme opp innsiden samtidig som de f\u00e5r varme utenfra. Du gir dem egentlig et heteslag, sier hun. \u2013 Det beste er \u00e5 kj\u00f8le dem ned p\u00e5 utsiden. Dusj dem under \u00abarmhulene\u00bb, eller generelt der de har tynn hud.Ogs\u00e5 i Tyskland har det v\u00e6rt h\u00f8ye temperaturer i sommer, og dyrepassere har m\u00e5ttet ta grep for \u00e5 avkj\u00f8le dyrene i varmen. I Osnabr\u00fcck, nord i landet, ble det registrert rundt 35 varmegrader onsdag. For tapirene i dyrehagen ble maten strategisk servert i skyggen, slik at dyrene ikke blir solbrent. Dyrepasser Daniel Chirico bestemte seg dessuten for \u00e5 spyle tapirene med en hageslange, for \u00e5 kj\u00f8le dem ned ytterligere. \u2013 Spesielt de nordiske artene i dyreparken har merket heteb\u00f8lgen, og tilbringer mesteparten av dagen i skyggen, sier Tobias Klumpe, biolog i Osnabr\u00fcck Zoo til den tyske avisen Osnabr\u00fccker Zeitung . Svartbj\u00f8rnene tar mer enn gjerne en kald dukkert i sola, samtidig som de nyter kalde forfriskninger med frukt og b\u00e6r.I Finland har ogs\u00e5 sommervarmen sl\u00e5tt inn for fullt. I Korkeasaari Zoo i Helsinki ble det torsdag registrert 30 varmegrader. L\u00f8sningen har blant annet v\u00e6rt \u00e5 installere en \u00abregnskog\u00bb for kenguruene, mens papeg\u00f8yene har f\u00e5tt egne dusjer de kan bruke. Bj\u00f8rnene har f\u00e5tt iskald vannmelon, som de nyter i det kalde vannet, og tigerne f\u00e5r frosne kaniner \u2013 s\u00e5fremt de faktisk \u00f8nsker \u00e5 spise. \u2013 Appetitten deres blir mindre i varmen. For eksempel spiser hunnene i snitt bare annenhver dag, sier dyrepasser Jonne Stenroth til den finske avisen MTV . Ellers tilbringer tigrene mesteparten av dagen i skyggen mens de slapper av i bassenget, skriver avisen.\",\n  \"target_text\": \"Mens solen skinner og temperaturene er som h\u00f8yest, tar dyreparker rundt om i Europa i bruk kreative l\u00f8sninger for \u00e5 holde dyrene avkj\u00f8lte.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Nick Corsellis, advokat for Carl Wood, sa at en \\\"innend\u00f8rs mann\\\" m\u00e5 ha v\u00e6rt involvert i razzia, men hans klient manglet ekspertise til \u00e5 v\u00e6re den personen. Mr Wood og tre andre menn nekter \u00e5 ha deltatt i \u00a3 14m r\u00f8veriet. Fire andre har allerede erkl\u00e6rt seg skyldig for deres roller i r\u00f8veriet. \\\"Og dette er en av grunnene til at Mr. Wood ikke er skyldig. Hva tok han med seg til bordet?\\\" sa han. Mr. Corsellis sa at det ikke fulgte at hans klient var mannen som ble identifisert av anklagemyndigheten som \\\"Man F\\\" i CCTV-opptak av razzia. \\\"Male F var faktisk en spiller. En innsider, eller knyttet til innsiden, som var fullt kjent med det indre arbeidet i Hatton Garden Safe Deposit\\\". Mr. Wood manglet slik kunnskap og ville bare ha v\u00e6rt i stand til \u00e5 fungere som en \\\"generell hundekrop\\\", sa advokaten. Corsellis spurte juryen om profesjonelle kriminelle ville v\u00e6rt forberedt p\u00e5 \u00e5 gi opp en del av sine millioner til en person som bare ville ha v\u00e6rt et \\\"ekstrapar hender (EPH)\\\". Han kalte det \\\"ilogisk\\\" og \\\"utrolig\\\" at en slik person var involvert da \\\"kriminelle ikke er veldedig folk\\\". \\\"Men hvem ville spille Carl Wood - EPH? Tror du at Mr. Tom Hardy eller Mr. Vinnie Jones vil haste \u00e5 ta rollen som... EPH?\\\" spurte han.\",\n  \"target_text\": \"En av mennene som er anklaget for \u00e5 v\u00e6re en del av Hatton Garden-raiden, kunne ikke ha v\u00e6rt involvert fordi han manglet noen ferdigheter \u00e5 tilby gjengen, har en domstol h\u00f8rt.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Verdenshjelpen forlot klubben i fjor p\u00e5 grunn av arbeids- og studietilbud, pluss behovet for \u00e5 komme seg fra en ryggskade. Manager Jamie Sherwood sa til klubbens nettside: \\\"Jeg er virkelig glad for \u00e5 ha brakt Natalie tilbake til klubben. \\\"Hennes erfaring, lederskap og \u00e5penbare evne blir et utmerket tillegg til v\u00e5r tropp for 2017\\\". Haigh la til: \\\"Etter skaden jeg fikk p\u00e5 ryggen for nesten 15 m\u00e5neder siden, trodde jeg aldri at jeg ville spille igjen, enn si p\u00e5 dette niv\u00e5et. \\\"Det er flott \u00e5 v\u00e6re tilbake i og rundt klubben - det er en ekte buzz etter den suksessen de oppn\u00e5dde i fjor\\\".\",\n  \"target_text\": \"Yeovil Town Ladies har gjenforenet tidligere kaptein Natalie Haigh f\u00f8r damer Super League One klubbens f\u00f8rste sesong i toppklassen.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger nyhetsartikler med tilh\u00f8rende sammendrag.\n</code></pre></li> <li>Base prompt template:   <pre><code>Nyhetsartikkel: {text}\nSammendrag: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Nyhetsartikkel: {text}\n\nSkriv et sammendrag av den ovennevnte artikkelen.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset no-sammendrag\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-norglm-multi-sum","title":"Unofficial: NorGLM Multi Sum","text":"<p>This dataset was released in this paper and features a manually annotated summarisation dataset based on Norwegian news articles.</p> <p>The original dataset contains 467 samples, which we split into 147 / 64 / 256 samples for training, validation and test, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \" En sel i England ble fanget i plast. Det kunne g\u00e5tt galt. Hver dag blir ogs\u00e5 dyr i Norge fanget i plast. Et vondt syn m\u00f8tte nylig dyrevernere p\u00e5 en strand i England. Der l\u00e5 en sel som hadde tuklet seg inn i plast. Det kunne g\u00e5tt veldig galt.\u2013 Det var tydelig at selen hadde det vondt, forteller en kvinne som s\u00e5 selen p\u00e5 stranden, til kanalen BBC.Men dyrlegene fra den britiske dyrevernsorganisasjonen BDMLR kom heldigvis i tide. De klarte \u00e5 fri selen fra plasten. Selen ble sluppet tilbake i sj\u00f8en.Heldigvis ble ikke selen skadet denne gangen, forklarte dyrevernsorganisasjonen til BBC.Men mange dyr er ikke s\u00e5 heldige n\u00e5r de blir fanget i plast. Dyr setter seg fast i plast over hele verden. Norske sj\u00f8dyr setter seg fast i plast hver eneste dag, forteller Per-Erik Schulze. Han jobber i Naturvernforbundet og er ekspert p\u00e5 plast og forurensing i havet. \u2013 Mange av dyrene st\u00e5r fast i mange dager eller m\u00e5neder uten \u00e5 slippe l\u00f8s. Det er helt grusomt, sier Schulze.Han forteller at disse dyrene ofte setter seg fast i plast: Sj\u00f8fuglerFiskSelerSm\u00e5hvalerHummerSkilpadderDet er ogs\u00e5 dyr p\u00e5 land som setter seg fast i plast, for eksempel sauer og reinsdyr. Hvert \u00e5r havner over \u00e5tte millioner tonn plast i havet, if\u00f8lge Verdens naturfond (WWF). Det meste synker til havbunnen, resten skyller inn p\u00e5 strender eller flyter p\u00e5 havoverflaten.Det er farlig for dyr som lever i og rundt havet, fordi de kan sette seg fast i plasten eller f\u00e5 den i magen.Hva skjer med dyrene som setter seg fast i plast?\u2013 Det er det st\u00f8rste dyreplageriet i verden. Det er veldig vondt \u00e5 hekte seg fast. Mange d\u00f8r kanskje ikke av plasten, men av sult, fordi de ikke kommer seg l\u00f8s s\u00e5 de kan dra og spise, sier han.Derfor er det viktig ikke \u00e5 kaste plast som fors\u00f8pler naturen, mener Schulze.\u2013 En fin tanke er at hver plastbit vi rydder opp, kanskje kan redde et dyr. For det finnes ogs\u00e5 en god nyhet: De siste \u00e5rene har mange ryddet s\u00f8ppel i naturen og langs kysten i Norge. Har det hjulpet? \u2013 Ja, det har v\u00e6rt en kjempe-ryddedugnad i Norge de siste fem \u00e5rene. Noen steder er det s\u00e5 rent n\u00e5 at det er vanskelig \u00e5 finne noe plast. Det er et godt tegn, sier Schulze.\",\n  \"target_text\": \" En sel i England som var fanget i plast ble reddet av dyrevernere. Dette er en vanlig situasjon, b\u00e5de i Norge og andre steder i verden, da mange dyr setter seg fast og lider lenge fordi de ikke kan komme seg l\u00f8s. Per-Erik Schulze, en ekspert fra Naturvernforbundet, oppfordrer folk til \u00e5 fortsette ryddearbeidet for \u00e5 minimere risikoen for dyr \u00e5 komme til skade assosiert med plastfors\u00f8pling. Han bekrefter at ryddedugnadene i Norge har v\u00e6rt en suksess.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \" Det drar seg til mot sommer, ferietid, og ikke minst helg. Usikker p\u00e5 hva du skal vie den til? Her har du et lite knippe velmente tips.Denne guiden gjelder fra fredag 10. juni til s\u00f8ndag 12. juni.Fredag og l\u00f8rdag er det duket for folkefest og musikkbonanza p\u00e5 Viking stadion i J\u00e5tt\u00e5v\u00e5gen.Anledningen er to konserter fra det folkekj\u00e6re Stavangerbandet Mods, som er tilbake igjen p\u00e5 arenaen hvor de i 2012 og i 2017 spilte foran flere titalls tusen elleville fans. Ogs\u00e5 Kvelertak er med p\u00e5 \u00e5 innramme en meget sterk musikkhelg i regionen. P\u00e5 fredag g\u00e5r de nemlig opp p\u00e5 scenen p\u00e5 Folken i Stavanger, og skal by p\u00e5 de herligste toner med b\u00e5de hardrock og metall. Ogs\u00e5 i utelivets verden skjer det ting i helgen. Fredag kveld gj\u00f8r et nytt nattklubb- og cocktailbar-konsept sitt inntog i Stavanger n\u00e5r LouLou \u00e5pner d\u00f8rene i de gamle Hot-lokalene i Skagen. \u2013 Vi har sett at Stavanger manglet en annen og kanskje litt mer eksklusiv plass, hvor man kan feire bursdager og andre store begivenheter, sa daglig leder i Rekom, Frederik Mygind til Byas i forrige uke.Ogs\u00e5 p\u00e5 Show Bar, nysatsingen til duoen Dennis Poppe og \u00d8yvind S\u00f8rensen, blir det \u00e5pning til helgen. \u00abEin liden (ein) pre-opening i morgen (l\u00f8rdag) og s\u00f8ndag p\u00e5 Show Bar! Sees kl. 20:00\u00bb, skriver Poppe p\u00e5 sin Instagram-konto. Etter seieren borte mot Sverige sist s\u00f8ndag, er det en revansjelysten \u00abs\u00f6ta bror\u00bb som gjester Ullevaal kommende s\u00f8ndag. Flere rogalendinger figurerer i viktige roller p\u00e5 landslaget, med Erling Braut Haaland, Veton Berisha, Kristian Thorstvedt og Birger Meling som navnene. Kampen kan sees p\u00e5 flere utesteder i Stavanger, men kan ogs\u00e5 nytes fra sofaen fra klokken 20:45. I det Aftenbladet omtaler som \u00absuperdagene\u00bb, med en hel rekke arrangementer den kommende uken, finner flere av de sted denne helgen. Det 91 kilometer lange sykkell\u00f8pet, Nordsj\u00f8rittet, fra Egersund til Sandnes g\u00e5r av stabelen l\u00f8rdag, og kan la svettekjertlene f\u00e5 fri utfoldelse. Rittet s\u00e5 dagens lys tilbake i 1998 og er et samarbeid mellom flere lokale sykkelklubber. Og p\u00e5 Sola blir det moro for b\u00e5de store og sm\u00e5 n\u00e5r Sola Airshow 2022, flystevnet som har vist fram gamle og nye luftmaskiner i en \u00e5rrekke, holdes p\u00e5 l\u00f8rdagen og s\u00f8ndagen. Er du derimot mer opptatt av folkelivet, s\u00e5 kan enten Tanangerdagene, eller Solafestivalen v\u00e6re for deg. I Sola kulturhus er det p\u00e5 fredag og l\u00f8rdag duket for ungdomsfestival.Arrangementet er gratis, for de mellom 13 og 20 \u00e5r, og byr blant annet p\u00e5 musikk fra den norske rapperen Hkeem, samt Stavanger-bandet Kriminell Kunst. Og et lite stykke unna, fra onsdag denne uken og fram til og med s\u00f8ndag, blir det folkeliv i Tananger, n\u00e5r Tanagerdagene g\u00e5r av stabelen. Arrangementet holdes i regi av Lions Club Tananger, og lover fem dager fulle av aktiviteter for familier, barn, ungdom og voksne. \u2013 Her er noe for alle og mye for mange. Hjertelig velkommen, skriver arrang\u00f8ren p\u00e5 Facebook-arrangementet sitt. Fra 10. til 12. juni holder fem kunstnere pop up-utstilling i Pedersgata.Kunstnerne det er snakk om er ragnhild.kristine, pryl.art, hwks.art, corneliussen.art og Rosa Ottestad.Det hele finner sted i Pedersgata 43, og det er ventet flere bes\u00f8kende til arrangementet. Utstillingen \u00e5pner kl. 18 p\u00e5 fredag, og holder \u00e5pent gjennom helga. Vet du bedre enn oss hva skjer neste helg? Send en e-post til\u00a0helga@byas.no!\",\n  \"target_text\": \" Artikkelen handler om hvilke arrangementer som skal holdes i perioden fra 10. juni til 12. juni. Blant arrangementene er konserter med bandene Mods og Kvelertak, landskamp i fotball p\u00e5 Ullevaal, og flystevnet Sola Airshow 2022 p\u00e5 Sola der det skal vises fram gamle og nye luftmaskiner. I tillegg arrangeres Tanangerdagene og Solafestivalen.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \" Regjeringen foresl\u00e5r \u00e5 \u00e5pne nye omr\u00e5der for oppdrettsn\u00e6ringen, men med strenge milj\u00f8krav. \u2013 Gir betydelige muligheter for \u00e5 \u00f8ke produksjonen, sier fiskeriministeren.N\u00e6rings- og fiskeridepartementet foresl\u00e5r n\u00e5 en ny tillatelsesordning for oppdrett med milj\u00f8krav.Det f\u00f8rste \u00e5ret kan det tildeles tillatelser p\u00e5 maksimalt 15.000 tonn biomasse (fisk). Hver enkelt s\u00f8ker kan maksimalt f\u00e5 tildelt ti tillatelser, og det vil stilles strenge milj\u00f8krav til s\u00f8kerne, heter det i meldingen fra departementet.\u2013 Dagens produksjon i \u00e5pne merder vil fortsatt v\u00e6re grunnstammen i norsk oppdrett. I tillegg har vi lagt til rette for landbasert oppdrett og havbruk til havs. Med denne ordningen peker vi ut en ny retning som gir oppdrettsn\u00e6ringen mulighet til \u00e5 ta i bruk nye arealer langs kysten, sier fiskeri- og sj\u00f8matminister Odd Emil Ingebrigtsen (H).Til sammenligning ble det produsert rundt 1,4 millioner tonn laks i Norge i 2019, if\u00f8lge SSB.Tillatelsene i den nye milj\u00f8teknologiordningen kommer i tillegg til veksten som blir tilbudt p\u00e5 ordin\u00e6r m\u00e5te gjennom trafikklyssystemet.\u2013 Samlet sett gir dette norsk havbruksn\u00e6ring betydelige muligheter for \u00e5 \u00f8ke produksjonen fremover, sier ministeren.Forslaget inneb\u00e6rer f\u00f8lgende milj\u00f8krav: Null utslipp av egg og frittsv\u00f8mmende stadier av lakselus, minimum 60 prosent oppsamling av slam, samt krav til r\u00f8mningssikkerhet.Prisen for tillatelsene vil bli satt med utgangspunkt i auksjonsprisene som er oppn\u00e5dd i forbindelse med ordin\u00e6re kapasitetsjusteringer, men med et rimelig fradrag.\u2013 Havbruksn\u00e6ringen skaper store verdier for Norge. Men videre vekst m\u00e5 skje innenfor b\u00e6rekraftige rammer. Hensynet til natur generelt, og villaksen spesielt, er av avgj\u00f8rende betydning, sier klima- og milj\u00f8minister Sveinung Rotevatn (V).Til tross for bedring p\u00e5 viktige omr\u00e5der, er antallet norsk laks i havet mer enn halvert siden 1980-tallet, if\u00f8lge\u00a0Vitenskapelig r\u00e5d for lakseforvaltning.Det er flere grunner til det, ogs\u00e5 overfiske, men r\u00e5det sl\u00e5r fast at r\u00f8mt oppdrettslaks og lakselus n\u00e5 er de st\u00f8rste truslene mot villaks.Forslaget skal p\u00e5 kort tid ut p\u00e5 h\u00f8ring.E24 skrev tidligere at siste sitat i saken var fra Ingebrigtsen, mens det egentlig var fra Rotevatn. E24 beklager og har n\u00e5 rettet feilen.\",\n  \"target_text\": \" Regjeringen foresl\u00e5r en ny tillatelsesordning for oppdrett med strenge milj\u00f8krav for \u00e5 muliggj\u00f8re b\u00e6rekraftig vekst i havbruksn\u00e6ringen. Denne ordningen vil \u00e5pne nye omr\u00e5der for oppdrett, tillate hver s\u00f8ker \u00e5 f\u00e5 maksimalt ti tillatelser, og krever null utslipp av egg og frittsv\u00f8mmende stadier av lakselus, minimum 60 prosent oppsamling av slam, samt krav til r\u00f8mningssikkerhet. Dette skal gi n\u00e6ringen mulighet til \u00e5 \u00f8ke produksjonen p\u00e5 b\u00e6rekraftig m\u00e5te.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger nyhetsartikler med tilh\u00f8rende sammendrag.\n</code></pre></li> <li>Base prompt template:   <pre><code>Nyhetsartikkel: {text}\nSammendrag: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Nyhetsartikkel: {text}\n\nSkriv et sammendrag av den ovennevnte artikkelen.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset norglm-multi-sum\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-schibsted-no","title":"Unofficial: Schibsted-no","text":"<p>This dataset was released here and features summaries of news articles from Schibsted Medias Norwegian newsrooms.</p> <p>The original dataset contains 1,240 / 347 / 374 samples for training, validation and testing, respectively. We use these splits as-is.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Klubblegenden med innr\u00f8mmelse under VAR-debatten: \u2013 Vanskelig \u00e5 st\u00e5 her : VAR-oppr\u00f8ret tok en knusende seier i Trondheim. Til og med styremedlem Ola By Rise m\u00e5tte innr\u00f8mme at det var mange gode argumenter imot videod\u00f8mmingen.  Den gamle keeperhelten talte RBK-styrets sak for VAR sammen med medstyremedlem Tore Reginiussen:  \u2013 Det er en veldig vanskelig sak. Det er ikke to VAR-tilhengere som st\u00e5r her, sa en engasjert By Rise fra talerstolen.  VAR-debatten hadde kommet til Rosenborgs medlemmer torsdag, som skulle stemme for at Rosenborg aktivt skulle arbeide for \u00e5 fjerne VAR eller ikke.  489 stemte for \u00e5 avvikle VAR. 157 stemte for \u00e5 beholde VAR. Stemmene ble lest opp til enorm applaus fra salen.  Forslaget om at RBK-styret skulle f\u00e5 \u00abutrede ulike modeller for \u00e5 f\u00e5 kapital inn i klubben\u00bb ble ogs\u00e5 stemt ned med god margin. \u2013 Medlemmene har definitivt makta i Rosenborg og de bruker den. Dette er et gedigent nederlag for det sittende styret og leder Cecilie Gotaas Johnsen, sier Adresseavisens kommentator Birger L\u00f8faldli til VG.  \u2013 S\u00e6rlig investorsaken tror jeg er tung \u00e5 svelge, der det forel\u00f8pig kun var snakk om en utredning. Jeg er spent p\u00e5 hvordan Gotaas Johnsen vil reagere p\u00e5 dette og hvordan hun vurderer arbeidsbetingelsene det kommende \u00e5ret, sier L\u00f8faldli.  VAR-debatten var den som tok lengst tid:  \u2013 Jeg har forst\u00e5else for klubbens posisjon og forst\u00e5r at m\u00e5ten oppleves som uvanlig detaljstyrende. Men for mange er dette en ekstraordin\u00e6r sak. Det er viktig at styret forst\u00e5r: VAR m\u00e5 ikke forbedres, VAR m\u00e5 fjernes! sa forslagsstiller Ole Christian Gullv\u00e5g.  \u2013 Talelista begynner \u00e5 bli lang, var meldingen fra ordstyrer etter at et par stykker hadde snakket sin side i VAR-saken.  Styremedlem By Rise argumenterte med at det ville bli vanskelig \u00e5 \u00absette tannkremen tilbake p\u00e5 tuben\u00bb. Forslagsstiller Gullv\u00e5g svarte:  \u2013 For oss oppleves det som at noen har spr\u00f8ytet tannkrem p\u00e5 stua midt under fredagstacoen. Vi har ikke bedt om det, vil ikke ha det.  Ola By Rise har tidligere v\u00e6rt ute p\u00e5 Twitter og v\u00e6rt kritisk til VAR. Han innr\u00f8mmet ogs\u00e5 sin tvil rundt temaet.  \u2013 Det er vanskelig \u00e5 st\u00e5 her. Man m\u00e5 ikke st\u00e5 hver kamp p\u00e5 \u00d8vre \u00d8st for \u00e5 reagere p\u00e5 hvordan VAR praktiseres i dag. S\u00e5 er det ikke sikkert den blir god nok. Involveringen av supporterne burde definitivt blitt bedre. Men det er ikke sikkert det er verkt\u00f8yet som er problemet, men gjennomf\u00f8ringen, sa By Rise.  Han og Reginiussen listet opp b\u00e5de negative og positive sider ved VAR, og pekte som flere andre klubber p\u00e5 det potensielle \u00f8konomiske tapet ved \u00e5 fjerne VAR.  Styret argumenterte for at Rosenborg skulle v\u00e6re en kritisk meningsb\u00e6rer rundt videod\u00f8mming. Et titalls medlemmer tok ordet og sa seg sv\u00e6rt uenige, og til slutt var det forslaget fra medlemmene som vant frem.  RBK-medlem Emil Alm\u00e5s var forslagsstiller sammen med Gullv\u00e5rg. Han sier f\u00f8lgende til VG: \u2013 Det vi har f\u00e5tt til i norsk toppfotball de siste dagene er en seier for fotballen og en seier for medlemsdemokratiet. Ved \u00e5 takke nei til VAR, har norske supportere startet et jordskred, som kommer til \u00e5 rase gjennom fotballeuropa i \u00e5rene som kommer! Den dagen VAR er historie, skal jeg med stolthet si at jeg, og mange andre norske fotballsupportere var med p\u00e5 \u00e5 trille de f\u00f8rste steinene nedover dalsiden, sier Alm\u00e5s.  PS. En r\u00f8rt Rune Bratseth mottok tittelen som \u00e6resmedlem i Rosenborg, etter en lang karriere som spiller, sportssjef og styremedlem. - Det er veldig spesielt for meg, sa Bratseth. \",\n  \"target_text\": \"489 RBK-medlemmer stemte for \u00e5 avvikle VAR ved et m\u00f8te torsdag, med 157 mot Styremedlem Ola By Rise innr\u00f8mmet gode argumenter mot videod\u00f8mming, men argumenterte for at Rosenborg skulle v\u00e6re en kritisk stemme imot. RBK-medlem Emil Alm\u00e5s hevder \\\"norske supportere starter et jordskred\\\" mot VAR i Europa Medlemmene ga ogs\u00e5 sitt nei til at RBK-styret skulle f\u00e5 \u00abutrede ulike modeller for \u00e5 f\u00e5 kapital inn i klubben\u00bb.  \u2013 Et gedigent nederlag for det sittende styret, mener Adresseavisens kommentator Birger L\u00f8faldli \"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Gazas befolkning sultes med vilje, sier FN-ekspert: Krigen har \u00f8delagt matproduksjonen. Samtidig slippes det ikke inn nok n\u00f8dhjelp. Israel driver en aktiv politikk for \u00e5 sulte ut Gazas befolkning, mener FNs spesialrapport\u00f8r. Israel har som m\u00e5l \u00e5 begrense Gazas sivilbefolkning tilgang til mat. Det hevder FNs spesialrapport\u00f8r for retten til mat, Michael Fakhri, til The Guardian. \u2013 Det finnes ingen grunn til \u00e5 med vilje stoppe leveringen av humanit\u00e6r hjelp eller \u00f8delegger sm\u00e5 fiskeb\u00e5ter, drivhus og frukt\u00e5kere, bortsett fra \u00e5 nekte folk tilgang til mat, sier Fakhri til den britiske avisen. Han mener at Israel med dette gj\u00f8r seg skyldig i b\u00e5de krigsforbrytelser og folkemord. Jan Egeland: \u2013 Fullstendig galskap Sentrale israelske politikere er flere ganger blitt anklaget for \u00e5 ha brukt retorikk som oppfordrer til folkemord. Dette ble blant annet lagt til grunn da S\u00f8r-Afrika klaget Israel inn til ICJ. \u2013 Som en menneskerettighetsekspert ved FN mener jeg at dette n\u00e5 er en folkemord-situasjon, understreker Fakhri. Fakhri er ikke den eneste som har advart om konsekvensene av hungersn\u00f8den i Gaza. En FN-rapport konkluderte nylig: Flyktninghjelpens generalsekret\u00e6r, Jan Egeland, reiste tirsdag inn i Gaza. Han beskriver rystende scener med desperate mennesker som gj\u00f8r alt i sin makt for \u00e5 kare til seg mat. \u2013 Jeg er fullstendig sjokkert over forholdene her. Folk sl\u00e5ss som ville og gale over madrasser og sekker med mat, sier Egeland til VG. \u2013 Det er fullstendig galskap at verden har latt en befolkning best\u00e5ende av stort sett helt uskyldige kvinner og barn bli utsatt for bombardement og utsulting siden midten av oktober. Hevder Israel trosser FN-domstol Situasjonen er ikke blitt bedre de siste ukene. Det sier bistandsorganisasjoner. Det til tross for at Den internasjonale domstolen (ICJ), FNs viktigste domstol, for \u00e9n m\u00e5ned siden bestemte at Israel m\u00e5 gj\u00f8re alt i sin makt for \u00e5 s\u00f8rge for \u00e5 stoppe et folkemord og s\u00f8rge for at palestinere har tilgang til bistand. Human Rights Watch (HRW) og Amnesty International p\u00e5peker at det slippes inn 30 prosent f\u00e6rre lastebiler med n\u00f8dhjelp hver dag n\u00e5 sammenlignet med f\u00f8r ICJs p\u00e5legg 26. januar. I februar slapp det inn halvparten s\u00e5 mye n\u00f8dhjelp i Gaza som m\u00e5neden f\u00f8r, if\u00f8lge FNs organisasjon for palestinske flyktninger (Unrwa). \u2013 Den israelske regjeringen sulter 2,4 millioner palestinere i Gaza.  Det sier Omar Shakir, som er lederen for HRWs virksomhet i Israel og Palestina. \u2013 Den israelske regjeringen har ganske enkelt oversett domstolens p\u00e5legg, f\u00f8yer han til. Tirsdag redegjorde Ramesh Rajasingham ved FNs kontor for koordinering av humanit\u00e6r innsats (UNOCHA) om situasjonen for FNs sikkerhetsr\u00e5d. Han advarte om at jordbruket i Gaza vil kollapse innen mai hvis situasjonen ikke blir bedre, og hvis det ikke blir pause i krigshandlingene. \u2013 Vi understreker derfor nok en gang v\u00e5rt krav om en v\u00e5penhvile, sa han. USA blokkerte i februar enda en gang en resolusjon i Sikkerhetsr\u00e5det om v\u00e5penhvile. Begrunnelsen var at resolusjonen kunne \u00f8delegge forhandlinger om v\u00e5penhvile og fangeutveksling som p\u00e5g\u00e5r mellom Egypt, Israel og Qatar. \u2013 Hvis ingenting skjer, frykter vi at storskala sult i Gaza nesten er uunng\u00e5elig, og det vil f\u00f8re til mange flere ofre, sa Rajasingham til Sikkerhetsr\u00e5det.\",\n  \"target_text\": \"FN mener Israel pr\u00f8ver \u00e5 sulte ut befolkningen p\u00e5 Gazastripen. M\u00e5lrettede angrep hindrer matproduksjon og levering av n\u00f8dhjelp.  Akutt underern\u00e6ring truer hele befolkningen. Barn og kvinner i Nord-Gaza og Rafah er mest utsatt.  Israel overser FN-domstolens p\u00e5legg om \u00e5 gi palestinere tilgang til bistand. Hjelpeorganisasjoner ser mindre n\u00f8dhjelp komme inn.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Marokkanske og albanske mafianettverk dominerer. Svenskene blir en stadig st\u00f8rre trussel.: Flere er bygd p\u00e5 lojalitet til familie og klan, if\u00f8lge ny rapport fra Kripos. Om kort tid legger politiet frem sin trusselvurdering. Der vil Politi-Norge peke p\u00e5 de st\u00f8rste truslene mot det norske samfunnet. En av truslene som vil bli viet mye plass, er organiserte kriminelle nettverk. I Norge er det rundt hundre slike nettverk. Kripos mener politiet har kapasitet til \u00e5 f\u00f8lge med p\u00e5 40 av dem. Nettverkene smugler og selger enorme mengder narkotika. De st\u00e5r bak skyteepisoder, eksplosjoner, menneskesmugling og bedragerier. M\u00e5let er profitt. Midlene er vold og hard indre justis. Noen av de mektigste nettverkene er bygd p\u00e5 lojalitet til familie og klan. N\u00e5 letter Kripos p\u00e5 sl\u00f8ret. For f\u00f8rste gang g\u00e5r politiet ut med en egen rapport om nettverkene som dominerer i den kriminelle underverdenen: I rapporten trekker Kripos frem fem store trusler: 1. Marokkanske narkonettverk En av de aller st\u00f8rste truslene er marokkanske narkonettverk. \u2013 De er utrolig sentrale, ikke bare i Norge og Norden, sier Eivind Borge fra Kripos. Norskmarokkanere dukker ogs\u00e5 opp i etterforskninger i andre europeiske land. Aftenposten har tidligere omtalt Zakariya Rahali, som har v\u00e6rt p\u00e5 r\u00f8mmen siden 2017. Rahali er pekt ut som lederen av Norges st\u00f8rste narkonettverk. 2. Albanske narkonettverk Etter marokkanerne, er det albanske nettverk som utgj\u00f8r den st\u00f8rste trusselen. Disse regnes for \u00e5 v\u00e6re blant de st\u00f8rste nettverkene som driver med kokain i hele Europa.  3. Svenske narkonettverk Borges skrekkscenario er at Norge kommer dit Sverige er i dag. Der har gjengkrigen herjet og deler av samfunnet er i ferd med \u00e5 bli infiltrert av kriminelle. I Norge har samtlige politidistrikt st\u00f8tt p\u00e5 svenske kriminelle nettverk. Og trusselen er \u00f8kende, vurderer Kripos. 4. Litauiske kriminelle nettverk For \u00e5 frakte narkotika, trengs det logistikk. For \u00e5 gj\u00f8re dette, tar mange kriminelle i bruk litauiske nettverk.  5. Norge som transittland I fjor opplevde Europa en \u00abkokaintsunami\u00bb. Enorme mengder kokain ble tatt av politi og tollere, ogs\u00e5 i Norge. Men prisene gikk ikke opp. Et tegn p\u00e5 at store mengder kokain er i oml\u00f8p.  I flere \u00e5r har havnene i Rotterdam og Antwerpen v\u00e6rt stedet hvor kokain er blitt smuglet inn til Europa. Men der har myndighetene kastet seg rundt. Dermed m\u00e5 de kriminelle se seg om etter nye havner for \u00e5 f\u00e5 det hvite pulveret til kundene. De store beslagene i fjor, kan peke mot at Norge i st\u00f8rre grad er i ferd med \u00e5 bli et av disse stedene. Enn s\u00e5 lenge er det for tidlig \u00e5 konkludere om Norge er blitt en del av kokainruten til Europa, mener Borge og Ole J\u00f8rgen Arvesen, avdelingsleder med ansvar for etterretning i Kripos. G\u00e5r sammen med kartellene Hvordan kan Kripos v\u00e6re s\u00e5 sikre i sin sak? Mye kommer fra p\u00e5g\u00e5ende etterforskninger, men de siste \u00e5rene har de ogs\u00e5 f\u00e5tt et unikt innblikk i hvordan de kriminelle jobber og samarbeider. De har f\u00e5tt meldinger og bilder fra Encrochat, Sky ECC og Anom. Det har ledet til flere store saker, men likevel er trusselen fra de kriminelle nettverkene blitt st\u00f8rre. \u2013 Den er betydelig og \u00f8kende for hele Europa, ogs\u00e5 Norge, sier Arvesen. Nettverkene er blitt mer profesjonelle og samarbeider mer med kriminelle i andre land.  \u2013 Vi ser tydelig at norske nettverk har direkte kontakt med karteller i S\u00f8r-Amerika, sier Eivind Borge fra Kripos. Han sier bakmennene de jobber for \u00e5 ta, ikke lar seg stoppe med forebygging. Det krever mye etterforskning og samarbeid med politi i andre land.\",\n  \"target_text\": \"For f\u00f8rste gang g\u00e5r politiet ut med en egen rapport om kriminelle nettverk. Rapporten peker p\u00e5 fem store trusler: marokkanske og albanske narkonettverk, svenske narkonettverk, litauiske kriminelle nettverk og at Norge blir et transittland for kokain. Nettverkene i Norge er blitt mer profesjonelle, har direkte kontakt med karteller i S\u00f8r-Amerika. Dette krever mer etterforskning og internasjonalt samarbeid.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger nyhetsartikler med tilh\u00f8rende sammendrag.\n</code></pre></li> <li>Base prompt template:   <pre><code>Nyhetsartikkel: {text}\nSammendrag: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Nyhetsartikkel: {text}\n\nSkriv et sammendrag av den ovennevnte artikkelen.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset schibsted-no\n</code></pre>"},{"location":"datasets/norwegian/#unofficial-personal-sum","title":"Unofficial: Personal Sum","text":"<p>This dataset was released here and contains human annotated summaries that reflect individual user preferences.</p> <p>The original dataset contains 1,099 summaries based on 441 unique articles. The dataset has been restructured into 441 samples, where each sample represents a unique article paired with all of its corresponding summaries (1 or more). The dataset has been split such that we have 121 / 64 / 256 samples for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"I en ny bok forteller Abid Rajas s\u00f8ster Abida Raja (49) at hun over lengre tid levde i et voldelig forhold. I en pressemelding avviser eksmannen anklagene. \u2013 Min klient \u00f8nsker \u00e5 p\u00e5peke at han nekter straffeskyld for partnervold og\\nvoldtektsanklager. Han vedkjenner at ekteskapet har hatt sine utfordringer, og at de derfor skilte seg i 2015, skriver eksmannens advokat Javeed H. Shah i en pressemelding. I boken \u00abFrihetens \u00d8yeblikk\u00bb, beskriver Raja at eksmannen hennes var voldelig, og at hun flere ganger fors\u00f8kte \u00e5 unnslippe mannen. I boken skriver forfatter H\u00e5kon F. H\u00f8ydal:\u00abDe siste tjue \u00e5rene hadde v\u00e6rt en kamp mot seg selv: Hun \u00f8nsket \u00e5 g\u00e5 fra mannen. Men hun m\u00e5tte bli. P\u00e5 grunn av barna, og p\u00e5 grunn av familien, p\u00e5 grunn av frykten for fattigdom og skam. N\u00e5 hadde hun verken barna, penger eller hus.\u00bbVG har tidligere v\u00e6rt i kontakt med Abida Rajas eksmann i forbindelse med bokutgivelsen, som tirsdag ikke hadde lest boken.\u2013 Jeg er i utlandet og har ikke lest boken, s\u00e5 kan ikke kommentere uten \u00e5 lese det, skriver han i en SMS til VG.I boka skriver forfatteren at Abida etter stort press fra familien, skal ha m\u00f8tt \u00e9n av ektemannkandidatene, en 23 \u00e5r gammel inngiftet onkel i Pakistan. Hun var 18 \u00e5r og skulle g\u00e5tt i andre klasse p\u00e5 videreg\u00e5ende hjemme i Norge.\u00abAbida husker ikke om hun sa ja. Men hun sa heller ikke nei. Hun ville bare bort\u00bb, heter det i boken.Onsdag svarer eksmannen via sin advokat, at han har levd i god tro om at Abida giftet seg av fri vilje slik hun selv uttrykte ovenfor han. \u2013 Derfor er opplysningene om tvangsekteskap noe han ble kjent med f\u00f8rst i 2020. Boken kommer ett \u00e5r etter at venstrepolitiker og tidligere statsr\u00e5d Abid Raja kom med sin bok\\xa0\u00abMin skyld\u00bb. Boken er skrevet av VG-journalist H\u00e5kon F. H\u00f8ydal og ble lansert tirsdag morgen\\xa0etter mye hemmelighold. VG har ikke hatt noe med utgivelsen \u00e5 gj\u00f8re.\",\n    \"target_text\": [\"I en ny bok forteller Abid Rajas s\u00f8ster Abida Raja om hennes erfaringer med et voldelig ekteskap, hvor hun beskriver flere fors\u00f8k p\u00e5 \u00e5 unnslippe. Eksmannen avviser anklagene og hevder at han levde i god tro om at ekteskapet var av fri vilje, noe han f\u00f8rst ble klar over i 2020.\",\n    \"Abida Raja beskriver i en ny bok et voldelig forhold med sin eksmann, som avviser anklagene om partnervold og voldtektsanklager. Boken avsl\u00f8rer ogs\u00e5 at Abida ble presset til \u00e5 m\u00f8te en ektemannkandidat i en tvangssituasjon, noe eksmannen hevder han ikke var klar over f\u00f8r i 2020.\",\n    \"I boken \u00abFrihetens \u00f8yeblikk\u00bb forteller forfatteren H\u00e5kon F. H\u00f8ydal at Rajas eksmann var voldelig og hun \u00f8nsket \u00e5 forlate ham. Hun ble v\u00e6rende fordi hun var redd for barnas lidelser, redd for fattigdom og hun skammet seg.\"]\n}\n</code></pre> <pre><code>{\n    \"text\": \"Flere lakseaksjer falt igjen tungt, dagen etter at skatteforslag ga b\u00f8rsras for sj\u00f8matselskaper. Samtidig steg Norwegian etter anbefaling fra storbank.Det Ble en noe vinglete dag p\u00e5 Oslo B\u00f8rs torsdag.Etter en positiv start vendte B\u00f8rsen snuten nedover i tidlig handel, f\u00f8r den hentet seg inn igjen til forsiktig oppgang omtrent halvveis ut i handelsdagen. Utover ettermiddagen snudde B\u00f8rsen s\u00e5 nedover igjen.Hovedindeksen endte til slutt dagen ned 1,58 prosent.Nedgangen tiltok den siste timen med handel, samtidig som Wall Street falt kraftig.Oljeprisen steg solid gjennom g\u00e5rsdagen, og handles rundt \u00e9n dollar h\u00f8yere enn da B\u00f8rsen stengte onsdag. Et fat Nordsj\u00f8olje (brent spot) koster ved stengetid torsdag 88,4 dollar, ned rundt 0,9 prosentsiden midnatt.Oljeselskapene Equinor og Aker BP falt i overkant av \u00e9n prosent, mens V\u00e5r Energi endte ned 3,82 prosent.Onsdag falt Hovedindeksen 2,76 prosent etter at lakseselskapene fikk gjennomg\u00e5 etter regjeringens foresl\u00e5tte grunnrenteskatt p\u00e5 havbruk. Verst gikk det for Salmar som stupte 30 prosent, samtidig som Ler\u00f8y Seafood falt 27,5 prosent. Torsdag fortsetter nedgangen for lakseaksjene. Sj\u00f8matindeksen endte ned 5,05 prosent.Slik s\u00e5 det ut for lakseaksjene ved stengetid (utvikling onsdag i parentes): Salmar falt 1,05 prosent (stupte 30,3 prosent)Grieg Seafood falt 2,75 prosent (falt 26,6 prosent)Mowi falt 3,15 prosent (falt 18,9 prosent) Ler\u00f8y Seafood falt 8,10 prosent (raste 27,5 prosent)Austevoll Seafood falt 6,28 prosent (falt 21,7 prosentNorway Royal Salmon falt 8,94 prosent (endte ned 22,9 prosent)Bakkafrost-aksjen falt samtidig 12,83 prosent.Selskapet har virksomhet p\u00e5 F\u00e6r\u00f8yene og understreket onsdag at de ikke p\u00e5virkes av det nye norske skatteforslaget. Samtidig understreket de at det arbeides med et forslag om justeringer av skattesatsen p\u00e5 F\u00e6r\u00f8yene.I USA peker pilene solid nedover p\u00e5 b\u00f8rsene torsdag ettermiddag.Det er kraftig nedgang p\u00e5 Wall Street, der den brede S&amp;P 500-indeksen faller godt over to prosent. Teknologiindeksen Nasdaq faller samtidig mer enn tre prosent.I Europa er det ogs\u00e5 bred, kraftig nedgang p\u00e5 de viktigste b\u00f8rsene. London-b\u00f8rsen, Frankfurt-b\u00f8rsen og Paris-b\u00f8rsen er alle ned i overkant av to prosent rundt stengetid i Oslo.Storbanken HSBC har gjenopptatt dekning p\u00e5 flyselskapet Norwegian, if\u00f8lge Bloomberg. Banken anbefaler kj\u00f8p og har satt et kursm\u00e5l p\u00e5 14,50 kroner. Dermed ser banken for seg en oppside p\u00e5 hele 119 prosent i aksjen, skriver nyhetsbyr\u00e5et. Norwegian-aksjen steg 6,81 prosent.\u2013 Nye Norwegian er en annen forretning enn den f\u00f8r pandemien, som har omstrukturert operasjonelt og \u00f8konomisk, skriver HSBC i analysen.\u2013 Den nye ledelsen har en solid strategi, en enkel og kostnadseffektiv\\nforretningsmodell med en enkelt type fly, et sterkt fokus p\u00e5 sine n\u00f8kkelmarkeder i Norden og en solid balanse og likviditet, alt innenfor et gunstig konkurranselandskap som b\u00f8r tillate ny NAS \u00e5 ta markedsandeler fra sine konkurrenter, heter det videre i analysen.Storbanken begrunner ogs\u00e5 sin nye dekning p\u00e5 flyselskapet ved at dets konkurrenter venter mye motvind og ny ettersp\u00f8rsel for Norwegian kan komme ut av det. I tillegg nevnes Norges sikkerhetsnett rundt h\u00f8ye energi- og str\u00f8mpriser.- Mens Europa st\u00e5r overfor h\u00f8y inflasjon og lav forbrukertillit, har Norge betydelig lysere utsikter med sine omfattende energiressurser, statlig finansiering og h\u00f8y inntekt per innbygger.HSBC viser ogs\u00e5 til h\u00f8y reiseettersp\u00f8rsel blant nordmenn.Fornybarselskapet Scatec er i fokus i forbindelse med at selskapet har kommet med nye m\u00e5lsetninger. Selskapet vil investere 10 milliarder kroner av egenkapitalen i nye kraftverk frem mot 2027. Investeringene har som m\u00e5l \u00e5 utvide kapasiteten med 1,5 gigawatt hvert \u00e5r i perioden. Scatec-aksjen endte dagen ned 2,93 prosentXXL er samtidig blant b\u00f8rstaperne torsdag. Aksjen til sportsbutikk-kjeden falt 11,66 prosent.\",\n    \"target_text\": [\"Lakseaksjer opplever fortsatt betydelig nedgang p\u00e5 Oslo B\u00f8rs etter regjeringens foresl\u00e5tte grunnrenteskatt p\u00e5 havbruk. Hovedindeksen endte ned 1,58 prosent, og sj\u00f8matindeksen falt ytterligere 5,05 prosent. Samtidig steg Norwegian-aksjen etter anbefaling fra HSBC, som gjenopptok dekning p\u00e5 selskapet og anbefalte kj\u00f8p med et kursm\u00e5l p\u00e5 14,50 kroner, med en forventet oppside p\u00e5 119 prosent.\"]\n}\n</code></pre> <pre><code>{\n    \"text\": \"(Minnesota Wild \u2013 St. Louis Blues 4\u20136) Mats Zuccarello (34) var sv\u00e6rt kritisk til seg selv og lagkameratene i Minnesota Wild etter nattens tap mot St. Louis Blues i 23 minusgrader foran 38.000 tilskuere.\u2013 Jeg har egentlig ikke ord. Det er pinlig n\u00e5r du har 40.000 mennesker som kommer og fryser r\u00e6va av seg, og s\u00e5 spiller vi s\u00e5nn, sa Zuccarello p\u00e5 pressekonferansen etter \u00abWinter Classic\u00bb-oppgj\u00f8ret p\u00e5 Target Field \u2013 et baseballstadion i Minneapolis. F\u00f8r siste periode ledet Blues 6\u20132, og Zuccarello beskriver de to f\u00f8rste periodene som at de ble \u00ablett utspilt\u00bb av Blues. Zuccarello hadde \u00e9n assist \u2013 da Ryan Hartman scoret lagets tredje m\u00e5l . Wild reduserte to ganger i siste periode og fastsatte sluttresultatet til 4\u20136. 34-\u00e5ringen mener det ikke nytter \u00e5 forklare tapet med kulden, vanskelige forhold og det faktum at de ikke har spilt kamp siden 20. desember: \u2013 Det er ingen unnskyldninger ... Det er kaldt for begge lag, isen er humpete for begge lag. Vi spilte ikke smart hockey som vi har gjort i store deler av sesongen. Det var Wilds femte strake tap i en sesong der Zuccarello og laget jevnt over har levert meget bra. \u2013 Dessverre skjedde det p\u00e5 en stor kveld som dette. Folk forlater hjemmene sine i kulden for \u00e5 st\u00f8tte oss, og s\u00e5 serverer vi dem dette. Vi har skuffet oss selv og alle andre. Det var p\u00e5 forh\u00e5nd varslet sprengkulde, og m\u00e5lingene viste 23 minusgrader. Zuccarello beskriver opplevelsen slik:\u2013 Jeg var skikkelig kald under oppvarmingen, men n\u00e5r kampen starter sl\u00e5r adrenalinet inn. Men jeg tror aldri jeg har v\u00e6rt s\u00e5 kald i hele mitt liv f\u00f8r sisteperioden da vi l\u00e5 under 6\u20132, eller hva det var. Det var ingen god f\u00f8lelse. \u2013 Det store bildet n\u00e5 er at vi har fem strake tap, og vi m\u00e5 finne tilbake til m\u00e5ten \u00e5 vinne p\u00e5 og hvordan vi skal spille som et lag, sier Zuccarello. Zuccarello har scoret \u00e5tte m\u00e5l og lagt 17 m\u00e5lgivende pasninger i l\u00f8pet av 25 kamper denne sesongen. Det vil si ett m\u00e5lpoeng per kamp i snitt. I sine beste m\u00e5lpoengsesonger for New York Rangers \u2013 2013/14, 2015/16 og 2016/17 \u2013 oppn\u00e5dde han henholdsvis 59 m\u00e5lpoeng p\u00e5 77 kamper, 61 m\u00e5lpoeng p\u00e5 81 kamper og 59 p\u00e5 80 kamper.PS! Natt til fredag spiller Minnesota Wild borte mot Boston Bruins. To dager senere er det hjemmekamp mot Washington Capitals.\",\n    \"target_text\": [\"Minnesota Wild led et nederlag mot St. Louis Blues under ekstreme v\u00e6rforhold p\u00e5 Target Field. Mats Zuccarello uttrykte sin skuffelse over lagets ytelse foran 38 000 tilskuere, og tilskrev tapet til d\u00e5rlig spill heller enn kulden. Til tross for Zuccarellos bidrag med en assist, endte Wild med sitt femte strake tap, noe som f\u00f8rte til et press for \u00e5 finne tilbake til seiersformen f\u00f8r kommende kamper mot Boston Bruins og Washington Capitals.\",\n    \"Det er ingen unnskyldninger for Wilds femte strake tap, til tross for at b\u00e5de Zuccarello og resten av laget generelt har spilt bra denne sesongen. Forholdene var like for begge lag, men laget spilte ikke smart hockey slik de har gjort tidligere i sesongen.\"]\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Her f\u00f8lger nyhetsartikler med tilh\u00f8rende sammendrag.\n</code></pre></li> <li>Base prompt template:   <pre><code>Nyhetsartikkel: {text}\nSammendrag: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Nyhetsartikkel: {text}\n\nSkriv et sammendrag av den ovennevnte artikkelen.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset personal-sum\n</code></pre>"},{"location":"datasets/portuguese/","title":"\ud83c\uddf5\ud83c\uddf9 Portuguese","text":"<p>This is an overview of all the datasets used in the European Portuguese part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/portuguese/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/portuguese/#sst2-pt","title":"SST2-PT","text":"<p>This dataset was published in this paper and is part of the ExtraGLUE dataset. It is created by taking the original SST-2 dataset and using machine translation (DeepL) to translate it.</p> <p>The original dataset contains 67,300 training, 872 validation, and 1,820 test samples. We use 1,024 / 256 / 2,048 samples for train / val / test respectively. Given that the original validation dataset only has 1,820 sample for testing, we derive that split from the training split, while ensuring no overlaps occur. This dataset only includes positive and negative labels, no neutrals.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"um drama psicol\u00f3gico absorvente e inquietante .\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"tudo o que n\u00e3o se pode suportar\",\n  \"label\": \"negative\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"m\u00e1 escrita\",\n  \"label\": \"negative\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Abaixo encontras documentos e os seus sentimentos correspondentes, que podem ser 'positivo' ou 'negativo'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Documento: {text}\nSentimento: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:</li> </ul> <pre><code>Texto: {text}\n\nClasifica o sentimento do documento. Responde apenas com 'positivo' ou 'negativo'.\n</code></pre> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset sst2-pt\n</code></pre>"},{"location":"datasets/portuguese/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/portuguese/#harem","title":"HAREM","text":"<p>This dataset was published in this paper and is based on the Primeiro HAREM evaluation campaign for Portuguese from Portugal, using the manually annotated Colec\u00e7\u00e3o Dourada. The text sources come from varied sources: web, news, fiction books, politics, email, speeches, technical, expository.</p> <p>We extract only documents where <code>&lt;ORIGEM&gt;</code> is <code>PT</code>, i.e., of Portuguese origin. The raw XML annotations are parsed and converted to token-level BIO labels. Tags are mapped to standard CoNLL categories:</p> <ul> <li><code>PER</code> (pessoa)</li> <li><code>LOC</code> (local)</li> <li><code>ORG</code> (organiza\u00e7\u00e3o)</li> <li><code>MISC</code> (diverso)</li> </ul> <p>Labels follow the standard CoNLL BIO scheme with numeric encoding:</p> <pre><code>{\n  \"O\": 0,\n  \"B-PER\": 1,\n  \"I-PER\": 2,\n  \"B-ORG\": 3,\n  \"I-ORG\": 4,\n  \"B-LOC\": 5,\n  \"I-LOC\": 6,\n  \"B-MISC\": 7,\n  \"I-MISC\": 8\n}\n</code></pre> <p>In addition to tokenization and label alignment, each document is split into individual sentences, using punctuation-based heuristics. This makes the dataset better suited for sentence-level inference and generation.</p> <p>Due to the limited number of PT-origin documents (1,965 examples total), we couldn\u2019t reach the target of 2,304 (1,024 + 256 + 1,024). The final split is:</p> <ul> <li>Train: 873 examples</li> <li>Validation: 218 examples</li> <li>Test: 874 examples</li> </ul> <p><pre><code>{\n  \"tokens\": array([\"Na\", \"Covilh\u00e3\", \"ainda\", \"n\u00e3o\", \"havia\", \"liceu\", \"nessa\", \"altura\", \".\"], dtype=object),\n  \"labels\": array([0, 5, 0, 0, 0, 0, 0, 0, 0], dtype=object)\n}\n</code></pre> <pre><code>{\n \"tokens\": array([\"Por\", \"exemplo\", \",\", \"em\", \"Filosofia\", \"est\u00e1\", \"muito\", \"boa\", \".\"], dtype=object),\n  \"labels\": array([0, 0, 0, 0, 7, 0, 0, 0, 0], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array([\"Sabe\", \"qual\", \"a\", \"origem\", \"da\", \"sua\", \"fam\u00edlia\", \"?\"], dtype=object),\n  \"labels\": array([0, 0, 0, 0, 0, 0, 0, 0], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Seguem-se frases e dicion\u00e1rios JSON com as entidades mencionadas presentes na frase indicada.\n</code></pre></li> <li>Base prompt template:   <pre><code>Frase: {text}\nEntidades mencionadas: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Frase: {text}\n\nIdentifica as entidades mencionadas na frase. Deves devolver um dicion\u00e1rio JSON com as chaves 'pessoa', 'organiza\u00e7\u00e3o', 'local' e 'diverso' . Os valores devem ser listas contendo as entidades mencionadas desse tipo, tal como ocorrem na frase.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>pessoa</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>pessoa</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>local</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>local</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organiza\u00e7\u00e3o</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organiza\u00e7\u00e3o</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diverso</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diverso</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset harem\n</code></pre>"},{"location":"datasets/portuguese/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/portuguese/#scala-pt","title":"ScaLA-pt","text":"<p>This dataset is a Portuguese version of ScaLA, which was originally published in this paper, created by corrupting grammatically correct sentences from the Universal Dependencies Portuguese-Bosque treebank, filtered to only include samples from the European Portuguese source CETEMP\u00fablico. The treebank is based on the Constraint Grammar conversion of the Bosque corpus, part of the Floresta Sint\u00e1(c)tica treebank.</p> <p>Corruptions were applied by either removing a word from the sentence or swapping two neighbouring words. Rules based on part-of-speech tags were used to ensure that these corruptions lead to grammatical errors.</p> <p>The final dataset contains:</p> <ul> <li>Training set: 1,024 examples</li> <li>Validation set: 256 examples</li> <li>Test set: 2,048 examples</li> </ul> <p>These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"Nos Em os mercados orientais, T\u00f3quio foi a excep\u00e7\u00e3o e, ao o meio da de a manh\u00e3, a bolsa tendia para uma alta marginal, com o \u00edndice Nikkei a marcar 12,07 pontos no em o fim da de a sess\u00e3o da de a manh\u00e3.\",\n    \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"A equipa est\u00e1 a mostrar progressos, mas ainda h\u00e1 muito para fazer.\",\n    \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"V\u00e1rios estudos t\u00eam mostrado que estes linfomas regridem depois de tratamentos dirigidos \u00e0 a HP a, o que sugere uma rela\u00e7\u00e3o entre os dois.\",\n    \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Seguem-se abaixo textos e se s\u00e3o gramaticalmente corretos.\n</code></pre></li> <li>Base prompt template:   <pre><code>  Texto: {text}\n  Gramaticalmente correcto: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>  Texto: {text}\n\n  Determina se o texto \u00e9 gramaticalmente correcto ou n\u00e3o. Responde com 'sim' ou 'n\u00e3o', e nada mais.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>sim</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>n\u00e3o</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-pt\n</code></pre>"},{"location":"datasets/portuguese/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/portuguese/#multiwikiqa-pt","title":"MultiWikiQA-pt","text":"<p>This dataset will be published in an upcoming paper, and contains Portuguese Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>As Portuguese Wikipedia is a mixture of both European Portuguese and Brazilian Portuguese, we filtered the Wikipedia articles with this classifier, published in this paper, keeping only the articles in European Portuguese.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Manuel Frederico Tojal de Valsassina Heitor (Lisboa, 21 de setembro de 1958) \u00e9 um professor universit\u00e1rio e pol\u00edtico portugu\u00eas, que foi ministro da Ci\u00eancia, Tecnologia e Ensino Superior do XXI e XXII Governos Constitucionais.\\n\\nBiografia \\nFilho de Frederico L\u00facio de Valsassina Heitor (17 de Julho de 1930 - 2010), Comendador da Ordem da Instru\u00e7\u00e3o P\u00fablica a 9 de Junho de 1995, trineto por via feminina dum Bar\u00e3o de Valsassina na \u00c1ustria, Diretor do Col\u00e9gio Valsassina, Membro-Honor\u00e1rio da Ordem da Instru\u00e7\u00e3o P\u00fablica a 9 de Novembro de 1985, e Comendador da Ordem da Instru\u00e7\u00e3o P\u00fablica, e de sua mulher Maria Manuela de Oliveira Tojal (1933 - Lisboa, 25 de Mar\u00e7o de 2017), irm\u00e3o do arquiteto Frederico Valsassina e neto materno do tamb\u00e9m arquitecto Raul Tojal, Manuel Heitor frequentou o Col\u00e9gio Valsassina.\\n\\nForma\u00e7\u00e3o acad\u00e9mica\\nManuel Heitor licenciou-se em Engenharia Mec\u00e2nica pelo Instituto Superior T\u00e9cnico da Universidade T\u00e9cnica de Lisboa em 1981, doutorou-se, em 1985, na mesma \u00e1rea, no dom\u00ednio da Combust\u00e3o Experimental, pelo Imperial College de Londres e obteve o t\u00edtulo de agregado pela Universidade T\u00e9cnica de Lisboa em 1992.\\nRealizou um p\u00f3s-doutoramento na Universidade da Calif\u00f3rnia, em San Diego.\\n\\nEnsino e investiga\u00e7\u00e3o\\n\u00c9 professor catedr\u00e1tico do Instituto Superior T\u00e9cnico, institui\u00e7\u00e3o onde tem desenvolvido a sua carreira acad\u00e9mica, inicialmente na \u00e1rea de Mec\u00e2nica de Fluidos e Combust\u00e3o Experimental, e, mais recentemente, coordenando os programas de doutoramento daquele Instituto nas \u00e1reas da \u00abEngenharia e Pol\u00edticas P\u00fablicas\u00bb e da \u00abEngenharia de Concep\u00e7\u00e3o e Sistemas Avan\u00e7ados de Manufactura\u00bb.\\n\\nDesempenhou as fun\u00e7\u00f5es de Presidente Adjunto do Instituto Superior T\u00e9cnico entre 1993 e 1998.\\n\\nDesde o in\u00edcio dos anos 90 do s\u00e9culo XX tem-se dedicado ao estudo de pol\u00edticas de ci\u00eancia, tecnologia e inova\u00e7\u00e3o, incluindo as pol\u00edticas e gest\u00e3o do ensino superior.\\n\\nDirige o \u00abCentro de Estudos em Inova\u00e7\u00e3o, Tecnologia e Politicas de Desenvolvimento, IN+\u00bb, do Instituto Superior T\u00e9cnico, cuja funda\u00e7\u00e3o promoveu em 1998.\\nEm 2005, este Centro foi nomeado como um dos Top 50 global centres of research on Management of Technology, pela International Association for the Management of Technology.\\n\\nFoi Professor Visitante na Universidade Harvard no ano letivo de 2011-2012.\\n\\n\u00c9 Research Fellow da Universidade do Texas em Austin, no Instituto IC2, Innovation, Creativity and Capital.\\n\\nEm julho 2015 promoveu em Portugal o Manifesto \u00abO Conhecimento como Futuro\u00bb e, mais recentemente, a declara\u00e7\u00e3o internacional \u00abKnowledge as Our Common Future\u00bb.\\n\\nAtividade pol\u00edtica\\n\\nFoi Secret\u00e1rio de Estado da Ci\u00eancia, Tecnologia e Ensino Superior, dos XVII e XVIII Governos, entre mar\u00e7o de 2005 e junho de 2011.\\n\\nNestas fun\u00e7\u00f5es participou ativamente na moderniza\u00e7\u00e3o do sistema de ensino portugu\u00eas e no aumento do financiamento p\u00fablico e privado para atividades de ci\u00eancia e tecnologia.\\n\\nNesta fun\u00e7\u00f5es desenvolveu igualmente a conce\u00e7\u00e3o e concretiza\u00e7\u00e3o de cons\u00f3rcios internacionais em investiga\u00e7\u00e3o e forma\u00e7\u00e3o avan\u00e7ada entre universidades portuguesas e norte americanas, envolvendo redes tem\u00e1ticas de ci\u00eancia e tecnologia.\\n\\n\u00c9 ministro da Ci\u00eancia, Tecnologia e Ensino Superior desde 2015.\\n\\nEm 2021 Manuel Heitor anunciou a cria\u00e7\u00e3o de mais tr\u00eas escolas de Medicina em \u00c9vora, Aveiro e Vila Real.\\n\\nPortugueses de ascend\u00eancia italiana\\nPortugueses de ascend\u00eancia austr\u00edaca\\nNaturais de Lisboa\\nAlunos do Instituto Superior T\u00e9cnico\\nAlunos da Universidade da Calif\u00f3rnia\\nEngenheiros mec\u00e2nicos de Portugal\\nProfessores universit\u00e1rios de Portugal\\nPol\u00edticos do Partido Socialista (Portugal)\\nSecret\u00e1rios de Estado de Portugal\\nMinistros da Ci\u00eancia de Portugal\\nMinistros de Portugal\\nPol\u00edticos de Portugal\\nGoverno de Portugal\",\n    \"question\": \"Quando Manuel Heitor divulgou os planos para estabelecer tr\u00eas novas faculdades de medicina em Portugal?\",\n    \"answers\": {\n        \"answer_start\": array([3176]),\n        \"text\": array([\"2021\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Multibanco \u00e9 uma rede portuguesa de caixas autom\u00e1ticos (ATM) e de terminais de pagamento autom\u00e1tico (POS) pertencente \u00e0 SIBS, que tem como acionistas praticamente a totalidade das institui\u00e7\u00f5es banc\u00e1rias portuguesas. Apesar do nome multibanco ser uma marca registada, propriedade da empresa SIBS, o termo \u00e9 frequentemente empregue para designar de forma gen\u00e9rica um sistema interbanc\u00e1rio que disponibilize servi\u00e7os como o levantamento de dinheiro num dispositivo autom\u00e1tico ou o pagamento de compras em lojas f\u00edsicas.\\n\\nAtualmente, a utiliza\u00e7\u00e3o da rede Multibanco n\u00e3o se encontra limitada \u00e0 utiliza\u00e7\u00e3o de um cart\u00e3o banc\u00e1rio sendo poss\u00edvel usufruir de alguns dos servi\u00e7os Multibanco atrav\u00e9s da aplica\u00e7\u00e3o MB Way, ao possibilitar o levantamento de numer\u00e1rio em qualquer caixa autom\u00e1tico Multibanco ou pagamentos de compras nos terminais de pagamento autom\u00e1tico da rede Multibanco atrav\u00e9s da leitura de um c\u00f3digo QR, por aproxima\u00e7\u00e3o do telem\u00f3vel ou usando o n\u00famero de telem\u00f3vel.\\n\\nHist\u00f3ria \\n\\nO funcionamento do Multibanco teve in\u00edcio em setembro de 1985, com a instala\u00e7\u00e3o de 12 caixas autom\u00e1ticos (ATM) nas duas principais cidades do pa\u00eds (Lisboa e Porto). Enquanto Portugal foi um dos \u00faltimos pa\u00edses da Europa ocidental a instal\u00e1-las, o equipamento usado representou o que havia de mais avan\u00e7ado, baseado nas experi\u00eancias de outros pa\u00edses, muitos dos quais gastam agora imenso dinheiro para substituir e atualizar m\u00e1quinas obsoletas. Segundo um estudo brit\u00e2nico, o Multibanco seria o mais funcional de toda a Europa (com 60 funcionalidades), permitindo fazer opera\u00e7\u00f5es que outros sistemas europeus n\u00e3o conseguem (por exemplo, o da Noruega n\u00e3o permite mais do que levantar dinheiro, saber os saldos e carregar o telem\u00f3vel). Em Portugal, os multibancos t\u00eam tido muito sucesso, o que levou ao aparecimento de novos servi\u00e7os n\u00e3o banc\u00e1rios, como a venda de bilhetes ou o pagamento de servi\u00e7os (\u00e1gua, eletricidade, g\u00e1s, telefone, Internet, carregamento de telem\u00f3vel, Via Verde, etc.)\\n\\nEm 1987, foram introduzidos os terminais de pagamento autom\u00e1tico (POS) Multibanco que permitiam pagar em lojas f\u00edsicas com a utiliza\u00e7\u00e3o de cart\u00f5es banc\u00e1rios, mesmo com cart\u00f5es n\u00e3o exclusivos da rede Multibanco. Em 2008, estes sistemas passaram a permitir pagar faturas, carregar o telem\u00f3vel, consultar o saldo e movimentar contas, sendo neste caso, ao contr\u00e1rio do que acontece com os caixas autom\u00e1ticos Multibanco, as opera\u00e7\u00f5es feitas pelos comerciantes.\\n\\nUtiliza\u00e7\u00e3o \\n\\nEm 2014, haviam cerca de 270 mil terminais de pagamento autom\u00e1tico Multibanco. Em 2018, existiam cerca de 12 mil caixas multibanco de norte a sul do pa\u00eds, incluindo as regi\u00f5es aut\u00f3nomas dos A\u00e7ores e da Madeira. Diariamente, s\u00e3o levantados das m\u00e1quinas de Multibanco cerca de 71 milh\u00f5es de euros. A SIBS gere cerca de tr\u00eas mil milh\u00f5es de opera\u00e7\u00f5es financeiras por ano com um valor superior a 4,5 mil milh\u00f5es de euros e conta com mais de 300 milh\u00f5es de utilizadores, nacionais e estrangeiros.\\n\\nCom a exce\u00e7\u00e3o de 2019, o n\u00famero de terminais no pa\u00eds tem vindo a diminuir ano ap\u00f3s ano. Esta redu\u00e7\u00e3o surge em paralelo com a redu\u00e7\u00e3o acelerada da utiliza\u00e7\u00e3o dos terminais em favor do uso de aplica\u00e7\u00f5es m\u00f3veis e web-sites.\\n\\nVer tamb\u00e9m\\n Rede interbanc\u00e1ria\\n Caixa autom\u00e1tico\\n Plus\\n Cirrus\\n\\nLiga\u00e7\u00f5es externas \\n\\n SIBS - institui\u00e7\u00e3o de pagamento gestora dos sistemas Multibanco em Portugal\\n\\nRedes interbanc\u00e1rias\\nCaixas eletr\u00f4nicos\\nSistema banc\u00e1rio\\nInven\u00e7\u00f5es e descobertas portuguesas\",\n    \"question\": \"Quando \u00e9 que os terminais de pagamento autom\u00e1tico Multibanco come\u00e7aram a ser usados?\",\n    \"answers\": {\n        \"answer_start\": array([1976]),\n        \"text\": array([\"1987\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"O furac\u00e3o do Dia do Trabalho de 1935 foi o ciclone tropical mais forte da temporada de furac\u00f5es no oceano Atl\u00e2ntico de 1935. Tem sido um dos mais intensos dos que t\u00eam tocado terra nos Estados Unidos e o primeiro dos tr\u00eas furac\u00f5es de categoria 5 que t\u00eam a\u00e7oitado este pa\u00eds durante o s\u00e9culo XX, sendo os outros o Furac\u00e3o Camille em 1969 e o Furac\u00e3o Andrew em 1992. Depois de ter-se gerado como uma d\u00e9bil tempestade tropical ao leste das Bahamas a 29 de agosto de 1935, avan\u00e7ou lentamente para o oeste, se convertendo em furac\u00e3o a 1 de setembro, intensificando rapidamente a sua pot\u00eancia antes de golpear a parte norte das Florida Keys a 2 de setembro. Ap\u00f3s tocar terra em seu pico de intensidade, seguiu ao noroeste ao longo da costa oeste da Fl\u00f3rida, e debilitado anteriormente a terra para perto de Cedar Keys a 4 de setembro.\\n\\nO furac\u00e3o causou graves danos na zona norte das Florida Keys, vendo-se toda a regi\u00e3o afectada por uma forte marejada, com ondas dentre 4 e 9 metros aproximadamente. Por causa dos fortes ventos a maioria dos edif\u00edcios na zona de Islamorada ficaram destru\u00eddos. As linhas ferrovi\u00e1rias da Key West Fl\u00f3rida viram-se gravemente danificadas ou destru\u00eddas. O furac\u00e3o tamb\u00e9m causou danos a seu passo pelo noroeste da Fl\u00f3rida, Ge\u00f3rgia e as Carolinas. Calcula-se que ao todo morreram mais de 400 pessoas. Este furac\u00e3o iguala o recorde com o Furac\u00e3o Dorian por ter sido o furac\u00e3o mais potente que tenha golpeado os Estados Unidos quanto a press\u00e3o barom\u00e9trica.\\n\\n1935 nos Estados Unidos\",\n    \"question\": \"Qual o furac\u00e3o mais intenso que ocorreu na \u00e9poca dos furac\u00f5es no Atl\u00e2ntico em 1935?\",\n    \"answers\": {\n        \"answer_start\": array([0]),\n        \"text': array([\"O furac\u00e3o do Dia do Trabalho de 1935\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Os textos que se seguem s\u00e3o acompanhados de perguntas e respostas.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texto: {text}\nPergunta: {question}\nResposta com um m\u00e1ximo de 3 palavras: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texto: {text}\n\nResponde \u00e0 seguinte pergunta sobre o texto acima num m\u00e1ximo de 3 palavras.\n\nPergunta: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-pt\n</code></pre>"},{"location":"datasets/portuguese/#unofficial-boolq-pt","title":"Unofficial: BoolQ-PT","text":"<p>This dataset was published in this paper and is part of the ExtraGLUE dataset. It is created by taking the original BoolQ dataset and using machine translation (DeepL) to translate it.</p> <p>The original dataset has a passage, question, and yes/no label. We adapt this dataset by taking the original passage, question, and yes/no options, and turning it into a Q/A style question where the model can answer yes or no.</p> <p>The original dataset contains 9,430 training, 3,270 validation, and 3,250 test samples. We use 1,024 / 256 / 2,048 samples for train / val / test respectively. We've observed some overlap in the splits, so decided to concatenate all splits into a single dataset, shuffling it, and extract splits.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Texto: Animais Fant\u00e1sticos e Onde Encontr\u00e1-los -- Fantastic Beasts and Where to Find Them \u00e9 um livro de 2001 escrito pela autora brit\u00e2nica J.K. Rowling (sob o pseud\u00f3nimo do autor fict\u00edcio Newt Scamander) sobre as criaturas m\u00e1gicas do universo Harry Potter. A vers\u00e3o original, ilustrada pela pr\u00f3pria autora, pretende ser a c\u00f3pia de Harry Potter do livro did\u00e1tico com o mesmo nome mencionado em Harry Potter e a Pedra Filosofal (ou Harry Potter and the Sorcerer's Stone nos EUA), o primeiro romance da s\u00e9rie Harry Potter. Inclui v\u00e1rias notas no seu interior, supostamente escritas \u00e0 m\u00e3o por Harry, Ron Weasley e Hermione Granger, detalhando as suas pr\u00f3prias experi\u00eancias com algumas das bestas descritas e incluindo piadas relacionadas com a s\u00e9rie original.\\nPergunta: Animais fant\u00e1sticos e onde encontr\u00e1-los est\u00e1 relacionado com Harry Potter?\\nOp\u00e7\u00f5es:\\na. sim\\nb. n\u00e3o\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texto: Oceano Ant\u00e1rtico -- O Oceano Ant\u00e1rtico, tamb\u00e9m conhecido como Oceano Ant\u00e1rtico ou Oceano Austral, compreende as \u00e1guas mais a sul do Oceano Mundial, geralmente consideradas a sul de 60\u00b0 de latitude sul e circundando a Ant\u00e1rctida. Como tal, \u00e9 considerado como a quarta maior das cinco principais divis\u00f5es oce\u00e2nicas: mais pequeno do que os oceanos Pac\u00edfico, Atl\u00e2ntico e \u00cdndico, mas maior do que o oceano \u00c1rtico. Esta zona oce\u00e2nica \u00e9 o local onde as \u00e1guas frias da Ant\u00e1rctida, que fluem para norte, se misturam com as \u00e1guas subant\u00e1rcticas, mais quentes.\\nPergunta: Existe um oceano chamado oceano Austral?\\nOp\u00e7\u00f5es:\\na. sim\\nb. n\u00e3o\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texto: Lista dos votos de desempate dos vice-presidentes dos Estados Unidos -- O vice-presidente dos Estados Unidos \u00e9 o presidente ex officio do Senado, como previsto no artigo I, sec\u00e7\u00e3o 3, cl\u00e1usula 4, da Constitui\u00e7\u00e3o dos Estados Unidos, mas s\u00f3 pode votar para desempatar. De acordo com o Senado dos Estados Unidos, at\u00e9 28 de fevereiro de 2018, o voto de desempate foi dado 264 vezes por 36 vice-presidentes.\\nPergunta: O vice-presidente j\u00e1 desempatou alguma vez no Senado?\\nOp\u00e7\u00f5es:\\na. sim\\nb. n\u00e3o\"\n  \"label\": \"a\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>As seguintes s\u00e3o perguntas de escolha m\u00faltipla (com respostas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pergunta: {text}\nOp\u00e7\u00f5es:\na. {option_a}\nb. {option_b}\nResposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:</li> </ul> <pre><code>Pergunta: {text}\nOp\u00e7\u00f5es:\na. {option_a}\nb. {option_b}\n\nResponde \u00e0 pergunta acima usando s\u00f3 'a' ou 'b', e nada mais.\n</code></pre> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset boolq-pt\n</code></pre>"},{"location":"datasets/portuguese/#knowledge","title":"Knowledge","text":""},{"location":"datasets/portuguese/#mmlu-pt","title":"MMLU-pt","text":"<p>This dataset was published in this paper and is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Portuguese was done using DeepL.</p> <p>The original full dataset consists of 270 / 1,439 / 14,774 samples for training, validation, and testing, respectively. These splits were merged, duplicates removed, and new splits were created with 1,024 / 256 / 2048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"De que tipo de direitos gozam os Estados costeiros sobre a sua plataforma continental?\\nOp\u00e7\u00f5es:\\na. O Estado costeiro goza ipso facto e ab initio de direitos soberanos sobre a sua plataforma continental para efeitos de explora\u00e7\u00e3o e aproveitamento dos seus recursos naturais\\nb. O Estado costeiro s\u00f3 pode exercer direitos soberanos sobre a sua plataforma continental mediante declara\u00e7\u00e3o\\nc. O Estado costeiro exerce direitos soberanos sobre a sua plataforma continental para efeitos de explora\u00e7\u00e3o dos seus recursos hali\u00eauticos\\nd. O Estado costeiro s\u00f3 pode exercer direitos limitados sobre a sua plataforma continental e apenas com o consentimento dos Estados vizinhos\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Qual delas n\u00e3o \u00e9 uma compet\u00eancia-chave reconhecida da gest\u00e3o?\\nOp\u00e7\u00f5es:\\na. Compet\u00eancias conceptuais\\nb. Compet\u00eancias humanas\\nc. Compet\u00eancias t\u00e9cnicas\\nd. Compet\u00eancias de reda\u00e7\u00e3o\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"O presidente executa um \"veto de bolso\" fazendo qual das seguintes op\u00e7\u00f5es?\\nOp\u00e7\u00f5es:\\na. Manifestando publicamente a rejei\u00e7\u00e3o de um projeto de lei\\nb. Emitindo uma ordem executiva que invalida um projeto de lei recentemente aprovado\\nc. N\u00e3o assinando um projeto de lei ap\u00f3s o encerramento do Congresso\\nd. Retirando embaixadores de uma negocia\u00e7\u00e3o de paz\",\n    \"label\": \"c\",\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>As seguintes s\u00e3o perguntas de escolha m\u00faltipla (com respostas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pergunta: {text}\nOp\u00e7\u00f5es:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nResposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:</li> </ul> <pre><code>Pergunta: {text}\nOp\u00e7\u00f5es:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nResponde \u00e0 pergunta acima usando s\u00f3 'a' ou 'b', 'c' ou 'd', e nada mais.\n</code></pre> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-pt\n</code></pre>"},{"location":"datasets/portuguese/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/portuguese/#goldenswag-pt","title":"GoldenSwag-pt","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Como fazer com que o seu namorado \u00e0 dist\u00e2ncia se sinta especial. Escreva uma carta de amor \u00e0 moda antiga para enviar por correio normal. Embora seja poss\u00edvel enviar um e-mail instantaneamente, receber um pacote ou uma carta pelo correio \u00e9 um esfor\u00e7o muito mais \u00edntimo e sincero. As cartas tamb\u00e9m criam uma recorda\u00e7\u00e3o que n\u00e3o pode ser feita por correio eletr\u00f3nico.\\nOp\u00e7\u00f5es:\\na. N\u00e3o se preocupe em escrever o poema perfeito ou algo profundo, o facto de se ter esfor\u00e7ado por escrever \u00e9 suficiente. Pode fazer um desenho, encontrar um cart\u00e3o pr\u00e9-fabricado ou at\u00e9 enviar um postal de um local especial.\\nb. Considere a possibilidade de criar um \u00e1lbum de recortes com as notas do seu casamento como forma de surpreender o seu namorado com flores, um colar sentido ou at\u00e9 uma caixa com os brinquedos favoritos dele. A carta ir\u00e1 acompanhar a maioria dos filmes favoritos dele, dos quais voc\u00ea e o seu homem gostam de falar.\\nc. Numa carta, escrevem-se palavras que v\u00e3o at\u00e9 ao cora\u00e7\u00e3o da pessoa. Se quiser enganar algu\u00e9m para que lhe conte um pequeno segredo que lhe contou, tem de ter cuidado.\\nd. Escreva-o em sil\u00eancio, n\u00e3o em voz alta e clara, e pe\u00e7a ao destinat\u00e1rio que o leia duas vezes. Utilize a linha de assunto para explicar a raz\u00e3o pela qual est\u00e1 a escrever ao seu namorado.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Como cultivar inhame. Comece a cultivar os rebentos. Os inhames n\u00e3o s\u00e3o cultivados a partir de sementes como a maioria dos outros vegetais - eles crescem a partir de estacas, que s\u00e3o derivadas dos rebentos de inhames adultos. Para fazer crescer os rebentos, corte um inhame ao meio e mergulhe uma das partes num copo de \u00e1gua fria.\\nOp\u00e7\u00f5es:\\na. Mesmo antes de as plantas come\u00e7arem a brotar, escave um peda\u00e7o do caule e coloque-o debaixo da \u00e1gua para que fique nivelado com o fundo do copo. Repita este processo at\u00e9 ter cerca de 5 cm de caule.\\nb. A meio do processo de imers\u00e3o, feche a outra metade num balde de \u00e1gua comercial. Pense em usar latas, baldes tupperware e outros recipientes que sejam grandes o suficiente para conter v\u00e1rios inhames de uma vez.\\nc. Voc\u00ea deve ver as sementes brotarem. Se n\u00e3o conseguir, corte pequenas sec\u00e7\u00f5es e mantenha os rebentos no copo de \u00e1gua fria.\\nd. Insira palitos de dentes em tr\u00eas pontos \u00e0 volta do meio do inhame e suspenda-o sobre o recipiente, meio submerso na \u00e1gua. Certifique-se de que o inhame escolhido tem um aspeto saud\u00e1vel.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n\"text\": \"Como detetar o pl\u00e1gio. Utilize aplica\u00e7\u00f5es online gratuitas que n\u00e3o requerem subscri\u00e7\u00f5es ou inscri\u00e7\u00f5es para verificar documentos electr\u00f3nicos. Pesquise no Google \"verificador de pl\u00e1gio\" para encontrar uma s\u00e9rie de aplica\u00e7\u00f5es Web gratuitas que cont\u00eam caixas onde pode colar o texto suspeito. Carregue no bot\u00e3o verificar e deixe que a aplica\u00e7\u00e3o analise a Internet em busca de inst\u00e2ncias de texto duplicado.\\nOp\u00e7\u00f5es:\\na. Qualquer coisa que apare\u00e7a indica que est\u00e1 a utilizar uma destas aplica\u00e7\u00f5es gratuitas. Normalmente, \u00e9 necess\u00e1rio iniciar sess\u00e3o no in\u00edcio da aplica\u00e7\u00e3o.\\nb. Cuidado! Utilizar os motores de busca para descobrir alguns sites oficiais de educa\u00e7\u00e3o e classific\u00e1-los como \"falsos\". Exemplo: ' math problem manuscript for mr.\\nc. Se quiser converter pdfs em texto, pode faz\u00ea-lo. Algu\u00e9m que entregue um documento pdf, embora n\u00e3o seja inerentemente suspeito, pode ser um sinal de que est\u00e1 a tentar evitar ser apanhado.\\nd. Aparecer\u00e1 uma janela de teste a perguntar se precisa de uma aplica\u00e7\u00e3o de pesquisa. Se n\u00e3o precisar, escolha google ' anti-pasteuriza\u00e7\u00e3o.\",\n\"label\": \"c\",\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>As seguintes s\u00e3o perguntas de escolha m\u00faltipla (com respostas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pergunta: {text}\nOp\u00e7\u00f5es:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nResposta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:</li> </ul> <pre><code>Pergunta: {text}\nOp\u00e7\u00f5es:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nResponde \u00e0 pergunta acima usando s\u00f3 'a' ou 'b', 'c' ou 'd', e nada mais.\n</code></pre> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-pt\n</code></pre>"},{"location":"datasets/portuguese/#summarization","title":"Summarization","text":""},{"location":"datasets/portuguese/#publico","title":"Publico","text":"<p>This dataset contains 3,304 news articles from the Portuguese newspaper P\u00fablico paired with extractive-style summaries. The samples all come from the CCNews corpus.</p> <p>To create summary\u2013document pairs, we extract the first two sentences of each article as the <code>target_text</code> (summary), and concatenate the title and the remainder of the article into <code>text</code>. This heuristic is grounded in the journalistic convention of placing concise leads at the beginning of articles.</p> <p>We provide 3 splits: - Train: 1,024 examples - Validation: 256 examples - Test: 2,024 examples</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"As grandes transi\u00e7\u00f5es, o risco de disrup\u00e7\u00e3o\\nPor que raz\u00e3o se acumulam tantos riscos elevados e com tal perigosidade? A raz\u00e3o principal, quero crer, reside no afloramento dos impactos das grandes transi\u00e7\u00f5es - clim\u00e1tica, ecol\u00f3gica, energ\u00e9tica, demogr\u00e1fica, digital, migrat\u00f3ria, laboral, sociocultural e sociopol\u00edtica - e numa inusitada converg\u00eancia de todos os seus efeitos, internos e externos, nas d\u00e9cadas mais pr\u00f3ximas e, bem assim, na impot\u00eancia da pol\u00edtica, tal como a conhecemos, para lidar com tantos eventos de tal amplitude. Sen\u00e3o vejamos. A vertigem digital e as suas in\u00fameras prova\u00e7\u00f5es Eis o v\u00f3rtice em que estamos metidos: chips e sensores, drones e c\u00e2maras de vigil\u00e2ncia, interfaces c\u00e9rebro-computacionais e nano-implantes, m\u00e1quinas inteligentes e mestres algoritmos, robots e ve\u00edculos aut\u00f3nomos, torres e antenas. Neste ambiente congestionado e num campo eletromagn\u00e9tico 4G+5G cada vez mais preenchido, seria imposs\u00edvel n\u00e3o acontecerem intera\u00e7\u00f5es fortuitas, incidentes imprevistos, impactos inusitados, descobertas acidentais. Estamos, assim, obrigados a multiplicar os \u00e2ngulos de observa\u00e7\u00e3o e as perspetivas de olhar para os problemas. A surpresa pode ser, deveras, surpreendente. Basta, apenas, que aconte\u00e7am alguns acidentes graves cuja responsabilidade seja atribu\u00edda, \u201cafinal\u201d, \u00e0 utiliza\u00e7\u00e3o abusiva de sistemas de intelig\u00eancia autom\u00e1ticos e ve\u00edculos aut\u00f3nomos. Estou convencido de que neste novo ambiente de virtualidade real a descontextualiza\u00e7\u00e3o que a intelig\u00eancia artificial e autom\u00e1tica carrega consigo nos far\u00e1 passar in\u00fameras prova\u00e7\u00f5es. Velocidade e colis\u00e3o Com a chegada das redes 4G e 5G chegam as tecnologias mais disruptivas, mas chega, tamb\u00e9m, o risco de mais imers\u00e3o, invas\u00e3o e intrus\u00e3o, ou seja, o risco iminente de uma grande colis\u00e3o. Dito de outro modo, com a chegada das redes distribu\u00eddas as tecnologias imersivas, intrusivas e invasivas ir\u00e3o colidir, tarde ou cedo, com os seus destinat\u00e1rios potenciais. O que importa sublinhar nesta altura, no preciso momento em que a alta velocidade da rede 5G est\u00e1 para chegar, \u00e9 o risco muito elevado de uma \u201cgrande colis\u00e3o por excesso de velocidade\u201d. De facto, a pandemia da covid-19 mostra-nos que est\u00e1 iminente uma grande colis\u00e3o entre o infinitamente grande dos macro-organismos, os seres humanos que n\u00f3s somos, e o infinitamente pequeno dos microorganismos, como \u00e9 o caso da covid-19. Efeitos assim\u00e9tricos Os efeitos assim\u00e9tricos destas grandes transi\u00e7\u00f5es v\u00e3o deixar muitos territ\u00f3rios para tr\u00e1s. Cada transi\u00e7\u00e3o tem o seu ciclo de vida espec\u00edfico, com uma dura\u00e7\u00e3o vari\u00e1vel, e \u00e9 completamente imposs\u00edvel abordar todas as suas consequ\u00eancias no \u00e2mbito limitado de uma escala de tempo ou geografia em concreto. Ou seja, cada territ\u00f3rio nacional ou regional acabar\u00e1 por sofrer, tarde ou cedo, os danos colaterais de medidas erradas tomadas pelos territ\u00f3rios seus vizinhos. \u00c9 nesta altura, justamente, que organiza\u00e7\u00f5es supranacionais como a Uni\u00e3o Europeia ou subnacionais como as comunidades intermunicipais poder\u00e3o e dever\u00e3o mostrar toda a sua relev\u00e2ncia geoecon\u00f3mica e geopol\u00edtica. As intera\u00e7\u00f5es fortuitas e os imponder\u00e1veis do acaso As caracter\u00edsticas principais da rede 5G s\u00e3o a hipervelocidade, baixa lat\u00eancia, alta conectividade, elevada densidade e intensidade, curto alcance. Se pensarmos, agora, no pol\u00edgono digital que esta rede nos oferece \u2013 Big data e computa\u00e7\u00e3o na nuvem, (BDCC), Internet dos objetos (IOT), Intelig\u00eancia artificial (IA), Realidade aumentada e virtual (RAV), Computa\u00e7\u00e3o perif\u00e9rica (EC) \u2013 e na intera\u00e7\u00e3o intensa entre estes e outros dispositivos tecnol\u00f3gicos e digitais, estamos cada vez mais pr\u00f3ximos das chamadas \u201cpropriedades emergentes\u201d do \u201cserendipismo\u201d (do ingl\u00eas serenpidity), a saber, intera\u00e7\u00f5es fortuitas, incidentes imprevistos, impactos inusitados, descobertas acidentais. Ou seja, perante a interdepend\u00eancia m\u00e1xima crescem extraordinariamente os imponder\u00e1veis do acaso. Dispositivos tecnol\u00f3gicos e assistentes inteligentes Na sociedade da informa\u00e7\u00e3o e da comunica\u00e7\u00e3o a intelig\u00eancia deixou de estar contida nos limites humanos originais. Com efeito, nos dias que correm, a intelig\u00eancia est\u00e1 dispersa e difusa, manifesta-se sob m\u00faltiplas formas e interage com praticamente tudo o que nos envolve. Deste ponto de vista, a realidade n\u00e3o para de aumentar todos os dias \u00e0 medida que a intelig\u00eancia se transfere para ambientes inteligentes que s\u00e3o extens\u00f5es da nossa pr\u00f3pria intelig\u00eancia. Hoje tudo \u00e9 smart, desde a realidade virtual e aumentada aos interfaces c\u00e9rebro-computacionais, desde a intelig\u00eancia dos objetos at\u00e9 \u00e0 intelig\u00eancia das m\u00e1quinas. De facto, a nossa intelig\u00eancia e as faculdades humanas est\u00e3o a transitar para fora do seu habitat biol\u00f3gico e o corpo humano instala-se em dispositivos tecnol\u00f3gicos transumanos e p\u00f3s-humanos cuja configura\u00e7\u00e3o futura nem sequer imaginamos. Entre a distra\u00e7\u00e3o e a alucina\u00e7\u00e3o Somos screeners muitas horas por dia, \u00e9 imposs\u00edvel manter a aten\u00e7\u00e3o num ambiente completamente saturado de notifica\u00e7\u00f5es e avisos. A multiplica\u00e7\u00e3o dos dispositivos tecnol\u00f3gicos e digitais \u2013 uma esp\u00e9cie de sexto continente - exige de n\u00f3s uma atualiza\u00e7\u00e3o constante. Todos os dias mergulhamos num imenso oceano de informa\u00e7\u00e3o, experimentamos uma vertigem permanente para separar o essencial do acess\u00f3rio e lutamos com imensas dificuldades para administrar a nossa economia da aten\u00e7\u00e3o. No final do dia estamos exaustos e no dia seguinte, ainda debilitados, tudo recome\u00e7a. Na vertigem o foco da aten\u00e7\u00e3o converte-se num turbilh\u00e3o, talvez, mesmo, em del\u00edrio e alucina\u00e7\u00e3o. As mudan\u00e7as paradigm\u00e1ticas Entre tantas transi\u00e7\u00f5es previs\u00edveis e excecionais haver\u00e1, tamb\u00e9m, mudan\u00e7as paradigm\u00e1ticas, cujos sinais de longo alcance s\u00f3 alguns vislumbrar\u00e3o. O drama das mudan\u00e7as paradigm\u00e1ticas \u00e9 que elas n\u00e3o se compadecem com a dura\u00e7\u00e3o dos ciclos pol\u00edticos curtos e muito menos com programas de governo reativos. A redu\u00e7\u00e3o dos passivos clim\u00e1ticos, tais como o sequestro e armazenamento de carbono, ou a mudan\u00e7a de alguns aspetos nucleares do modelo de desenvolvimento dominante, por exemplo, a revis\u00e3o de algumas cadeias de valor no sentido da sua reterritorializa\u00e7\u00e3o, ou, ainda, a mudan\u00e7a de aspetos fundamentais do nosso comportamento quotidiano, por exemplo, no que diz respeito ao cumprimento de regras base de economia circular. Quer dizer, temos de estar avisados, n\u00e3o podemos permitir que os efeitos contraproducentes ou paradoxais das v\u00e1rias transi\u00e7\u00f5es acabem por absorver os pequenos/grandes sinais das mudan\u00e7as paradigm\u00e1ticas. Notas Finais Como se observa, o risco de disrup\u00e7\u00e3o est\u00e1 sempre presente, seja o car\u00e1cter invasivo e intrusivo das tecnologias 5G, a histeria coletiva de informa\u00e7\u00e3o e comunica\u00e7\u00e3o num ambiente totalmente saturado, a cren\u00e7a nos mestres-algoritmos e na metalinguagem normalizadora das plataformas digitais. Digamos que, doravante, crescer\u00e1 bastante o risco sist\u00e9mico da economia digital 4G e 5G e, nesse sentido, estamos obrigados a desenvolver treino espec\u00edfico e capacidades especiais para entender e antecipar como se forjam e desenvolvem as intera\u00e7\u00f5es fortuitas, os incidentes imprevistos e, por via deles, tamb\u00e9m, as descobertas acidentais. Este \u00e9 o grande paradoxo do nosso tempo. Mais liberdade, mais incerteza, mais epis\u00f3dios acidentais. Por outro lado, os sinais dessas intera\u00e7\u00f5es acidentais podem ser de tal modo fortuitos e furtivos que dificilmente caber\u00e3o no interior das nossas m\u00e9tricas conceptuais e instrumentais habituais. O nosso arsenal te\u00f3rico e, muito em especial, o campo das ci\u00eancias sociais e humanas, com origem no iluminismo moderno e na cultura anal\u00f3gica, est\u00e3o definitivamente postos em causa e a academia deve preparar-se para rever o seu estatuto cient\u00edfico eminente se n\u00e3o quiser ser um ator secund\u00e1rio que corre pelo lado de fora da realidade da cultura tecnol\u00f3gica e digital.\",\n    \"target_text\": \"O nosso tempo n\u00e3o corre de fei\u00e7\u00e3o. Desastres ambientais motivados por altera\u00e7\u00f5es clim\u00e1ticas, campos de refugiados em n\u00famero crescente, pandemia da covid-19, elevado n\u00famero de abalos de terra e erup\u00e7\u00f5es vulc\u00e2nicas, adi\u00e7\u00e3o digital e \u00f3dio nas redes sociais, polariza\u00e7\u00e3o social e radicaliza\u00e7\u00e3o pol\u00edtica, crise da transi\u00e7\u00e3o energ\u00e9tica, precariedade nos mercados de trabalho e baixos sal\u00e1rios, d\u00edvidas p\u00fablicas acumuladas gigantescas, crescente tens\u00e3o geopol\u00edtica entre grandes pot\u00eancias.\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Sloane Stephens bateu todas as probabilidades\\nFiel \u00e0s indica\u00e7\u00f5es do treinador \u2013 \u201cRespira, bate na bola, mexe os p\u00e9s\u201d \u2013, Stephens soube controlar melhor as emo\u00e7\u00f5es, embora, na v\u00e9spera n\u00e3o soubesse o que fazer para lidar com o nervosismo. \u201cEstive a ler revistas de carros, cr\u00edticas sobre a seguran\u00e7a\u2026 \u00e9 um pouco estranho mas foi o que fiz. Estava muito nervosa, mas sabia que ela, provavelmente, sentia o mesmo\u201d, contou a norte-americana de 24 anos. N\u00e3o foi preciso muito tempo para se saber quem estava mais \u00e0 vontade no Arthur Ashe Stadium: tr\u00eas erros directos de Keys conduziram ao primeiro break e deram uma vantagem de 3-2 \u00e0 compatriota. A ansiedade da jogadora de 22 anos foi aumentando, o que n\u00e3o ajudou a que reencontrasse o seu t\u00e9nis poderoso. E Keys terminou com somente metade dos pontos disputados com o seu primeiro servi\u00e7o e sem concretizar nenhum dos tr\u00eas break-points \u2013 todos no segundo jogo do segundo set. Mais conservadora no seu estilo de jogo, Stephens n\u00e3o precisou muito mais do que manter a bola em campo para manter o ascendente no encontro. Mas tamb\u00e9m serviu bem, contra-atacou e defendeu-se muito bem nas espor\u00e1dicas tentativas de reac\u00e7\u00e3o de Keys, e fechou o encontro ao fim dos 61 minutos. \u201cFiz seis erros em todo o encontro? Inacredit\u00e1vel! Acho que isso nunca me aconteceu antes\u201d, confessou Stephens, j\u00e1 na confer\u00eancia de imprensa, ap\u00f3s a vit\u00f3ria por 6-3, 6-0. Antes, tamb\u00e9m tinha ficado boquiaberta quando Keys cometeu o \u00faltimo erro, no terceiro match-point. \u201c\u2019Ganhei mesmo o Open dos EUA\u2019. Fiquei assim um bocadinho\u2026 Uau!\u201d, admitiu. E foi de estupefac\u00e7\u00e3o o seu ar quando recebeu o cheque de tr\u00eas milh\u00f5es de euros. Pelo meio, abra\u00e7ou longamente na rede a amiga Maddy, que n\u00e3o conseguiu conter as l\u00e1grimas. E depois de subir \u00e0s bancadas para abra\u00e7ar treinador, fam\u00edlia e o namorado (o futebolista Jozy Altidore), foi sentar-se ao lado dela, fazendo-a sorrir. \u201cSendo a amiga que \u00e9, Sloane apoiou-me muito\u201d, contou Keys, que tamb\u00e9m reconheceu os nervos. \u201cEstive nervosa toda a manh\u00e3, obviamente. Sloane \u00e9 uma advers\u00e1ria dif\u00edcil de defrontar, especialmente quando n\u00e3o metemos muitas bolas e ela tamb\u00e9m n\u00e3o falha. N\u00e3o sabia o que fazer quando estava no court, o que intensificou ainda mais o nervosismo\u201d, admitiu Keys. Por causa das paragens for\u00e7adas, nenhuma delas vai surgir no \"top-10\" do ranking desta segunda-feira. Stephens, que regressou \u00e0 competi\u00e7\u00e3o em Julho, ap\u00f3s uma paragem de 11 meses e uma opera\u00e7\u00e3o ao p\u00e9 direito, vai surgir no 17.\u00ba lugar. J\u00e1 Keys, operada por duas vezes ao pulso esquerdo, a segunda em Junho, vai subir ao 12.\u00ba lugar. Mas com o regresso em pleno das veteranas Serena Williams, Victoria Azarenka e Maria Sharapova, o confronto com a nova gera\u00e7\u00e3o, em que se incluem as duas norte-americanas, mas tamb\u00e9m as campe\u00e3s Jelena Ostapenko (Roland Garros) e Garbi\u00f1e Muguruza (Wimbledon), vai elevar o interesse sobre o circuito feminino em 2018. Quatro anos e meio depois de derrotar Serena Williams, ser apontada como sua sucessora e chegar \u00e0s meias-finais do Open da Austr\u00e1lia, Stephens est\u00e1 orgulhosa por ter confirmado as expectativas. \u201cUm dia, vou poder mostrar aos meus filhos que venci o Open dos EUA. Quantas pessoas podem dizer isto? At\u00e9 j\u00e1 gravaram o meu nome no vestu\u00e1rio. Isto \u00e9 espantoso\u201d, disse Stephens, ainda incr\u00e9dula.\",\n    \"target_text\": \"Se j\u00e1 era altamente improv\u00e1vel que duas jogadoras vindas de recentes interven\u00e7\u00f5es cir\u00fargicas pudessem, poucos meses depois, estar numa final de um torneio do Grand Slam, as hip\u00f3teses de Sloane Stephens vencer o Open dos EUA eram mais reduzidas depois da sua amiga Madison Keys ter realizado uma exibi\u00e7\u00e3o de sonho nas meias-finais. Mas, no derradeiro encontro entre duas estreantes em finais de majors, o maior nervosismo de Keys impediu-a de produzir o t\u00e9nis que a levou a eliminar Venus Williams e, com 30 erros n\u00e3o for\u00e7ados, contribuiu com metade dos pontos ganhos por Stephens e suficientes para erguer o seu primeiro trof\u00e9u do Grand Slam.\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Praia algarvia entre as seis melhores do mundo, destaca TripAdvisor\\nDesta vez, deixa a segunda metade da tabela para firmar-se entre os dez melhores areais do planeta, subindo seis lugares em rela\u00e7\u00e3o a 2021. \u201c\u00c9 uma praia deslumbrante... o sol bate nos diferentes tons de areia laranja e amarela das fal\u00e9sias altas que reflectem uma cor quente\u201d, l\u00ea-se no coment\u00e1rio de um utilizador, destacado pela TripAdvisor em comunicado. \u201cA pr\u00f3pria areia da praia \u00e9 um amarelo dourado de gr\u00e3o fino. As ondas quebram na praia com uma ferocidade gentil que cria um surf branco para nadadores e surfistas.\u201d Para criar a lista, renovada anualmente, a TripAdvisor rev\u00ea \u201cdezenas de milh\u00f5es de avalia\u00e7\u00f5es enviadas por milh\u00f5es de viajantes globais nos \u00faltimos 12 meses\u201d, analisando \u201ca qualidade e a quantidade das avalia\u00e7\u00f5es\u201d para \u201cdeterminar as praias favoritas dos viajantes\u201d no ano anterior, antecipando tend\u00eancias para os pr\u00f3ximos meses. Este ano, as escapadelas para praias insulares surgem particularmente \u201cpopulares\u201d, \u201ccom quase tr\u00eas quartos das dez melhores do mundo a situarem-se em locais remotos\u201d, destaca a empresa em comunicado. \u00c9 o caso da praia vencedora de 2023, a brasileira Ba\u00eda do Sancho, localizada na ilha Fernando de Noronha. \u00c9 um regresso ao topo da lista, subindo seis posi\u00e7\u00f5es relativamente ao ano passado. Outro destaque \u00e9 uma \u201cnova e empolgante entrada\u201d: a \u201cdram\u00e1tica\u201d praia de Reynisfjara, em Vik, na Isl\u00e2ndia. \u201c\u00c9 uma praia como nenhuma outra\u201d, assegura a nota de imprensa. \u201cCom as suas mundialmente famosas areias negras e imponentes forma\u00e7\u00f5es rochosas que se elevam sobre a costa, alguns podem reconhecer o impressionante cen\u00e1rio de A Guerra dos Tronos.\u201d Apesar de \u201cpopular entre os observadores de p\u00e1ssaros devido aos v\u00e1rios tipos de aves marinhas avistadas nas proximidades, principalmente os papagaios-do-mar\u201d, as \u201c\u00e1guas geladas\u201d e as ondas, que podem atingir os 40 metros de altitude, n\u00e3o convidam a banhos. \u201c\u00c9 uma praia mais bem admirada da seguran\u00e7a do litoral.\u201d \u201cAl\u00e9m das adoradas praias do Havai, das Cara\u00edbas e da Europa continental, a nossa comunidade est\u00e1 mesmo \u00e0 procura de melhorar as suas experi\u00eancias ao abra\u00e7ar as fal\u00e9sias de Cannon Beach, na costa de Oregon, no Oeste dos Estados Unidos, e destinos mais frios, como a praia de Reynisfjara, na Isl\u00e2ndia\u201d, nota Sarah Firshein, chefe editorial da TripAdvisor, em comunicado.\",\n    \"target_text\": \"As \u201cexuberantes fal\u00e9sias de areia vermelha\u201d que emolduram \u201cuma praia de areia branca que parece estender-se infinitamente\u201d, terminando num \u201coceano azul-esverdeado\u201d, valeram \u00e0 praia da Fal\u00e9sia, situada em Olhos de \u00c1gua, no concelho de Albufeira, o sexto lugar do ranking das melhores praias do mundo, eleito anualmente pelos Traveler's Choice Awards, da TripAdvisor. H\u00e1 anos que o areal algarvio surge entre as prefer\u00eancias dos utilizadores da plataforma internacional, mantendo-se a \u00fanica praia portuguesa no top mundial.\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Abaixo encontras documentos com resumos associados.\n</code></pre></li> <li>Base prompt template:   <pre><code>Documento: {text}\nResumo: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Documento: {text}\n\nEscreve um resumo do documento anterior.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset publico\n</code></pre>"},{"location":"datasets/spanish/","title":"\ud83c\uddea\ud83c\uddf8 Spanish","text":"<p>This is an overview of all the datasets used in the Spanish part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/spanish/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/spanish/#sentimentheadlines-es","title":"SentimentHeadlines-es","text":"<p>This dataset was published in this paper and features political news headlines.</p> <p>The original full dataset consists of 1,371 /  609 / 459 samples for training, validation, and testing, respectively. We use 861 /  256 / 1,024 samples for training, validation, and testing, respectively. All our splits are subsets of the original ones. The label distribution for the splits are as follows:</p> Split positive negative neutral Total Train 368 248 245 861 Val 88 90 78 256 Test 417 293 314 1,024 Total 873 631 637 2,141 <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"Mauricio Macri, en el cierre de campa\u00f1a: \u201cEsta marcha no termina hoy ac\u00e1, sino en noviembre\u201d\",\n    \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Lavagna reforz\u00f3 su discurso econ\u00f3mico y pidi\u00f3 m\u00e1s consumo\",\n    \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Sin la aprobaci\u00f3n del Fondo, Macri quema reservas para la fuga\",\n    \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Lo siguiente son rese\u00f1as y su sentimiento, que puede ser 'positivo', 'neutral' o 'negativo'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texto: {text}\nSentimiento: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texto: {text}\n\nClasifica el sentimiento de la rese\u00f1a. Responde con 'positivo', 'neutral' o 'negativo', y nada m\u00e1s.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset sentiment-headlines-es\n</code></pre>"},{"location":"datasets/spanish/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/spanish/#conll-es","title":"CoNLL-es","text":"<p>This dataset was published in this paper and contains 8,324 / 1,916 / 1,518 samples for training, validation, and testing, respectively. We use 1,024 / 256 / 1,024 samples for training, validation, and testing, respectively. All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"tokens\": array([\"Todo\", \"estar\u00e1\", \"integrado\", \",\", \"la\", \"relaci\u00f3n\", \"entre\", \"los\", \"espacios\", \"y\", \"entre\", \"los\", \"m\u00fasicos\", \"y\", \"la\", \"audiencia\", \".\"], dtype=object),\n    \"labels\": array([\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], dtype=object),\n}\n</code></pre> <pre><code>{\n  \"tokens\": array([\"(\", \"NA2428-NH4437\", \")\", \"PSOE\", \"PIDE\", \"QUE\", \"COMISION\", \"CONTROL\", \"DE\", \"RTVE\", \"CONOZCA\", \"PRESUPUESTO\", \"ENTE\", \"Madrid\", \"(\", \"EFE\", \")\", \".\"], dtype=object),\n  \"labels\": array([\"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"B-ORG\", \"O\", \"O\"], dtype=object),\n}\n</code></pre> <pre><code>{\n  \"tokens\": array([\"(\", \"NA2428-NH4437\", \")\", \"PSOE\", \"PIDE\", \"QUE\", \"COMISION\", \"CONTROL\", \"DE\", \"RTVE\", \"CONOZCA\", \"PRESUPUESTO\", \"ENTE\", \"Madrid\", \"(\", \"EFE\", \")\", \".\"], dtype=object),\n  \"labels\": array([\"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"B-ORG\", \"O\", \"O\"], dtype=object),\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>Lo siguiente son oraciones y diccionarios JSON con las entidades nombradas que aparecen en la oraci\u00f3n dada.\n</code></pre></li> <li>Base prompt template:   <pre><code>Oraci\u00f3n: {text}\nEntidades nombradas: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Oraci\u00f3n: {text}\n\nIdentifica las entidades nombradas en la oraci\u00f3n. Debes producir esto como un diccionario JSON con las claves 'persona', 'lugar', 'organizaci\u00f3n' y 'miscel\u00e1neo'. Los valores deben ser listas de las entidades nombradas de ese tipo, exactamente como aparecen en la oraci\u00f3n.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>persona</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>lugar</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>lugar</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organizaci\u00f3n</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organizaci\u00f3n</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>miscel\u00e1neo</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>miscel\u00e1neo</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset conll-es\n</code></pre>"},{"location":"datasets/spanish/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/spanish/#scala-es","title":"ScaLA-es","text":"<p>This dataset was published in this paper and was automatically created from the Spanish Universal Dependencies by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 17,662 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"El fuego oblig\u00f3 al a el desalojo preventivo de algunas casas y del de el observatorio del de el Roque de los Muchachos, del de el Instituto de Astrof\u00edsica de Canarias.\",\n    \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"El libro que leemos intenta explicarlo explicar, pero sin exagerar las posturas de tirios y troyanos.\",\n    \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Por su parte, el Consejo de Ministros dio ayer otra vuelta de tuerca al a el control urban\u00edstico de las ciudades aut\u00f3nomas de Ceuta y de Melilla para evitar la urban\u00edstica por parte del de el Grupo Independiente Liberal (GIL), que gobierna en Ceuta.\",\n    \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>Lo siguiente son textos y si son gramaticalmente correctos.\n</code></pre></li> <li>Base prompt template:   <pre><code>  Texto: {text}\n  Gramaticalmente correcto: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>  Texto: {text}\n\n  Determina si el texto es gramaticalmente correcto o no. Responde con 's\u00ed' si el texto es correcto, y 'no' si no lo es.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>s\u00ed</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>no</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-es\n</code></pre>"},{"location":"datasets/spanish/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/spanish/#mlqa-es","title":"MLQA-es","text":"<p>This dataset was published in this paper and contains 0 / 500 / 5,253 samples for training, validation, and testing, respectively. We have made a 1,024 / 256 / 2,048 split, where we use the 500 validation samples + 524 test samples for training. Then we split the remaining test set into validation (256 samples) and test (2048 samples).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"En 1978, el Banco Estatal de Vietnam introdujo los primeros billetes de 5 hao, 1, 5, 10, 20 y 50 \u0111\u1ed3ng fechados en 1976. En 1980 se a\u00f1adieron los billetes de 2 y 10 \u0111\u1ed3ng, seguidos de los de 30 y 100 \u0111\u1ed3ng en 1981.\",\n    \"question\": \"\u00bfCu\u00e1ndo a\u00f1adi\u00f3 el Banco Estatal de Vietnam los billetes de 2 y 10 \u0111\u1ed3ng?\",\n    \"answers\": {\n      \"answer_start\": [120],\n      \"text\": [\"En 1980\"]\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Como otros ter\u00f3podos de la familia Dromaeosauridae, Saurornitholestes era un dinosaurio carn\u00edvoro b\u00edpedo, equipado con una garra retr\u00e1ctil con forma de oz en el segundo dedo de cada pie. Saurornitholestes era m\u00e1s ligero y ten\u00eda las patas m\u00e1s largas que otros dromaeos\u00e1uridos como Velociraptor o Dromaeosaurus. Se asemeja a Velociraptor en tener dientes grandes, parecidos a colmillos, en la parte frontal de las mand\u00edbulas.\",\n    \"question\": \"\u00bfD\u00f3nde se encuentra la garra de Saurornitholestes?\",\n    \"answers\": {\n        \"answer_start\": [161],\n        \"text\": [\"segundo dedo de cada pie\"]\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"En cinco ediciones (en las tres primeras, 1896, 1900 y 1904, as\u00ed como en las de 1988 y 1992) fueron entregadas por prueba dos medallas de bronce (una a cada uno de los perdedores de las semifinales); en el resto de ediciones se ha disputado adicionalmente un partido por el tercer lugar para definir al ganador de la medalla de bronce.\",\n    \"question\": \"\u00bfDe qu\u00e9 material fueron las medallas entregadas a los semifinalistas en 1896?\",\n    \"answers\": {\n        \"answer_start\": [138], \"text\": [\"bronce\"]\n        }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>A continuaci\u00f3n se presentan textos con sus preguntas y respuestas correspondientes.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texto: {text}\nPregunta: {question}\nRespuesta en m\u00e1ximo 3 palabras: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texto: {text}\n\nResponda la siguiente pregunta sobre el texto anterior en m\u00e1ximo 3 palabras.\n\nPregunta: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset xquad-es\n</code></pre>"},{"location":"datasets/spanish/#unofficial-xquad-es","title":"Unofficial: XQuAD-es","text":"<p>This dataset was published in this paper and contains 1190 question-answer pairs from SQuAD v1.1 translated into ten languages by professional translators.</p> <p>The dataset is split intro 550 / 128 / 512 question-answer pairs for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"El Mercado del Grainger reemplaz\u00f3 a un mercado anterior construido originalmente en 1808 llamado el Mercado del Carnicero. El Mercado del Grainger en s\u00ed mismo, se abri\u00f3 en 1835 y fue el primer mercado interior de Newcastle. En el momento de su apertura en 1835 se dijo que era uno de los mercados m\u00e1s grandes y hermosos de Europa. La inauguraci\u00f3n se celebr\u00f3 con una gran cena a la que asistieron 2000 invitados, y la Galer\u00eda de Arte Laing tiene un cuadro de este evento. Con la excepci\u00f3n del techo de madera, que fue destruido por un incendio en 1901 y sustituido por arcos de celos\u00eda de acero, el mercado se encuentra en su mayor parte en su estado original. La arquitectura del Mercado del Grainger, como la mayor\u00eda de las de Grainger Town, que est\u00e1n clasificadas en el grado I o II, fue clasificada en el grado I en 1954 por Patrimonio Ingl\u00e9s.\",\n    \"question\": \"\u00bfCu\u00e1ntos invitados asistieron a la cena de inauguraci\u00f3n del Mercado del Grainger?\",\n    \"answer\": {\n      \"answer_start\": [396],\n      \"text\": [\"2000\"]\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Los avances realizados en Oriente Medio en bot\u00e1nica y qu\u00edmica llevaron a la medicina en el Islam medieval a desarrollar sustancialmente la farmacolog\u00eda. Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes) (865-915), por ejemplo, actu\u00f3 para promover los usos m\u00e9dicos de los compuestos qu\u00edmicos. Abu al-Qasim al-Zahrawi (Abulcasis) (936-1013) fue pionero en la preparaci\u00f3n de medicamentos por sublimaci\u00f3n y destilaci\u00f3n. Su Liber servitoris es de particular inter\u00e9s, ya que proporciona al lector recetas y explica c\u00f3mo preparar los 'simples' a partir de los cuales se compon\u00edan los complejos medicamentos que se utilizaban entonces de forma generalizada. Sabur Ibn Sahl (d 869), fue, sin embargo, el primer m\u00e9dico en iniciar la farmacopedia, describiendo una gran variedad de medicamentos y remedios para las dolencias. Al-Biruni (973-1050) escribi\u00f3 una de las obras isl\u00e1micas m\u00e1s valiosas sobre farmacolog\u00eda, titulada Kitab al-Saydalah (El libro de los medicamentos), en la que detallaba las propiedades de los medicamentos y esbozaba el papel de la farmacia, as\u00ed como las atribuciones y los deberes de los farmac\u00e9uticos. Avicena tambi\u00e9n describi\u00f3 nada menos que 700 preparados, sus propiedades, modos de acci\u00f3n y sus indicaciones. De hecho, dedic\u00f3 todo un volumen a los medicamentos simples en El canon de la medicina. De gran impacto fueron tambi\u00e9n las obras de al-Maridini de Bagdad y El Cairo, y de Ibn al-Wafid (1008-1074), ambas impresas en lat\u00edn m\u00e1s de cincuenta veces, apareciendo como De Medicinis universalibus et particularibus de 'Mesue' el m\u00e1s joven, y el Medicamentis simplicibus de 'Abenguefit'. Pedro de Abano (1250-1316) tradujo y a\u00f1adi\u00f3 un suplemento a la obra de al-Maridini bajo el t\u00edtulo De Veneris. Las contribuciones de Al-Muwaffaq en este campo tambi\u00e9n son pioneras. En su vida en el siglo X, escribi\u00f3 Los fundamentos de las verdaderas propiedades de los remedios, describiendo, entre otras cosas, el \u00f3xido arsenioso, y conociendo el \u00e1cido sil\u00edcico. Hizo una clara distinci\u00f3n entre carbonato de sodio y carbonato de potasio y llam\u00f3 la atenci\u00f3n sobre la naturaleza venenosa de los compuestos de cobre, especialmente el vitriolo de cobre, y tambi\u00e9n los compuestos de plomo. Tambi\u00e9n describe la destilaci\u00f3n de agua de mar para beber [se requiere verificaci\u00f3n].\",\n    \"question\": \"\u00bfCu\u00e1les fueron los desarrollos en los que los cient\u00edficos influyeron en la creaci\u00f3n de la farmacolog\u00eda en el Islam medieval?\",\n    \"answer\": {\n      \"answer_start\": [43],\n      \"text\": [\"bot\u00e1nica y qu\u00edmica\"]\n    }\n}\n</code></pre> <pre><code>{\n    \"id\": \"5725c91e38643c19005acced\",\n    \"context\": \"A pesar de sus cuerpos blandos y gelatinosos, los f\u00f3siles que se cree que representan a los cten\u00f3foros, aparentemente sin tent\u00e1culos pero con muchas m\u00e1s filas de p\u00faas que las formas modernas, han sido encontrados en lagerst\u00e4tten en los primeros tiempos de la \u00e9poca de la era C\u00e1mbrica, hace alrededor de 515 millones de a\u00f1os. La posici\u00f3n de los cten\u00f3foros en el \u00e1rbol geneal\u00f3gico evolutivo de los animales se ha discutido durante mucho tiempo, y la opini\u00f3n mayoritaria en la actualidad, basada en la filogen\u00e9tica molecular, es que los cnidarios y los bilaterianos est\u00e1n m\u00e1s estrechamente relacionados entre s\u00ed que cualquiera de ellos con los cten\u00f3foros. Un an\u00e1lisis reciente de filogen\u00e9tica molecular concluy\u00f3 que el antepasado com\u00fan de todos los cten\u00f3foros modernos era similar a los cid\u00edpidos, y que todos los grupos modernos aparecieron relativamente recientemente, probablemente despu\u00e9s del evento de extinci\u00f3n del Cret\u00e1cico-Pale\u00f3geno hace 66 millones de a\u00f1os. Las pruebas acumuladas desde la d\u00e9cada de 1980 indican que los \"cid\u00edpidos\" no son monofil\u00e9ticos, es decir, no incluyen a todos y solo a los descendientes de un \u00fanico antepasado com\u00fan, ya que todos los dem\u00e1s grupos tradicionales de cten\u00f3foros son descendientes de varios cid\u00edpidos.\",\n    \"question\": \"\u00bfQu\u00e9 edad tienen los f\u00f3siles encontrados que representan los cten\u00f3foros?\",\n    \"answer\": {\n      \"answer_start\": [303],\n      \"text\": [\"515 millones de a\u00f1os\"]\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>A continuaci\u00f3n se presentan textos con sus preguntas y respuestas correspondientes.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texto: {text}\nPregunta: {question}\nRespuesta en m\u00e1ximo 3 palabras: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texto: {text}\n\nResponda la siguiente pregunta sobre el texto anterior en m\u00e1ximo 3 palabras.\n\nPregunta: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset xquad-es\n</code></pre>"},{"location":"datasets/spanish/#unofficial-belebele-es","title":"Unofficial: BeleBele-es","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Texto: Beba alcohol con moderaci\u00f3n. Este afecta a cada persona de manera diferente y conocer sus propios l\u00edmites es sumamente importante. La ingesta excesiva de alcohol puede causar problemas de salud cr\u00f3nicos como da\u00f1o hep\u00e1tico e incluso ceguera y muerte. El peligro potencial se incrementa con el consumo de alcohol elaborado de forma ilegal. En las bebidas alcoh\u00f3licas ilegales puede haber varias impurezas amenazantes, como el metanol, capaz de provocar ceguera o incluso la muerte, aun cuando se ingiera poca cantidad.\\nPregunta: Seg\u00fan el fragmento, \u00bfcu\u00e1l de los siguientes sentidos puede verse afectado por el consumo excesivo de alcohol?\\nOpciones:\\na. Audici\u00f3n\\nb. Vista\\nc. Gusto\\nd. Olfato\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texto: Leslie Aun, vocero de la Fundaci\u00f3n Komen, inform\u00f3 que rige una nueva normativa en la organizaci\u00f3n conforme la cual no proceder\u00e1 el otorgamiento de subvenciones o fondos en favor de entidades que sean objeto de investigaci\u00f3n oficial. La pol\u00edtica de Komen desacredit\u00f3 a Planned Parenthood a ra\u00edz de una investigaci\u00f3n en curso que dirige el representante Cliff Stearns sobre la forma en la que esta organizaci\u00f3n informa y utiliza sus fondos. En su rol de director del Subcomit\u00e9 de Supervisi\u00f3n e Investigaci\u00f3n, que se encuentra bajo el paraguas del Comit\u00e9 de Energ\u00eda y Comercio, Stearns conduce una investigaci\u00f3n para determinar si los impuestos se usan para financiar interrupciones de embarazos a trav\u00e9s de Paternidad Planificada.\\nPregunta: \u00bfQu\u00e9 comit\u00e9 preside Cliff Stearns?\\nOpciones:\\na. Comit\u00e9 de Energ\u00eda y Comercio de la C\u00e1mara de Representantes\\nb. La Fundaci\u00f3n Komen\\nc. Planned Parenthood\\nd. El Subcomit\u00e9 de Supervisi\u00f3n e Investigaci\u00f3n\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Texto: El elemento del determinismo cultural se encontraba muy presente en el romanticismo, seg\u00fan estudiosos como Goether, Fichte y Schlegel. En el contexto del Romanticismo, la geograf\u00eda molde\u00f3 a las personas y, con el transcurso del tiempo, se desarrollaron costumbres y culturas relacionadas con esa geograf\u00eda que, al estar en armon\u00eda con la localizaci\u00f3n de esa sociedad, eran preferibles a leyes que se impusieran de forma arbitraria.\\nPregunta: De acuerdo con el texto, \u00bfqu\u00e9 molde\u00f3 a las personas durante el per\u00edodo del Romanticismo?\\nOpciones:\\na. Leyes\\nb. Geograf\u00eda\\nc. Costumbres\\nd. Cultura\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Las siguientes son preguntas de opci\u00f3n m\u00faltiple (con respuestas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRespuesta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nResponda la pregunta anterior usando solo 'a', 'b', 'c' o 'd', y nada m\u00e1s.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-es\n</code></pre>"},{"location":"datasets/spanish/#unofficial-multiwikiqa-es","title":"Unofficial: MultiWikiQA-es","text":"<p>This dataset will be published in an upcoming paper, and contains Spanish Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"El moretum es una especie de queso untable tradicional que se serv\u00eda como acompa\u00f1amiento de algunos de los platos de la Antigua Roma. Se trata de un tipo de aderezo o salsa cuyos ingredientes se machacan en un mortero, del cual toma el nombre.\\n\\nCitas \\n\\nEn el Appendix Vergiliana, obra que, como indica su nombre, se atribuye a Virgilio, se dice que los ingredientes del moretum son hierbas arom\u00e1ticas, ajo, queso, vinagre, aceite de oliva y sal, y se describe su preparaci\u00f3n como desayuno por un campesino. Con respecto a la combinaci\u00f3n de los ingredientes, en la l\u00ednea 103 se lee \\n\\nEl moretum tambi\u00e9n es nombrado por Columela en el libro XII de su obra De re rustica.\\n\\nV\u00e9ase tambi\u00e9n \\n\\n Pesto\\n Almodrote\\n\\nBibliograf\u00eda \\n\\n Rodr\u00edguez-Pantoja M\u00e1rquez, Miguel: El \\\"Moretum\\\", estudio ling\u00fc\u00edstico y literario. , n.\u00ba 8, 1977, pp. 117 - 148. Departamento de Prehistoria y Arqueolog\u00eda. Universidad de Sevilla. ISSN 0210-7694\\n Texto en PDF.\\n\\nNotas y referencias\\n\\nEnlaces externos \\n\\nGastronom\u00eda de la Antigua Roma\\nDesayunos\\nAlimentos untables\\nPlatos de queso\\nSalsas de Italia\",\n    \"question\": \"\u00bfQui\u00e9n es considerado el autor del poema Moretum, que forma parte del Appendix Vergiliana?\",\n    \"answers\": {\n        \"answer_start\": array([327]),\n        \"text\": array([\"Virgilio\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"La culebra-viborera mexicana (Clelia scytalina) tambi\u00e9n conocida como zopilota de altura, es una especie de serpiente que pertenece a la familia Colubridae. Es nativo del sur de M\u00e9xico, Am\u00e9rica Central y Colombia.\\nComo las dem\u00e1s especies de musurana, se alimenta principalmente de otras serpientes, especialmente de serpientes venenosas del g\u00e9nero Bothrops.\\n\\nDescripci\u00f3n \\nLos adultos poseen una coloraci\u00f3n negra gris\u00e1cea iridiscente o negra azulada en el dorso. Los juveniles tienen un dorso rojo, cabeza negra y un collar nucal amarillo opaco que est\u00e1 rodeado de pigmento negro; el vientre es color crema inmaculado; escamas dorsales en 17 hileras.\\n\\nDistribuci\u00f3n \\nClelia scytalina se distribuye a bajas y moderadas elevaciones (hasta 1,200 ) de Veracruz en la vertiente del Atl\u00e1ntico y desde Jalisco en la vertiente del Pac\u00edfico hacia el sur a trav\u00e9s de Am\u00e9rica Central hasta Colombia. Est\u00e1 especie es generalmente rara en M\u00e9xico excepto en la Sierra de los Tuxtlas en el sur de Veracruz donde es considerada como relativamente com\u00fan. Es conocida de localidades dispersas en la vertiente del Atl\u00e1ntico en el centro de Veracruz, Oaxaca, Chiapas, Tabasco, suroeste de Campeche y sur de Quintana roo, y en el vertiente del Pac\u00edfico\\xa0 en Jalisco, Colima, Guerrero y Chiapas.\\n\\nH\u00e1bitat \\nEsta serpiente grande y activa habita el bosque caducifolio tropical, el bosque estacional perennifolio y el bosque lluvioso. Es principalmente terrestre y nocturna, pero tambi\u00e9n se puede encontrar activa durante el d\u00eda. Por lo general, forrajea por la noche en bosques primarios o secundarios, a menudo a lo largo de arroyos. Se alimenta principalmente de serpientes, incluidas las nauyacas (Bothrops asper) y otras serpientes venenosas, que a veces pueden ser tan largas como ella. Ocasionalmente comen ranas, lagartijas y mam\u00edferos. Clelia scytalina es ov\u00edpara.\\n\\nEstado de conservaci\u00f3n \\nSe encuentra catalogada dentro de la lista roja de la IUCN como una especie con preocupaci\u00f3n menor (LC).\\n\\nReferencias\\n\\nEnlaces externos \\n . Encyclopedia of Life.\\n\\nscytalina\\nReptiles de Am\u00e9rica Central\\nAnimales descritos en 1867\\nTaxones descritos por Edward Drinker Cope\",\n    \"question\": \"\u00bfCu\u00e1l es el l\u00edmite altitudinal de la distribuci\u00f3n de Clelia scytalina?\",\n    \"answers\": {\n        \"answer_start\": array([735]),\n        \"text\": array([\"1,200\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Coslada Central es una estaci\u00f3n de la l\u00ednea 7 del Metro de Madrid, situada entre la calle de Pablo Neruda y el paseo de Francisco Javier Sauquillo, en el municipio madrile\u00f1o de Coslada.\\n\\nOfrece una conexi\u00f3n con la estaci\u00f3n de Coslada de las l\u00edneas C-2, C-7 y C-8 de Cercan\u00edas Madrid, formando ambas un intercambiador de transporte.\\n\\nHistoria y caracter\u00edsticas \\nLa estaci\u00f3n fue inaugurada el 5 de mayo de 2007 y est\u00e1 decorada con grandes murales por los andenes y el vest\u00edbulo, realizados por Ra\u00fal D\u00edaz Reyes, los cuales, bajo el t\u00edtulo de \\\"De Madrid al cielo\\\", reflejan diferentes im\u00e1genes de cielos de Madrid.\\n\\nLa estaci\u00f3n ha sufrido varias obras de rehabilitaci\u00f3n desde su inauguraci\u00f3n para garantizar la seguridad y aliviar las grietas que se han formado encima de los t\u00faneles por los que discurre el tramo MetroEste. V\u00e9ase Obras de rehabilitaci\u00f3n en L\u00ednea 7 para m\u00e1s detalles.\\n\\nAccesos \\nVest\u00edbulo Coslada Central (Metro de Madrid)\\n Doctor Fleming C/ Doctor Fleming, s/n (en el parque Doctor Fleming)\\n  Ascensor C/ Doctor Fleming, s/n (en el parque Doctor Fleming)\\n Renfe Abierto de 6:00 a 0:30 Correspondencia con Cercan\u00edas Renfe\\nVest\u00edbulo Renfe\\n  Luis Braille C/ Luis Braille, s/n (Correspondencia con Cercan\u00edas Renfe)\\n\\nL\u00edneas y conexiones\\n\\nMetro\\n\\nCercan\u00edas\\n\\nAutobuses\\n\\nReferencias\\n\\nV\u00e9ase tambi\u00e9n \\n L\u00ednea 7 (Metro de Madrid)\\n MetroEste\\n Estaciones del Metro de Madrid\\n Coslada, ,\\n\\nEnlaces externos y referencias \\n\\n Ficha de la estaci\u00f3n en metromadrid.es\\n P\u00e1gina oficial del Metro de Madrid\\n\\nCoslada\\nCoslada\\nEstaciones de metro de Espa\u00f1a inauguradas en 2007\",\n    \"question\": \"\u00bfC\u00f3mo se llaman las obras de arte que adornan esta estaci\u00f3n de metro?\",\n    \"answers\": {\n        \"answer_start\": array([539]),\n        \"text\": array([\"\\\"De Madrid al cielo\\\"\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>A continuaci\u00f3n se presentan textos con sus preguntas y respuestas correspondientes.\n</code></pre></li> <li>Base prompt template:   <pre><code>Texto: {text}\nPregunta: {question}\nRespuesta en m\u00e1ximo 3 palabras: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Texto: {text}\n\nResponda la siguiente pregunta sobre el texto anterior en m\u00e1ximo 3 palabras.\n\nPregunta: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-es\n</code></pre>"},{"location":"datasets/spanish/#knowledge","title":"Knowledge","text":""},{"location":"datasets/spanish/#mmlu-es","title":"MMLU-es","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to French was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 272 / 1,465 / 13,334 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"\u00bfQu\u00e9 m\u00e9todo de los siguientes utiliza el m\u00e9todo de loci como ayuda para la memoria?\\nOpciones:\\na. Codificaci\u00f3n sem\u00e1ntica\\nb. Imaginer\u00eda visual\\nc. Se\u00f1ales auditivas\\nd. Memoria ecoica\",\n    \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n    \"text\": \"Cuando una medida realmente cuantifica lo que afirma medir, decimos que tiene buena\\nOpciones:\\na. precisi\u00f3n\\nb. validez\\nc. confiabilidad\\nd. valor asociativo\",\n    \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n    \"text\": \"Un ranchero, siendo el propietario en un simple t\u00edtulo, transfiri\u00f3 la propiedad mediante una escritura de garant\u00eda a una mujer. La mujer opignor\u00f3 la finca a favor de su sobrina para asegurar un pr\u00e9stamo de la sobrina a la mujer por la cantidad de $500,000. La hipoteca fue inmediatamente registrada. Dos a\u00f1os despu\u00e9s, la mujer transfiri\u00f3 la finca a un granjero mediante una escritura de renuncia. La mujer, entonces, incumpli\u00f3 con la hipoteca, y la sobrina entabl\u00f3 una acci\u00f3n in personam contra el granjero para recuperar la cantidad adeudada por la hipoteca. Se presume que la escritura de renuncia de la mujer al granjero no hac\u00eda referencia a la hipoteca. Es probable que el acreedor hipotecario\\nOpciones:\\na. tenga \u00e9xito, porque la transferencia de la propiedad de la mujer al granjero result\u00f3 en una delegaci\u00f3n impl\u00edcita de responsabilidades.\\nb. tenga \u00e9xito, porque la sobrina era una beneficiaria de tercera parte en la transferencia entre la mujer y el granjero.\\nc. no tenga \u00e9xito, porque el granjero no prometi\u00f3 pagar la deuda hipotecaria.\\nd. no tenga \u00e9xito, a menos que el granjero tuviera conocimiento constructivo de la existencia de la hipoteca.\",\n    \"label\": \"c\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Las siguientes son preguntas de opci\u00f3n m\u00faltiple (con respuestas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRespuesta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nResponda la pregunta anterior usando solo 'a', 'b', 'c' o 'd', y nada m\u00e1s.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-es\n</code></pre>"},{"location":"datasets/spanish/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/spanish/#hellaswag-es","title":"HellaSwag-es","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,374 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"[header] C\u00f3mo crear tinta de tatuaje de prisi\u00f3n [title] Encuentra una lata o un contenedor de metal. [step] Debe poder contener de 4 a 6 onzas de aceite para beb\u00e9s, junto con un poco de algod\u00f3n apretado. Prueba usando una lata de pulimento para botas vac\u00eda y limpia.\\nOpciones:\\na. [title] Usa alcohol isoprop\u00edlico como lubricante. [step] Mientras que algunos pulidores de escritorio tradicionalmente utilizados para tatuajes se manchan o amenazan, mezcla \u00bc taza de agua tibia y \u00bc taza de detergente regular para platos.\\nb. Si no tienes acceso a un contenedor pre-hecho: usa una herramienta afilada para cortar una lata de aluminio de 12 onzas por la mitad, y usa la mitad inferior como tu contenedor. [substeps] Puede que puedas comprar una lata de pulimento para botas en la tienda de la c\u00e1rcel.\\nc. No se recomienda el vidrio ya que se piensa que es muy fr\u00e1gil y es probable que reaccione mal al metal. [title] Quita cualquier objeto extranjero o bordado del contenedor.\\nd. [title] Vierte el pulimento blanco en un tubo de pl\u00e1stico como fluido sellante. [step] Un tubo ligero y bastante delgado funciona mejor como reservorio.\",\n    \"label\": \"b\",\n}\n</code></pre> <pre><code>{\n  \"text\": \"Entonces, la ni\u00f1a baja firmemente sus manos hacia su costado, junta sus pies y hace una reverencia, continuando con una rutina de varios movimientos de karate. la ni\u00f1a\\nOpciones:\\na. luego da una triunfante ola mientras levanta una mano derecha en el aire y contin\u00faa su rutina.\\nb. cae en un tatami alto en el aire y un hombre se acerca y le ayuda mientras desmonta.\\nc. finalmente desmonta y coloca su instrumento en su soporte, sin hacer una reverencia, su postura seria cambia a una de plena concentraci\u00f3n mientras levanta sus manos en el aire y eleva sus brazos.\\nd. termina su rutina un poco m\u00e1s lejos del punto donde comenz\u00f3, baja firmemente sus manos hacia su costado y hace una peque\u00f1a reverencia, luego abre sus piernas a la altura de los hombros y vuelve a la misma posici\u00f3n en la que estaba cuando empez\u00f3.\",\n  \"label\": \"d\",\n}\n</code></pre> <pre><code>{\n\"text\": \"[header] C\u00f3mo llevar tu peinado del d\u00eda a la noche [title] Humedece tu cabello. [step] Crear ondas a partir de un mo\u00f1o es una gran opci\u00f3n para cabello largo. Cuando quieras usar un mo\u00f1o para crear ondas en tu cabello, lo mejor es comenzar con el cabello al menos parcialmente h\u00famedo.\\nOpciones:\\na. As\u00ed que antes de comenzar, usa una toalla para secar en el lugar donde quieres poner el cabello. [substeps] Una buena regla es secar el cabello con una toalla antes de ponerlo en un mo\u00f1o.\\nb. Si te lavas el cabello por la ma\u00f1ana, s\u00e9calo con secadora o al aire hasta la mitad antes de hacer el mo\u00f1o. Si no planeas lavar tu cabello, roc\u00edalo ligeramente con una botella rociadora llena de agua.\\nc. [substeps] El cabello rizado se ver\u00e1 sin esfuerzo y m\u00e1s esponjado con la cabeza h\u00fameda porque es suave y brillante. Si tu cabello no est\u00e1 tan seco como quieres, no te vuelvas loca.\\nd. Si quieres dejarlo suelto durante la noche, usa una secadora. [substeps] Una secadora de cabello normalmente funciona mejor.\",\n\"label\": \"b\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Las siguientes son preguntas de opci\u00f3n m\u00faltiple (con respuestas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRespuesta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nResponda la pregunta anterior usando solo 'a', 'b', 'c' o 'd', y nada m\u00e1s.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-es\n</code></pre>"},{"location":"datasets/spanish/#unofficial-goldenswag-es","title":"Unofficial: GoldenSwag-es","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"C\u00f3mo desmaquillarse. Empapa un disco de algod\u00f3n con desmaquillante de ojos. Un desmaquillante de ojos bif\u00e1sico sirve para la mayor\u00eda del maquillaje de ojos. Combina el poder disolvente de un desmaquillante a base de aceite con las cualidades suaves y calmantes del agua limpiadora.\\nOpciones:\\na. Es una buena opci\u00f3n para el maquillaje de ojos intenso; s\u00f3lo aseg\u00farate de agitar bien el envase antes de usarlo, ya que la f\u00f3rmula tiende a separarse. Si utilizas m\u00e1scara y delineador de ojos resistentes al agua o un maquillaje muy resistente, utiliza un limpiador a base de aceite.\\nb. Normalmente, el objetivo es hacer que el proceso de limpieza espec\u00edfico sea una experiencia m\u00e1s agradable, en lugar de que sea completamente autocalmante. Como alternativa, puedes simplemente humedecer tu disco de algod\u00f3n con una soluci\u00f3n de agua fr\u00eda y aplicarla desde el rabillo del ojo hacia las esquinas interiores.\\nc. Compra un bote de este desmaquillante en una farmacia o por Internet. Cuanto m\u00e1s tiempo lo apliques, m\u00e1s oscura ser\u00e1 la capa externa de maquillaje de los ojos.\\nd. Aunque estos productos son menos caros que los limpiadores faciales normales, no siempre son infalibles. Utilizarlos en exceso afectar\u00e1 a la eficacia de tu maquillaje.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"C\u00f3mo hacer turr\u00f3n. Forre el molde. Forre el fondo y los lados de un molde de 20 cm por 20 cm con papel pergamino. Res\u00e9rvalo para utilizarlo m\u00e1s tarde.\\nOpciones:\\na. Si quieres enfriar el pan sin papel pergamino, vierte 2 cucharadas (45 ml) de az\u00facar en un bol y m\u00e9telo en el congelador para que se enfr\u00ede. Tambi\u00e9n puede refrigerar la mezcla durante al menos un d\u00eda.\\nb. Lleve el agua a ebullici\u00f3n. En el fuego, ponga el fuego a tope para que el agua hierva.\\nc. Verter\u00e1 el sirope de arce en el cazo despu\u00e9s de cocer la miel y el az\u00facar.. Calienta el agua en el cazo.\\nd. Como alternativa, puedes engrasar el fondo y los lados del molde con mantequilla, manteca o spray antiadherente para cocinar. El papel de pergamino facilitar\u00e1 la limpieza del molde.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"C\u00f3mo seguir amamantando despu\u00e9s de volver al trabajo. Prep\u00e1rate. Antes de volver al trabajo, tienes que planificarte y prepararte con tiempo. Esto significa hacer acopio de leche materna extra\u00edda (ebm) y establecer la infraestructura necesaria para extraer leche materna con \u00e9xito en el trabajo.\\nOpciones:\\na. Hacer acopio parece consolidar la s\u00edntesis eficaz de un ciclo de lactancia sano y constante. Sin embargo, tener un suministro fresco de ebm puede dificultar el mantenimiento de una relaci\u00f3n sana y productiva con tu beb\u00e9.\\nb. Determina la edad ideal de tu hija. Si tu hija s\u00f3lo tiene seis meses, reserva un poco de tiempo para empezar a amamantarla.\\nc. Si inviertes tiempo y esfuerzo en conseguirlo antes, ser\u00e1 menos complicado una vez que vuelvas al trabajo. Haz acopio de ebm mientras est\u00e9s de baja por maternidad.\\nd. Escribe todo lo que quieras saber en una hoja aparte y gu\u00e1rdalo para m\u00e1s tarde o sustit\u00fayelo por una nota escrita a mano. Si es posible, planifica tomarte un d\u00eda libre en el trabajo.\",\n  \"label\": \"c\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>Las siguientes son preguntas de opci\u00f3n m\u00faltiple (con respuestas).\n</code></pre></li> <li>Base prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nRespuesta: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Pregunta: {text}\nOpciones:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nResponda la pregunta anterior usando solo 'a', 'b', 'c' o 'd', y nada m\u00e1s.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-es\n</code></pre>"},{"location":"datasets/spanish/#summarization","title":"Summarization","text":""},{"location":"datasets/spanish/#mlsum-es","title":"MLSum-es","text":"<p>The dataset was published in this paper and is obtained from online newspapers.</p> <p>The original full dataset consists of 266,367 / 10,358 / 13,920 samples for training, validation, and testing, respectively. We use 1,024 / 256 / 2,024 samples for training, validation, and testing, respectively. All our splits are subsets of the original ones.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"text\": \"El todopoderoso secretario general de los populares bajo la presidencia de Jos\u00e9 Mar\u00eda Aznar, Francisco \u00c1lvarez-Cascos, ha desencadenado en su partido una tormenta en un vaso de agua. Ampar\u00e1ndose en una ret\u00f3rica de servicio a Asturias que apenas alcanza a disimular la frustraci\u00f3n de sus ambiciones personales, \u00c1lvarez-Cascos ha anunciado su baja en el partido de Mariano Rajoy y ha insinuado la creaci\u00f3n de una nueva fuerza pol\u00edtica para concurrir como candidato a la presidencia de Asturias en las elecciones auton\u00f3micas de mayo. Nada tiene de extra\u00f1o que quien fuera uno de los m\u00e1ximos adalides del 'todo vale' desde la oposici\u00f3n y tambi\u00e9n desde el Gobierno, aplique ahora esta m\u00e1xima a su propio partido. \u00c1lvarez-Cascos, durante sus a\u00f1os de protagonismo, tens\u00f3 la vida pol\u00edtica espa\u00f1ola hasta bordear los l\u00edmites de la estabilidad institucional, arremetiendo contra sus adversarios con instrumentos que despreciaban normas elementales del juego democr\u00e1tico. Su intento de regresar a la pol\u00edtica activa, rechazado por la direcci\u00f3n nacional de su partido, no responde al deseo de ofrecer un programa diferente a los asturianos, sino al de saciar su sed de poder tras a\u00f1os de obligada abstinencia. En la comparecencia para explicar las razones de su marcha dej\u00f3 entrever ajustes de cuentas y venganzas, pero ni una sola idea sobre la que articular el proyecto pol\u00edtico que defiende. Es cierto que la democracia interna que \u00c1lvarez-Cascos reclama ahora en el PP fue abolida mientras fue \u00e9l quien tuvo las riendas. Pero no porque sea \u00c1lvarez-Cascos su repentino y parad\u00f3jico abanderado deja de ser una reclamaci\u00f3n justa: el PP ha recurrido a la cooptaci\u00f3n para decidir la candidatura a la presidencia de Asturias, reafirm\u00e1ndose en un m\u00e9todo que aplica a todos los niveles, tanto municipal como auton\u00f3mico. E, incluso, nacional, como lo atestigua la presidencia de Mariano Rajoy por una decisi\u00f3n personal de su antecesor en el cargo. La aventura de \u00c1lvarez-Cascos no solo tendr\u00e1 dificultades para prosperar por las mezquinas razones que la impulsan, sino por el momento elegido para emprenderla. Un partido que se ve en la antesala del poder cierra filas con su direcci\u00f3n y no destruye sus expectativas desangr\u00e1ndose en luchas internas. Si el PP se encuentra en esta tesitura es por la forma de entender la pol\u00edtica de \u00c1lvarez-Cascos, pero tambi\u00e9n por la fragilidad del liderazgo de Rajoy. Dirigentes regionales como la presidenta de la Comunidad de Madrid no dudan en aprovechar cualquier circunstancia para desafiarlo. \u00c1lvarez-Cascos ha conseguido mostrar con un \u00fanico movimiento cu\u00e1l es la realidad interna de un partido que se considera en v\u00edsperas de alcanzar el Gobierno. El vaso de agua donde se desarrolla la ruidosa tormenta que ha desencadenado tiene el valor de un s\u00edntoma. Estas son las fuerzas que conviven en el PP y estas son las formas con las que los populares dirimen sus diferencias. * Este art\u00edculo apareci\u00f3 en la edici\u00f3n impresa del Martes, 4 de enero de 2011\",\n    \"target_text\": \"El hist\u00f3rico dirigente del PP se revuelve contra Rajoy al ver frustrada su ambici\u00f3n en Asturias\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"Eladio Loizaga tiene un bigote fino y un hablar pausado. El Ministro de Relaciones Exteriores de Paraguay, de 66 a\u00f1os, ha estado en Madrid para preparar la visita del presidente de su pa\u00eds, Horacio Cartes, el pr\u00f3ximo junio. Despu\u00e9s de una charla en Casa de Am\u00e9rica, Loizaga reflexiona sobre las relaciones diplom\u00e1ticas en Am\u00e9rica Latina, la actualidad en Venezuela y Cuba, y los lazos de la regi\u00f3n con Estados Unidos, Europa y China. Pregunta. \u00bfQu\u00e9 tipo de relaci\u00f3n hay entre los pa\u00edses de Am\u00e9rica Latina? Respuesta. Las relaciones diplom\u00e1ticas, comerciales y pol\u00edticas son \u00f3ptimas. Se basan en respetar el principio de pluralidad y no injerencia en los asuntos internos de cada Estado, a menos que sea una decisi\u00f3n tan grosera que choque con los principios democr\u00e1ticos y las normas constitucionales. En Am\u00e9rica Latina hemos aprendido a convivir dentro de esa pluralidad, sin que esa pluralidad se uniforme. Cada uno tiene su filosof\u00eda y eso tiene que ser respetado. No hay conflictos que pongan en peligro las relaciones entre nosotros. Hemos entendido que podemos convivir con esas diferencias ideol\u00f3gicas. La no inferencia es una piedra angular. P. \u00bfIncluso en Venezuela con la situaci\u00f3n de los presos pol\u00edticos? R. Paraguay tiene una consolidaci\u00f3n democr\u00e1tica plena. En nuestro pa\u00eds ya no hay presos por expresar una idea pol\u00edtica distinta a la del Gobierno. Somos miembro del Consejo de Derechos Humanos de Naciones Unidas. En ese sentido, pensamos que acallar voces no contribuye a la libertad de la naci\u00f3n. P. \u00bfCondena pues las decisiones de Nicol\u00e1s Maduro? R. Tenemos una posici\u00f3n expresada a trav\u00e9s de Unasur. Constituy\u00f3 una decisi\u00f3n de tres cancilleres, Colombia, Brasil y Ecuador, para cooperar en el di\u00e1logo con todos los sectores pol\u00edticos democr\u00e1ticos de Venezuela. Queremos que Venezuela encuentre una salida conforme a sus propias reglas constitucionales. Hay una l\u00ednea muy fina en lo que es una injerencia interna, y nosotros somos muy celosos porque la hemos sufrido. Estados Unidos tuvo por mucho tiempo, no un abandono, sino una negligencia benigna hacia Am\u00e9rica Latina. Como Europa. P. \u00bfPor qu\u00e9 la mayor\u00eda de gobiernos latinoamericanos guardaron silencio? R. Varios gobiernos han mostrado su preocupaci\u00f3n y ratificado su posici\u00f3n de que las partes dialoguen, que el Gobierno y la oposici\u00f3n se sienten para encontrar una salida democr\u00e1tica. Tenemos que evitar una salida traum\u00e1tica. Queremos apoyar al pueblo venezolano, porque sabemos las necesidades que est\u00e1n pasando. Estamos en contacto con el Gobierno para ayudar y proveer alimentos y otros productos que se necesitan. P. \u00bfApoya la labor que pretende hacer Felipe Gonz\u00e1lez? R. No me puedo referir a eso. Hay situaciones en las que, sin desconocer los derechos fundamentales de la persona, hay que tener cierto respeto por el marco interno de cada pa\u00eds. P. \u00bfCu\u00e1l es la salud de los derechos humanos en Am\u00e9rica Latina? R. Los derechos humanos no se definen hoy solo como derechos pol\u00edticos. Am\u00e9rica Latina estaba gobernada por dictaduras, por posiciones extremas, de izquierda y de derecha. Hoy tenemos un adelanto pol\u00edtico en toda la regi\u00f3n y tambi\u00e9n la necesidad de ir dando respuesta a los derechos humanos de cuarta generaci\u00f3n, la vivienda, la salud, el agua potable... Avanzamos en la lucha contra la pobreza. Y en que los chicos vayan a la escuela. Sin educaci\u00f3n no vamos a desarrollarnos. P. \u00bfPuede Am\u00e9rica Latina tener una voz \u00fanica en cuanto a pol\u00edtica exterior? R. Hoy no va a ser posible. Sabemos muy bien las posiciones ideol\u00f3gicas de cada uno. En lo posible tratamos de consensuar en la educaci\u00f3n, el desarrollo social, pero tener una sola voz pol\u00edtica es dif\u00edcil. Tenemos visiones distintas de c\u00f3mo vemos el mundo y las relaciones con otros Estados. P. Colombia est\u00e1 en un proceso de paz. \u00bfQu\u00e9 es m\u00e1s importante, justicia o paz? R. No es f\u00e1cil. Hay muchas aristas que deben tenerse en cuenta en el campo penal. El Gobierno busca las medidas jur\u00eddicas que den garant\u00eda al proceso. P. En otra mesa se sientan Cuba y EE UU. \u00bfNormalizar\u00e1n plenamente sus relaciones? R. Era la \u00faltima r\u00e9mora de la guerra fr\u00eda. Obama ha tomado una decisi\u00f3n de mucho coraje, en un momento pol\u00edtico interno dif\u00edcil, y con un sentido pragm\u00e1tico. Se\u00f1al\u00f3 que las conductas hacia Cuba no daban resultado y que hab\u00eda que buscar otro camino. La Cumbre de las Am\u00e9ricas en Panam\u00e1 fue hist\u00f3rica. El presidente Castro se expres\u00f3 con mucha honestidad. Y Obama reconoci\u00f3 que no son perfectos, que tienen problemas. Ojal\u00e1 se restablezcan las embajadas y el pueblo cubano camine por la senda de la democracia. P. \u00bfCu\u00e1l es el papel del papa Francisco en la pol\u00edtica exterior en Latinoam\u00e9rica? R. El Papa ha tenido un rol muy activo en asuntos de inter\u00e9s general en el mundo, como los problemas de la mujer, el cambio clim\u00e1tico, Cuba y Estados Unidos... su presencia en el mundo social es importante. Nos recuerda que existe gente, gente marginada, necesitada. Los pa\u00edses m\u00e1s ricos tienen que contribuir a que tengamos un mundo m\u00e1s equilibrado. P. \u00bfQu\u00e9 tipo de relaci\u00f3n hay entre EE UU y Am\u00e9rica Latina? R. Estados Unidos tuvo por mucho tiempo, no un abandono, sino una negligencia benigna hacia Am\u00e9rica Latina. Como Europa. \u00bfQui\u00e9n ocup\u00f3 ese espacio? China. Con Europa tenemos valores compartidos, y la independencia paraguaya est\u00e1 inspirada en la revoluci\u00f3n francesa. De Espa\u00f1a, como puente, necesit\u00e1bamos m\u00e1s acompa\u00f1amiento. China ocup\u00f3 ese espacio. A Estados Unidos se le mira con diversos cristales. Para Paraguay es un pa\u00eds amigo. P. \u00bfLa relaci\u00f3n con Argentina? R. Es un socio comercial importante. Pero hay cuestiones del d\u00eda a d\u00eda que pueden enturbiar nuestras relaciones. Queremos hacer un Mercosur m\u00e1s abierto, sin trabas.\",\n    \"target_text\": \"El ministro paraguayo reflexiona sobre las relaciones diplom\u00e1ticas en Am\u00e9rica Latina y la actualidad en Venezuela y Cuba\"\n}\n</code></pre> <pre><code>{\n    \"text\": \"La Audiencia Nacional ha aprobado extraditar al empresario egipcio Husein Salem a Egipto, donde est\u00e1 siendo juzgado por su supuesta implicaci\u00f3n en el caso de corrupci\u00f3n que se sigue contra el expresidente Hosni Mubarak, seg\u00fan inform\u00f3 el Ministerio de Exteriores egipcio. El tribunal tambi\u00e9n aprob\u00f3 la entrega de Jaled, hijo de Salem, mientras se estudia si su hija Magda ser\u00e1 extraditada. La fiscal\u00eda acusa a Salem de haber obtenido favores pol\u00edticos a cambio de la donaci\u00f3n a la familia Mubarak de cinco mansiones, camuflada como una venta ficticia. Esos favores se tradujeron en la asignaci\u00f3n de terrenos a su favor y la adquisici\u00f3n fraudulenta de contratos p\u00fablicos de venta y exportaci\u00f3n de gas a Israel, en la localidad de Sharm El Sheik. Esta venta hizo perder al Estado egipcio 536 millones. El empresario, detenido en Espa\u00f1a el 16 junio de 2011, fue condenado el jueves a 15 a\u00f1os de c\u00e1rcel por otro caso de corrupci\u00f3n. Y en octubre ya fue sentenciado a siete a\u00f1os, al igual que sus hijos Jaled y Magda, por blanquear 1,7 millones.\",\n    \"target_text\": \"La fiscal\u00eda acusa a Salem de haber obtenido favores pol\u00edticos a cambio de la donaci\u00f3n al exdictador de cinco mansiones, como una venta ficticia\",\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Los siguientes son art\u00edculos de noticias con sus res\u00famenes.\n</code></pre></li> <li>Base prompt template:   <pre><code>Art\u00edculo: {text}\nResumen: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Art\u00edculo: {text}\n\nEscribe un resumen del art\u00edculo anterior.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mlsum-es\n</code></pre>"},{"location":"datasets/swedish/","title":"\ud83c\uddf8\ud83c\uddea Swedish","text":"<p>This is an overview of all the datasets used in the Swedish part of EuroEval. The datasets are grouped by their task - see the task overview for more information about what these constitute.</p>"},{"location":"datasets/swedish/#sentiment-classification","title":"Sentiment Classification","text":""},{"location":"datasets/swedish/#swerec","title":"SweReC","text":"<p>This dataset was published in this B.Sc. thesis and is a manually annotated dataset of Swedish reviews from both Trustpilot and Reco.se.</p> <p>The original dataset contains 10,757 reviews. We use a split of 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"J\u00e4ttebra och rekommenderas till alla\",\n  \"label\": \"positive\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Lugnt och trevlig st\u00e4mning, inte f\u00f6r bullrigt. god mat, lite mer variation hade \u00f6nskats p\u00e5 de varma r\u00e4tterna. trevlig personal, dock missade de att ta dryckesbest\u00e4llningar fr\u00e5n oss vilket var ett litet minus. \u00f6verlag trevlig st\u00e4lle.\",\n  \"label\": \"neutral\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Extremt d\u00e5lig mottagning - b\u00e5de gsm och 3g? samtalen bryts hela tiden och s\u00e5 tar dom betalt f\u00f6r en ny uppkopplingsavgift varje g\u00e5ng.\",\n  \"label\": \"negative\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r recensioner och deras sentiment, som kan vara 'positiv', 'neutral' eller 'negativ'.\n</code></pre></li> <li>Base prompt template:   <pre><code>Recension: {text}\nSentiment: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Recension: {text}\n\nKlassificera sentimentet i recensionen. Svara med 'positiv', 'neutral' eller 'negativ'.\n</code></pre></li> <li>Label mapping:<ul> <li><code>positive</code> \u27a1\ufe0f <code>positiv</code></li> <li><code>neutral</code> \u27a1\ufe0f <code>neutral</code></li> <li><code>negative</code> \u27a1\ufe0f <code>negativ</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset swerec\n</code></pre>"},{"location":"datasets/swedish/#named-entity-recognition","title":"Named Entity Recognition","text":""},{"location":"datasets/swedish/#suc-30","title":"SUC 3.0","text":"<p>This dataset, also known as the Stockholm-Ume\u00e5 Corpus 3.0, was published here and is a manually NER-annotated dataset, based on Swedish texts from the 1990s. The dataset does not follow the CONLL format, so we convert it into that format using the following mapping:</p> <ul> <li><code>animal</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>event</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>inst</code> \u27a1\ufe0f <code>ORG</code></li> <li><code>myth</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>other</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>person</code> \u27a1\ufe0f <code>PER</code></li> <li><code>place</code> \u27a1\ufe0f <code>LOC</code></li> <li><code>product</code> \u27a1\ufe0f <code>MISC</code></li> <li><code>work</code> \u27a1\ufe0f <code>MISC</code></li> </ul> <p>The dataset consists of 74,245 samples, which we split into 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"tokens\": array(['Det', 'l\u00e5ter', 'som', 'en', 'v\u00e4stanfl\u00e4kt', 'j\u00e4mf\u00f6rt', 'med', 'den', 'i', 'filmen', 'f\u00f6rk\u00e4ttrade', 'bilj\u00e4tten', 'General', 'Motors', ',', 'som', 'frist\u00e4llt', '35000', 'jobbare', 'i', 'staden', 'Flint', ',', 'Michigan', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['En', 'liknande', 'kunskapsteoretisk', 'grundfr\u00e5ga', ',', 'fast', 'i', 'mer', 'modernt', 'sofistikerad', 'form', ',', 'n\u00e5r', 'oss', 'nu', 'fr\u00e5n', 'Paris', ':'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)\n}\n</code></pre> <pre><code>{\n  \"tokens\": array(['-', 'Dessv\u00e4rre', ',', 'sa', 'man', ',', 'vi', 'har', 'ingen', 'Bj\u00f6rn', 'Eriksson', 'p\u00e5', 'passagerarlistan', '.'], dtype=object),\n  \"labels\": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O'], dtype=object)\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 8</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r meningar och JSON-ordb\u00f6cker med de namngivna enheter som f\u00f6rekommer i den givna meningen.\n</code></pre></li> <li>Base prompt template:   <pre><code>Mening: {text}\nNamngivna entiteter: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Mening: {text}\n\nIdentifiera de namngivna enheterna i meningen. Du ska outputta detta som en JSON-ordbok med nycklarna 'person', 'plats', 'organisation' och 'diverse'. V\u00e4rdena ska vara listor \u00f6ver de namngivna enheter av den typen, precis som de f\u00f6rekommer i meningen.\n</code></pre></li> <li>Label mapping:<ul> <li><code>B-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>I-PER</code> \u27a1\ufe0f <code>person</code></li> <li><code>B-LOC</code> \u27a1\ufe0f <code>plats</code></li> <li><code>I-LOC</code> \u27a1\ufe0f <code>plats</code></li> <li><code>B-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>I-ORG</code> \u27a1\ufe0f <code>organisation</code></li> <li><code>B-MISC</code> \u27a1\ufe0f <code>diverse</code></li> <li><code>I-MISC</code> \u27a1\ufe0f <code>diverse</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset suc3\n</code></pre>"},{"location":"datasets/swedish/#linguistic-acceptability","title":"Linguistic Acceptability","text":""},{"location":"datasets/swedish/#scala-sv","title":"ScaLA-sv","text":"<p>This dataset was published in this paper and was automatically created from the Swedish Universal Dependencies treebank by assuming that the documents in the treebank are correct, and corrupting the samples to create grammatically incorrect samples. The corruptions were done by either removing a word from a sentence, or by swapping two neighbouring words in a sentence. To ensure that this does indeed break the grammaticality of the sentence, a set of rules were used on the part-of-speech tags of the words in the sentence.</p> <p>The original dataset consists of 6,026 samples, from which we use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples used in total). These splits are used as-is in the framework.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"U-l\u00e4nderna m\u00e5ste ta en genv\u00e4g f\u00f6r att komma i fatt.\",\n  \"label\": \"correct\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Undra att vi blev lite undandragna.\",\n  \"label\": \"incorrect\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Det \u00e4r ocks\u00e5 att viktigt ha tillr\u00e4ckligt korta dubbar.\",\n  \"label\": \"incorrect\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 12</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r meningar och huruvida de \u00e4r grammatiskt korrekta.\n</code></pre></li> <li>Base prompt template:   <pre><code>Mening: {text}\nGrammatisk korrekt: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Mening: {text}\n\nBest\u00e4m om meningen \u00e4r grammatiskt korrekt eller inte. Svara med 'ja' om meningen \u00e4r korrekt och 'nej' om den inte \u00e4r.\n</code></pre></li> <li>Label mapping:<ul> <li><code>correct</code> \u27a1\ufe0f <code>ja</code></li> <li><code>incorrect</code> \u27a1\ufe0f <code>nej</code></li> </ul> </li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scala-sv\n</code></pre>"},{"location":"datasets/swedish/#reading-comprehension","title":"Reading Comprehension","text":""},{"location":"datasets/swedish/#scandiqa-sv","title":"ScandiQA-sv","text":"<p>This dataset was published in this paper and was automatically created from the Swedish part of the MKQA dataset. The MKQA dataset is based on the English Natural Questions dataset, based on search queries from the Google search engine. The questions and answers were manually translated to Swedish (and other languages) as part of MKQA, and the contexts were in ScandiQA-sv machine translated using the DeepL translation API. A rule-based approach was used to ensure that the translated contexts still contained the answer to the question, potentially by changing the answers slightly.</p> <p>The original full dataset consists of 6,810 / 500 / 500 samples for training, validation and testing, respectively (so 3,328 samples used in total). We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, where the splits are made by randomly sampling from the full dataset without considering the original train/validation/test splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"context\": \"I Freedom Cry f\u00e5r spelaren ta rollen som Ad\u00e9wal\u00e9, en frigiven slav fr\u00e5n Trinidad som blev Edward Kenways kvarterm\u00e4stare och senare medlem i Assassin Order. Ber\u00e4ttelsel\u00e4get utspelar sig 15 \u00e5r efter h\u00e4ndelserna i Assassin's Creed IV: Black Flag d\u00e4r Ad\u00e9wal\u00e9 har blivit en tr\u00e4nad l\u00f6nnm\u00f6rdare och finner sig sj\u00e4lv skeppsbruten i Saint-Domingue, d\u00e4r han st\u00e4lls \u00f6ga mot \u00f6ga med n\u00e5got av det mest brutala slaveriet i V\u00e4stindien. DLC:n \u00e4r skriven av Jill Murray, som skrev Liberation och Aveline-inneh\u00e5llet f\u00f6r Black Flag. I februari 2014 meddelades att Freedom Cry skulle sl\u00e4ppas som en frist\u00e5ende titel till PlayStation 4 och PlayStation 3 den 18 februari 2014 f\u00f6r Nordamerika och den 19 februari 2014 f\u00f6r Europa. Det sl\u00e4pptes f\u00f6r PC den 25 februari 2014.\",\n  \"question\": \"N\u00e4r sl\u00e4pptes assassin's creed freedom cry?\",\n  \"answers\": {\n    \"answer_start\": array([637]),\n    \"text\": array(['18 februari 2014'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Political history of the United Kingdom (1945\u2013present)\\n\u00c5r 1950 orsakade Koreakriget ett nytt tungt tryck p\u00e5 statskassan f\u00f6r milit\u00e4ra utgifter. Detta orsakade en bitter splittring inom Labourpartiet.  De konservativa gjorde \u00e5tstramningspolitiken till en viktig fr\u00e5ga i parlamentsvalet 1950. Labour f\u00f6rlorade det mesta av sin stora majoritet. Sv\u00e4ngningen var 3,6 % mot dem och de f\u00f6rlorade 78 platser, vilket gav Attlee en knapp majoritet i parlamentet. Ett \u00e5r senare f\u00f6rlorade Labour dock parlamentsvalet 1951 trots att det fick fler r\u00f6ster \u00e4n i valet 1945, och faktiskt fler r\u00f6ster \u00e4n det konservativa partiet.',\n  \"question\": 'Hur m\u00e5nga \u00e5r har det varit sen 1940?',\n  \"answers\": {\n    \"answer_start\": array([388]),\n    \"text\": array(['78'], dtype=object)\n  }\n}\n</code></pre> <pre><code>{\n  \"context\": 'Data link layer\\nOSI-modellen\\nper skikt\\n\\n\\n\\n\\n7.  Applikationslager[visa]\\n\\n\\nNNTP\\nSIP\\nSSI\\nDNS\\nFTP\\nGopher\\nHTTP\\nNFS\\nNTP\\nSMPP\\nSMTP\\nSNMP\\nTelnet\\nDHCP\\nNetconf\\nmer....\\n\\n\\n\\n\\n\\n\\n\\n\\n6.  Presentationslager[visa]\\n\\n\\nMIME\\nXDR\\n\\n\\n\\n\\n\\n\\n\\n\\n5.  Sessionsskikt[visa]\\n\\n\\nNamngiven pipe\\nNetBIOS\\nSAP\\nPPTP\\nRTP\\nSOCKS\\nSPDY\\n\\n\\n\\n\\n\\n\\n\\n\\n4.  Transportlager[visa]\\n\\n\\nTCP\\nUDP\\nSCTP\\nDCCP\\nSPX\\n\\n\\n\\n\\n\\n\\n\\n\\n3.  N\u00e4tverksskikt[visa]\\n\\n\\nIP\\n\\nIPv4\\nIPv6\\n\\n\\nICMP\\nIPsec\\nIGMP\\nIPX\\nAppleTalk\\nX.25 PLP\\n\\n\\n\\n\\n\\n\\n\\n\\n2.  Datal\u00e4nkskiktet[visa]\\n\\n\\nATM\\nARP\\nIS-IS\\nSDLC\\nHDLC\\nCSLIP\\nSLIP\\nGFP\\nPLIP\\nIEEE 802.2\\nLLC\\nMAC\\nL2TP\\nIEEE 802.3\\nFrame Relay\\nITU-T G.hn DLL\\nPPP\\nX.25 LAPB\\nQ.921 LAPD\\nQ.922 LAPF\\n\\n\\n\\n\\n\\n\\n\\n\\n1.  Fysiskt lager[visa]\\n\\n\\nEIA/TIA-232\\nEIA/TIA-449\\nITU-T V-serien\\nI.430\\nI.431\\nPDH\\nSONET/SDH\\nPON\\nOTN\\nDSL\\nIEEE 802.3\\nIEEE 802.11\\nIEEE 802.15\\nIEEE 802.16\\nIEEE 1394\\nITU-T G.hn PHY\\nUSB\\nBluetooth\\nRS-232\\nRS-449\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nv\\nt\\ne',\n  \"question\": 'Vilket lager av osi-modellen \u00e4r uppdelad i tv\u00e5 delskikt?',\n  \"answers\": {\n    \"answer_start\": array([0]),\n    \"text\": array(['Data link layer'], dtype=object)\n  }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Nedan f\u00f6ljer texter med tillh\u00f6rande fr\u00e5gor och svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nFr\u00e5ga: {question}\nSvar p\u00e5 max 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nBesvara f\u00f6ljande fr\u00e5ga om texten ovan med h\u00f6gst 3 ord.\n\nFr\u00e5ga: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset scandiqa-sv\n</code></pre>"},{"location":"datasets/swedish/#unofficial-belebele-sv","title":"Unofficial: BeleBele-sv","text":"<p>This dataset was published in this paper and features multiple-choice reading comprehension questions across 122 languages.</p> <p>The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Sundarbans \u00e4r det st\u00f6rsta kustmangroveb\u00e4ltet i v\u00e4rlden och str\u00e4cker sig 80 km in i Bangladesh och det indiska inlandet fr\u00e5n kusten. Sundarbans har antagits p\u00e5 Unescos v\u00e4rldsarvslista. Den del av skogen som ligger p\u00e5 indiskt territorium kallas Sundarbans National Park. Skogarna \u00e4r dock inte bara mangrovetr\u00e4sk \u2014 de inneh\u00e5ller n\u00e5gra av de sista kvarvarande st\u00e5ndorterna av de stora djunglerna som en g\u00e5ng t\u00e4ckte Gangessl\u00e4tten. Sundarban t\u00e4cker ett omr\u00e5de p\u00e5 3 850 km\u00b2, varav ungef\u00e4r en tredjedel utg\u00f6rs av v\u00e5tmarker. Sedan 1966 har Sundarbans varit ett reservat f\u00f6r vilda djur, och det uppskattas att det nu finns 400 bengaliska tigrar och omkring 30 000 axishjortar i omr\u00e5det.\\nFr\u00e5ga: Vilken del av skogen ligger p\u00e5 indiskt territorium?\\nSvarsalternativ:\\na. Sundarbans National Park\\nb. Reservatet f\u00f6r vilda djur\\nc. V\u00e4rldsarvet\\nd. Gangessl\u00e4tten\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Italiens nationella fotboll, tillsammans med det tyska fotbollslaget, \u00e4r v\u00e4rldens n\u00e4st mest framg\u00e5ngsrika lag och var m\u00e4stare i FIFA-v\u00e4rldscupen \u00e5r 2006. Popul\u00e4ra sporter inkluderar fotboll, basket, volleyboll, vattenpolo, f\u00e4ktning, rugby, cykel, ishockey, rullskridskohockey och Formel 1. Vintersporter \u00e4r mest popul\u00e4ra i de norra regionerna, d\u00e4r italienare t\u00e4vlar i internationella t\u00e4vlingar och olympiska evenemang.\\nFr\u00e5ga: I vilken av f\u00f6ljande sporter vann Italien en v\u00e4rldscup enligt avsnittet?\\nSvarsalternativ:\\na. Fotboll\\nb. Vattenpolo\\nc. Basket\\nd. Cykel\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Bokning i f\u00f6rv\u00e4g ger resen\u00e4ren trygghet och en f\u00f6rs\u00e4kran om att de kommer att ha n\u00e5gonstans att sova n\u00e4r de anl\u00e4nder till sin destination. Resebyr\u00e5er har ofta avtal med s\u00e4rskilda hotell, men det kan vara m\u00f6jligt att boka andra typer av boenden, s\u00e5som campingplatser, genom en resebyr\u00e5. Resebyr\u00e5er erbjuder ofta paket som inkluderar frukost, transfer till och fr\u00e5n flygplatsen, och till och med paketresor som kombinerar flyg och hotell. De kan ocks\u00e5 reservera din bokning \u00e5t dig om du beh\u00f6ver tid att t\u00e4nka \u00f6ver erbjudandet eller skaffa fram ytterligare dokument som kr\u00e4vs f\u00f6r din destination (t.ex. visering). Alla \u00e4ndringar och f\u00f6rfr\u00e5gningar ska dock g\u00e5 genom resebyr\u00e5n f\u00f6rst, och inte direkt till hotellet.\\nFr\u00e5ga: Vilken typ av resen\u00e4r kommer sannolikt inte att dra nytta av att anv\u00e4nda sig av tj\u00e4nster fr\u00e5n en resebyr\u00e5, enligt det som st\u00e5r i texten?\\nSvarsalternativ:\\na. En obeslutsam resen\u00e4r\\nb. En resen\u00e4r som \u00e4r spontan\\nc. En resen\u00e4r som inte har skaffat visum \u00e4n\\nd. En resen\u00e4r som f\u00f6redra att boka paketerbjudanden\",\n  \"label\": \"b\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r flervalsfr\u00e5gor (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvara f\u00f6ljande fr\u00e5ga med 'a', 'b', 'c' eller 'd', och inget annat.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset belebele-sv\n</code></pre>"},{"location":"datasets/swedish/#unofficial-multiwikiqa-sv","title":"Unofficial: MultiWikiQA-sv","text":"<p>This dataset will be published in an upcoming paper, and contains Swedish Wikipedia articles with generated questions and answers, using the LLM Gemini-1.5-pro.</p> <p>The original full dataset consists of 5,000 samples in a single split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively, sampled randomly.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n    \"context\": \"Juan Mayorga, f\u00f6dd 6 april 1965 i Madrid, \u00e4r en spansk dramatiker och manusf\u00f6rfattare.\\n\\nBiografi\\nJuan Mayorga har en examen i matematik och filosofi fr\u00e5n Universidad Complutense de Madrid 1988. D\u00e4refter arbetade han som forskarassistent i filosofi vid Consejo Superior de Investigaciones Cient\u00edficas. Fortsatta studier i M\u00fcnster, Berlin och Paris ledde till en doktorsexamen i filosofi 1997 med en avhandling om Walter Benjamin. Han debuterade som dramatiker 1989 med Siete hombres buenos (Sju goda m\u00e4n). Tillsammans med dramatiker kollegorna Jos\u00e9 Ram\u00f3n Fern\u00e1ndez, Luis Miguel Gonz\u00e1lez Cruz och Ra\u00fal Hern\u00e1ndez Garrido grundade han 1993 teatergruppen Teatro del Astillero. 2011 grundade han en ny teatergrupp, La Loca de la Casa. Sedan 1998 \u00e4r Mayorga har han undervisat i filosofi och dramatik vid Escuela Superior de Arte Dram\u00e1tico i Madrid. F\u00f6r n\u00e4rvarande (2017) \u00e4r han chef f\u00f6r avdelningen f\u00f6r scenkonst vid Universidad Carlos III de Madrid. Han har skrivit ett trettiotal pj\u00e4ser (2017) och hans dramatik har spelats i 18 l\u00e4nder och \u00f6versatts till 16 spr\u00e5k. Han efterstr\u00e4var en filosofiskt pr\u00e4glad teater som tvingar publiken till st\u00e4llningstaganden. Till hans f\u00f6rebilder h\u00f6r Harold Pinter. Bland utm\u00e4rkelser han tilldelats kan n\u00e4mnas de spanska priserna Nacional de Teatro 2007 och Nacional de Literatura Dram\u00e1tica 2013 samt Premio Europa New Theatrical Realities 2016.\\n\\n2007 regisserade Alexander M\u00f8rk-Eidem Mayorgas Himmelweg p\u00e5 Nationaltheatret i Oslo. 2014 skulle han \u00e4ven ha regisserat den p\u00e5 Stockholms stadsteater under titeln Himlav\u00e4gen i Jens Nordenh\u00f6ks \u00f6vers\u00e4ttning men det st\u00e4lldes in.\\n\\nReferenser\\n\\nK\u00e4llor\\n Pressrelease, Premio Europa 14/3 2016 \\n Juan Mayorga, The Playwrights Database (l\u00e4st 5 april 2017)\\n Juan Mayorga, France culture (l\u00e4st 5 april 2017)\\n Juan Mayorga, theatre-contemporain.net (l\u00e4st 5 april 2017)\\n Juan Mayorga, Th\u00e9\u00e2tre de Rond-Point, Paris (l\u00e4st 5 april 2017)\\n Juan Mayorga, madridesteatro.com (l\u00e4st 5 april 2017)\\n Arkiv, Kulturhuset Stadsteatern (l\u00e4st 5 april 2017)\\n Lillian Bikset: Teater, l\u00f8gn og bedrag, Dagbladet 31/8 2007\\n Elisabeth Leinslie: Kjenn din bes\u00f8kelsestid, Dagsavisen 2/9 2007\\n Roc\u00edo Garc\u00eda: Juan Mayorga: las obsesiones de un matem\u00e1tico y autor de \u00e9xito, El Pa\u00eds 1/6 2016\\n\\nNoter\\n\\nExterna l\u00e4nkar\\n Juan Mayorga, Internet Movie Database (IMDb)\\n\\nSpanska dramatiker\\nSpanskspr\u00e5kiga dramatiker\\nSpanska manusf\u00f6rfattare\\nSpanska f\u00f6rfattare under 1900-talet\\nSpanska f\u00f6rfattare under 2000-talet\\nDramatiker under 1900-talet\\nDramatiker under 2000-talet\\nPersoner fr\u00e5n Madrid\\nF\u00f6dda 1965\\nLevande personer\\nM\u00e4n\",\n    \"question\": \"Vilka akademiska examina har Juan Mayorga avlagt vid Universidad Complutense de Madrid?\",\n    \"answers\": {\n        \"answer_start\": array([126]),\n        \"text\": array([\"matematik och filosofi\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Janka Kupala (egentligen Ivan Daminikavitj Lutsevitj) f\u00f6dd 7 juli 1882 i Vjazynka utanf\u00f6r Minsk, d\u00f6d 28 juni 1942 i Moskva, var en belarusisk f\u00f6rfattare. Tillsammans med Jakub Kolas r\u00e4knas han som en av den moderna belarusiska litteraturens grundare.\\n\\nKupala var till stor del sj\u00e4lvl\u00e4rd som f\u00f6rfattare. Han blev aktiv i den \\\"belarusiska p\u00e5nyttf\u00f6delsen\\\" (1903\u20131921) och redakt\u00f6r f\u00f6r den belarusiska tidskriften Nasja niva (1914\u20131915). 1928 blev han ledamot av den belarusiska och ukrainska vetenskapsakademin.\\n\\nHans tidiga diktning var patriotisk idealiserade den \u00f6stslaviska statsbildningen i Polotsk under 900- till 1200-talet som ett slags vision f\u00f6r Belarus. Han var \u00e4ven en h\u00e5rd kritiker av b\u00e5de det tidiga polsk-litauiska och ryska v\u00e4ldet \u00f6ver Belarus, varf\u00f6r m\u00e5nga av hans verk f\u00f6rbj\u00f6ds av sovjetregimen. P\u00e5 grund av den politiska f\u00f6rf\u00f6ljelsen under Stalin f\u00f6rs\u00f6kte han 1930 beg\u00e5 sj\u00e4lvmord och d\u00e4refter blev han mindre produktiv som f\u00f6rfattare. Under de sista \u00e5rtiondena var hans diktning en l\u00e5ng hyllning till socialismen och sovjetmakten. 1941 fick han ta emot Leninorden f\u00f6r sin diktsamling \u0410\u0434 \u0441\u044d\u0440\u0446\u0430 (1940).\\n\\nVid Nazitysklands ockupation av Vitryska SSR 1941 flyttade han till Moskva och senare till Tatarstan. \\n \\nHans fru grundade ett museum \u00f6ver honom i Minsk d\u00e4r m\u00e5nga av hans verk finns samlade. Staden Hrodna namngav ett universitet efter honom Janka Kupala Statsuniversitet 1978.\\n\\nBibliografi i urval \\n Sjalejka 1908 (diktsamling)\\n Husljar 1910 (diktsamling)\\n Advetsjnaja pesnja 1910 (poem)\\n Paulinka 1912 (sk\u00e5despel)\\n Sjljacham sjytstsia 1913 (diktsamling)\\n Son na kurgane 1913 (poem)\\n Raskidanaje hnjazdo 1913 (sk\u00e5despel)\\n\\nK\u00e4llor\\n\\nNoter\\n\\nBelarusiska f\u00f6rfattare\\nBelarusiskspr\u00e5kiga f\u00f6rfattare\\nSovjetiska f\u00f6rfattare\\nPersoner fr\u00e5n Minsk voblast\\nM\u00e4n\\nF\u00f6dda 1882\\nAvlidna 1942\",\n    \"question\": \"Vilket datum \u00e4r Janka Kupalas f\u00f6delsedag?\",\n    \"answers\": {\n        \"answer_start\": array([59]),\n        \"text\": array([\"7 juli 1882\"], dtype=object)\n    }\n}\n</code></pre> <pre><code>{\n    \"context\": \"Stors\u00e4l (Erignathus barbatus) \u00e4r en s\u00e4lart som lever i Norra ishavet.\\n\\nUtseende och anatomi \\n\\nStors\u00e4len har gr\u00e5brun p\u00e4ls som \u00e4r ljusare p\u00e5 buken \u00e4n p\u00e5 ryggen. P\u00e5 vintern f\u00e5r den ett mycket tjock fettskikt s\u00e5 att huvudet ser ovanligt litet ut. Vikten \u00e4r p\u00e5 vintern omkring 360\\xa0kg (ibland upp till 430\\xa0kg) och p\u00e5 sommaren ungef\u00e4r 230\\xa0kg. Djuret \u00e4r vanligen mellan 230 och 250\\xa0cm l\u00e5ngt och har ett l\u00e5ngt vitt sk\u00e4gg. Br\u00f6stfenorna har en k\u00e4nnetecknande fyrkantig form. Mellan mars och augusti byter individerna p\u00e4lsens h\u00e5r.\\n\\nUtbredning \\n\\nStors\u00e4len f\u00f6rekommer p\u00e5 isflaken i hela Arktis. M\u00e5nga individer lever i Berings hav. Under vandringen h\u00e4nder det ibland att n\u00e5gra djur simmar fel s\u00e5 att de kommer till europeiska kustlinjer. En g\u00e5ng har djuret observerats i norra Portugal. Liknande iakttagelser rapporterades i norra Kina och fr\u00e5n den japanska \u00f6n Hokkaido.\\n\\nEkologi \\n\\nStors\u00e4len lever mestadels ensam. De vistas alltid i n\u00e4rheten av vattnet, s\u00e5 de kan flytta sig n\u00e4r en isbj\u00f6rn n\u00e4rmar sig. Djuret kan dyka till 200\\xa0meters djup men f\u00f6redrar att f\u00f6rbli i n\u00e4rheten av havsytan. Under sommaren n\u00e4r antalet isflak minskar vilar den ibland p\u00e5 land. Med sk\u00e4gget letar den p\u00e5 havsbotten efter r\u00e4kor, musslor och sn\u00e4ckor. Dessutom ing\u00e5r fiskar i f\u00f6dan.\\n\\nHannen skapar under vattnet ett ljud som liknar valarnas s\u00e5ng. Troligtvis \u00e4r ljudet till f\u00f6r att skydda s\u00e4lens territorium eller f\u00f6r att imponera p\u00e5 honan.\\n\\nHonan \u00e4r dr\u00e4ktig i omkring elva m\u00e5nader och f\u00f6der i april eller maj ett ungdjur. Under dessa elva m\u00e5nader stannar embryots utveckling av en tid s\u00e5 att ungen inte f\u00f6ds f\u00f6r tidig. Kuten v\u00e4ger vid f\u00f6delsen omkring 34\\xa0kg. Honan ger di till kuten tv\u00e5 till tre veckor (18 till 24 dagar) och l\u00e4mnar den sedan ensam p\u00e5 isen. Oftast kan kuten simma redan vid denna \u00e5lder. Unga honor blir efter 3 till 8 \u00e5r k\u00f6nsmogna och unga hannar efter 6 till 7 \u00e5r. Vanligen blir stors\u00e4lar inte \u00e4ldre \u00e4n 25 \u00e5r men enskilda individer med en livsl\u00e4ngd p\u00e5 31 \u00e5r \u00e4r dokumenterade.\\n\\nStors\u00e4lar jagas aktiv av isbj\u00f6rnar och de d\u00f6das ibland av sp\u00e4ckhuggare. S\u00e4llsynt faller ungar offer f\u00f6r valross.\\n\\nStors\u00e4l och m\u00e4nniskan \\n\\nJakt p\u00e5 stors\u00e4l f\u00f6r k\u00f6tt och hud har bedrivits l\u00e4nge. Men stors\u00e4len lever inte i flockar och \u00e4r d\u00e4rf\u00f6r inte lika l\u00e4ttjagad som andra s\u00e4larter. Huden anv\u00e4nds till exempel f\u00f6r umiak och skor. Sj\u00e4lva p\u00e4lsen \u00e4r inte eftertraktad. Under senare 1900-talet och b\u00f6rjan av 2000-talet uppskattades antalet d\u00f6dade individer per \u00e5r till 6\\xa0800 i Alaska, 2\\xa0400 i Kanada och 500 till 1\\xa0000 p\u00e5 Gr\u00f6nland. En mera omfattande jakt skedde efter andra v\u00e4rldskriget i de sovjetiska delarna av Arktiska havet, d\u00e4r upp till 13\\xa0000 individer d\u00f6dades per \u00e5r. N\u00e4r arten blev s\u00e4llsynt under 1970-talet minskade jakten betydlig. Den sovjetiska/ryska f\u00e5ngsten under 1980-talet uppgick bara till 2\\xa0000 individer per \u00e5r. IUCN listar arten som livskraftig (LC) p\u00e5 grund av det stora utbredningsomr\u00e5det och eftersom best\u00e5ndsutvecklingen bed\u00f6ms som stabil.\\n\\nNoter \\n\\n\u00d6ronl\u00f6sa s\u00e4lar\\nD\u00e4ggdjur i palearktiska regionen\\nD\u00e4ggdjur i nearktiska regionen\",\n    \"question\": \"Vilken bevarandestatus har stors\u00e4len enligt IUCN?\",\n    \"answers\": {\n        \"answer_start\": array([2804]),\n        \"text\": array([\"livskraftig (LC)\"], dtype=object)\n    }\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 4</li> <li>Prefix prompt:   <pre><code>Nedan f\u00f6ljer texter med tillh\u00f6rande fr\u00e5gor och svar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Text: {text}\nFr\u00e5ga: {question}\nSvar p\u00e5 max 3 ord: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Text: {text}\n\nBesvara f\u00f6ljande fr\u00e5ga om texten ovan med h\u00f6gst 3 ord.\n\nFr\u00e5ga: {question}\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset multi-wiki-qa-sv\n</code></pre>"},{"location":"datasets/swedish/#knowledge","title":"Knowledge","text":""},{"location":"datasets/swedish/#mmlu-sv","title":"MMLU-sv","text":"<p>This dataset is a machine translated version of the English MMLU dataset and features questions within 57 different topics, such as elementary mathematics, US history and law. The translation to Swedish was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 269 / 1,410 / 13,200 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). These splits are new and there can thus be some overlap between the original validation and test sets and our validation and test sets.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Varf\u00f6r \u00e4r tidpunkten f\u00f6r monumental byggnation vid Ceibal signifikant?\\nSvarsalternativ:\\na. Det mots\u00e4ger hypotesen att den monumental byggnationen av Maya i huvudsak inspirerades av Olmekerna.\\nb. Det bekr\u00e4ftar att inv\u00e5narna i Ceibal inspirerades av Olmekerna f\u00f6r att bygga stora plattformar.\\nc. Det mots\u00e4ger hypotesen att utvecklingen av monumental byggnation bland Maya var en intern process.\\nd. Det bekr\u00e4ftar att Olmekerna, som byggde de flesta Maya-monumenten, inspirerades av egyptierna.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Vilken populationsstatistik visar f\u00f6delsetalet vid vilket en befolkning precis f\u00e5r tillr\u00e4ckligt med f\u00f6dslar f\u00f6r att ers\u00e4tta f\u00f6r\u00e4ldrarna och kompensera f\u00f6r tidiga d\u00f6dsfall?\\nSvarsalternativ:\\na. R\u00e5 f\u00f6delsetal\\nb. Ers\u00e4ttningstal\\nc. D\u00f6dlighetstal\\nd. Total fertilitetstal\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En subenhet av DNA och protein som best\u00e5r av 134-baspar l\u00e5nga str\u00e4ckor av DNA som omger en proteinoktomer kallas (a)\\nSvarsalternativ:\\na. histon\\nb. kromatin\\nc. nukleosom\\nd. solenoid\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r flervalsfr\u00e5gor (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Fr\u00e5ga: {text}\n\nBesvara f\u00f6ljande fr\u00e5ga med 'a', 'b', 'c' eller 'd', och inget annat.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset mmlu-sv\n</code></pre>"},{"location":"datasets/swedish/#unofficial-arc-sv","title":"Unofficial: ARC-sv","text":"<p>This dataset is a machine translated version of the English ARC dataset and features US grade-school science questions. The translation to Swedish was done by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 1,110 / 297 / 1,170 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training, validation and testing, respectively (so 2,304 samples used in total). All new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"En typ av f\u00e5gel i Afrika \u00e4ter blodsugande insekter fr\u00e5n stora d\u00e4ggdjur. Vilket ord beskriver b\u00e4st relationen mellan f\u00e5geln och d\u00e4ggdjuren?\\nSvarsalternativ:\\na. mutualism\\nb. parasitism\\nc. neutralism\\nd. kommensalism\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Mr. Pratt g\u00f6r en vetenskaplig demonstration. Han bl\u00e5ser upp en ballong, placerar den i en frys och tar sedan ut den efter 10 minuter. Vilket alternativ beskriver b\u00e4st ballongens volym n\u00e4r den \u00e4r i frysen och efter att den har tagits ut och \u00e5ter till\u00e5tits att v\u00e4rmas upp?\\nSvarsalternativ:\\na. expanderar i frysen och kontraherar sedan n\u00e4r den blir varmare igen\\nb. kontraherar i frysen och expanderar sedan n\u00e4r den blir varmare igen\\nc. expanderar i frysen och h\u00e5ller sedan den volymen n\u00e4r den v\u00e4rms upp\\nd. kontraherar i frysen och h\u00e5ller sedan den volymen n\u00e4r den v\u00e4rms upp\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"En elev tills\u00e4tter vatten och reng\u00f6ringsmedel till en kopp med jord. Blandningen skakas och till\u00e5ts s\u00e4tta sig. Eleven observerar att silt-partiklar f\u00f6rblir uppsuspenderade l\u00e5ngt efter att de andra partiklarna bildar lager p\u00e5 botten av beh\u00e5llaren. Den mest troliga f\u00f6rklaringen \u00e4r att silt-partiklarna \u00e4r\\nSvarsalternativ:\\na. organiska.\\nb. uppl\u00f6sta.\\nc. mindre t\u00e4tt packade.\\nd. r\u00f6r sig snabbare.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r flervalsfr\u00e5gor (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvara f\u00f6ljande fr\u00e5ga med 'a', 'b', 'c' eller 'd', och inget annat.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset arc-sv\n</code></pre>"},{"location":"datasets/swedish/#common-sense-reasoning","title":"Common-sense Reasoning","text":""},{"location":"datasets/swedish/#hellaswag-sv","title":"HellaSwag-sv","text":"<p>This dataset is a machine translated version of the English HellaSwag dataset. The original dataset was based on both video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset was translated by the University of Oregon as part of this paper, using GPT-3.5-turbo.</p> <p>The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"[header] Hur man hittar de perfekta brudt\u00e4rnekl\u00e4nningarna [title] Internet \u00e4r en underbar resurs f\u00f6r att hitta brudt\u00e4rnekl\u00e4nningar. [step] Vi rekommenderar ocks\u00e5 att bl\u00e4ddra genom popul\u00e4ra br\u00f6llopstidningar, s\u00e5som brudens och moderna brudt\u00e4rnets tidningar. Rekommenderat \u00e4r att bruden g\u00e5r och handlar med en eller tv\u00e5 av sina brudt\u00e4rnor och ser vilka stilar de gillar.\\nSvarsalternativ:\\na. N\u00e4r du har begr\u00e4nsat urvalet kan du sedan f\u00e5 input fr\u00e5n dina andra brudt\u00e4rnor om du \u00f6nskar det. [title] Vilka \u00e4r de senaste trenderna i brudt\u00e4rnekl\u00e4nningar? [title] A-linje kl\u00e4nningar som ser bra ut p\u00e5 alla olika kroppsformer och storlekar \u00e4r mycket popul\u00e4ra.\\nb. Tyv\u00e4rr kan du inte handla lika ofta som om du letade efter matchade brudt\u00e4rnor. [title] N\u00e4r du v\u00e4ljer din brud, v\u00e4lj tre olika stilar: [step] Klipp l\u00e4ngd, klipp tjocklek och fr\u00e5n de flesta \\\"f\u00f6r-skjutna\\\" stilarna till de grundl\u00e4ggande.\\nc. Medan varje brud \u00e4r annorlunda, alla \u00e4r b\u00e5de olika och har olika smaker. [title] Se om bruden har en favoritlook f\u00f6r sin br\u00f6llopskl\u00e4nning.\\nd. [title] B\u00f6rja s\u00f6ka efter id\u00e9er eller allm\u00e4nna \u00e5sikter om s\u00e4rskilda br\u00f6llopskl\u00e4nningar. [step] F\u00f6rs\u00f6k att inte bli f\u00f6r stel och s\u00f6k bara efter n\u00e5gra kl\u00e4nningar som du tror kan fungera bra tillsammans.\",\n  \"label\": \"a\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"[header] Hur man g\u00f6r en pedikyr [title] Ta bort all befintlig f\u00e4rg med nagellacksborttagare. [step] T\u00e4ck toppen p\u00e5 din nagellacksborttagare med en bomullstuss, v\u00e4nd snabbt upp och ner den och omedelbart upp och ner igen f\u00f6r att applicera lite av produkten. Gnugga sedan nagellacksborttagaren \u00f6ver dina t\u00e5naglar f\u00f6r att ta bort f\u00e4rgen.\\nSvarsalternativ:\\na. [title] L\u00e5t dina t\u00e5naglar bl\u00f6tl\u00e4ggas i vatten i 10 till 20 minuter. [step] Vatten kan g\u00f6ra dina naglar vitare genom att l\u00f6sa upp andra f\u00f6reningar, s\u00e4rskilt syror.\\nb. [substeps] Flytta bomullstussen i sm\u00e5, cirkul\u00e4ra r\u00f6relser om du har sv\u00e5rt att ta bort f\u00e4rgen. [title] Fyll en fotspa eller en balja med varmt vatten.\\nc. [substeps] Om du inte har nagellacksborttagare kan du \u00f6verv\u00e4ga att anv\u00e4nda den vita nagellacksborttagaren fr\u00e5n f\u00f6reg\u00e5ende steg f\u00f6r en enklare applikation. [title] T\u00e4ck dina h\u00e4nder med bandage eller tejp med canvas-lining.\\nd. [title] Anv\u00e4nd aceton p\u00e5 dina t\u00e5naglar. [step] Aceton kan verkligen hj\u00e4lpa till att ta bort gammalt nagellack fr\u00e5n dina naglar.\",\n  \"label\": \"b\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Han forts\u00e4tter att klippa gr\u00e4set. Kameran fokuserar p\u00e5 det rinnande vattnet igen. Den g\u00e5r tillbaka till mannen som klipper gr\u00e4set. sedan\\nSvarsalternativ:\\na. den g\u00e5r tillbaka till filmen av mannen som klipper jord.\\nb. \u00e5terv\u00e4nder till honom och dem som pratar igen.\\nc. v\u00e4xlar tillbaka till det rinnande vattnet.\\nd. m\u00f6rk himmel igen.\",\n  \"label\": \"c\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r flervalsfr\u00e5gor (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvara f\u00f6ljande fr\u00e5ga med 'a', 'b', 'c' eller 'd', och inget annat.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset hellaswag-sv\n</code></pre>"},{"location":"datasets/swedish/#unofficial-goldenswag-sv","title":"Unofficial: GoldenSwag-sv","text":"<p>This dataset is a filtered and machine translated version of the English HellaSwag dataset, featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in this paper and was done using DeepL, and the filtering was published in this paper, which resulted in higher quality samples.</p> <p>The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.</p> <p>Here are a few examples from the training split:</p> <pre><code>{\n  \"text\": \"Hur man staplar h\u00f6. Placera dina pallar p\u00e5 en tillg\u00e4nglig plats. Det m\u00e5ste vara l\u00e4tt att ta sig till staplarna, s\u00e5 v\u00e4lj en plats som du kan n\u00e5 utan problem. Undvik att stapla balar direkt p\u00e5 marken.\\nSvarsalternativ:\\na. H\u00e5ll balarna i detta omr\u00e5de inom arml\u00e4ngds avst\u00e5nd s\u00e5 att du inte skadar dig sj\u00e4lv och andra i byggnaden. T\u00e4nk p\u00e5 att det b\u00f6r finnas ca 6 balar s\u00e5 att varje person i rummet ska kunna komma \u00e5t en bal.\\nb. Undvik att stapla balar p\u00e5 asfalterade ytor. Hitta en oj\u00e4mn yta att stapla pallar p\u00e5.\\nc. Dina pallar m\u00e5ste vara l\u00e5dliknande och h\u00e5lla dina ben ut \u00e5t sidorna, samt st\u00f6dja din fulla vikt. Anv\u00e4nd betongblock om du har tillg\u00e5ng till s\u00e5dana.\\nd. H\u00f6et suger \u00e5t sig fukt och blir m\u00f6gligt. F\u00f6r att f\u00f6rhindra detta, anv\u00e4nd tr\u00e4pallar som grund.\",\n  \"label\": \"d\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hur du v\u00e4ljer vem som ska f\u00f6lja dig till altaret. Identifiera den viktigaste familjemedlemmen i ditt liv. Det kan vara bra att b\u00f6rja med att fundera p\u00e5 vem som \u00e4r den viktigaste familjemedlemmen i ditt liv och sedan fundera p\u00e5 att be den personen att f\u00f6lja dig till altaret. Du kanske anser att din bror \u00e4r den viktigaste personen i ditt liv.\\nSvarsalternativ:\\na. Eller s\u00e5 t\u00e4nker du p\u00e5 din mamma, vars liv du \u00e4lskade mest. Att identifiera din familjemedlem kan hj\u00e4lpa dig att g\u00e5 igenom n\u00e5gra av de mer upplyftande stunderna, eftersom din familjemedlem sannolikt kan vara din make eller sambo.\\nb. Kanske \u00e4r din bror din pappas b\u00e4sta v\u00e4n och din mamma har varit din mammas b\u00e4sta v\u00e4n under en mycket l\u00e5ng tid. Att g\u00f6ra en lista \u00f6ver dessa personer kan hj\u00e4lpa dig att f\u00f6rst\u00e5 varf\u00f6r din mamma \u00e4r viktig f\u00f6r dig och vad som motiverar henne att f\u00f6lja dig till altaret.\\nc. Eller s\u00e5 kanske den f\u00f6rsta personen som dyker upp i ditt huvud \u00e4r din ensamst\u00e5ende mamma som uppfostrade dig p\u00e5 egen hand. Du kan skriva ner n\u00e5gra personer som \u00e4r viktiga f\u00f6r dig i din familj p\u00e5 ett papper och sedan v\u00e4lja en fr\u00e5n listan.\\nd. Eller s\u00e5 kanske du v\u00e4ljer din mammas pappa som din hedersbrudt\u00e4rna. En lista kan dyka upp framf\u00f6r dig n\u00e4r du organiserar dina kalendrar och m\u00f6ten, s\u00e5 det \u00e4r viktigt att hitta n\u00e5gra ord som tydligt hj\u00e4lper dig.\",\n  \"label\": \"c\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Hur man f\u00e5r gratis uppgraderingar p\u00e5 smekm\u00e5naden. Registrera dig f\u00f6r medlemskort f\u00f6r frequent flier miles. Om du har ett favoritflygbolag, registrera dig f\u00f6r dess bonusprogram s\u00e5 snart du kan, s\u00e4rskilt om du g\u00f6r m\u00e5nga aff\u00e4rsresor. Frekventa flygmil kan snabbt l\u00e4ggas ihop och leda till gratisbiljetter och uppgraderingar.\\nSvarsalternativ:\\na. Vissa flygbolag till\u00e5ter till och med att dina v\u00e4nner och familj ger dig sina miles, s\u00e5 uppmuntra dem att ocks\u00e5 registrera sig.. Fr\u00e5ga ditt kreditkortsf\u00f6retag om incitament.\\nb. V\u00e4lj en destination som du \u00e4r villig att spendera pengar p\u00e5. Det \u00e4r en bra id\u00e9 att prova n\u00e5gra destinationer som du skulle \u00e4lska att bes\u00f6ka, inklusive Japan, som \u00f6ppnar upp ekonomiska m\u00f6jligheter omedelbart.\\nc. Skicka uppgifterna till det flygbolag du f\u00f6redrar. Om du har f\u00f6r avsikt att anv\u00e4nda bonuspo\u00e4ng f\u00f6r aff\u00e4rs\u00e4ndam\u00e5l ska du skicka uppgifterna till ditt favoritflygbolag p\u00e5 n\u00e5got av f\u00f6ljande s\u00e4tt.\\nd. Bes\u00f6k webbplatsen f\u00f6r det flygbolag som arrangerar flygningar f\u00f6r dig, eller leta online f\u00f6r att hitta en resplan som specificerar miles. F\u00f6rutom gratis resor kan du ocks\u00e5 anv\u00e4nda back to back-bokningstj\u00e4nster.\",\n  \"label\": \"a\"\n}\n</code></pre> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 5</li> <li>Prefix prompt:   <pre><code>F\u00f6ljande \u00e4r flervalsfr\u00e5gor (med svar).\n</code></pre></li> <li>Base prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\nSvar: {label}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Fr\u00e5ga: {text}\nSvarsalternativ:\na. {option_a}\nb. {option_b}\nc. {option_c}\nd. {option_d}\n\nBesvara f\u00f6ljande fr\u00e5ga med 'a', 'b', 'c' eller 'd', och inget annat.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset goldenswag-sv\n</code></pre>"},{"location":"datasets/swedish/#summarization","title":"Summarization","text":""},{"location":"datasets/swedish/#swedn","title":"SweDN","text":"<p>This dataset was published in this paper and are based on news articles from the Swedish newspaper Dagens Nyheter, with the summaries being the first paragraph of the article (and that paragraph being removed from the article).</p> <p>The original dataset consists of 29,800 / 4,530 / 3,750 samples for training, validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total). All the new splits are subsets of the original splits.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Ett \u00f6verraskande ras p\u00e5 den ryska lastbilsmarknaden har gjort att Scania blivit fr\u00e5nsprunget av konkurrenten Volvo som \u00f6kat sina leveranser, skriver Dagens Industri. Bakom Scanias tapp p\u00e5 24 procent ligger bland annat problem med tillst\u00e5nden f\u00f6r att producera Euro-3 lastbilar i fabriken i S:t Petersburg. Men det r\u00e4knar Scanias Rysslandschef Hans Tardell med att ta tillbaka under \u00e5ret. Konkurrenten Volvo, som \u00f6kat leveranserna med 40 procent och ordering\u00e5ngen med 68 procent j\u00e4mf\u00f6rt mot f\u00f6rsta kvartalet 2011, hoppas kunna v\u00e4xa ytterligare.  \",\n  \"target_text\": \"Ett \u00f6verraskande ras p\u00e5 den ryska lastbilsmarknaden har gjort att Scania blivit fr\u00e5nsprunget av konkurrenten Volvo som \u00f6kat sina leveranser, skriver Dagens Industri.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Scenen som beskrivs i \u00e5talet kunde vara h\u00e4mtad ur en skr\u00e4ckfilm. Den d\u00e5 tolv\u00e5riga flickan har ber\u00e4ttat hur hon f\u00f6rs\u00e5gs med handbojor och kedjades vid en krok i taket. Enligt \u00e5talet ska hon \u00e4ven ha f\u00e5tt ett koppel kring halsen och piskats. \u00c5klagaren menar att det handlar om ett utdraget f\u00f6rlopp. \u2013 En tolv\u00e5rig flicka ska inte sitta fastsatt i en krok i taket, s\u00e4ger \u00e5klagare Daniel Veivo Pettersson, som nu har \u00e5talat en 25-\u00e5rig man f\u00f6r grov v\u00e5ldt\u00e4kt mot barn. I veckan ber\u00e4ttade TT att sju m\u00e4n d\u00f6mts f\u00f6r att vid olika tillf\u00e4llen ha utsatt samma flicka f\u00f6r sexuella \u00f6vergrepp. M\u00e4nnen fick kontakt med flickan via forum p\u00e5 n\u00e4tet och tjatade sig till tr\u00e4ffar med henne. En av m\u00e4nnen band och v\u00e5ldtog henne i en skog. 25-\u00e5ringen blir nu den \u00e5ttonde mannen som \u00e5talas f\u00f6r \u00f6vergrepp. \u2013 Man h\u00e4pnar n\u00e4r man h\u00f6r hennes ber\u00e4ttelse. Hon \u00e4r mycket trov\u00e4rdig och vi har \u00e4ven kunnat styrka \u00e5talen mot m\u00e4nnen genom teknisk bevisning som chattkonversationer och i n\u00e5got fall fanns dna p\u00e5 en kondom och p\u00e5 en bh, s\u00e4ger Daniel Veivo Pettersson. Vid en husrannsakan i 25-\u00e5ringens hem i Stockholm, d\u00e4r v\u00e5ldt\u00e4kten ska ha beg\u00e5tts under h\u00f6sten 2013, hittades kedjor, handbojor, koppel och en piska. Enligt flickan hade delar av \u00f6vergreppen filmats. Polisen misst\u00e4nkte att filmerna kunde ha sparats i en s\u00e5 kallad molntj\u00e4nst, och \u00e5klagaren fick ta hj\u00e4lp av Microsoft i USA. \u2013 Det drog ut p\u00e5 tiden, men tyv\u00e4rr hittade vi inte det vi letade efter. Han har raderat en hel del information i sin dator, s\u00e4ger Daniel Veivo Pettersson. 25-\u00e5ringen \u00e5talas dessutom f\u00f6r ytterligare en v\u00e5ldt\u00e4kt p\u00e5 flickan, eftersom han misst\u00e4nks ha v\u00e5ldtagit henne p\u00e5 en toalett. Mannen \u00e4r tidigare d\u00f6md f\u00f6r \u00f6vergrepp p\u00e5 en annan minder\u00e5rig flicka, och \u00e5klagaren har nu beg\u00e4rt honom h\u00e4ktad i sin fr\u00e5nvaro. \u2013 Han kan vara hemma, men han kan \u00e4ven vara utomlands. Om han h\u00e4ktas i sin utevaro kommer han att efterlysas, s\u00e4ger Daniel Veivo Pettersson. 25-\u00e5ringen f\u00f6rsvaras av advokat Thomas Bodstr\u00f6m. Han vill inte ber\u00e4tta om 25-\u00e5ringen kommer n\u00e4rvara vid h\u00e4ktningsf\u00f6rhandlingen, men han s\u00e4ger: \u2013 Han nekar till samtliga brott, \u00e4r helt oskyldig och det finns ingen grund f\u00f6r h\u00e4ktning. Enligt \u00e5klagaren misst\u00e4nks flickan ha utsatts av ytterligare minst en man som polisen inte har lyckats identifiera. M\u00e4nnen i h\u00e4rvan 37-\u00e5ring, \u00d6sterg\u00f6tland: V\u00e5ldt\u00e4kt mot barn och barnpornografibrott \u2013 fem \u00e5rs f\u00e4ngelse. 26-\u00e5ring, Dalarna: Sexuellt ofredande \u2013 skyddstillsyn. 29-\u00e5ring, Stockholmstrakten: V\u00e5ldt\u00e4kt mot barn (tv\u00e5 tillf\u00e4llen) \u2013 tre \u00e5rs f\u00e4ngelse. 26-\u00e5ring, Stockholmstrakten: V\u00e5ldt\u00e4kt mot barn \u2013 tv\u00e5 och ett halvt \u00e5rs f\u00e4ngelse. 27-\u00e5ring, Stockholmstrakten: Grov v\u00e5ldt\u00e4kt mot barn och v\u00e5ldt\u00e4kt mot barn (fyra tillf\u00e4llen) \u2013 sju \u00e5rs f\u00e4ngelse. 55-\u00e5ring, \u00d6sterg\u00f6tland: Utnyttjande av barn f\u00f6r sexuell posering (elva tillf\u00e4llen) och sexuellt ofredande (tv\u00e5 tillf\u00e4llen) \u2013 \u00e5tta m\u00e5naders f\u00e4ngelse. 19-\u00e5ring, V\u00e4stra G\u00f6taland: V\u00e5ldt\u00e4kt mot barn \u2013 \u00e5tta m\u00e5naders f\u00e4ngelse (domen \u00e4r \u00f6verklagad). 25-\u00e5ring, Stockholmstrakten: \u00c5talad f\u00f6r grov v\u00e5ldt\u00e4kt mot barn och v\u00e5ldt\u00e4kt mot barn. \",\n  \"target_text\": \"Den tolv\u00e5riga flickan kedjades vid en krok i taket och v\u00e5ldtogs. En 25-\u00e5rig man har nu \u00e5talats f\u00f6r grov v\u00e5ldt\u00e4kt mot barn, men det \u00e4r oklart var han \u00e4r. Sju m\u00e4n d\u00f6mdes nyss f\u00f6r \u00f6vergrepp p\u00e5 samma flicka.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Det \u00e4r Gr\u00f6na partiets ledare Jill Stein som har uppmanat valkommissionen i delstaten Wisconsin att r\u00e4kna om r\u00f6sterna, det skriver Reuters och Wisconsins valkommission. Valkommissionen skriver att man \u201dr\u00e4knar med att omr\u00e4kningen b\u00f6rjar inom en vecka efter det att Steins kampanj har betalat avgiften omr\u00e4kningen, som vi fortfarande h\u00e5ller p\u00e5 att ber\u00e4kna\u201d. En omr\u00e4kning ska vara genomf\u00f6rd f\u00f6re den 13 december. Delstaten vanns av Donald Trump med 47,9 procent av r\u00f6sterna mot Hillary Clintons 46,9 procent och gav honom 10 elektorsr\u00f6ster. Skillnaden mellan de tv\u00e5 kandidaterna var 23.000 r\u00f6ster. Jill Stein har tidigare sagt att hon \u00e4r beredd att \u00e4ven f\u00f6rs\u00f6ka f\u00e5 r\u00f6sterna i Michigan och Pennsylvania omr\u00e4knade. Om hon ska beg\u00e4ra en omr\u00e4kning ocks\u00e5 i dessa tv\u00e5 delstater m\u00e5ste den beg\u00e4ran inkomma under n\u00e4sta vecka, skriver NBC News. Jill Stein. Foto: AP F\u00f6r att f\u00e5 till st\u00e5nd en omr\u00e4kning m\u00e5ste Gr\u00f6na partiet ha pengar nog att driva en s\u00e5dan. Enligt Washington Post har partiet lyckats samla in 4,5 miljoner dollar som ska t\u00e4cka juridiska omkostnader och annat som har med en eventuell omr\u00e4kning att g\u00f6ra i de tre delstaterna. Enligt tidningen kommer det sannolikt att beh\u00f6vas sammanlagt mellan 6 och 7 miljoner f\u00f6r att genomf\u00f6ra en omr\u00e4kning. Om Clinton skulle g\u00e5 segrande ur en omr\u00e4kning i Wisconsin skulle detta \u00e4nd\u00e5 inte inneb\u00e4ra n\u00e5gon skillnad n\u00e4r det g\u00e4ller utg\u00e5ngen av presidentvalet. Skulle Clinton vinna \u00e4ven i Michigan och Pennsylvania skulle det d\u00e4remot betyda en annan utg\u00e5ng av valet. \u00c4ven om f\u00e5 tror att en omr\u00e4kning skulle betyda n\u00e5got i praktiken, Hillary Clinton har redan erk\u00e4nt sig besegrad, s\u00e5 skulle en omr\u00e4kning i hennes fav\u00f6r i Wisconsin och Pennsylvania ge henne 30 elektorsr\u00f6ster medan Trump f\u00f6rlorar lika m\u00e5nga. Om s\u00e5, rent hypotetiskt, skulle bli fallet, skiljer bara 10 elektorsr\u00f6ster till Trumps f\u00f6rdel \u2013 och d\u00e5 \u00e5terst\u00e5r \u00e4nnu Michigans r\u00f6ster att slutr\u00e4knas. Skulle Clinton vinna \u00e4ven dem s\u00e5 har hon flest antal elektorsr\u00f6ster. Jill Stein har i en intervju sj\u00e4lv sagt att hon inte beg\u00e4r en omr\u00e4kning f\u00f6r att gynna n\u00e5gon av kandidaterna utan f\u00f6r att \u201damerikanerna inte blev s\u00e4rskilt glada \u00f6ver utg\u00e5ngen av valet\u201d. Sett till enbart r\u00f6sterna, och inte till elektorerna, leder just nu Hillary Clinton med 48,1 procent av r\u00f6sterna mot Donald Trumps 46,6 procent. I antal r\u00f6ster leder Clinton med 2.012.331 r\u00f6ster. \",\n  \"target_text\": \"Valkommissionen i Wisconsin i har f\u00e5tt en uppmaning om att r\u00f6sterna i presidentvalet ska r\u00e4knas om. Wisconsin har nu b\u00f6rjat f\u00f6rbereda en omr\u00e4kning. Och det kan bli fler.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Nedan f\u00f6ljer artiklar med tillh\u00f6rande sammanfattningar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Artikel: {text}\nSammanfattning: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Artikel: {text}\n\nSkriv en sammanfattning av artikeln ovan.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset swedn\n</code></pre>"},{"location":"datasets/swedish/#unofficial-schibsted-sv","title":"Unofficial: Schibsted-sv","text":"<p>This dataset was published here and features summaries of news articles from Schibsted Medias Swedish newsroom, from Aftonbladet.</p> <p>The original dataset has 528 / 96 / 89 samples for training, validation and testing, respectively. We use these splits as-is.</p> <p>Here are a few examples from the training split:</p> <p><pre><code>{\n  \"text\": \"Richard Jomshof blir uppr\u00f6rd och v\u00e4grar svara p\u00e5 fr\u00e5gor: SD-toppen Richard Jomshof v\u00e4grar kommentera kritiken efter p\u00e5hoppet p\u00e5 Daniel Riazat (V).  N\u00e4r Aftonbladet m\u00f6ter honom i riksdagen blir han uppr\u00f6rd och g\u00e5r iv\u00e4g. \u2013 Jag uppskattar inte skjutj\u00e4rnsjournalistik, det \u00e4r ett oseri\u00f6st s\u00e4tt att jobba, s\u00e4ger han.  Justitieutskottets ordf\u00f6rande Richard Jomshof (SD) f\u00e5r h\u00e5rd kritik f\u00f6r sitt uttalande att V-ledamoten Daniel Riazat borde flytta fr\u00e5n Sverige.  Flera i den politiska oppositionen d\u00f6mer ut det som rasistiskt. \u00c4ven i Tid\u00f6partierna h\u00f6rs protester.  \u201d\u00c4r man svensk medborgare s\u00e5 \u00e4r man. Skamligt var ordet!\u201d skriver L-politikern Jan J\u00f6nsson i ett uttalande p\u00e5 X.  \u201dTa det med pressavdelningen\u201d Aftonbladet var p\u00e5 plats utanf\u00f6r justitieutskottets m\u00f6te i riksdagen vid lunchtid p\u00e5 tisdagen. Jomshof anl\u00e4nde f\u00f6rst av alla ledam\u00f6ter, tio minuter innan m\u00f6tet inleddes, men ville inte svara p\u00e5 fr\u00e5gor.  \u2013 Du f\u00e5r ta det med pressavdelningen. Varf\u00f6r vill du inte svara, det \u00e4r ju du som har skrivit de h\u00e4r tweetsen? \u2013 Du f\u00e5r ta det med pressavdelningen. Du kan l\u00e4sa min senaste tweet f\u00f6rresten, s\u00e5 kan vi utg\u00e5 fr\u00e5n den. Varf\u00f6r tycker du att han borde l\u00e4mna Sverige? \u2013 B\u00f6rja med att l\u00e4sa min tweet, det framg\u00e5r v\u00e4ldigt tydligt d\u00e4r. \u201dUppskattar inte skjutj\u00e4rnsjournalistik\u201d Inl\u00e4gget som Jomshof syftar p\u00e5 lades upp kort innan justitieutskottets m\u00f6te. Jomshof g\u00e5r d\u00e4r till nytt angrepp mot Riazat. Han anklagar honom f\u00f6r att ha ett \u201dsunkigt\u201d beteende, att vara of\u00f6rsk\u00e4md och komma med aggressiva p\u00e5hopp p\u00e5 politiska motst\u00e5ndare.  M\u00f6tet med justitieutskottet varade en timme, n\u00e4r Richard Jomshof kom ut fr\u00e5n salen var uppr\u00f6rd \u00f6ver Aftonbladets n\u00e4rvaro. Detta trots att media brukar bevaka m\u00f6tena och att ledam\u00f6terna i utskottet ofta tar tillf\u00e4lle att ge intervjuer efter\u00e5t.  \u2013 F\u00f6r det f\u00f6rsta, vill ni prata med mig s\u00e5 g\u00e5r ni till pressavdelningen. Jag uppskattar inte skjutj\u00e4rnsjournalistik, det \u00e4r ett oseri\u00f6st s\u00e4tt att jobba. Tv\u00e5, jag har inget mer att till\u00e4gga \u00e4n det jag lagt ut p\u00e5 plattformen X. D\u00e4r framg\u00e5r det tydligt vad det h\u00e4r handlar om. Tre, ett tips i all v\u00e4nlighet, ni kan ju prata med Riazat sj\u00e4lv, om hans of\u00f6rsk\u00e4mdheter och aggressiva beteende, om varf\u00f6r han inte vill ta politiska motst\u00e5ndare och kvinnor i hand. Nu t\u00e4nker jag g\u00e5 och \u00e4ta lunch, s\u00e4ger Jomshof.  Busch: Jag \u00e4r ganska osugen Daniel Riazat kallade ig\u00e5r Richard Jomshofs uttalande f\u00f6r rasistiskt och uppmanar statsminister Ulf Kristersson (M) att ta avst\u00e5nd. Aftonbladet har s\u00f6kt Kristersson, hans pressekreterare ber att f\u00e5 \u00e5terkomma om statsministern har m\u00f6jlighet att uttala sig. Vice statsminister Ebba Busch (KD) var f\u00e5ordig n\u00e4r hon fick fr\u00e5gor om det p\u00e5 tisdagen.  \u2013 Jag \u00e4r ganska osugen p\u00e5 att bidra till det rubrikspelet, sa hon i samband med en utfr\u00e5gning i riksdagen.  Vice ordf\u00f6rande i justitieutskottet, Ardalan Shekarabi (S), har tidigare kr\u00e4vt Jomshofs avg\u00e5ng. Han uppmanar f\u00f6retr\u00e4dare f\u00f6r regeringen att sluta ge Jomshof st\u00f6d.  \u2013 Tyv\u00e4rr \u00e4r det ett konsekvent beteende han har. Han verkar f\u00f6r splittring, mots\u00e4ttningar och i vissa fall hat mot folkgrupper. Han anv\u00e4nder den plattform som ordf\u00f6rande i justitieutskottet medf\u00f6r till att bedriva den typen av agitation, s\u00e4ger han.  Aftonbladet har s\u00f6kt Sverigedemokraternas pressavdelning. De ber om att f\u00e5 fr\u00e5gorna till Richard Jomshof p\u00e5 mejl och att f\u00e5 \u00e5terkomma senare. Aftonbladet har s\u00f6kt Daniel Riazat. V\u00e4nsterpartiets pressavdelning ber att f\u00e5 \u00e5terkomma. \",\n  \"target_text\": \"SD-toppen Richard Jomshof v\u00e4grar kommentera kritiken f\u00f6r sitt p\u00e5st\u00e5ende att V\u00e4nsterpartiets riksdagsledamot Daniel Riazat borde l\u00e4mna Sverige. M\u00e5nga inom den politiska oppositionen kallar uttalandet rasistiskt N\u00e4r Jomshof konfronteras med fr\u00e5gor fr\u00e5n Aftonbladet vid ett utskottsm\u00f6te i riksdagen, blir han uppr\u00f6rd och g\u00e5r iv\u00e4g utan att svara p\u00e5 fr\u00e5gorna. Han h\u00e4nvisar till SD:s pressavdelning.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Fredrik Bolanders uttalande i \u201dRobinson\u201d f\u00e5r kritik: \u201dSkriver att jag \u00e4r en mansgris\u201d: Kvinnor \u00e4r bra p\u00e5 att st\u00e4da, laga mat och h\u00e5lla ordning.  Killar vill \u00e4ta mat, \u00e4r starkare och b\u00e4ttre. Fredrik Bolanders uttalande i \u201dRobinson\u201d har f\u00e5tt m\u00e5nga att reagera. \u2013 Jag vet att folk st\u00f6r sig p\u00e5 s\u00e5dana uttalanden, det \u00e4r ju ett s\u00e5dan samh\u00e4lle vi lever vi, s\u00e4ger han. \u2013 Om jag hade f\u00e5tt best\u00e4mma hade det varit en kvinna i laget f\u00f6r de \u00e4r ju bra p\u00e5 att laga mat, de \u00e4r bra p\u00e5 att h\u00e5lla ordning och st\u00e4da. D\u00e4r har vi det negativa med att inte ha en kvinna i laget. Vi m\u00e4n vill ju \u00e4ta s\u00e5klart. Uttalandet fr\u00e5n \u201dRobinson\u201d-deltagaren Fredrik Bolander, 40, har f\u00e5tt m\u00e5nga att reagera, bland annat p\u00e5 \u201dRobinsons\u201d sociala medier.  \u00c4ndringen i \u201dRobinson\u201d 2024 I \u00e5rets s\u00e4song delas kvinnor och m\u00e4n upp i olika lag.  N\u00e4r programledaren Anders Lundin, 65, fr\u00e5gar Bolander om han tror att det ger kvinnorna en st\u00f6rre chans att vinna i \u00e5r f\u00e5r han ett snabbt svar.  \u2013 Nej, det blir en kille som vinner i \u00e5r. Killar \u00e4r ofta lite starkare och b\u00e4ttre \u00e4n tjejer. Flera deltagare reagerar p\u00e5 uttalandet i programmet. Tjejerna protesterar h\u00f6gljutt och Gustav Jacobson, 27, g\u00f6r en f\u00f6rskr\u00e4ckt min.  Bolander s\u00e4ger \u00e4ven i programmet att han inte g\u00e5r s\u00e5 bra ihop med kvinnor och feminister. \u2013 Jag \u00e4r v\u00e4ldigt manlig i mig sj\u00e4lv, och jag har en v\u00e4ldigt manlig jargong, och tycker att det ska vara j\u00e4mlikt men man ska ocks\u00e5 f\u00f6rst\u00e5 vem som \u00e4r mannen i huset. \u201dSkriver att jag \u00e4r en mansgris\u201d N\u00e4r Aftonbladet pratar med Bolander samma dag som \u201dRobinson\u201d har premi\u00e4r ber\u00e4ttar han att han redan f\u00e5tt reaktioner och meddelanden fr\u00e5n tittare.  \u2013 De skriver att jag \u00e4r en mansgris och att jag har fel kvinnosyn. Samtidigt \u00e4r han medveten om att det han s\u00e4ger om kvinnor triggar folk.  \u2013 Jag \u00e4lskar att provocera. Det \u00e4r klart att jag gillar att se reaktioner, det vill jag ju, s\u00e4ger Bolander.  Han forts\u00e4tter:  \u2013 Jag vet att folk st\u00f6r sig p\u00e5 s\u00e5dana uttalanden, det \u00e4r ju ett s\u00e5dan samh\u00e4lle vi lever vi. S\u00e5 det var roligt att k\u00f6ra lite tv\u00e4rtom t\u00e4nkte jag. Fredrik Bolander om reaktionerna Just uttalandet om att det beh\u00f6vs en kvinna f\u00f6r att st\u00e4da och laga mat i killarnas lag \u00e4r det han f\u00e5tt mest reaktioner p\u00e5.  \u2013 M\u00e5nga som skrivit \u00e4r ju inte j\u00e4tteglada. Vad skriver folk? \u2013 Att vi lever i 2024 och man ska inte vara s\u00e5 och alla ska vara lika och allt det d\u00e4r. Men samtidigt s\u00e5, man g\u00f6r ju det man \u00e4r bra p\u00e5? Men m\u00e4n kan v\u00e4l ocks\u00e5 vara bra p\u00e5 att laga mat och st\u00e4da? \u2013 Jo men vi har ju mycket annat att g\u00f6ra? Som att tr\u00e4na med stenar? \u2013 Exakt. Pumpa muskler och tr\u00e4na, vi m\u00e5ste t\u00e4nka p\u00e5 hur vi ser ut, vi m\u00e5ste se solbr\u00e4nda ut och det tar tid. Det h\u00e4r \u00e4r ju ett uttalande som uppr\u00f6r m\u00e5nga. K\u00e4nner du att du kan st\u00e5 f\u00f6r det uttalandet? \u2013 Det d\u00e4r \u00e4r en sv\u00e5r fr\u00e5ga. Jag s\u00e4ger s\u00e5 h\u00e4r; man f\u00e5r se lite under programmets g\u00e5ng om det \u00e4r n\u00e5got jag st\u00e5r f\u00f6r eller inte. S\u00e5 kan jag s\u00e4ga. M\u00e5nga undrar ocks\u00e5 om du \u00e4r seri\u00f6s eller skojar? \u2013 Det \u00e4r det som \u00e4r fr\u00e5gan, skojar jag eller \u00e4r jag seri\u00f6s? Det svarar jag inte p\u00e5. Varf\u00f6r inte? \u2013 Antingen kanske jag st\u00e5r f\u00f6r det senare eller s\u00e5 g\u00f6r jag inte det. Det f\u00e5r ni se. \u201dRobinson\u201d s\u00e4nds s\u00f6ndagar klockan 21.00 samt m\u00e5ndag till torsdag klockan 19.30 p\u00e5 TV4 och p\u00e5 TV4 play. \",\n  \"target_text\": \"\\\"Robinson\\\"-deltagaren Fredrik Bolander har hamnat i bl\u00e5sv\u00e4der efter sina uttalanden om kvinnor och m\u00e4n, och f\u00e5r kritik p\u00e5 sociala medier. Han p\u00e5st\u00e5r att kvinnor \u00e4r bra p\u00e5 att laga mat och st\u00e4dning medan m\u00e4n \u00e4r starkare och b\u00e4ttre, och detta uppr\u00f6rde andra deltagare och tittare. Bolander s\u00e4ger att han \u00e4lskar att provocera, men v\u00e4grar svara p\u00e5 fr\u00e5gan om han sk\u00e4mtar eller \u00e4r seri\u00f6s.\"\n}\n</code></pre> <pre><code>{\n  \"text\": \"Polisen om den \u00f6vergivna diplomatbilen: \u201dVi unders\u00f6ker immunitetsfr\u00e5gan\u201d: En diplomatbil l\u00e4mnades \u00f6vergiven p\u00e5 ett t\u00e5gsp\u00e5r i centrala Stockholm i helgen. Fordonet tillh\u00f6r Etiopiens ambassad som har bett om urs\u00e4kt f\u00f6r vansinnesf\u00e4rden. Men n\u00e4r Aftonbladet knackar p\u00e5 \u00e4r de f\u00e5ordiga.  \u2013 Vi \u00e5terkommer s\u00e5 fort det g\u00e5r, s\u00e4ger en anst\u00e4lld p\u00e5 ambassaden. Det var natten till s\u00f6ndag som minibussen krockade p\u00e5 tv\u00e4rbanans sp\u00e5r vid Alviks strand i Stockholm. \u201dV\u00e5r ambassad ber om urs\u00e4kt f\u00f6r olyckan och besv\u00e4ren den orsakat. Vi har startat en internutredning f\u00f6r att ta reda p\u00e5 hur olyckan ska ha skett\u201d, skriver Etiopiens ambassad i Stockholm i ett mail till Aftonbladet. I \u00f6vrigt har de inte kommenterat h\u00e4ndelsen och n\u00e4r Aftonbladet knackar p\u00e5 hos ambassaden \u00e4r svaret kort. \u2013 Vi h\u00e5ller p\u00e5 att jobba med det. Vi \u00e5terkommer s\u00e5 fort det g\u00e5r, s\u00e4ger en anst\u00e4lld p\u00e5 ambassaden. Men n\u00e4r vill de inte svara p\u00e5. 17 300 kronor i obetalda b\u00f6ter T\u00e5gtrafiken var tillf\u00e4lligt avst\u00e4ngd under s\u00f6ndagsmorgonen och bilen fick b\u00e4rgas med hj\u00e4lp av en sp\u00e5rtraktor. Den har troligtvis k\u00f6rt upp p\u00e5 sp\u00e5ret vid Gr\u00f6ndal, enligt SL. D\u00e4r k\u00f6r bilar och sp\u00e5rvagnar p\u00e5 gatan innan r\u00e4lsen viker av p\u00e5 en egen banvall. \u2013 D\u00e4refter ska den i s\u00e5 fall ha k\u00f6rt tv\u00e5 kilometer p\u00e5 kross och makadam innan den krockat med en stolpe, s\u00e4ger Claes Keisu, pressansvarig p\u00e5 SL. Minibussen har ocks\u00e5 obetalda b\u00f6ter p\u00e5 17\u00a0300 kronor, enligt Transportstyrelsen.  \u201dHar skett en g\u00e5ng tidigare\u201d Den h\u00e4r typen av felk\u00f6rning sker cirka tio g\u00e5nger om \u00e5ret. Under februari skedde det tv\u00e5 g\u00e5nger, just vid Gr\u00f6ndal. Vanligtvis uppt\u00e4cks misstaget tidigt och d\u00e5 brukar f\u00f6raren kunna backa tillbaka p\u00e5 v\u00e4gen. \u2013 Det h\u00e4r fordonet har lite h\u00f6gre markfrig\u00e5ng s\u00e5 det kan f\u00f6rklara att den kunnat ta sig l\u00e4ngre, s\u00e4ger Claes Keisu. Men att bilen lyckats ta sig s\u00e5 l\u00e5ngt \u00e4r v\u00e4ldigt ovanligt. \u2013 Vad vi vet har det bara skett en g\u00e5ng tidigare. 2012 var det en \u00c5l\u00e4nning med sin familj som kom upp p\u00e5 banan i Hammarby sj\u00f6stad och k\u00f6rde hela v\u00e4gen till Gullmarsplan, s\u00e4ger Keisu. F\u00f6raren ska d\u00e5 ha k\u00f6rt uppemot en kilometer p\u00e5 sp\u00e5ret. \u201dVi unders\u00f6ker immunitetsfr\u00e5gan\u201d Polisen har inlett en f\u00f6runders\u00f6kning om v\u00e5rdsl\u00f6shet i trafik. Det \u00e4r fortfarande oklart om n\u00e5gon kan \u00e5talas.  \u2013 Vi unders\u00f6ker immunitetsfr\u00e5gan, s\u00e4ger Nadya Norton, presstalesperson vid Stockholmspolisen. \u201dUtredningen f\u00e5r visa om personen som k\u00f6rde bilen hade immunitet eller inte. Om en person har immunitet kan denne inte lagf\u00f6ras i Sverige\u201d, skriver f\u00f6runders\u00f6kningsledaren, Timmy Malmgren, i ett mail till Aftonbladet. Diplomater f\u00e5r inte straffas i landet de arbetar i, enligt internationella \u00f6verrenskommelser. \u2013 Jag har inga uppgifter om n\u00e5gon \u00e4r misst\u00e4nkt i \u00e4rendet, s\u00e4ger Nadya Norton. Hade fest under kv\u00e4llen Kv\u00e4llen innan bilen hittades p\u00e5 t\u00e5gsp\u00e5ret ska Ambassaden anordnat en fest i sina lokaler. \u201dVi p\u00e5 Ambassaden f\u00f6r Demokratiska f\u00f6rbundsrepubliken Etiopien p\u00e5 v\u00e5ning 3 kommer att ha ett event p\u00e5 l\u00f6rdag den 2. Observera att vi kommer ha g\u00e4ster. Vi hoppas att vi inte st\u00f6r er, k\u00e4ra grannar. Tack f\u00f6r er f\u00f6rst\u00e5else\u201d, skriver de p\u00e5 en lapp som sitter i fastighetens hiss.\",\n  \"target_text\": \"En bil fr\u00e5n Etiopiens ambassad l\u00e4mnades \u00f6vergiven p\u00e5 ett t\u00e5gsp\u00e5r i centrala Stockholm under helgen, vilket ledde till tillf\u00e4lligt avst\u00e4ngd t\u00e5gtrafik. Ambassaden har bett om urs\u00e4kt och p\u00e5b\u00f6rjat en intern utredning f\u00f6r att ta reda p\u00e5 h\u00e4ndelsef\u00f6rloppet. En polisutredning \u00e4r ig\u00e5ng f\u00f6r v\u00e5rdsl\u00f6shet i trafik, men det \u00e4r oklart om n\u00e5gon kan \u00e5talas p\u00e5 grund av diplomatisk immunitet.\"\n}\n</code></pre></p> <p>When evaluating generative models, we use the following setup (see the methodology for more information on how these are used):</p> <ul> <li>Number of few-shot examples: 1</li> <li>Prefix prompt:   <pre><code>Nedan f\u00f6ljer artiklar med tillh\u00f6rande sammanfattningar.\n</code></pre></li> <li>Base prompt template:   <pre><code>Artikel: {text}\nSammanfattning: {target_text}\n</code></pre></li> <li>Instruction-tuned prompt template:   <pre><code>Artikel: {text}\n\nSkriv en sammanfattning av artikeln ovan.\n</code></pre></li> </ul> <p>You can evaluate this dataset directly as follows:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --dataset schibsted-sv\n</code></pre>"},{"location":"extras/radial_plotter/","title":"Radial Plot","text":"<p>This tool can be used to compare individual models across each task in the benchmark, using a so-called radial plot (also known as a spider plot). You can access the underlying Hugging Face Space here.</p> <p> </p> <p></p>"},{"location":"leaderboards/","title":"Leaderboards","text":"<p>\ud83d\udc48 Choose a leaderboard on the left to see the results.</p>"},{"location":"leaderboards/#types-of-leaderboards","title":"\ud83c\udff7\ufe0f Types of Leaderboards","text":"<p>Each language has two leaderboards:</p> <ul> <li>Generative Leaderboard: This leaderboard shows the performance of models that can   generate text. These models have been evaluated on all tasks, both NLU and   NLG.</li> <li>NLU Leaderboard: This leaderboard shows the performance of models that can only   understand text, and not generate text themselves. These models have been evaluated on   the NLU tasks only.</li> </ul>"},{"location":"leaderboards/#how-to-read-the-leaderboards","title":"\ud83d\udcca How to Read the Leaderboards","text":"<p>The main score column is the <code>Rank</code>, showing the mean rank score of the model across all the tasks in the leaderboard. The lower the rank, the better the model.</p> <p>The columns that follow the rank columns are metadata about the model:</p> <ul> <li><code>Parameters</code>: The total number of parameters in the model, in millions.</li> <li><code>Vocabulary</code>: The size of the model's vocabulary, in thousands.</li> <li><code>Context</code>: The maximum number of tokens that the model can process at a time.</li> <li><code>Speed</code>: The inference time of the model - see more here.</li> <li><code>Type</code>: The type of model:<ul> <li>\ud83d\udd0d indicates that it is an encoder model (e.g., BERT)</li> <li>\ud83e\udde0 indicates that it is a base generative model (e.g., GPT-2)</li> <li>\ud83d\udcdd indicates that it is an instruction-tuned model (e.g., ChatGPT)</li> <li>\ud83e\udd14 indicates that it is a reasoning model (e.g., o1)</li> </ul> </li> <li><code>Commercial</code>: Whether the model can be used for commercial purposes. See here   for more information.</li> <li><code>Merge</code>: Whether the model is a merge of other models.</li> </ul> <p>After these metadata columns, the individual scores for each dataset is shown. Each dataset has a primary and secondary score - see what these are on the task page. Lastly, the final columns show the EuroEval version used to benchmark the given model on each of the datasets.</p> <p>To read more about the individual datasets, see the datasets page. If you're interested in the methodology behind the benchmark, see the methodology page.</p> Generative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/danish/","title":"\ud83c\udde9\ud83c\uddf0 Danish","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/dutch/","title":"\ud83c\uddf3\ud83c\uddf1 Dutch","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/english/","title":"\ud83c\uddec\ud83c\udde7 English","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/faroese/","title":"\ud83c\uddeb\ud83c\uddf4 Faroese","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardNLU Scatter Plot <p>   A generative leaderboard for Faroese is not available yet, as the necessary datasets   are not yet available. </p>"},{"location":"leaderboards/Monolingual/finnish/","title":"\ud83c\uddeb\ud83c\uddee Finnish","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/french/","title":"\ud83c\uddeb\ud83c\uddf7 French","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/german/","title":"\ud83c\udde9\ud83c\uddea German","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/icelandic/","title":"\ud83c\uddee\ud83c\uddf8 Icelandic","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/italian/","title":"\ud83c\uddee\ud83c\uddf9 Italian","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/norwegian/","title":"\ud83c\uddf3\ud83c\uddf4 Norwegian","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/portuguese/","title":"\ud83c\uddf5\ud83c\uddf9 Portuguese","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/spanish/","title":"\ud83c\uddea\ud83c\uddf8 Spanish","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Monolingual/swedish/","title":"\ud83c\uddf8\ud83c\uddea Swedish","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Multilingual/european/","title":"\ud83c\uddea\ud83c\uddfa European","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Multilingual/germanic/","title":"\ud83c\udde9\ud83c\uddf0\ud83c\uddf3\ud83c\uddf1\ud83c\uddec\ud83c\udde7\ud83c\uddeb\ud83c\uddf4\ud83c\udde9\ud83c\uddea\ud83c\uddee\ud83c\uddf8\ud83c\uddf3\ud83c\uddf4\ud83c\uddf8\ud83c\uddea Germanic","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Multilingual/mainland-scandinavian/","title":"\ud83c\udde9\ud83c\uddf0\ud83c\uddf3\ud83c\uddf4\ud83c\uddf8\ud83c\uddea Mainland Scandinavian","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"leaderboards/Multilingual/romance/","title":"\ud83c\uddeb\ud83c\uddf7\ud83c\uddee\ud83c\uddf9\ud83c\uddea\ud83c\uddf8 Romance","text":"<p>See the leaderboard page for more information about all the columns.</p> Generative LeaderboardNLU LeaderboardGenerative Scatter PlotNLU Scatter Plot"},{"location":"tasks/","title":"Tasks","text":"<p>\ud83d\udc48 Choose a task on the left to see detailed information about that task.</p>"},{"location":"tasks/#overview","title":"\ud83d\udcda Overview","text":"<p>This page covers all the evaluation tasks used in EuroEval. These tasks fall under two categories, corresponding to whether the models should merely understand the input documents (NLU), or rather they are also required to generate new text (NLG).</p>"},{"location":"tasks/#nlu-tasks","title":"NLU Tasks","text":"<p>NLU tasks are tasks where the model is required to understand the natural language input and provide an output based on this understanding. The outputs are typically very short, often just a single label or a couple of words. The performance on these tasks is thus relevant to you if you primarily aim to use the language models for processing documents rather than generating entirely new documents. Both encoder and decoder models can be evaluated on these tasks, enabling you to compare the performance across all language models out there. The tasks in this category are:</p> <ol> <li>Sentiment Classification</li> <li>Named Entity Recognition</li> <li>Linguistic Acceptability</li> <li>Reading Comprehension</li> </ol>"},{"location":"tasks/#nlg-tasks","title":"NLG Tasks","text":"<p>NLG tasks are tasks where the model is required to generate natural language output based on some input. The outputs are typically longer than in NLU tasks, often multiple paragraphs. The performance on these tasks is thus relevant to you if you aim to use the language models for generating new documents. Only decoder models can be evaluated on these tasks, as encoder models do not have the capability to generate text. The tasks in this category are:</p> <ol> <li>Summarization</li> <li>Knowledge \uff0a</li> <li>Common-sense Reasoning \uff0a</li> </ol> <p>\uff0a These tasks should be considered as NLU tasks, but currently encoder models have not been set up to be evaluated on them. This will be added in a future version of EuroEval - see the progress in this issue.</p>"},{"location":"tasks/common-sense-reasoning/","title":"Common-sense Reasoning","text":""},{"location":"tasks/common-sense-reasoning/#overview","title":"\ud83d\udcda Overview","text":"<p>Common-sense reasoning is testing whether a model is able to understand basic deduction about the world. For instance, if the model is given the statement \"It is raining outside, and Peter is in his garden without an umbrella\", it should be able to deduce that Peter is getting wet. The task is set up as a multiple-choice question answering task, where the model is given a question and a set of possible answers, and it has to choose the correct answer.</p> <p>When evaluating generative models, we allow the model to generate 5 tokens on this task.</p>"},{"location":"tasks/common-sense-reasoning/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric we use when evaluating the performance of a model on the common-sense reasoning task, we use Matthews correlation coefficient (MCC), which has a value between -100% and +100%, where 0% reflects a random guess. The primary benefit of MCC is that it is balanced even if the classes are imbalanced.</p> <p>We also report the accuracy score, as this is the most common metric used for this task, enabling comparisons with other benchmarks.</p>"},{"location":"tasks/common-sense-reasoning/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the common-sense reasoning task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task common-sense-reasoning\n</code></pre>"},{"location":"tasks/knowledge/","title":"Knowledge","text":""},{"location":"tasks/knowledge/#overview","title":"\ud83d\udcda Overview","text":"<p>The knowledge task is testing how much factual knowledge a model has. The task is set up as a multiple-choice question answering task, where the model is given a question and a set of possible answers, and it has to choose the correct answer. Crucially, it is not given any context in which the answer appears, so it has to answer purely based on its knowledge of the world.</p> <p>When evaluating generative models, we allow the model to generate 5 tokens on this task.</p>"},{"location":"tasks/knowledge/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric we use when evaluating the performance of a model on the knowledge task, we use Matthews correlation coefficient (MCC), which has a value between -100% and +100%, where 0% reflects a random guess. The primary benefit of MCC is that it is balanced even if the classes are imbalanced.</p> <p>We also report the accuracy score, as this is the most common metric used for this task, enabling comparisons with other benchmarks.</p>"},{"location":"tasks/knowledge/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the knowledge task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task knowledge\n</code></pre>"},{"location":"tasks/linguistic-acceptability/","title":"Linguistic Acceptability","text":""},{"location":"tasks/linguistic-acceptability/#overview","title":"\ud83d\udcda Overview","text":"<p>Linguistic acceptability is a task of determining whether a given text is grammatically correct or not. It thus tests whether the model is able to understand the detailed syntax of a given document, and not just understand the overall gist of it. It roughly corresponds to when a native speaker would say \"this sentence sounds weird\".</p> <p>When evaluating generative models, we allow the model to generate 5 tokens on this task.</p>"},{"location":"tasks/linguistic-acceptability/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric we use when evaluating the performance of a model on the linguistic acceptability task, we use Matthews correlation coefficient (MCC), which has a value between -100% and +100%, where 0% reflects a random guess. The primary benefit of MCC is that it is balanced even if the classes are imbalanced.</p> <p>We also report the macro-average F1-score, being the average of the F1-score for each class, thus again weighing each class equally.</p>"},{"location":"tasks/linguistic-acceptability/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the linguistic acceptability task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task linguistic-acceptability\n</code></pre>"},{"location":"tasks/named-entity-recognition/","title":"Named Entity Recognition","text":""},{"location":"tasks/named-entity-recognition/#overview","title":"\ud83d\udcda Overview","text":"<p>Named entity recognition is a task of determining the named entities in a given text, such as named of persons, organisations, or locations. It thus both tests the knowledge the model has about these things, as well as being able to extract multiple pieces of information from a document at once.</p> <p>When evaluating generative models, we allow the model to generate 128 tokens on this task.</p>"},{"location":"tasks/named-entity-recognition/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric we use when evaluating the performance of a model on the named entity recognition task, we use the micro-average F1-score without MISC, computed as the total number of true positives for all (non-trivial) entities except <code>MISC</code>, divided by the total number of predicted positives for all entities except <code>MISC</code>.</p> <p>We also report the micro-average F1-score, computed the same way, but where we include the <code>MISC</code> entity as well. This is useful for comparing with other benchmarks, as it is the most common metric used for this task. We find that excluding <code>MISC</code> gives a more accurate picture of the model's performance, however, as the the <code>MISC</code> entity is not well-defined and varies across datasets.</p>"},{"location":"tasks/named-entity-recognition/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the named entity recognition task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task named-entity-recognition\n</code></pre>"},{"location":"tasks/reading-comprehension/","title":"Reading Comprehension","text":""},{"location":"tasks/reading-comprehension/#overview","title":"\ud83d\udcda Overview","text":"<p>Reading comprehension is a task of determining whether a model is able to understand a given text and answer questions about it. The model receives a text passage and a question about the text, and it has to provide the answer as it is stated in the text. This is very related to Retrieval-augmented Generation (RAG) applications, where a generative model is used to answer a question based on one or more retrieved documents.</p> <p>When evaluating generative models, we allow the model to generate 32 tokens on this task.</p>"},{"location":"tasks/reading-comprehension/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric we use when evaluating the performance of a model on the reading comprehension task is the exact match (EM) score, which is the percentage of questions for which the model provides the exact answer.</p> <p>We also report the F1-score on a character-basis, which is more lenient than the EM score, as it allows for small differences in the answer.</p>"},{"location":"tasks/reading-comprehension/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the reading comprehension task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task reading-comprehension\n</code></pre>"},{"location":"tasks/sentiment-classification/","title":"Sentiment Classification","text":""},{"location":"tasks/sentiment-classification/#overview","title":"\ud83d\udcda Overview","text":"<p>Sentiment classification is a classical task of determining the sentiment of a given text, which can be positive, negative, or neutral. It thus tests whether the model is able to understand the overall semantics of a given document.</p> <p>When evaluating generative models, we allow the model to generate 5 tokens on this task.</p>"},{"location":"tasks/sentiment-classification/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric we use when evaluating the performance of a model on the sentiment classification task, we use Matthews correlation coefficient (MCC), which has a value between -100% and +100%, where 0% reflects a random guess. The primary benefit of MCC is that it is balanced even if the classes are imbalanced.</p> <p>We also report the macro-average F1-score, being the average of the F1-score for each class, thus again weighing each class equally.</p>"},{"location":"tasks/sentiment-classification/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the sentiment classification task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task sentiment-classification\n</code></pre>"},{"location":"tasks/speed/","title":"Speed","text":""},{"location":"tasks/speed/#overview","title":"\ud83d\udcda Overview","text":"<p>Speed is a task of measuring how quickly a model can process a given input. The model receives text passages of varying lengths, and it has to process the documents as quickly as possible, which includes tokenisation of the input. We let the model process the input repeatedly for 3 seconds, and then we measure how quick it was. We use the <code>pyinfer</code> package to perform the speed measurement.</p> <p>The speed is of course very dependent on available hardware, and for APIs it also fluctuates depending on the number of requests in the queue, so the speed benchmark should be taken as only a rough estimate of the model's speed, rather than an exact measurement.</p>"},{"location":"tasks/speed/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric used to evaluate the performance of a model on the speed task is the average number of GPT-2 tokens processed per second on GPUs, when the model is processing documents with roughly 100, 200, ..., 1,000 tokens. If the model is only accessible through an API then the speed is measured on the API. The GPUs used here vary, depending on the size of the model - we preferably use an NVIDIA RTX 3090 Ti GPU, if the model has less than ~8B parameters, and one or more NVIDIA A100 GPUs is larger.</p> <p>The secondary metric is the same, but where the documents are shorter, with roughly 12.5, 15, ..., 125 tokens.</p>"},{"location":"tasks/speed/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the speed task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task speed\n</code></pre>"},{"location":"tasks/summarization/","title":"Summarization","text":""},{"location":"tasks/summarization/#overview","title":"\ud83d\udcda Overview","text":"<p>Summarization is a task of generating a shorter version of a given text, while preserving the main points of the original text. The model receives a long text and has to generate a shorter version of it, typically a handful of sentences long. This is abstractive summarization, meaning that the summary typically do not appear verbatim in the original text, but that the model has to generate new text based on the input.</p> <p>When evaluating generative models, we allow the model to generate 256 tokens on this task.</p>"},{"location":"tasks/summarization/#metrics","title":"\ud83d\udcca Metrics","text":"<p>The primary metric used to evaluate the performance of a model on the summarization task is the BERTScore, which uses a pretrained encoder model to encode each token in both the reference summary and the generated summary, and then uses cosine similarity to measure how the tokens match up. Using an encoder model allows for the model to phrase a summary differently than the reference, while still being rewarded for capturing the same meaning. We use the <code>microsoft/mdeberta-v3-base</code> encoder model for all languages, as it is the best performing encoder model consistently across all languages in the framework.</p> <p>We also report the ROUGE-L score, which measures the longest sequence of words that the generated summary and the reference summary have in common. This is a more traditional metric for summarization, which is why we report it as well, but it correlates less well with human judgments than BERTScore.</p>"},{"location":"tasks/summarization/#how-to-run","title":"\ud83d\udee0\ufe0f How to run","text":"<p>In the command line interface of the EuroEval Python package, you can benchmark your favorite model on the summarization task like so:</p> <pre><code>$ euroeval --model &lt;model-id&gt; --task summarization\n</code></pre>"},{"location":"api/euroeval/","title":"euroeval","text":"euroeval<p> source package euroeval </p> <p>EuroEval - A benchmarking framework for language models.</p> <p> Classes </p> <ul> <li> <p>Benchmarker \u2014 Benchmarking all the language models.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>block_terminal_output \u2014 Blocks libraries from writing output to the terminal.</p> </li> </ul> <p> source class Benchmarker(progress_bar: bool = True, save_results: bool = True, task: str | list[str] | None = None, dataset: list[str] | str | None = None, language: str | list[str] = 'all', model_language: str | list[str] | None = None, dataset_language: str | list[str] | None = None, device: Device | None = None, batch_size: int = 32, raise_errors: bool = False, cache_dir: str = '.euroeval_cache', api_key: str | None = None, force: bool = False, verbose: bool = False, trust_remote_code: bool = False, clear_model_cache: bool = False, evaluate_test_split: bool = False, few_shot: bool = True, num_iterations: int = 10, api_base: str | None = None, api_version: str | None = None, gpu_memory_utilization: float = 0.9, debug: bool = False, run_with_cli: bool = False, requires_safetensors: bool = False) </p> <p>Benchmarking all the language models.</p> <p>Initialise the benchmarker.</p> <p> Attributes </p> <ul> <li> <p>benchmark_config_default_params \u2014 The default parameters for the benchmark configuration.</p> </li> <li> <p>benchmark_config \u2014 The benchmark configuration.</p> </li> <li> <p>force \u2014 Whether to force evaluations of models, even if they have been benchmarked already.</p> </li> <li> <p>results_path \u2014 The path to the results file.</p> </li> <li> <p>benchmark_results :  list[BenchmarkResult] \u2014 The benchmark results.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>progress_bar :  bool \u2014 Whether progress bars should be shown. Defaults to True.</p> </li> <li> <p>save_results :  bool \u2014 Whether to save the benchmark results to 'euroeval_benchmark_results.jsonl'. Defaults to True.</p> </li> <li> <p>task :  str | list[str] | None \u2014 The tasks benchmark the model(s) on. Mutually exclusive with <code>dataset</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked.</p> </li> <li> <p>dataset :  list[str] | str | None \u2014 The datasets to benchmark on. Mutually exclusive with <code>task</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked.</p> </li> <li> <p>language :  str | list[str] \u2014 The language codes of the languages to include, both for models and datasets. Set this to 'all' if all languages should be considered. Defaults to \"all\".</p> </li> <li> <p>model_language :  str | list[str] | None \u2014 The language codes of the languages to include for models. If specified then this overrides the <code>language</code> parameter for model languages. Defaults to None.</p> </li> <li> <p>dataset_language :  str | list[str] | None \u2014 The language codes of the languages to include for datasets. If specified then this overrides the <code>language</code> parameter for dataset languages. Defaults to None.</p> </li> <li> <p>device :  Device | None \u2014 The device to use for benchmarking. Defaults to None.</p> </li> <li> <p>batch_size :  int \u2014 The batch size to use. Defaults to 32.</p> </li> <li> <p>raise_errors :  bool \u2014 Whether to raise errors instead of skipping the model evaluation. Defaults to False.</p> </li> <li> <p>cache_dir :  str \u2014 Directory to store cached models. Defaults to '.euroeval_cache'.</p> </li> <li> <p>api_key :  str | None \u2014 The API key to use for a given inference API.</p> </li> <li> <p>force :  bool \u2014 Whether to force evaluations of models, even if they have been benchmarked already. Defaults to False.</p> </li> <li> <p>verbose :  bool \u2014 Whether to output additional output. This is automatically set if <code>debug</code> is True. Defaults to False.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code when loading models. Defaults to False.</p> </li> <li> <p>clear_model_cache :  bool \u2014 Whether to clear the model cache after benchmarking each model. Defaults to False.</p> </li> <li> <p>evaluate_test_split :  bool \u2014 Whether to evaluate the test split of the datasets. Defaults to False.</p> </li> <li> <p>few_shot :  bool \u2014 Whether to only evaluate the model using few-shot evaluation. Only relevant if the model is generative. Defaults to True.</p> </li> <li> <p>num_iterations :  int \u2014 The number of times each model should be evaluated. This is only meant to be used for power users, and scores will not be allowed on the leaderboards if this is changed. Defaults to 10.</p> </li> <li> <p>api_base :  str | None \u2014 The base URL for a given inference API. Only relevant if <code>model</code> refers to a model on an inference API. Defaults to None.</p> </li> <li> <p>api_version :  str | None \u2014 The version of the API to use. Defaults to None.</p> </li> <li> <p>gpu_memory_utilization :  float \u2014 The GPU memory utilization to use for vLLM. Only relevant if the model is generative. A larger value will result in faster evaluation, but at the risk of running out of GPU memory. Only reduce this if you are running out of GPU memory. Defaults to 0.9.</p> </li> <li> <p>debug :  bool \u2014 Whether to output debug information. Defaults to False.</p> </li> <li> <p>run_with_cli :  bool \u2014 Whether the benchmarker is being run from the command-line interface. Defaults to False.</p> </li> <li> <p>requires_safetensors :  bool \u2014 Whether to only allow models that use the safetensors format. Defaults to False.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError \u2014 If both <code>task</code> and <code>dataset</code> are specified.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>benchmark \u2014 Benchmarks models on datasets.</p> </li> </ul> <p> source property Benchmarker.benchmark_results: list[BenchmarkResult] </p> <p>The benchmark results.</p> <p> source method Benchmarker.benchmark(model: list[str] | str, task: str | list[str] | None = None, dataset: list[str] | str | None = None, progress_bar: bool | None = None, save_results: bool | None = None, language: str | list[str] | None = None, model_language: str | list[str] | None = None, dataset_language: str | list[str] | None = None, device: Device | None = None, batch_size: int | None = None, raise_errors: bool | None = None, cache_dir: str | None = None, api_key: str | None = None, force: bool | None = None, verbose: bool | None = None, trust_remote_code: bool | None = None, clear_model_cache: bool | None = None, evaluate_test_split: bool | None = None, few_shot: bool | None = None, num_iterations: int | None = None, requires_safetensors: bool | None = None) \u2192 list[BenchmarkResult] </p> <p>Benchmarks models on datasets.</p> <p> Parameters </p> <ul> <li> <p>model :  list[str] | str \u2014 The full Hugging Face Hub path(s) to the pretrained transformer model. The specific model version to use can be added after the suffix '@': \"model@v1.0.0\". It can be a branch name, a tag name, or a commit id, and defaults to the latest version if not specified.</p> </li> <li> <p>task :  str | list[str] | None \u2014 The tasks benchmark the model(s) on. Mutually exclusive with <code>dataset</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked. Defaults to None.</p> </li> <li> <p>dataset :  list[str] | str | None \u2014 The datasets to benchmark on. Mutually exclusive with <code>task</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked. Defaults to None.</p> </li> <li> <p>progress_bar :  bool | None \u2014 Whether progress bars should be shown. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>save_results :  bool | None \u2014 Whether to save the benchmark results to 'euroeval_benchmark_results.jsonl'. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>language :  str | list[str] | None \u2014 The language codes of the languages to include, both for models and datasets. Here 'no' means both Bokm\u00e5l (nb) and Nynorsk (nn). Set this to 'all' if all languages should be considered. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>model_language :  str | list[str] | None \u2014 The language codes of the languages to include for models. If specified then this overrides the <code>language</code> parameter for model languages. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>dataset_language :  str | list[str] | None \u2014 The language codes of the languages to include for datasets. If specified then this overrides the <code>language</code> parameter for dataset languages. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>device :  Device | None \u2014 The device to use for benchmarking. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>batch_size :  int | None \u2014 The batch size to use. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>raise_errors :  bool | None \u2014 Whether to raise errors instead of skipping the model evaluation.</p> </li> <li> <p>cache_dir :  str | None \u2014 Directory to store cached models. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>api_key :  str | None \u2014 The API key to use for a given inference server. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>force :  bool | None \u2014 Whether to force evaluations of models, even if they have been benchmarked already. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>verbose :  bool | None \u2014 Whether to output additional output. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>trust_remote_code :  bool | None \u2014 Whether to trust remote code when loading models. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>clear_model_cache :  bool | None \u2014 Whether to clear the model cache after benchmarking each model. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>evaluate_test_split :  bool | None \u2014 Whether to evaluate the test split of the datasets. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>few_shot :  bool | None \u2014 Whether to only evaluate the model using few-shot evaluation. Only relevant if the model is generative. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>num_iterations :  int | None \u2014 The number of times each model should be evaluated. This is only meant to be used for power users, and scores will not be allowed on the leaderboards if this is changed. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>requires_safetensors :  bool | None \u2014 Whether to only allow models that use the safetensors format. Defaults to the value specified when initialising the benchmarker.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[BenchmarkResult] \u2014 A list of benchmark results.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError \u2014 If both <code>task</code> and <code>dataset</code> are specified.</p> </li> <li> <p>benchmark_output_or_err</p> </li> <li> <p>e</p> </li> </ul> <p> source block_terminal_output() \u2192 None </p> <p>Blocks libraries from writing output to the terminal.</p> <p>This filters warnings from some libraries, sets the logging level to ERROR for some libraries, disabled tokeniser progress bars when using Hugging Face tokenisers, and disables most of the logging from the <code>transformers</code> library.</p>"},{"location":"api/euroeval/benchmark_modules/","title":"euroeval.benchmark_modules","text":"euroeval.benchmark_modules<p> source package euroeval.benchmark_modules </p> <p>The different types of modules that can be benchmarked.</p> <p> Classes </p> <ul> <li> <p>BenchmarkModule \u2014 Abstract class for a benchmark module.</p> </li> <li> <p>FreshEncoderModel \u2014 A freshly initialised encoder model.</p> </li> <li> <p>HuggingFaceEncoderModel \u2014 An encoder model from the Hugging Face Hub.</p> </li> <li> <p>LiteLLMModel \u2014 A generative model from LiteLLM.</p> </li> <li> <p>VLLMModel \u2014 A generative model using the vLLM inference framework.</p> </li> </ul> <p> source class BenchmarkModule(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : ABC</p> <p>Abstract class for a benchmark module.</p> <p>Initialise the benchmark module.</p> <p> Attributes </p> <ul> <li> <p>model_config \u2014 The model configuration.</p> </li> <li> <p>dataset_config \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config \u2014 The benchmark configuration.</p> </li> <li> <p>buffer :  dict[str, t.Any] \u2014 A buffer to store temporary data.</p> </li> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the metadata of the model.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>get_pytorch_module \u2014 Get the underlying PyTorch module.</p> </li> <li> <p>get_tokeniser \u2014 Get the underlying tokeniser.</p> </li> <li> <p>prepare_datasets \u2014 Prepare the datasets for the model.</p> </li> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>generate \u2014 Generate outputs from the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source method BenchmarkModule.get_pytorch_module() \u2192 nn.Module </p> <p>Get the underlying PyTorch module.</p> <p> Returns </p> <ul> <li> <p>nn.Module \u2014 The PyTorch module.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> </ul> <p> source method BenchmarkModule.get_tokeniser() \u2192 PreTrainedTokenizer </p> <p>Get the underlying tokeniser.</p> <p> Returns </p> <ul> <li> <p>PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> </ul> <p> source property BenchmarkModule.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property BenchmarkModule.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if the model is not generative.</p> </li> </ul> <p> source property BenchmarkModule.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property BenchmarkModule.model_max_length: int </p> <p>The maximum length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum length of the model.</p> </li> </ul> <p> source property BenchmarkModule.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property BenchmarkModule.compute_metrics: ComputeMetricsFunction </p> <p>The function used to compute the metrics.</p> <p> Returns </p> <ul> <li> <p>ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> </ul> <p> source property BenchmarkModule.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source property BenchmarkModule.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source method BenchmarkModule.prepare_datasets(datasets: list[DatasetDict], task: Task) \u2192 list[DatasetDict] </p> <p>Prepare the datasets for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>datasets :  list[DatasetDict] \u2014 The datasets to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the datasets for.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[DatasetDict] \u2014 The prepared datasets.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the dataset does not have a 'train' split for token classification tasks.</p> </li> </ul> <p> source method BenchmarkModule.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> source method BenchmarkModule.generate(inputs: dict) \u2192 GenerativeModelOutput </p> <p>Generate outputs from the model.</p> <p> Parameters </p> <ul> <li> <p>inputs :  dict \u2014 A batch of inputs to pass through the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The generated model outputs.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> </ul> <p> source classmethod BenchmarkModule.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod BenchmarkModule.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> source class FreshEncoderModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : HuggingFaceEncoderModel</p> <p>A freshly initialised encoder model.</p> <p>Initialise the model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log metadata about the model and the benchmark.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source property FreshEncoderModel.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property FreshEncoderModel.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property FreshEncoderModel.model_max_length: int </p> <p>The maximum context length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum context length of the model.</p> </li> </ul> <p> source classmethod FreshEncoderModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod FreshEncoderModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> source class HuggingFaceEncoderModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : BenchmarkModule</p> <p>An encoder model from the Hugging Face Hub.</p> <p>Initialise the model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the model metadata.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.model_max_length: int </p> <p>The maximum context length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum context length of the model.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if it has not been set yet.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source method HuggingFaceEncoderModel.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source classmethod HuggingFaceEncoderModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod HuggingFaceEncoderModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul> <p> source class LiteLLMModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True, **generation_kwargs: dict[str, t.Any]) </p> <p>Bases : BenchmarkModule</p> <p>A generative model from LiteLLM.</p> <p>Initialise the model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the model metadata.</p> </li> <li> <p>generation_kwargs :  dict[str, t.Any] \u2014 The generation kwargs to pass to the model. If None, default values will be used.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>generate \u2014 Generate outputs from the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>get_generation_kwargs \u2014 Get the generation arguments for the model.</p> </li> </ul> <p> source property LiteLLMModel.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if it has not been set yet.</p> </li> </ul> <p> source method LiteLLMModel.generate(inputs: dict) \u2192 GenerativeModelOutput </p> <p>Generate outputs from the model.</p> <p> Parameters </p> <ul> <li> <p>inputs :  dict \u2014 A batch of inputs to pass through the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The generated model outputs.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source property LiteLLMModel.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property LiteLLMModel.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property LiteLLMModel.model_max_length: int </p> <p>The maximum length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum length of the model.</p> </li> </ul> <p> source property LiteLLMModel.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property LiteLLMModel.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source property LiteLLMModel.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source classmethod LiteLLMModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>e</p> </li> </ul> <p> source classmethod LiteLLMModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> source method LiteLLMModel.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> source method LiteLLMModel.get_generation_kwargs(dataset_config: DatasetConfig) \u2192 dict[str, t.Any] </p> <p>Get the generation arguments for the model.</p> <p> Parameters </p> <ul> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration, which is used to determine the generative type of the model. We use this as an argument here rather than using <code>self.dataset_config</code> to ensure that that the cache is updated when the dataset configuration changes.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, t.Any] \u2014 The generation arguments for the model.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source class VLLMModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : HuggingFaceEncoderModel</p> <p>A generative model using the vLLM inference framework.</p> <p>Initialise the vLLM model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the model and dataset metadata.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>generate \u2014 Generate outputs from the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source property VLLMModel.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if it has not been set yet.</p> </li> </ul> <p> source property VLLMModel.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source method VLLMModel.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> source method VLLMModel.generate(inputs: dict) \u2192 GenerativeModelOutput </p> <p>Generate outputs from the model.</p> <p> Parameters </p> <ul> <li> <p>inputs :  dict \u2014 A batch of inputs to pass through the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The generated model outputs.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the dataset requires logprobs, but we could not get the first token of each label in the dataset.</p> </li> </ul> <p> source classmethod VLLMModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod VLLMModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul> <p> source property VLLMModel.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property VLLMModel.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul>"},{"location":"api/euroeval/benchmark_modules/base/","title":"euroeval.benchmark_modules.base","text":"euroeval.benchmark_modules.base<p> source module euroeval.benchmark_modules.base </p> <p>Abstract benchmark module class that the model classes inherit from.</p> <p> Classes </p> <ul> <li> <p>BenchmarkModule \u2014 Abstract class for a benchmark module.</p> </li> </ul> <p> source class BenchmarkModule(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : ABC</p> <p>Abstract class for a benchmark module.</p> <p>Initialise the benchmark module.</p> <p> Attributes </p> <ul> <li> <p>model_config \u2014 The model configuration.</p> </li> <li> <p>dataset_config \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config \u2014 The benchmark configuration.</p> </li> <li> <p>buffer :  dict[str, t.Any] \u2014 A buffer to store temporary data.</p> </li> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the metadata of the model.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>get_pytorch_module \u2014 Get the underlying PyTorch module.</p> </li> <li> <p>get_tokeniser \u2014 Get the underlying tokeniser.</p> </li> <li> <p>prepare_datasets \u2014 Prepare the datasets for the model.</p> </li> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>generate \u2014 Generate outputs from the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source method BenchmarkModule.get_pytorch_module() \u2192 nn.Module </p> <p>Get the underlying PyTorch module.</p> <p> Returns </p> <ul> <li> <p>nn.Module \u2014 The PyTorch module.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> </ul> <p> source method BenchmarkModule.get_tokeniser() \u2192 PreTrainedTokenizer </p> <p>Get the underlying tokeniser.</p> <p> Returns </p> <ul> <li> <p>PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> </ul> <p> source property BenchmarkModule.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property BenchmarkModule.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if the model is not generative.</p> </li> </ul> <p> source property BenchmarkModule.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property BenchmarkModule.model_max_length: int </p> <p>The maximum length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum length of the model.</p> </li> </ul> <p> source property BenchmarkModule.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property BenchmarkModule.compute_metrics: ComputeMetricsFunction </p> <p>The function used to compute the metrics.</p> <p> Returns </p> <ul> <li> <p>ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> </ul> <p> source property BenchmarkModule.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source property BenchmarkModule.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source method BenchmarkModule.prepare_datasets(datasets: list[DatasetDict], task: Task) \u2192 list[DatasetDict] </p> <p>Prepare the datasets for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>datasets :  list[DatasetDict] \u2014 The datasets to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the datasets for.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[DatasetDict] \u2014 The prepared datasets.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the dataset does not have a 'train' split for token classification tasks.</p> </li> </ul> <p> source method BenchmarkModule.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> source method BenchmarkModule.generate(inputs: dict) \u2192 GenerativeModelOutput </p> <p>Generate outputs from the model.</p> <p> Parameters </p> <ul> <li> <p>inputs :  dict \u2014 A batch of inputs to pass through the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The generated model outputs.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> </ul> <p> source classmethod BenchmarkModule.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod BenchmarkModule.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul>"},{"location":"api/euroeval/benchmark_modules/fresh/","title":"euroeval.benchmark_modules.fresh","text":"euroeval.benchmark_modules.fresh<p> source module euroeval.benchmark_modules.fresh </p> <p>Freshly initialised encoder models.</p> <p> Classes </p> <ul> <li> <p>FreshEncoderModel \u2014 A freshly initialised encoder model.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>load_model_and_tokeniser \u2014 Load the model and tokeniser.</p> </li> </ul> <p> source class FreshEncoderModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : HuggingFaceEncoderModel</p> <p>A freshly initialised encoder model.</p> <p>Initialise the model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log metadata about the model and the benchmark.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source property FreshEncoderModel.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property FreshEncoderModel.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property FreshEncoderModel.model_max_length: int </p> <p>The maximum context length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum context length of the model.</p> </li> </ul> <p> source classmethod FreshEncoderModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod FreshEncoderModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> source load_model_and_tokeniser(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, model_max_length: int) \u2192 tuple[PreTrainedModel, PreTrainedTokenizer] </p> <p>Load the model and tokeniser.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple[PreTrainedModel, PreTrainedTokenizer] \u2014 The loaded model and tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> <li> <p>InvalidModel</p> </li> </ul>"},{"location":"api/euroeval/benchmark_modules/hf/","title":"euroeval.benchmark_modules.hf","text":"euroeval.benchmark_modules.hf<p> source module euroeval.benchmark_modules.hf </p> <p>Encoder models from the Hugging Face Hub.</p> <p> Classes </p> <ul> <li> <p>HuggingFaceEncoderModel \u2014 An encoder model from the Hugging Face Hub.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>load_model_and_tokeniser \u2014 Load the model and tokeniser.</p> </li> <li> <p>get_model_repo_info \u2014 Get the information about the model from the HF Hub or a local directory.</p> </li> <li> <p>load_tokeniser \u2014 Load the tokeniser.</p> </li> <li> <p>get_dtype \u2014 Get the torch dtype, used for loading the model.</p> </li> <li> <p>load_hf_model_config \u2014 Load the Hugging Face model configuration.</p> </li> <li> <p>setup_model_for_question_answering \u2014 Setup a model for question answering.</p> </li> <li> <p>get_children_of_module \u2014 Get the children of a module.</p> </li> <li> <p>align_model_and_tokeniser \u2014 Aligns the model and the tokeniser.</p> </li> <li> <p>task_group_to_class_name \u2014 Convert a task group to a class name.</p> </li> </ul> <p> source class HuggingFaceEncoderModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : BenchmarkModule</p> <p>An encoder model from the Hugging Face Hub.</p> <p>Initialise the model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the model metadata.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.model_max_length: int </p> <p>The maximum context length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum context length of the model.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if it has not been set yet.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source property HuggingFaceEncoderModel.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source method HuggingFaceEncoderModel.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError</p> </li> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source classmethod HuggingFaceEncoderModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod HuggingFaceEncoderModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul> <p> source load_model_and_tokeniser(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 tuple['PreTrainedModel', 'PreTrainedTokenizer'] </p> <p>Load the model and tokeniser.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple['PreTrainedModel', 'PreTrainedTokenizer'] \u2014 The loaded model and tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> <li> <p>InvalidModel</p> </li> </ul> <p> source get_model_repo_info(model_id: str, revision: str, benchmark_config: BenchmarkConfig) \u2192 HFModelInfo | None </p> <p>Get the information about the model from the HF Hub or a local directory.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>revision :  str \u2014 The revision of the model.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>HFModelInfo | None \u2014 The information about the model, or None if the model could not be found.</p> </li> </ul> <p> source load_tokeniser(model: PreTrainedModel | None, model_id: str, trust_remote_code: bool) \u2192 PreTrainedTokenizer </p> <p>Load the tokeniser.</p> <p> Parameters </p> <ul> <li> <p>model :  PreTrainedModel | None \u2014 The model, which is used to determine whether to add a prefix space to the tokens. Can be None.</p> </li> <li> <p>model_id :  str \u2014 The model identifier. Used for logging.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>PreTrainedTokenizer \u2014 The loaded tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul> <p> source get_dtype(device: torch.device, dtype_is_set: bool, bf16_available: bool) \u2192 str | torch.dtype </p> <p>Get the torch dtype, used for loading the model.</p> <p> Parameters </p> <ul> <li> <p>device :  torch.device \u2014 The device to use. Whether the data type is set in the model configuration.</p> </li> <li> <p>bf16_available :  bool \u2014 Whether bfloat16 is available.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str | torch.dtype \u2014 The dtype.</p> </li> </ul> <p> source load_hf_model_config(model_id: str, num_labels: int, id2label: dict[int, str], label2id: dict[str, int], revision: str, model_cache_dir: str | None, api_key: str | None, trust_remote_code: bool, run_with_cli: bool) \u2192 PretrainedConfig </p> <p>Load the Hugging Face model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The Hugging Face model ID.</p> </li> <li> <p>num_labels :  int \u2014 The number of labels in the dataset.</p> </li> <li> <p>id2label :  dict[int, str] \u2014 The mapping from label IDs to labels.</p> </li> <li> <p>label2id :  dict[str, int] \u2014 The mapping from labels to label IDs.</p> </li> <li> <p>revision :  str \u2014 The revision of the model.</p> </li> <li> <p>model_cache_dir :  str | None \u2014 The directory to cache the model in.</p> </li> <li> <p>api_key :  str | None \u2014 The Hugging Face API key.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code.</p> </li> <li> <p>run_with_cli :  bool \u2014 Whether the script is being run with the CLI.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>PretrainedConfig \u2014 The Hugging Face model configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> <li> <p>NeedsAdditionalArgument</p> </li> </ul> <p> source setup_model_for_question_answering(model: PreTrainedModel) \u2192 PreTrainedModel </p> <p>Setup a model for question answering.</p> <p> Parameters </p> <ul> <li> <p>model :  PreTrainedModel \u2014 The model to setup.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>PreTrainedModel \u2014 The setup model.</p> </li> </ul> <p> source get_children_of_module(name: str, module: nn.Module) \u2192 nn.Module | dict[str, t.Any] | None </p> <p>Get the children of a module.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the module.</p> </li> <li> <p>module :  nn.Module \u2014 The module to get the children of.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>nn.Module | dict[str, t.Any] | None \u2014 The children of the module, or None if the module has no children.</p> </li> </ul> <p> source align_model_and_tokeniser(model: PreTrainedModel, tokeniser: PreTrainedTokenizer, model_max_length: int, raise_errors: bool = False) \u2192 tuple['PreTrainedModel', 'PreTrainedTokenizer'] </p> <p>Aligns the model and the tokeniser.</p> <p> Parameters </p> <ul> <li> <p>model :  PreTrainedModel \u2014 The model to fix.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser to fix.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum length of the model.</p> </li> <li> <p>raise_errors :  bool \u2014 Whether to raise errors instead of trying to fix them silently.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple['PreTrainedModel', 'PreTrainedTokenizer'] \u2014 The fixed model and tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> <li> <p>e</p> </li> </ul> <p> source task_group_to_class_name(task_group: TaskGroup) \u2192 str </p> <p>Convert a task group to a class name.</p> <p> Parameters </p> <ul> <li> <p>task_group :  TaskGroup \u2014 The task group.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str \u2014 The class name.</p> </li> </ul>"},{"location":"api/euroeval/benchmark_modules/litellm/","title":"euroeval.benchmark_modules.litellm","text":"euroeval.benchmark_modules.litellm<p> source module euroeval.benchmark_modules.litellm </p> <p>Generative models from an inference API, using the LiteLLM framework.</p> <p> Classes </p> <ul> <li> <p>LiteLLMModel \u2014 A generative model from LiteLLM.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>raise_if_wrong_params \u2014 Raise an error if the model configuration has invalid parameters.</p> </li> <li> <p>try_download_ollama_model \u2014 Try to download an Ollama model.</p> </li> </ul> <p> source class LiteLLMModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True, **generation_kwargs: dict[str, t.Any]) </p> <p>Bases : BenchmarkModule</p> <p>A generative model from LiteLLM.</p> <p>Initialise the model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the model metadata.</p> </li> <li> <p>generation_kwargs :  dict[str, t.Any] \u2014 The generation kwargs to pass to the model. If None, default values will be used.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>generate \u2014 Generate outputs from the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>get_generation_kwargs \u2014 Get the generation arguments for the model.</p> </li> </ul> <p> source property LiteLLMModel.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if it has not been set yet.</p> </li> </ul> <p> source method LiteLLMModel.generate(inputs: dict) \u2192 GenerativeModelOutput </p> <p>Generate outputs from the model.</p> <p> Parameters </p> <ul> <li> <p>inputs :  dict \u2014 A batch of inputs to pass through the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The generated model outputs.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source property LiteLLMModel.num_params: int </p> <p>The number of parameters in the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The number of parameters in the model.</p> </li> </ul> <p> source property LiteLLMModel.vocab_size: int </p> <p>The vocabulary size of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The vocabulary size of the model.</p> </li> </ul> <p> source property LiteLLMModel.model_max_length: int </p> <p>The maximum length of the model.</p> <p> Returns </p> <ul> <li> <p>int \u2014 The maximum length of the model.</p> </li> </ul> <p> source property LiteLLMModel.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property LiteLLMModel.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source property LiteLLMModel.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source classmethod LiteLLMModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>e</p> </li> </ul> <p> source classmethod LiteLLMModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> source method LiteLLMModel.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> source method LiteLLMModel.get_generation_kwargs(dataset_config: DatasetConfig) \u2192 dict[str, t.Any] </p> <p>Get the generation arguments for the model.</p> <p> Parameters </p> <ul> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration, which is used to determine the generative type of the model. We use this as an argument here rather than using <code>self.dataset_config</code> to ensure that that the cache is updated when the dataset configuration changes.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, t.Any] \u2014 The generation arguments for the model.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source raise_if_wrong_params(model_config: ModelConfig, allowed_params: dict[str, list[str]]) \u2192 None </p> <p>Raise an error if the model configuration has invalid parameters.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>allowed_params :  dict[str, list[str]] \u2014 The allowed parameters for the model.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel \u2014 If the model configuration has invalid parameters.</p> </li> </ul> <p> source try_download_ollama_model(model_id: str) \u2192 bool </p> <p>Try to download an Ollama model.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID. If the model does not start with \"ollama/\" or \"ollama_chat/\" then this function will return False.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool \u2014 Whether the model was downloaded successfully.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel \u2014 If Ollama is not running or the model cannot be downloaded.</p> </li> </ul>"},{"location":"api/euroeval/benchmark_modules/vllm/","title":"euroeval.benchmark_modules.vllm","text":"euroeval.benchmark_modules.vllm<p> source module euroeval.benchmark_modules.vllm </p> <p>Generative models using the vLLM inference framework.</p> <p> Classes </p> <ul> <li> <p>VLLMModel \u2014 A generative model using the vLLM inference framework.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>load_model_and_tokeniser \u2014 Load the model and tokeniser.</p> </li> <li> <p>load_tokeniser \u2014 Load the tokeniser.</p> </li> <li> <p>clear_vllm \u2014 Clear the GPU memory used by the vLLM model, enabling re-initialisation.</p> </li> <li> <p>get_end_of_reasoning_token \u2014 Get the end-of-reasoning token for a generative model.</p> </li> <li> <p>get_custom_stop_tokens \u2014 Get the stop tokens for a generative model.</p> </li> <li> <p>get_pbar_without_leave \u2014 Get a progress bar for vLLM which disappears after completion.</p> </li> </ul> <p> source class VLLMModel(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, log_metadata: bool = True) </p> <p>Bases : HuggingFaceEncoderModel</p> <p>A generative model using the vLLM inference framework.</p> <p>Initialise the vLLM model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log the model and dataset metadata.</p> </li> </ul> <p> Attributes </p> <ul> <li> <p>num_params :  int \u2014 The number of parameters in the model.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 Get the generative type of the model.</p> </li> <li> <p>vocab_size :  int \u2014 The vocabulary size of the model.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum context length of the model.</p> </li> <li> <p>data_collator :  c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator used to prepare samples during finetuning.</p> </li> <li> <p>compute_metrics :  ComputeMetricsFunction \u2014 The function used to compute the metrics.</p> </li> <li> <p>extract_labels_from_generation :  ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> <li> <p>trainer_class :  t.Type['Trainer'] \u2014 The Trainer class to use for finetuning.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>prepare_dataset \u2014 Prepare the dataset for the model.</p> </li> <li> <p>generate \u2014 Generate outputs from the model.</p> </li> <li> <p>model_exists \u2014 Check if a model exists.</p> </li> <li> <p>get_model_config \u2014 Fetch the model configuration.</p> </li> </ul> <p> source property VLLMModel.generative_type: GenerativeType | None </p> <p>Get the generative type of the model.</p> <p> Returns </p> <ul> <li> <p>GenerativeType | None \u2014 The generative type of the model, or None if it has not been set yet.</p> </li> </ul> <p> source property VLLMModel.extract_labels_from_generation: ExtractLabelsFunction </p> <p>The function used to extract the labels from the generated output.</p> <p> Returns </p> <ul> <li> <p>ExtractLabelsFunction \u2014 The function used to extract the labels from the generated output.</p> </li> </ul> <p> source method VLLMModel.prepare_dataset(dataset: DatasetDict, task: Task, itr_idx: int) \u2192 DatasetDict </p> <p>Prepare the dataset for the model.</p> <p>This includes things like tokenisation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to prepare.</p> </li> <li> <p>task :  Task \u2014 The task to prepare the dataset for.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The prepared dataset.</p> </li> </ul> <p> source method VLLMModel.generate(inputs: dict) \u2192 GenerativeModelOutput </p> <p>Generate outputs from the model.</p> <p> Parameters </p> <ul> <li> <p>inputs :  dict \u2014 A batch of inputs to pass through the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The generated model outputs.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the dataset requires logprobs, but we could not get the first token of each label in the dataset.</p> </li> </ul> <p> source classmethod VLLMModel.model_exists(model_id: str, benchmark_config: BenchmarkConfig) \u2192 bool | NeedsExtraInstalled | NeedsEnvironmentVariable </p> <p>Check if a model exists.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool | NeedsExtraInstalled | NeedsEnvironmentVariable \u2014 Whether the model exists, or an error describing why we cannot check whether the model exists.</p> </li> </ul> <p> source classmethod VLLMModel.get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetch the model configuration.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul> <p> source property VLLMModel.data_collator: c.Callable[[list[t.Any]], dict[str, t.Any]] </p> <p>The data collator used to prepare samples during finetuning.</p> <p> Returns </p> <ul> <li> <p>c.Callable[[list[t.Any]], dict[str, t.Any]] \u2014 The data collator.</p> </li> </ul> <p> source property VLLMModel.trainer_class: t.Type['Trainer'] </p> <p>The Trainer class to use for finetuning.</p> <p> Returns </p> <ul> <li> <p>t.Type['Trainer'] \u2014 The Trainer class.</p> </li> </ul> <p> source load_model_and_tokeniser(model_config: ModelConfig, benchmark_config: BenchmarkConfig) \u2192 tuple['LLM', 'PreTrainedTokenizer'] </p> <p>Load the model and tokeniser.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple['LLM', 'PreTrainedTokenizer'] \u2014 A pair (model, tokeniser), with the loaded model and tokeniser</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NeedsExtraInstalled</p> </li> <li> <p>InvalidModel</p> </li> </ul> <p> source load_tokeniser(model_id: str, revision: str, adapter_base_model_id: str | None, trust_remote_code: bool, model_max_length: int, model_cache_dir: str, token: str | bool) \u2192 PreTrainedTokenizer </p> <p>Load the tokeniser.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model identifier.</p> </li> <li> <p>revision :  str \u2014 The revision of the model.</p> </li> <li> <p>adapter_base_model_id :  str | None \u2014 The base model ID for the adapter model. Can be None if the model is not an adapter model.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code.</p> </li> <li> <p>model_max_length :  int \u2014 The maximum length of the model.</p> </li> <li> <p>model_cache_dir :  str \u2014 The cache directory for the model.</p> </li> <li> <p>token :  str | bool \u2014 The Hugging Face API token.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>PreTrainedTokenizer \u2014 The loaded tokeniser.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul> <p> source clear_vllm() \u2192 None </p> <p>Clear the GPU memory used by the vLLM model, enabling re-initialisation.</p> <p> source get_end_of_reasoning_token(model: LLM, tokeniser: PreTrainedTokenizer, model_id: str) \u2192 str | None </p> <p>Get the end-of-reasoning token for a generative model.</p> <p> Parameters </p> <ul> <li> <p>model :  LLM \u2014 The vLLM model.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> <li> <p>model_id :  str \u2014 The model ID.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str | None \u2014 The end of reasoning token, or None if it could not be found.</p> </li> </ul> <p> source get_custom_stop_tokens(model: LLM, tokeniser: PreTrainedTokenizer, model_id: str, is_reasoning_model: bool) \u2192 list[str] </p> <p>Get the stop tokens for a generative model.</p> <p> Parameters </p> <ul> <li> <p>model :  LLM \u2014 The vLLM model.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>is_reasoning_model :  bool \u2014 Whether the model is a reasoning model. This is used to determine the number of generated tokens to allow before stopping the generation.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[str] \u2014 A list of stop tokens.</p> </li> </ul> <p> source get_pbar_without_leave(*tqdm_args, **tqdm_kwargs) \u2192 tqdm </p> <p>Get a progress bar for vLLM which disappears after completion.</p> <p> Parameters </p> <ul> <li> <p>*tqdm_args \u2014 Positional arguments to pass to tqdm.</p> </li> <li> <p>**tqdm_kwargs \u2014 Additional keyword arguments to pass to tqdm.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tqdm \u2014 A tqdm progress bar.</p> </li> </ul>"},{"location":"api/euroeval/dataset_configs/","title":"euroeval.dataset_configs","text":"euroeval.dataset_configs<p> source package euroeval.dataset_configs </p> <p>All dataset configurations used in EuroEval.</p> <p> Functions </p> <ul> <li> <p>get_all_dataset_configs \u2014 Get a mapping of all the dataset configurations.</p> </li> <li> <p>get_dataset_config \u2014 Get the dataset configuration for a dataset.</p> </li> </ul> <p> source get_all_dataset_configs() \u2192 dict[str, DatasetConfig] </p> <p>Get a mapping of all the dataset configurations.</p> <p> Returns </p> <ul> <li> <p>dict[str, DatasetConfig] \u2014 A mapping between names of datasets and their configurations.</p> </li> </ul> <p> source get_dataset_config(dataset_name: str) \u2192 DatasetConfig </p> <p>Get the dataset configuration for a dataset.</p> <p> Parameters </p> <ul> <li> <p>dataset_name :  str \u2014 The name of the dataset.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetConfig \u2014 The dataset configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError \u2014 If the dataset is not found.</p> </li> </ul>"},{"location":"api/euroeval/dataset_configs/danish/","title":"euroeval.dataset_configs.danish","text":"euroeval.dataset_configs.danish<p> source module euroeval.dataset_configs.danish </p> <p>All Danish dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/dutch/","title":"euroeval.dataset_configs.dutch","text":"euroeval.dataset_configs.dutch<p> source module euroeval.dataset_configs.dutch </p> <p>All Dutch dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/english/","title":"euroeval.dataset_configs.english","text":"euroeval.dataset_configs.english<p> source module euroeval.dataset_configs.english </p> <p>All English dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/estonian/","title":"euroeval.dataset_configs.estonian","text":"euroeval.dataset_configs.estonian<p> source module euroeval.dataset_configs.estonian </p> <p>All Estonian dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/faroese/","title":"euroeval.dataset_configs.faroese","text":"euroeval.dataset_configs.faroese<p> source module euroeval.dataset_configs.faroese </p> <p>All Faroese dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/finnish/","title":"euroeval.dataset_configs.finnish","text":"euroeval.dataset_configs.finnish<p> source module euroeval.dataset_configs.finnish </p> <p>All Finnish dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/french/","title":"euroeval.dataset_configs.french","text":"euroeval.dataset_configs.french<p> source module euroeval.dataset_configs.french </p> <p>All French dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/german/","title":"euroeval.dataset_configs.german","text":"euroeval.dataset_configs.german<p> source module euroeval.dataset_configs.german </p> <p>All German dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/icelandic/","title":"euroeval.dataset_configs.icelandic","text":"euroeval.dataset_configs.icelandic<p> source module euroeval.dataset_configs.icelandic </p> <p>All Icelandic dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/italian/","title":"euroeval.dataset_configs.italian","text":"euroeval.dataset_configs.italian<p> source module euroeval.dataset_configs.italian </p> <p>All Italian dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/latvian/","title":"euroeval.dataset_configs.latvian","text":"euroeval.dataset_configs.latvian<p> source module euroeval.dataset_configs.latvian </p> <p>All Latvian dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/norwegian/","title":"euroeval.dataset_configs.norwegian","text":"euroeval.dataset_configs.norwegian<p> source module euroeval.dataset_configs.norwegian </p> <p>All Norwegian dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/portuguese/","title":"euroeval.dataset_configs.portuguese","text":"euroeval.dataset_configs.portuguese<p> source module euroeval.dataset_configs.portuguese </p> <p>All Portuguese dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/spanish/","title":"euroeval.dataset_configs.spanish","text":"euroeval.dataset_configs.spanish<p> source module euroeval.dataset_configs.spanish </p> <p>All Spanish dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/dataset_configs/swedish/","title":"euroeval.dataset_configs.swedish","text":"euroeval.dataset_configs.swedish<p> source module euroeval.dataset_configs.swedish </p> <p>All Swedish dataset configurations used in EuroEval.</p>"},{"location":"api/euroeval/metrics/","title":"euroeval.metrics","text":"euroeval.metrics<p> source package euroeval.metrics </p> <p>All the metrics used in EuroEval.</p> <p> Classes </p> <ul> <li> <p>Metric \u2014 Abstract base class for all metrics.</p> </li> <li> <p>HuggingFaceMetric \u2014 A metric which is implemented in the <code>evaluate</code> package.</p> </li> <li> <p>LLMAsAJudgeMetric \u2014 Use an LLM to judge the quality of the predictions.</p> </li> <li> <p>Fluency \u2014 Response format for the fluency metric.</p> </li> <li> <p>PipelineMetric \u2014 Load a scikit-learn pipeline and use it to get scores from the predictions.</p> </li> <li> <p>SpeedMetric \u2014 Speed metric.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>european_values_preprocessing_fn \u2014 Preprocess the model predictions for the European Values metric.</p> </li> <li> <p>european_values_scoring_function \u2014 Scoring function for the European Values metric.</p> </li> </ul> <p> source class Metric(name: str, pretty_name: str, postprocessing_fn: t.Callable[[float], tuple[float, str]] | None = None) </p> <p>Bases : abc.ABC</p> <p>Abstract base class for all metrics.</p> <p>Initialise the metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>postprocessing_fn :  t.Callable[[float], tuple[float, str]] | None \u2014 A function to apply to the metric scores after they are computed, taking the score to the postprocessed score along with its string representation. Defaults to x -&gt; (100 * x, f\"{x:.2%}\").</p> </li> </ul> <p> source class HuggingFaceMetric(name: str, pretty_name: str, huggingface_id: str, results_key: str, compute_kwargs: dict[str, t.Any] | None = None, postprocessing_fn: t.Callable[[float], tuple[float, str]] | None = None) </p> <p>Bases : Metric</p> <p>A metric which is implemented in the <code>evaluate</code> package.</p> <p>Initialise the Hugging Face metric.</p> <p> Attributes </p> <ul> <li> <p>name \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>huggingface_id \u2014 The Hugging Face ID of the metric.</p> </li> <li> <p>results_key \u2014 The name of the key used to extract the metric scores from the results dictionary.</p> </li> <li> <p>compute_kwargs :  dict[str, t.Any] \u2014 Keyword arguments to pass to the metric's compute function. Defaults to an empty dictionary.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>huggingface_id :  str \u2014 The Hugging Face ID of the metric.</p> </li> <li> <p>results_key :  str \u2014 The name of the key used to extract the metric scores from the results dictionary.</p> </li> <li> <p>compute_kwargs :  dict[str, t.Any] | None \u2014 Keyword arguments to pass to the metric's compute function. Defaults to an empty dictionary.</p> </li> <li> <p>postprocessing_fn :  t.Callable[[float], tuple[float, str]] | None \u2014 A function to apply to the metric scores after they are computed, taking the score to the postprocessed score along with its string representation. Defaults to x -&gt; (100 * x, f\"{x:.2%}\").</p> </li> </ul> <p> source class LLMAsAJudgeMetric(name: str, pretty_name: str, judge_id: str, judge_kwargs: dict[str, t.Any], user_prompt: str, response_format: t.Type[BaseModel], scoring_fn: t.Callable[[BaseModel | None], float], condition_formatting_fn: t.Callable[[str], str] = lambda x: x, system_prompt: str | None = None) </p> <p>Bases : Metric</p> <p>Use an LLM to judge the quality of the predictions.</p> <p>Initialise the LLM as a judge metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>judge_id :  str \u2014 The model ID of the LLM to use as a judge.</p> </li> <li> <p>judge_kwargs :  dict[str, t.Any] \u2014 Generation parameters for the judge model, such as temperature.</p> </li> <li> <p>user_prompt :  str \u2014 The user prompt to use for the judge model. The prompt should be formatted with the variables <code>prediction</code> and <code>condition</code>, to include the model predictions and a description of what the prediction should be judged on, respectively. If the condition is not needed, it can be omitted from the prompt, but the <code>prediction</code> variable must still be present.</p> </li> <li> <p>response_format :  t.Type[BaseModel] \u2014 The response format to use for the judge model. This should be a Pydantic model that defines the expected structure of the judge's response.</p> </li> <li> <p>scoring_fn :  t.Callable[[BaseModel | None], float] \u2014 A function that takes the judge's response and returns a score.</p> </li> <li> <p>condition_formatting_fn :  optional \u2014 A function to format the condition string before it is included in the user prompt. Defaults to a no-op function that returns the input unchanged.</p> </li> <li> <p>system_prompt :  optional \u2014 The system prompt to use for the judge model. If not provided, no system prompt will be used.</p> </li> </ul> <p> source class Fluency(**data: Any) </p> <p>Bases : BaseModel</p> <p>Response format for the fluency metric.</p> <p>Create a new model by parsing and validating input data from keyword arguments.</p> <p>Raises [<code>ValidationError</code>][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p> Attributes </p> <ul> <li> <p>fluency :  t.Annotated[int, Field(ge=1, le=5)] \u2014 The fluency rating, an integer between 1 and 5.</p> </li> <li> <p>model_config :  ClassVar[ConfigDict] \u2014 Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p> </li> <li> <p>model_extra :  dict[str, Any] | None \u2014 Get extra fields set during validation.</p> </li> <li> <p>model_fields_set :  set[str] \u2014 Returns the set of fields that have been explicitly set on this model instance.</p> </li> </ul> <p> source class PipelineMetric(name: str, pretty_name: str, pipeline_repo: str, pipeline_scoring_function: c.Callable[['Pipeline', c.Sequence], float], pipeline_file_name: str = 'pipeline.pkl', preprocessing_fn: c.Callable[[c.Sequence[T]], c.Sequence[T]] = lambda x: x, postprocessing_fn: c.Callable[[float], tuple[float, str]] | None = None) </p> <p>Bases : Metric</p> <p>Load a scikit-learn pipeline and use it to get scores from the predictions.</p> <p>Initialise the pipeline transform metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>pipeline_repo :  str \u2014 The Hugging Face repository ID of the scikit-learn pipeline to load.</p> </li> <li> <p>pipeline_scoring_method \u2014 The method to use for scoring the predictions with the pipeline. Takes a 1D sequence of predictions and returns a float score.</p> </li> <li> <p>pipeline_file_name :  optional \u2014 The name of the file to download from the Hugging Face repository. Defaults to \"pipeline.joblib\".</p> </li> <li> <p>preprocessing_fn :  optional \u2014 A function to apply to the predictions before they are passed to the pipeline. This is useful for preprocessing the predictions to match the expected input format of the pipeline. Defaults to a no-op function that returns the input unchanged.</p> </li> <li> <p>postprocessing_fn :  optional \u2014 A function to apply to the metric scores after they are computed, taking the score to the postprocessed score along with its string representation. Defaults to x -&gt; (100 * x, f\"{x:.2%}\").</p> </li> </ul> <p> source european_values_preprocessing_fn(predictions: c.Sequence[int]) \u2192 c.Sequence[int] </p> <p>Preprocess the model predictions for the European Values metric.</p> <p> Parameters </p> <ul> <li> <p>predictions :  c.Sequence[int] \u2014 The model predictions, a sequence of integers representing the predicted choices for each question.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>c.Sequence[int] \u2014 The preprocessed model predictions, a sequence of integers representing the final predicted choices for each question after any necessary aggregation and mapping.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>AssertionError \u2014 If the number of predictions is not a multiple of 53, which is required for the European Values metric.</p> </li> </ul> <p> source european_values_scoring_function(pipeline: Pipeline, predictions: c.Sequence[int]) \u2192 float </p> <p>Scoring function for the European Values metric.</p> <p> source class SpeedMetric(name: str, pretty_name: str) </p> <p>Bases : Metric</p> <p>Speed metric.</p> <p>Initialise the speed metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> </ul>"},{"location":"api/euroeval/metrics/base/","title":"euroeval.metrics.base","text":"euroeval.metrics.base<p> source module euroeval.metrics.base </p> <p>The abstract base class for all metrics.</p> <p> Classes </p> <ul> <li> <p>Metric \u2014 Abstract base class for all metrics.</p> </li> </ul> <p> source class Metric(name: str, pretty_name: str, postprocessing_fn: t.Callable[[float], tuple[float, str]] | None = None) </p> <p>Bases : abc.ABC</p> <p>Abstract base class for all metrics.</p> <p>Initialise the metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>postprocessing_fn :  t.Callable[[float], tuple[float, str]] | None \u2014 A function to apply to the metric scores after they are computed, taking the score to the postprocessed score along with its string representation. Defaults to x -&gt; (100 * x, f\"{x:.2%}\").</p> </li> </ul>"},{"location":"api/euroeval/metrics/huggingface/","title":"euroeval.metrics.huggingface","text":"euroeval.metrics.huggingface<p> source module euroeval.metrics.huggingface </p> <p>All the Hugging Face metrics used in EuroEval.</p> <p> Classes </p> <ul> <li> <p>HuggingFaceMetric \u2014 A metric which is implemented in the <code>evaluate</code> package.</p> </li> </ul> <p> source class HuggingFaceMetric(name: str, pretty_name: str, huggingface_id: str, results_key: str, compute_kwargs: dict[str, t.Any] | None = None, postprocessing_fn: t.Callable[[float], tuple[float, str]] | None = None) </p> <p>Bases : Metric</p> <p>A metric which is implemented in the <code>evaluate</code> package.</p> <p>Initialise the Hugging Face metric.</p> <p> Attributes </p> <ul> <li> <p>name \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>huggingface_id \u2014 The Hugging Face ID of the metric.</p> </li> <li> <p>results_key \u2014 The name of the key used to extract the metric scores from the results dictionary.</p> </li> <li> <p>compute_kwargs :  dict[str, t.Any] \u2014 Keyword arguments to pass to the metric's compute function. Defaults to an empty dictionary.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>huggingface_id :  str \u2014 The Hugging Face ID of the metric.</p> </li> <li> <p>results_key :  str \u2014 The name of the key used to extract the metric scores from the results dictionary.</p> </li> <li> <p>compute_kwargs :  dict[str, t.Any] | None \u2014 Keyword arguments to pass to the metric's compute function. Defaults to an empty dictionary.</p> </li> <li> <p>postprocessing_fn :  t.Callable[[float], tuple[float, str]] | None \u2014 A function to apply to the metric scores after they are computed, taking the score to the postprocessed score along with its string representation. Defaults to x -&gt; (100 * x, f\"{x:.2%}\").</p> </li> </ul>"},{"location":"api/euroeval/metrics/llm_as_a_judge/","title":"euroeval.metrics.llm_as_a_judge","text":"euroeval.metrics.llm_as_a_judge<p> source module euroeval.metrics.llm_as_a_judge </p> <p>Metrics based on LLM-as-a-judge.</p> <p> Classes </p> <ul> <li> <p>LLMAsAJudgeMetric \u2014 Use an LLM to judge the quality of the predictions.</p> </li> <li> <p>Fluency \u2014 Response format for the fluency metric.</p> </li> </ul> <p> source class LLMAsAJudgeMetric(name: str, pretty_name: str, judge_id: str, judge_kwargs: dict[str, t.Any], user_prompt: str, response_format: t.Type[BaseModel], scoring_fn: t.Callable[[BaseModel | None], float], condition_formatting_fn: t.Callable[[str], str] = lambda x: x, system_prompt: str | None = None) </p> <p>Bases : Metric</p> <p>Use an LLM to judge the quality of the predictions.</p> <p>Initialise the LLM as a judge metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>judge_id :  str \u2014 The model ID of the LLM to use as a judge.</p> </li> <li> <p>judge_kwargs :  dict[str, t.Any] \u2014 Generation parameters for the judge model, such as temperature.</p> </li> <li> <p>user_prompt :  str \u2014 The user prompt to use for the judge model. The prompt should be formatted with the variables <code>prediction</code> and <code>condition</code>, to include the model predictions and a description of what the prediction should be judged on, respectively. If the condition is not needed, it can be omitted from the prompt, but the <code>prediction</code> variable must still be present.</p> </li> <li> <p>response_format :  t.Type[BaseModel] \u2014 The response format to use for the judge model. This should be a Pydantic model that defines the expected structure of the judge's response.</p> </li> <li> <p>scoring_fn :  t.Callable[[BaseModel | None], float] \u2014 A function that takes the judge's response and returns a score.</p> </li> <li> <p>condition_formatting_fn :  optional \u2014 A function to format the condition string before it is included in the user prompt. Defaults to a no-op function that returns the input unchanged.</p> </li> <li> <p>system_prompt :  optional \u2014 The system prompt to use for the judge model. If not provided, no system prompt will be used.</p> </li> </ul> <p> source class Fluency(**data: Any) </p> <p>Bases : BaseModel</p> <p>Response format for the fluency metric.</p> <p>Create a new model by parsing and validating input data from keyword arguments.</p> <p>Raises [<code>ValidationError</code>][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p> Attributes </p> <ul> <li> <p>fluency :  t.Annotated[int, Field(ge=1, le=5)] \u2014 The fluency rating, an integer between 1 and 5.</p> </li> <li> <p>model_config :  ClassVar[ConfigDict] \u2014 Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p> </li> <li> <p>model_extra :  dict[str, Any] | None \u2014 Get extra fields set during validation.</p> </li> <li> <p>model_fields_set :  set[str] \u2014 Returns the set of fields that have been explicitly set on this model instance.</p> </li> </ul>"},{"location":"api/euroeval/metrics/pipeline/","title":"euroeval.metrics.pipeline","text":"euroeval.metrics.pipeline<p> source module euroeval.metrics.pipeline </p> <p>Metrics based on a scikit-learn Pipeline.</p> <p> Classes </p> <ul> <li> <p>PipelineMetric \u2014 Load a scikit-learn pipeline and use it to get scores from the predictions.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>european_values_preprocessing_fn \u2014 Preprocess the model predictions for the European Values metric.</p> </li> <li> <p>european_values_scoring_function \u2014 Scoring function for the European Values metric.</p> </li> </ul> <p> source class PipelineMetric(name: str, pretty_name: str, pipeline_repo: str, pipeline_scoring_function: c.Callable[['Pipeline', c.Sequence], float], pipeline_file_name: str = 'pipeline.pkl', preprocessing_fn: c.Callable[[c.Sequence[T]], c.Sequence[T]] = lambda x: x, postprocessing_fn: c.Callable[[float], tuple[float, str]] | None = None) </p> <p>Bases : Metric</p> <p>Load a scikit-learn pipeline and use it to get scores from the predictions.</p> <p>Initialise the pipeline transform metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> <li> <p>pipeline_repo :  str \u2014 The Hugging Face repository ID of the scikit-learn pipeline to load.</p> </li> <li> <p>pipeline_scoring_method \u2014 The method to use for scoring the predictions with the pipeline. Takes a 1D sequence of predictions and returns a float score.</p> </li> <li> <p>pipeline_file_name :  optional \u2014 The name of the file to download from the Hugging Face repository. Defaults to \"pipeline.joblib\".</p> </li> <li> <p>preprocessing_fn :  optional \u2014 A function to apply to the predictions before they are passed to the pipeline. This is useful for preprocessing the predictions to match the expected input format of the pipeline. Defaults to a no-op function that returns the input unchanged.</p> </li> <li> <p>postprocessing_fn :  optional \u2014 A function to apply to the metric scores after they are computed, taking the score to the postprocessed score along with its string representation. Defaults to x -&gt; (100 * x, f\"{x:.2%}\").</p> </li> </ul> <p> source european_values_preprocessing_fn(predictions: c.Sequence[int]) \u2192 c.Sequence[int] </p> <p>Preprocess the model predictions for the European Values metric.</p> <p> Parameters </p> <ul> <li> <p>predictions :  c.Sequence[int] \u2014 The model predictions, a sequence of integers representing the predicted choices for each question.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>c.Sequence[int] \u2014 The preprocessed model predictions, a sequence of integers representing the final predicted choices for each question after any necessary aggregation and mapping.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>AssertionError \u2014 If the number of predictions is not a multiple of 53, which is required for the European Values metric.</p> </li> </ul> <p> source european_values_scoring_function(pipeline: Pipeline, predictions: c.Sequence[int]) \u2192 float </p> <p>Scoring function for the European Values metric.</p>"},{"location":"api/euroeval/metrics/speed/","title":"euroeval.metrics.speed","text":"euroeval.metrics.speed<p> source module euroeval.metrics.speed </p> <p>Inference speed metric.</p> <p> Classes </p> <ul> <li> <p>SpeedMetric \u2014 Speed metric.</p> </li> </ul> <p> source class SpeedMetric(name: str, pretty_name: str) </p> <p>Bases : Metric</p> <p>Speed metric.</p> <p>Initialise the speed metric.</p> <p> Parameters </p> <ul> <li> <p>name :  str \u2014 The name of the metric in snake_case.</p> </li> <li> <p>pretty_name :  str \u2014 The pretty name of the metric, used for display purposes.</p> </li> </ul>"},{"location":"api/euroeval/prompt_templates/","title":"euroeval.prompt_templates","text":"euroeval.prompt_templates<p> source package euroeval.prompt_templates </p> <p>The different prompt templates used in EuroEval.</p> <p> Modules </p> <ul> <li> <p>euroeval.prompt_templates.linguistic_acceptability \u2014 Templates for the Linguistic Acceptability task.</p> </li> <li> <p>euroeval.prompt_templates.multiple_choice \u2014 Templates for all multiple choice tasks.</p> </li> <li> <p>euroeval.prompt_templates.named_entity_recognition \u2014 Templates for the Named Entity Recognition task.</p> </li> <li> <p>euroeval.prompt_templates.reading_comprehension \u2014 Templates for the Reading Comprehension task.</p> </li> <li> <p>euroeval.prompt_templates.sentiment_classification \u2014 Templates for the Sentiment Analysis task.</p> </li> <li> <p>euroeval.prompt_templates.summarization \u2014 Templates for the Summarization task.</p> </li> </ul>"},{"location":"api/euroeval/prompt_templates/linguistic_acceptability/","title":"euroeval.prompt_templates.linguistic_acceptability","text":"euroeval.prompt_templates.linguistic_acceptability<p> source module euroeval.prompt_templates.linguistic_acceptability </p> <p>Templates for the Linguistic Acceptability task.</p>"},{"location":"api/euroeval/prompt_templates/multiple_choice/","title":"euroeval.prompt_templates.multiple_choice","text":"euroeval.prompt_templates.multiple_choice<p> source module euroeval.prompt_templates.multiple_choice </p> <p>Templates for all multiple choice tasks.</p>"},{"location":"api/euroeval/prompt_templates/named_entity_recognition/","title":"euroeval.prompt_templates.named_entity_recognition","text":"euroeval.prompt_templates.named_entity_recognition<p> source module euroeval.prompt_templates.named_entity_recognition </p> <p>Templates for the Named Entity Recognition task.</p>"},{"location":"api/euroeval/prompt_templates/reading_comprehension/","title":"euroeval.prompt_templates.reading_comprehension","text":"euroeval.prompt_templates.reading_comprehension<p> source module euroeval.prompt_templates.reading_comprehension </p> <p>Templates for the Reading Comprehension task.</p>"},{"location":"api/euroeval/prompt_templates/sentiment_classification/","title":"euroeval.prompt_templates.sentiment_classification","text":"euroeval.prompt_templates.sentiment_classification<p> source module euroeval.prompt_templates.sentiment_classification </p> <p>Templates for the Sentiment Analysis task.</p>"},{"location":"api/euroeval/prompt_templates/summarization/","title":"euroeval.prompt_templates.summarization","text":"euroeval.prompt_templates.summarization<p> source module euroeval.prompt_templates.summarization </p> <p>Templates for the Summarization task.</p>"},{"location":"api/euroeval/task_group_utils/","title":"euroeval.task_group_utils","text":"euroeval.task_group_utils<p> source package euroeval.task_group_utils </p> <p>Utility functions related to the different tasks and task groups.</p> <p> Modules </p> <ul> <li> <p>euroeval.task_group_utils.multiple_choice_classification \u2014 Utility functions related to the multiple-choice classification task group.</p> </li> <li> <p>euroeval.task_group_utils.question_answering \u2014 Utility functions related to the question-answering task group.</p> </li> <li> <p>euroeval.task_group_utils.sequence_classification \u2014 Utility functions related to the sequence-classification task group.</p> </li> <li> <p>euroeval.task_group_utils.text_to_text \u2014 Utility functions related to the text-to-text task group.</p> </li> <li> <p>euroeval.task_group_utils.token_classification \u2014 Utility functions related to the token-classification task group.</p> </li> </ul>"},{"location":"api/euroeval/task_group_utils/multiple_choice_classification/","title":"euroeval.task_group_utils.multiple_choice_classification","text":"euroeval.task_group_utils.multiple_choice_classification<p> source module euroeval.task_group_utils.multiple_choice_classification </p> <p>Utility functions related to the multiple-choice classification task group.</p> <p> Classes </p> <ul> <li> <p>MultipleChoiceClassificationTrainer \u2014 Trainer subclass for multiple-choice classification tasks.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>prepare_examples \u2014 Prepare the features.</p> </li> <li> <p>postprocess_predictions_and_labels \u2014 Postprocess the predictions and labels.</p> </li> </ul> <p> source class MultipleChoiceClassificationTrainer(model: Union[PreTrainedModel, nn.Module, None] = None, args: TrainingArguments = None, data_collator: Optional[DataCollator] = None, train_dataset: Optional[Union[Dataset, IterableDataset, 'datasets.Dataset']] = None, eval_dataset: Optional[Union[Dataset, dict[str, Dataset], 'datasets.Dataset']] = None, processing_class: Optional[Union[PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin]] = None, model_init: Optional[Callable[[], PreTrainedModel]] = None, compute_loss_func: Optional[Callable] = None, compute_metrics: Optional[Callable[[EvalPrediction], dict]] = None, callbacks: Optional[list[TrainerCallback]] = None, optimizers: tuple[Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None), optimizer_cls_and_kwargs: Optional[tuple[type[torch.optim.Optimizer], dict[str, Any]]] = None, preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None) </p> <p>Bases : Trainer</p> <p>Trainer subclass for multiple-choice classification tasks.</p> <p> Methods </p> <ul> <li> <p>evaluate \u2014 Evaluate the model on the given dataset.</p> </li> </ul> <p> source method MultipleChoiceClassificationTrainer.evaluate(eval_dataset: Dataset | None = None, ignore_keys: list[str] | None = None, metric_key_prefix: str = 'eval') \u2192 dict[str, float] </p> <p>Evaluate the model on the given dataset.</p> <p> Parameters </p> <ul> <li> <p>eval_dataset :  Dataset | None \u2014 The dataset to evaluate on. If None, then use the stored evaluation dataset.</p> </li> <li> <p>ignore_keys :  list[str] | None \u2014 The keys to ignore when computing the metrics.</p> </li> <li> <p>metric_key_prefix :  str \u2014 The prefix to use for the metric keys.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 The metrics computed on the evaluation dataset.</p> </li> </ul> <p> source prepare_examples(examples: BatchEncoding, tokeniser: PreTrainedTokenizer) \u2192 BatchEncoding </p> <p>Prepare the features.</p> <p> Parameters </p> <ul> <li> <p>examples :  BatchEncoding \u2014 The examples to prepare.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser to use to prepare the examples.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BatchEncoding \u2014 The prepared examples.</p> </li> </ul> <p> source postprocess_predictions_and_labels(predictions: np.ndarray, dataset: Dataset) \u2192 tuple['Predictions', 'Labels'] </p> <p>Postprocess the predictions and labels.</p> <p> Parameters </p> <ul> <li> <p>predictions :  np.ndarray \u2014 The model predictions, of shape (num_examples, 2), corresponding to the False/True probabilities for each example.</p> </li> <li> <p>dataset :  Dataset \u2014 The dataset containing the examples.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple['Predictions', 'Labels'] \u2014 The postprocessed predictions and labels.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul>"},{"location":"api/euroeval/task_group_utils/question_answering/","title":"euroeval.task_group_utils.question_answering","text":"euroeval.task_group_utils.question_answering<p> source module euroeval.task_group_utils.question_answering </p> <p>Utility functions related to the question-answering task group.</p> <p> Classes </p> <ul> <li> <p>QuestionAnsweringTrainer \u2014 Trainer subclass for question answering tasks.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>compute_metrics \u2014 Compute the metrics needed for evaluation.</p> </li> <li> <p>extract_labels_from_generation \u2014 Extract the predicted labels from the generated output.</p> </li> <li> <p>prepare_train_examples \u2014 Prepare the features for training.</p> </li> <li> <p>prepare_test_examples \u2014 Prepare test examples.</p> </li> <li> <p>postprocess_predictions_and_labels \u2014 Postprocess the predictions and labels, to allow easier metric computation.</p> </li> <li> <p>find_best_answer \u2014 Find the best answer for a given example.</p> </li> <li> <p>find_valid_answers \u2014 Find the valid answers from the start and end indexes.</p> </li> </ul> <p> source class QuestionAnsweringTrainer(model: PreTrainedModel | nn.Module, processing_class: PreTrainedTokenizerBase, args: TrainingArguments, train_dataset: Dataset, eval_dataset: Dataset, compute_metrics: c.Callable[[EvalPrediction], dict[str, float]], callbacks: list[TrainerCallback], data_collator: c.Callable, **kwargs) </p> <p>Bases : Trainer</p> <p>Trainer subclass for question answering tasks.</p> <p>Initialise the trainer.</p> <p> Methods </p> <ul> <li> <p>evaluate \u2014 Evaluate the model on the given dataset.</p> </li> </ul> <p> source method QuestionAnsweringTrainer.evaluate(eval_dataset: Dataset | None = None, orig_eval_dataset: Dataset | None = None, ignore_keys: list[str] | None = None, metric_key_prefix: str = 'eval') \u2192 dict[str, float] </p> <p>Evaluate the model on the given dataset.</p> <p> Parameters </p> <ul> <li> <p>eval_dataset :  Dataset | None \u2014 The dataset to evaluate on. If None, then use the stored evaluation dataset.</p> </li> <li> <p>orig_eval_dataset :  Dataset | None \u2014 The original evaluation dataset, before any postprocessing. If None, then use the stored original evaluation dataset.</p> </li> <li> <p>ignore_keys :  list[str] | None \u2014 The keys to ignore when computing the metrics.</p> </li> <li> <p>metric_key_prefix :  str \u2014 The prefix to use for the metric keys.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 The metrics computed on the evaluation dataset.</p> </li> </ul> <p> source compute_metrics(model_outputs_and_labels: tuple[Predictions, Labels] | EvalPrediction, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, dataset: Dataset) \u2192 dict[str, float] </p> <p>Compute the metrics needed for evaluation.</p> <p> Parameters </p> <ul> <li> <p>model_outputs_and_labels :  tuple[Predictions, Labels] | EvalPrediction \u2014 The first sequence contains the model outputs and the second sequence contains the true labels.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> <li> <p>dataset :  Dataset \u2014 The dataset used for evaluation. This is only used in case any additional metadata is used to compute the metrics.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 A dictionary with the names of the metrics as keys and the metric values as values.</p> </li> </ul> <p> source extract_labels_from_generation(input_batch: dict[str, list], model_output: GenerativeModelOutput) \u2192 list[t.Any] </p> <p>Extract the predicted labels from the generated output.</p> <p> Parameters </p> <ul> <li> <p>input_batch :  dict[str, list] \u2014 The input batch, where the keys are the feature names and the values are lists with the feature values.</p> </li> <li> <p>model_output :  GenerativeModelOutput \u2014 The raw generated output of the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[t.Any] \u2014 The predicted labels.</p> </li> </ul> <p> source prepare_train_examples(examples: BatchEncoding, tokeniser: PreTrainedTokenizer) \u2192 BatchEncoding </p> <p>Prepare the features for training.</p> <p> Parameters </p> <ul> <li> <p>examples :  BatchEncoding \u2014 The examples to prepare.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser to use to prepare the examples.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BatchEncoding \u2014 The prepared examples.</p> </li> </ul> <p> source prepare_test_examples(examples: BatchEncoding, tokeniser: PreTrainedTokenizer) \u2192 BatchEncoding </p> <p>Prepare test examples.</p> <p> Parameters </p> <ul> <li> <p>examples :  BatchEncoding \u2014 Dictionary of test examples.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser used to preprocess the examples.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BatchEncoding \u2014 The prepared test examples.</p> </li> </ul> <p> source postprocess_predictions_and_labels(predictions: tuple[np.ndarray, ...], dataset: Dataset, prepared_dataset: Dataset, cls_token_index: int) \u2192 tuple[list[dict], list[dict]] </p> <p>Postprocess the predictions and labels, to allow easier metric computation.</p> <p> Parameters </p> <ul> <li> <p>predictions :  tuple[np.ndarray, ...] \u2014 A tuple whose first two elements are (start_logits, end_logits).</p> </li> <li> <p>dataset :  Dataset \u2014 The dataset containing the examples.</p> </li> <li> <p>prepared_dataset :  Dataset \u2014 The dataset containing the prepared examples.</p> </li> <li> <p>cls_token_index :  int \u2014 The index of the CLS token.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple[list[dict], list[dict]] \u2014 The postprocessed predictions and labels.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source find_best_answer(all_start_logits: np.ndarray, all_end_logits: np.ndarray, prepared_dataset: Dataset, feature_indices: list[int], context: str, max_answer_length: int, num_best_logits: int, min_null_score: float, cls_token_index: int) \u2192 str </p> <p>Find the best answer for a given example.</p> <p> Parameters </p> <ul> <li> <p>all_start_logits :  np.ndarray \u2014 The start logits for all the features.</p> </li> <li> <p>all_end_logits :  np.ndarray \u2014 The end logits for all the features.</p> </li> <li> <p>prepared_dataset :  Dataset \u2014 The dataset containing the prepared examples.</p> </li> <li> <p>feature_indices :  list[int] \u2014 The indices of the features associated with the current example.</p> </li> <li> <p>context :  str \u2014 The context of the example.</p> </li> <li> <p>max_answer_length :  int \u2014 The maximum length of the answer.</p> </li> <li> <p>num_best_logits :  int \u2014 The number of best logits to consider.</p> </li> <li> <p>min_null_score :  float \u2014 The minimum score an answer can have.</p> </li> <li> <p>cls_token_index :  int \u2014 The index of the CLS token.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str \u2014 The best answer for the example.</p> </li> </ul> <p> source find_valid_answers(start_logits: np.ndarray, end_logits: np.ndarray, offset_mapping: list[tuple[int, int]], context: str, max_answer_length: int, num_best_logits: int, min_null_score: float) \u2192 list[dict] </p> <p>Find the valid answers from the start and end indexes.</p> <p> Parameters </p> <ul> <li> <p>start_logits :  np.ndarray \u2014 The logits for the start of the answer.</p> </li> <li> <p>end_logits :  np.ndarray \u2014 The logits for the end of the answer.</p> </li> <li> <p>offset_mapping :  list[tuple[int, int]] \u2014 The offset mapping, being a list of pairs of integers for each token index, containing the start and end character index in the original context.</p> </li> <li> <p>context :  str \u2014 The context of the example.</p> </li> <li> <p>max_answer_length :  int \u2014 The maximum length of the answer.</p> </li> <li> <p>num_best_logits :  int \u2014 The number of best logits to consider. Note that this function will run in O(<code>num_best_logits</code> ^ 2) time.</p> </li> <li> <p>min_null_score :  float \u2014 The minimum score an answer can have.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[dict] \u2014 A list of the valid answers, each being a dictionary with keys \"text\" and \"score\", the score being the sum of the start and end logits.</p> </li> </ul>"},{"location":"api/euroeval/task_group_utils/sequence_classification/","title":"euroeval.task_group_utils.sequence_classification","text":"euroeval.task_group_utils.sequence_classification<p> source module euroeval.task_group_utils.sequence_classification </p> <p>Utility functions related to the sequence-classification task group.</p> <p> Functions </p> <ul> <li> <p>compute_metrics \u2014 Compute the metrics needed for evaluation.</p> </li> <li> <p>extract_labels_from_generation \u2014 Extract the predicted labels from the generated output.</p> </li> <li> <p>get_closest_logprobs_labels \u2014 Get the labels with the highest predicted logprob value.</p> </li> </ul> <p> source compute_metrics(model_outputs_and_labels: tuple[Predictions, Labels] | EvalPrediction, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, dataset: Dataset) \u2192 dict[str, float] </p> <p>Compute the metrics needed for evaluation.</p> <p> Parameters </p> <ul> <li> <p>model_outputs_and_labels :  tuple[Predictions, Labels] | EvalPrediction \u2014 The first sequence contains the model outputs and the second sequence contains the true labels.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> <li> <p>dataset :  Dataset \u2014 The dataset used for evaluation. This is only used in case any additional metadata is used to compute the metrics.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 A dictionary with the names of the metrics as keys and the metric values as values.</p> </li> </ul> <p> source extract_labels_from_generation(input_batch: dict[str, list], model_output: GenerativeModelOutput, dataset_config: DatasetConfig, first_label_token_mapping: dict[str, str] | bool) \u2192 list[str] </p> <p>Extract the predicted labels from the generated output.</p> <p> Parameters </p> <ul> <li> <p>input_batch :  dict[str, list] \u2014 The input batch, where the keys are the feature names and the values are lists with the feature values.</p> </li> <li> <p>model_output :  GenerativeModelOutput \u2014 The raw generated output of the model.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>first_label_token_mapping :  dict[str, str] | bool \u2014 A mapping from labels to the first token in each label, or alternatively a Boolean value indicating whether the model should output scores (if the mapping is outputted then the model will always output scores).</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[str] \u2014 The predicted labels.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the task requires log probabilities, but the model did not output them, or if the model outputted log probabilities but the first label token mapping is not provided.</p> </li> </ul> <p> source get_closest_logprobs_labels(generation_logprobs: list[list[list[tuple[str, float]]]], dataset_config: DatasetConfig, first_label_token_mapping: dict[str, str] | t.Literal[True]) \u2192 list[str] | None </p> <p>Get the labels with the highest predicted logprob value.</p> <p>In case a candidate label is split into multiple tokens, we only use the first token to compute the logprob value. E.g., if the candidate label \"positive\" is tokenised as [\"pos\", \"itive\"], we only use the logprob value of \"pos\" to represent the logprob value of the entire label.</p> <p> Parameters </p> <ul> <li> <p>generation_logprobs :  list[list[list[tuple[str, float]]]] \u2014 The logprobs of the generated tokens, for all samples in the batch. Of shape (batch_size, num_tokens, num_logprobs).</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>first_label_token_mapping :  dict[str, str] | t.Literal[True] \u2014 A mapping from labels to the first token in each label, or alternatively a <code>True</code> value indicating that the model should output logprobs.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[str] | None \u2014 The predicted labels, or None if labels could not be extracted.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If no candidate label can be found for any of the generated labels.</p> </li> </ul>"},{"location":"api/euroeval/task_group_utils/text_to_text/","title":"euroeval.task_group_utils.text_to_text","text":"euroeval.task_group_utils.text_to_text<p> source module euroeval.task_group_utils.text_to_text </p> <p>Utility functions related to the text-to-text task group.</p> <p> Functions </p> <ul> <li> <p>compute_metrics \u2014 Compute the metrics needed for evaluation.</p> </li> <li> <p>extract_labels_from_generation \u2014 Extract the predicted labels from the generated output.</p> </li> </ul> <p> source compute_metrics(model_outputs_and_labels: tuple[Predictions, Labels] | EvalPrediction, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, dataset: Dataset) \u2192 dict[str, float] </p> <p>Compute the metrics needed for evaluation.</p> <p> Parameters </p> <ul> <li> <p>model_outputs_and_labels :  tuple[Predictions, Labels] | EvalPrediction \u2014 The first sequence contains the model outputs and the second sequence contains the true labels.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> <li> <p>dataset :  Dataset \u2014 The dataset used for evaluation. This is only used in case any additional metadata is used to compute the metrics.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 A dictionary with the names of the metrics as keys and the metric values as values.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source extract_labels_from_generation(input_batch: dict[str, list], model_output: GenerativeModelOutput) \u2192 list[t.Any] </p> <p>Extract the predicted labels from the generated output.</p> <p> Parameters </p> <ul> <li> <p>input_batch :  dict[str, list] \u2014 The input batch, where the keys are the feature names and the values are lists with the feature values.</p> </li> <li> <p>model_output :  GenerativeModelOutput \u2014 The raw generated output of the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[t.Any] \u2014 The predicted labels.</p> </li> </ul>"},{"location":"api/euroeval/task_group_utils/token_classification/","title":"euroeval.task_group_utils.token_classification","text":"euroeval.task_group_utils.token_classification<p> source module euroeval.task_group_utils.token_classification </p> <p>Utility functions related to the token-classification task group.</p> <p> Functions </p> <ul> <li> <p>compute_metrics \u2014 Compute the metrics needed for evaluation.</p> </li> <li> <p>extract_labels_from_generation \u2014 Extract the predicted labels from the generated output.</p> </li> <li> <p>tokenize_and_align_labels \u2014 Tokenise all texts and align the labels with them.</p> </li> <li> <p>handle_unk_tokens \u2014 Replace unknown tokens in the tokens with the corresponding word.</p> </li> </ul> <p> source compute_metrics(model_outputs_and_labels: tuple[Predictions, Labels] | EvalPrediction, has_misc_tags: bool, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, dataset: Dataset) \u2192 dict[str, float] </p> <p>Compute the metrics needed for evaluation.</p> <p> Parameters </p> <ul> <li> <p>model_outputs_and_labels :  tuple[Predictions, Labels] | EvalPrediction \u2014 The first array contains the probability predictions and the second array contains the true labels.</p> </li> <li> <p>has_misc_tags :  bool \u2014 Whether the dataset has MISC tags.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> <li> <p>dataset :  Dataset \u2014 The dataset used for evaluation. This is only used in case any additional metadata is used to compute the metrics.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 A dictionary with the names of the metrics as keys and the metric values as values.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source extract_labels_from_generation(input_batch: dict[str, list], model_output: GenerativeModelOutput, dataset_config: DatasetConfig) \u2192 list[t.Any] </p> <p>Extract the predicted labels from the generated output.</p> <p> Parameters </p> <ul> <li> <p>input_batch :  dict[str, list] \u2014 The input batch, where the keys are the feature names and the values are lists with the feature values.</p> </li> <li> <p>model_output :  GenerativeModelOutput \u2014 The raw generated output of the model.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[t.Any] \u2014 The predicted labels.</p> </li> </ul> <p> source tokenize_and_align_labels(examples: dict, tokeniser: PreTrainedTokenizer, label2id: dict[str, int]) \u2192 BatchEncoding </p> <p>Tokenise all texts and align the labels with them.</p> <p> Parameters </p> <ul> <li> <p>examples :  dict \u2014 The examples to be tokenised.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 A pretrained tokeniser.</p> </li> <li> <p>label2id :  dict[str, int] \u2014 A dictionary that converts NER tags to IDs.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BatchEncoding \u2014 A dictionary containing the tokenized data as well as labels.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source handle_unk_tokens(tokeniser: PreTrainedTokenizer, tokens: list[str], words: list[str]) \u2192 list[str] </p> <p>Replace unknown tokens in the tokens with the corresponding word.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser used to tokenize the words.</p> </li> <li> <p>tokens :  list[str] \u2014 The list of tokens.</p> </li> <li> <p>words :  list[str] \u2014 The list of words.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[str] \u2014 The list of tokens with unknown tokens replaced by the corresponding word.</p> </li> </ul>"},{"location":"api/euroeval/benchmarker/","title":"euroeval.benchmarker","text":"euroeval.benchmarker<p> source module euroeval.benchmarker </p> <p>Class that benchmarks language models.</p> <p> Classes </p> <ul> <li> <p>Benchmarker \u2014 Benchmarking all the language models.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>model_has_been_benchmarked \u2014 Checks whether a model has already been benchmarked on a dataset.</p> </li> <li> <p>adjust_logging_level \u2014 Adjust the logging level based on verbosity.</p> </li> <li> <p>clear_model_cache_fn \u2014 Clear the model cache.</p> </li> <li> <p>prepare_dataset_configs \u2014 Prepare the dataset configuration(s) to be benchmarked.</p> </li> <li> <p>initial_logging \u2014 Initial logging at the start of the benchmarking process.</p> </li> </ul> <p> source class Benchmarker(progress_bar: bool = True, save_results: bool = True, task: str | list[str] | None = None, dataset: list[str] | str | None = None, language: str | list[str] = 'all', model_language: str | list[str] | None = None, dataset_language: str | list[str] | None = None, device: Device | None = None, batch_size: int = 32, raise_errors: bool = False, cache_dir: str = '.euroeval_cache', api_key: str | None = None, force: bool = False, verbose: bool = False, trust_remote_code: bool = False, clear_model_cache: bool = False, evaluate_test_split: bool = False, few_shot: bool = True, num_iterations: int = 10, api_base: str | None = None, api_version: str | None = None, gpu_memory_utilization: float = 0.9, debug: bool = False, run_with_cli: bool = False, requires_safetensors: bool = False) </p> <p>Benchmarking all the language models.</p> <p>Initialise the benchmarker.</p> <p> Attributes </p> <ul> <li> <p>benchmark_config_default_params \u2014 The default parameters for the benchmark configuration.</p> </li> <li> <p>benchmark_config \u2014 The benchmark configuration.</p> </li> <li> <p>force \u2014 Whether to force evaluations of models, even if they have been benchmarked already.</p> </li> <li> <p>results_path \u2014 The path to the results file.</p> </li> <li> <p>benchmark_results :  list[BenchmarkResult] \u2014 The benchmark results.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>progress_bar :  bool \u2014 Whether progress bars should be shown. Defaults to True.</p> </li> <li> <p>save_results :  bool \u2014 Whether to save the benchmark results to 'euroeval_benchmark_results.jsonl'. Defaults to True.</p> </li> <li> <p>task :  str | list[str] | None \u2014 The tasks benchmark the model(s) on. Mutually exclusive with <code>dataset</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked.</p> </li> <li> <p>dataset :  list[str] | str | None \u2014 The datasets to benchmark on. Mutually exclusive with <code>task</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked.</p> </li> <li> <p>language :  str | list[str] \u2014 The language codes of the languages to include, both for models and datasets. Set this to 'all' if all languages should be considered. Defaults to \"all\".</p> </li> <li> <p>model_language :  str | list[str] | None \u2014 The language codes of the languages to include for models. If specified then this overrides the <code>language</code> parameter for model languages. Defaults to None.</p> </li> <li> <p>dataset_language :  str | list[str] | None \u2014 The language codes of the languages to include for datasets. If specified then this overrides the <code>language</code> parameter for dataset languages. Defaults to None.</p> </li> <li> <p>device :  Device | None \u2014 The device to use for benchmarking. Defaults to None.</p> </li> <li> <p>batch_size :  int \u2014 The batch size to use. Defaults to 32.</p> </li> <li> <p>raise_errors :  bool \u2014 Whether to raise errors instead of skipping the model evaluation. Defaults to False.</p> </li> <li> <p>cache_dir :  str \u2014 Directory to store cached models. Defaults to '.euroeval_cache'.</p> </li> <li> <p>api_key :  str | None \u2014 The API key to use for a given inference API.</p> </li> <li> <p>force :  bool \u2014 Whether to force evaluations of models, even if they have been benchmarked already. Defaults to False.</p> </li> <li> <p>verbose :  bool \u2014 Whether to output additional output. This is automatically set if <code>debug</code> is True. Defaults to False.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code when loading models. Defaults to False.</p> </li> <li> <p>clear_model_cache :  bool \u2014 Whether to clear the model cache after benchmarking each model. Defaults to False.</p> </li> <li> <p>evaluate_test_split :  bool \u2014 Whether to evaluate the test split of the datasets. Defaults to False.</p> </li> <li> <p>few_shot :  bool \u2014 Whether to only evaluate the model using few-shot evaluation. Only relevant if the model is generative. Defaults to True.</p> </li> <li> <p>num_iterations :  int \u2014 The number of times each model should be evaluated. This is only meant to be used for power users, and scores will not be allowed on the leaderboards if this is changed. Defaults to 10.</p> </li> <li> <p>api_base :  str | None \u2014 The base URL for a given inference API. Only relevant if <code>model</code> refers to a model on an inference API. Defaults to None.</p> </li> <li> <p>api_version :  str | None \u2014 The version of the API to use. Defaults to None.</p> </li> <li> <p>gpu_memory_utilization :  float \u2014 The GPU memory utilization to use for vLLM. Only relevant if the model is generative. A larger value will result in faster evaluation, but at the risk of running out of GPU memory. Only reduce this if you are running out of GPU memory. Defaults to 0.9.</p> </li> <li> <p>debug :  bool \u2014 Whether to output debug information. Defaults to False.</p> </li> <li> <p>run_with_cli :  bool \u2014 Whether the benchmarker is being run from the command-line interface. Defaults to False.</p> </li> <li> <p>requires_safetensors :  bool \u2014 Whether to only allow models that use the safetensors format. Defaults to False.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError \u2014 If both <code>task</code> and <code>dataset</code> are specified.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>benchmark \u2014 Benchmarks models on datasets.</p> </li> </ul> <p> source property Benchmarker.benchmark_results: list[BenchmarkResult] </p> <p>The benchmark results.</p> <p> source method Benchmarker.benchmark(model: list[str] | str, task: str | list[str] | None = None, dataset: list[str] | str | None = None, progress_bar: bool | None = None, save_results: bool | None = None, language: str | list[str] | None = None, model_language: str | list[str] | None = None, dataset_language: str | list[str] | None = None, device: Device | None = None, batch_size: int | None = None, raise_errors: bool | None = None, cache_dir: str | None = None, api_key: str | None = None, force: bool | None = None, verbose: bool | None = None, trust_remote_code: bool | None = None, clear_model_cache: bool | None = None, evaluate_test_split: bool | None = None, few_shot: bool | None = None, num_iterations: int | None = None, requires_safetensors: bool | None = None) \u2192 list[BenchmarkResult] </p> <p>Benchmarks models on datasets.</p> <p> Parameters </p> <ul> <li> <p>model :  list[str] | str \u2014 The full Hugging Face Hub path(s) to the pretrained transformer model. The specific model version to use can be added after the suffix '@': \"model@v1.0.0\". It can be a branch name, a tag name, or a commit id, and defaults to the latest version if not specified.</p> </li> <li> <p>task :  str | list[str] | None \u2014 The tasks benchmark the model(s) on. Mutually exclusive with <code>dataset</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked. Defaults to None.</p> </li> <li> <p>dataset :  list[str] | str | None \u2014 The datasets to benchmark on. Mutually exclusive with <code>task</code>. If both <code>task</code> and <code>dataset</code> are None then all datasets will be benchmarked. Defaults to None.</p> </li> <li> <p>progress_bar :  bool | None \u2014 Whether progress bars should be shown. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>save_results :  bool | None \u2014 Whether to save the benchmark results to 'euroeval_benchmark_results.jsonl'. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>language :  str | list[str] | None \u2014 The language codes of the languages to include, both for models and datasets. Here 'no' means both Bokm\u00e5l (nb) and Nynorsk (nn). Set this to 'all' if all languages should be considered. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>model_language :  str | list[str] | None \u2014 The language codes of the languages to include for models. If specified then this overrides the <code>language</code> parameter for model languages. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>dataset_language :  str | list[str] | None \u2014 The language codes of the languages to include for datasets. If specified then this overrides the <code>language</code> parameter for dataset languages. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>device :  Device | None \u2014 The device to use for benchmarking. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>batch_size :  int | None \u2014 The batch size to use. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>raise_errors :  bool | None \u2014 Whether to raise errors instead of skipping the model evaluation.</p> </li> <li> <p>cache_dir :  str | None \u2014 Directory to store cached models. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>api_key :  str | None \u2014 The API key to use for a given inference server. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>force :  bool | None \u2014 Whether to force evaluations of models, even if they have been benchmarked already. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>verbose :  bool | None \u2014 Whether to output additional output. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>trust_remote_code :  bool | None \u2014 Whether to trust remote code when loading models. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>clear_model_cache :  bool | None \u2014 Whether to clear the model cache after benchmarking each model. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>evaluate_test_split :  bool | None \u2014 Whether to evaluate the test split of the datasets. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>few_shot :  bool | None \u2014 Whether to only evaluate the model using few-shot evaluation. Only relevant if the model is generative. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>num_iterations :  int | None \u2014 The number of times each model should be evaluated. This is only meant to be used for power users, and scores will not be allowed on the leaderboards if this is changed. Defaults to the value specified when initialising the benchmarker.</p> </li> <li> <p>requires_safetensors :  bool | None \u2014 Whether to only allow models that use the safetensors format. Defaults to the value specified when initialising the benchmarker.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[BenchmarkResult] \u2014 A list of benchmark results.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError \u2014 If both <code>task</code> and <code>dataset</code> are specified.</p> </li> <li> <p>benchmark_output_or_err</p> </li> <li> <p>e</p> </li> </ul> <p> source model_has_been_benchmarked(model_id: str, dataset: str, few_shot: bool, validation_split: bool, benchmark_results: list[BenchmarkResult]) \u2192 bool </p> <p>Checks whether a model has already been benchmarked on a dataset.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>dataset :  str \u2014 The dataset.</p> </li> <li> <p>few_shot :  bool \u2014 Whether the model was evaluated using few-shot evaluation.</p> </li> <li> <p>validation_split :  bool \u2014 Whether the model was evaluated on the validation split.</p> </li> <li> <p>benchmark_results :  list[BenchmarkResult] \u2014 The benchmark results.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool \u2014 Whether the model has already been evaluated on the dataset.</p> </li> </ul> <p> source adjust_logging_level(verbose: bool, ignore_testing: bool = False) \u2192 int </p> <p>Adjust the logging level based on verbosity.</p> <p> Parameters </p> <ul> <li> <p>verbose :  bool \u2014 Whether to output additional output.</p> </li> <li> <p>ignore_testing :  bool \u2014 Whether to ignore the testing flag.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>int \u2014 The logging level that was set.</p> </li> </ul> <p> source clear_model_cache_fn(cache_dir: str) \u2192 None </p> <p>Clear the model cache.</p> <p>Note that this will not remove the stored completions.</p> <p> Parameters </p> <ul> <li> <p>cache_dir :  str \u2014 The path to the cache directory.</p> </li> </ul> <p> source prepare_dataset_configs(dataset_names: list[str]) \u2192 list['DatasetConfig'] </p> <p>Prepare the dataset configuration(s) to be benchmarked.</p> <p> Parameters </p> <ul> <li> <p>dataset_names :  list[str] \u2014 The dataset names to benchmark.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list['DatasetConfig'] \u2014 The prepared list of model IDs.</p> </li> </ul> <p> source initial_logging(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 None </p> <p>Initial logging at the start of the benchmarking process.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The configuration of the model we are evaluating.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset we are evaluating on.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The general benchmark configuration.</p> </li> </ul>"},{"location":"api/euroeval/benchmark_config_factory/","title":"euroeval.benchmark_config_factory","text":"euroeval.benchmark_config_factory<p> source module euroeval.benchmark_config_factory </p> <p>Factory class for creating dataset configurations.</p> <p> Functions </p> <ul> <li> <p>build_benchmark_config \u2014 Create a benchmark configuration.</p> </li> <li> <p>get_correct_language_codes \u2014 Get correct language code(s).</p> </li> <li> <p>prepare_languages \u2014 Prepare language(s) for benchmarking.</p> </li> <li> <p>prepare_tasks_and_datasets \u2014 Prepare task(s) and dataset(s) for benchmarking.</p> </li> <li> <p>prepare_device \u2014 Prepare device for benchmarking.</p> </li> </ul> <p> source build_benchmark_config(progress_bar: bool, save_results: bool, task: str | list[str] | None, dataset: str | list[str] | None, language: str | list[str], model_language: str | list[str] | None, dataset_language: str | list[str] | None, device: Device | None, batch_size: int, raise_errors: bool, cache_dir: str, api_key: str | None, force: bool, verbose: bool, trust_remote_code: bool, clear_model_cache: bool, evaluate_test_split: bool, few_shot: bool, num_iterations: int, api_base: str | None, api_version: str | None, gpu_memory_utilization: float, debug: bool, run_with_cli: bool, requires_safetensors: bool) \u2192 BenchmarkConfig </p> <p>Create a benchmark configuration.</p> <p> Parameters </p> <ul> <li> <p>progress_bar :  bool \u2014 Whether to show a progress bar when running the benchmark.</p> </li> <li> <p>save_results :  bool \u2014 Whether to save the benchmark results to a file.</p> </li> <li> <p>task :  str | list[str] | None \u2014 The tasks to include for dataset. If None then datasets will not be filtered based on their task.</p> </li> <li> <p>dataset :  str | list[str] | None \u2014 The datasets to include for task. If None then all datasets will be included, limited by the <code>task</code> parameter.</p> </li> <li> <p>language :  str | list[str] \u2014 The language codes of the languages to include, both for models and datasets. Here 'no' means both Bokm\u00e5l (nb) and Nynorsk (nn). Set this to 'all' if all languages should be considered.</p> </li> <li> <p>model_language :  str | list[str] | None \u2014 The language codes of the languages to include for models. If None then the <code>language</code> parameter will be used.</p> </li> <li> <p>dataset_language :  str | list[str] | None \u2014 The language codes of the languages to include for datasets. If None then the <code>language</code> parameter will be used.</p> </li> <li> <p>device :  Device | None \u2014 The device to use for running the models. If None then the device will be set automatically.</p> </li> <li> <p>batch_size :  int \u2014 The batch size to use for running the models.</p> </li> <li> <p>raise_errors :  bool \u2014 Whether to raise errors when running the benchmark.</p> </li> <li> <p>cache_dir :  str \u2014 The directory to use for caching the models.</p> </li> <li> <p>api_key :  str | None \u2014 The API key to use for a given inference server.</p> </li> <li> <p>force :  bool \u2014 Whether to force the benchmark to run even if the results are already cached.</p> </li> <li> <p>verbose :  bool \u2014 Whether to print verbose output when running the benchmark. This is automatically set if <code>debug</code> is True.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code when running the benchmark.</p> </li> <li> <p>clear_model_cache :  bool \u2014 Whether to clear the model cache before running the benchmark.</p> </li> <li> <p>evaluate_test_split :  bool \u2014 Whether to use the test split for the datasets.</p> </li> <li> <p>few_shot :  bool \u2014 Whether to use few-shot learning for the models.</p> </li> <li> <p>num_iterations :  int \u2014 The number of iterations each model should be evaluated for.</p> </li> <li> <p>api_base :  str | None \u2014 The base URL for a given inference API. Only relevant if <code>model</code> refers to a model on an inference API.</p> </li> <li> <p>api_version :  str | None \u2014 The version of the API to use for a given inference API.</p> </li> <li> <p>gpu_memory_utilization :  float \u2014 The GPU memory utilization to use for vLLM. A larger value will result in faster evaluation, but at the risk of running out of GPU memory. Only reduce this if you are running out of GPU memory. Only relevant if the model is generative.</p> </li> <li> <p>debug :  bool \u2014 Whether to run the benchmark in debug mode.</p> </li> <li> <p>run_with_cli :  bool \u2014 Whether the benchmark is being run with the CLI.</p> </li> <li> <p>requires_safetensors :  bool \u2014 Whether to only allow evaluations of models stored as safetensors.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> source get_correct_language_codes(language_codes: str | list[str]) \u2192 list[str] </p> <p>Get correct language code(s).</p> <p> Parameters </p> <ul> <li> <p>language_codes :  str | list[str] \u2014 The language codes of the languages to include, both for models and datasets. Here 'no' means both Bokm\u00e5l (nb) and Nynorsk (nn). Set this to 'all' if all languages should be considered.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[str] \u2014 The correct language codes.</p> </li> </ul> <p> source prepare_languages(language_codes: str | list[str] | None, default_language_codes: list[str]) \u2192 list['Language'] </p> <p>Prepare language(s) for benchmarking.</p> <p> Parameters </p> <ul> <li> <p>language_codes :  str | list[str] | None \u2014 The language codes of the languages to include for models or datasets. If specified then this overrides the <code>language</code> parameter for model or dataset languages.</p> </li> <li> <p>default_language_codes :  list[str] \u2014 The default language codes of the languages to include.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list['Language'] \u2014 The prepared dataset languages.</p> </li> </ul> <p> source prepare_tasks_and_datasets(task: str | list[str] | None, dataset_languages: list['Language'], dataset: str | list[str] | None) \u2192 tuple[list['Task'], list[str]] </p> <p>Prepare task(s) and dataset(s) for benchmarking.</p> <p> Parameters </p> <ul> <li> <p>task :  str | list[str] | None \u2014 The tasks to include for dataset. If None then datasets will not be filtered based on their task.</p> </li> <li> <p>dataset_languages :  list['Language'] \u2014 The languages of the datasets in the benchmark.</p> </li> <li> <p>dataset :  str | list[str] | None \u2014 The datasets to include for task. If None then all datasets will be included, limited by the <code>task</code> and <code>dataset_languages</code> parameters.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple[list['Task'], list[str]] \u2014 The prepared tasks and datasets.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the task or dataset is not found in the benchmark tasks or datasets.</p> </li> </ul> <p> source prepare_device(device: Device | None) \u2192 torch.device </p> <p>Prepare device for benchmarking.</p> <p> Parameters </p> <ul> <li> <p>device :  Device | None \u2014 The device to use for running the models. If None then the device will be set automatically.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>torch.device \u2014 The prepared device.</p> </li> </ul>"},{"location":"api/euroeval/callbacks/","title":"euroeval.callbacks","text":"euroeval.callbacks<p> source module euroeval.callbacks </p> <p>Callbacks for the Hugging Face Trainer.</p> <p> Classes </p> <ul> <li> <p>NeverLeaveProgressCallback \u2014 Progress callback which never leaves the progress bar.</p> </li> </ul> <p> source class NeverLeaveProgressCallback(max_str_len: int = 100) </p> <p>Bases : ProgressCallback</p> <p>Progress callback which never leaves the progress bar.</p> <p>Initialise the callback.</p> <p> Methods </p> <ul> <li> <p>on_train_begin \u2014 Callback actions when training begins.</p> </li> <li> <p>on_step_end \u2014 Callback actions when a training step ends.</p> </li> <li> <p>on_prediction_step \u2014 Callback actions when a prediction step ends.</p> </li> </ul> <p> source method NeverLeaveProgressCallback.on_train_begin(args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs: str) \u2192 None </p> <p>Callback actions when training begins.</p> <p> source method NeverLeaveProgressCallback.on_step_end(args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs: str) \u2192 None </p> <p>Callback actions when a training step ends.</p> <p> source method NeverLeaveProgressCallback.on_prediction_step(args: TrainingArguments, state: TrainerState, control: TrainerControl, eval_dataloader: DataLoader | None = None, **kwargs: str) \u2192 None </p> <p>Callback actions when a prediction step ends.</p>"},{"location":"api/euroeval/cli/","title":"euroeval.cli","text":"euroeval.cli<p> source module euroeval.cli </p> <p>Command-line interface for benchmarking.</p> <p> Functions </p> <ul> <li> <p>benchmark \u2014 Benchmark pretrained language models on language tasks.</p> </li> </ul> <p> source benchmark(model: tuple[str], dataset: tuple[str], language: tuple[str], model_language: tuple[str], dataset_language: tuple[str], raise_errors: bool, task: tuple[str], batch_size: str, progress_bar: bool, save_results: bool, cache_dir: str, api_key: str | None, force: bool, verbose: bool, device: str | None, trust_remote_code: bool, clear_model_cache: bool, evaluate_test_split: bool, few_shot: bool, num_iterations: int, api_base: str | None, api_version: str | None, gpu_memory_utilization: float, debug: bool, requires_safetensors: bool) \u2192 None </p> <p>Benchmark pretrained language models on language tasks.</p>"},{"location":"api/euroeval/constants/","title":"euroeval.constants","text":"euroeval.constants<p> source module euroeval.constants </p> <p>Constants used throughout the project.</p>"},{"location":"api/euroeval/data_loading/","title":"euroeval.data_loading","text":"euroeval.data_loading<p> source module euroeval.data_loading </p> <p>Functions related to the loading of the data.</p> <p> Functions </p> <ul> <li> <p>load_data \u2014 Load the raw bootstrapped datasets.</p> </li> <li> <p>load_raw_data \u2014 Load the raw dataset.</p> </li> </ul> <p> source load_data(rng: Generator, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 list['DatasetDict'] </p> <p>Load the raw bootstrapped datasets.</p> <p> Parameters </p> <ul> <li> <p>rng :  Generator \u2014 The random number generator to use.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration for the dataset.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration for the benchmark.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list['DatasetDict'] \u2014 A list of bootstrapped datasets, one for each iteration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If the dataset cannot be loaded.</p> </li> <li> <p>HuggingFaceHubDown \u2014 If the Hugging Face Hub is down.</p> </li> </ul> <p> source load_raw_data(dataset_config: DatasetConfig, cache_dir: str) \u2192 DatasetDict </p> <p>Load the raw dataset.</p> <p> Parameters </p> <ul> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration for the dataset.</p> </li> <li> <p>cache_dir :  str \u2014 The directory to cache the dataset.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>DatasetDict \u2014 The dataset.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> <li> <p>HuggingFaceHubDown</p> </li> </ul>"},{"location":"api/euroeval/data_models/","title":"euroeval.data_models","text":"euroeval.data_models<p> source module euroeval.data_models </p> <p>Data models used in EuroEval.</p> <p> Classes </p> <ul> <li> <p>Language \u2014 A benchmarkable language.</p> </li> <li> <p>Task \u2014 A dataset task.</p> </li> <li> <p>BenchmarkConfig \u2014 General benchmarking configuration, across datasets and models.</p> </li> <li> <p>BenchmarkConfigParams \u2014 The parameters for the benchmark configuration.</p> </li> <li> <p>BenchmarkResult \u2014 A benchmark result.</p> </li> <li> <p>DatasetConfig \u2014 Configuration for a dataset.</p> </li> <li> <p>ModelConfig \u2014 Configuration for a model.</p> </li> <li> <p>PreparedModelInputs \u2014 The inputs to a model.</p> </li> <li> <p>GenerativeModelOutput \u2014 The output of a generative model.</p> </li> <li> <p>SingleGenerativeModelOutput \u2014 A single output of a generative model.</p> </li> <li> <p>HFModelInfo \u2014 Information about a Hugging Face model.</p> </li> <li> <p>PromptConfig \u2014 Configuration for task-specific prompting across languages.</p> </li> </ul> <p> source dataclass Language(code: str, name: str, _and_separator: str | None = field(repr=False, default=None), _or_separator: str | None = field(repr=False, default=None)) </p> <p>A benchmarkable language.</p> <p> Attributes </p> <ul> <li> <p>code :  str \u2014 The ISO 639-1 language code of the language.</p> </li> <li> <p>name :  str \u2014 The name of the language.</p> </li> <li> <p>and_separator :  optional \u2014 The word 'and' in the language.</p> </li> <li> <p>or_separator :  optional \u2014 The word 'or' in the language.</p> </li> </ul> <p> source property Language.and_separator: str </p> <p>Get the word 'and' in the language.</p> <p> Returns </p> <ul> <li> <p>str \u2014 The word 'and' in the language.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError \u2014 If <code>and_separator</code> is <code>None</code>.</p> </li> </ul> <p> source property Language.or_separator: str </p> <p>Get the word 'or' in the language.</p> <p> Returns </p> <ul> <li> <p>str \u2014 The word 'or' in the language.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>NotImplementedError \u2014 If <code>or_separator</code> is <code>None</code>.</p> </li> </ul> <p> source dataclass Task(name: str, task_group: TaskGroup, template_dict: dict['Language', 'PromptConfig'], metrics: list['Metric'], default_num_few_shot_examples: int, default_max_generated_tokens: int, default_labels: list[str], requires_zero_shot: bool = False, uses_structured_output: bool = False, uses_logprobs: bool = False, requires_logprobs: bool = False, allowed_model_types: list[ModelType] = field(default_factory=lambda: [ModelType.ENCODER, ModelType.GENERATIVE]), allowed_generative_types: list[GenerativeType] = field(default_factory=lambda: [GenerativeType.BASE, GenerativeType.INSTRUCTION_TUNED, GenerativeType.REASONING])) </p> <p>A dataset task.</p> <p> Attributes </p> <ul> <li> <p>name :  str \u2014 The name of the task.</p> </li> <li> <p>task_group :  TaskGroup \u2014 The task group of the task.</p> </li> <li> <p>template_dict :  dict['Language', 'PromptConfig'] \u2014 The template dictionary for the task, from language to prompt template.</p> </li> <li> <p>metrics :  list['Metric'] \u2014 The metrics used to evaluate the task.</p> </li> <li> <p>default_num_few_shot_examples :  int \u2014 The default number of examples to use when benchmarking the task using few-shot evaluation. For a classification task, these will be drawn evenly from each label.</p> </li> <li> <p>default_max_generated_tokens :  int \u2014 The default maximum number of tokens to generate when benchmarking the task using few-shot evaluation.</p> </li> <li> <p>default_labels :  list[str] \u2014 The default labels for datasets using this task.</p> </li> <li> <p>requires_zero_shot :  optional \u2014 Whether to only allow zero-shot evaluation for this task. If True, the task will not be evaluated using few-shot examples.</p> </li> <li> <p>uses_structured_output :  optional \u2014 Whether the task uses structured output. If True, the task will return structured output (e.g., BIO tags for NER). Defaults to False.</p> </li> <li> <p>uses_logprobs :  optional \u2014 Whether the task uses log probabilities. If True, the task will return log probabilities for the generated tokens. Defaults to False.</p> </li> <li> <p>requires_logprobs :  optional \u2014 Whether the task requires log probabilities. Implies <code>uses_logprobs</code>.</p> </li> <li> <p>allowed_model_types :  optional \u2014 A list of model types that are allowed to be evaluated on this task. Defaults to all model types being allowed.</p> </li> <li> <p>allowed_generative_types :  optional \u2014 A list of generative model types that are allowed to be evaluated on this task. If None, all generative model types are allowed. Only relevant if <code>allowed_model_types</code> includes generative models.</p> </li> </ul> <p> source dataclass BenchmarkConfig(model_languages: list[Language], dataset_languages: list[Language], tasks: list[Task], datasets: list[str], batch_size: int, raise_errors: bool, cache_dir: str, api_key: str | None, force: bool, progress_bar: bool, save_results: bool, device: torch.device, verbose: bool, trust_remote_code: bool, clear_model_cache: bool, evaluate_test_split: bool, few_shot: bool, num_iterations: int, api_base: str | None, api_version: str | None, gpu_memory_utilization: float, debug: bool, run_with_cli: bool, requires_safetensors: bool) </p> <p>General benchmarking configuration, across datasets and models.</p> <p> Attributes </p> <ul> <li> <p>model_languages :  list[Language] \u2014 The languages of the models to benchmark.</p> </li> <li> <p>dataset_languages :  list[Language] \u2014 The languages of the datasets in the benchmark.</p> </li> <li> <p>tasks :  list[Task] \u2014 The tasks benchmark the model(s) on.</p> </li> <li> <p>datasets :  list[str] \u2014 The datasets to benchmark on.</p> </li> <li> <p>batch_size :  int \u2014 The batch size to use.</p> </li> <li> <p>raise_errors :  bool \u2014 Whether to raise errors instead of skipping them.</p> </li> <li> <p>cache_dir :  str \u2014 Directory to store cached models and datasets.</p> </li> <li> <p>api_key :  str | None \u2014 The API key to use for a given inference API.</p> </li> <li> <p>force :  bool \u2014 Whether to force the benchmark to run even if the results are already cached.</p> </li> <li> <p>progress_bar :  bool \u2014 Whether to show a progress bar.</p> </li> <li> <p>save_results :  bool \u2014 Whether to save the benchmark results to 'euroeval_benchmark_results.json'.</p> </li> <li> <p>device :  torch.device \u2014 The device to use for benchmarking.</p> </li> <li> <p>verbose :  bool \u2014 Whether to print verbose output.</p> </li> <li> <p>trust_remote_code :  bool \u2014 Whether to trust remote code when loading models from the Hugging Face Hub.</p> </li> <li> <p>clear_model_cache :  bool \u2014 Whether to clear the model cache after benchmarking each model.</p> </li> <li> <p>evaluate_test_split :  bool \u2014 Whether to evaluate on the test split.</p> </li> <li> <p>few_shot :  bool \u2014 Whether to only evaluate the model using few-shot evaluation. Only relevant if the model is generative.</p> </li> <li> <p>num_iterations :  int \u2014 The number of iterations each model should be evaluated for.</p> </li> <li> <p>api_base :  str | None \u2014 The base URL for a given inference API. Only relevant if <code>model</code> refers to a model on an inference API.</p> </li> <li> <p>api_version :  str | None \u2014 The version of the API to use. Only relevant if <code>model</code> refers to a model on an inference API.</p> </li> <li> <p>gpu_memory_utilization :  float \u2014 The GPU memory utilization to use for vLLM. A larger value will result in faster evaluation, but at the risk of running out of GPU memory. Only reduce this if you are running out of GPU memory. Only relevant if the model is generative.</p> </li> <li> <p>debug :  bool \u2014 Whether to run the benchmark in debug mode.</p> </li> <li> <p>run_with_cli :  bool \u2014 Whether the benchmark is being run with the CLI.</p> </li> <li> <p>requires_safetensors :  bool \u2014 Whether to only allow models that use the safetensors format.</p> </li> </ul> <p> source class BenchmarkConfigParams(**data: Any) </p> <p>Bases : pydantic.BaseModel</p> <p>The parameters for the benchmark configuration.</p> <p>Create a new model by parsing and validating input data from keyword arguments.</p> <p>Raises [<code>ValidationError</code>][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p> Attributes </p> <ul> <li> <p>model_extra :  dict[str, Any] | None \u2014 Get extra fields set during validation.</p> </li> <li> <p>model_fields_set :  set[str] \u2014 Returns the set of fields that have been explicitly set on this model instance.</p> </li> </ul> <p> source class BenchmarkResult(**data: Any) </p> <p>Bases : pydantic.BaseModel</p> <p>A benchmark result.</p> <p>Create a new model by parsing and validating input data from keyword arguments.</p> <p>Raises [<code>ValidationError</code>][pydantic_core.ValidationError] if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p> Attributes </p> <ul> <li> <p>model_config :  ClassVar[ConfigDict] \u2014 Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p> </li> <li> <p>model_extra :  dict[str, Any] | None \u2014 Get extra fields set during validation.</p> </li> <li> <p>model_fields_set :  set[str] \u2014 Returns the set of fields that have been explicitly set on this model instance.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>from_dict \u2014 Create a benchmark result from a dictionary.</p> </li> <li> <p>append_to_results \u2014 Append the benchmark result to the results file.</p> </li> </ul> <p> source classmethod BenchmarkResult.from_dict(config: dict) \u2192 BenchmarkResult </p> <p>Create a benchmark result from a dictionary.</p> <p> Parameters </p> <ul> <li> <p>config :  dict \u2014 The configuration dictionary.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BenchmarkResult \u2014 The benchmark result.</p> </li> </ul> <p> source method BenchmarkResult.append_to_results(results_path: pathlib.Path) \u2192 None </p> <p>Append the benchmark result to the results file.</p> <p> Parameters </p> <ul> <li> <p>results_path :  pathlib.Path \u2014 The path to the results file.</p> </li> </ul> <p> source dataclass DatasetConfig(name: str, pretty_name: str, huggingface_id: str, task: Task, languages: list[Language], _prompt_prefix: str | None = None, _prompt_template: str | None = None, _instruction_prompt: str | None = None, _num_few_shot_examples: int | None = None, _max_generated_tokens: int | None = None, _labels: list[str] | None = None, _prompt_label_mapping: dict[str, str] | t.Literal['auto'] | None = None, splits: list[str] = field(default_factory=lambda: ['train', 'val', 'test']), bootstrap_samples: bool = True, unofficial: bool = False) </p> <p>Configuration for a dataset.</p> <p> Attributes </p> <ul> <li> <p>name :  str \u2014 The name of the dataset. Must be lower case with no spaces.</p> </li> <li> <p>pretty_name :  str \u2014 A longer prettier name for the dataset, which allows cases and spaces. Used for logging.</p> </li> <li> <p>huggingface_id :  str \u2014 The Hugging Face ID of the dataset.</p> </li> <li> <p>task :  Task \u2014 The task of the dataset.</p> </li> <li> <p>languages :  list[Language] \u2014 The ISO 639-1 language codes of the entries in the dataset.</p> </li> <li> <p>id2label :  dict[int, str] \u2014 The mapping from ID to label.</p> </li> <li> <p>label2id :  dict[str, int] \u2014 The mapping from label to ID.</p> </li> <li> <p>num_labels :  int \u2014 The number of labels in the dataset.</p> </li> <li> <p>_prompt_prefix :  optional \u2014 The prefix to use in the few-shot prompt. Defaults to the template for the task and language.</p> </li> <li> <p>_prompt_template :  optional \u2014 The template for the prompt to use when benchmarking the dataset using few-shot evaluation. Defaults to the template for the task and language.</p> </li> <li> <p>_instruction_prompt :  optional \u2014 The prompt to use when benchmarking the dataset using instruction-based evaluation. Defaults to the template for the task and language.</p> </li> <li> <p>_num_few_shot_examples :  optional \u2014 The number of examples to use when benchmarking the dataset using few-shot evaluation. For a classification task, these will be drawn evenly from each label. Defaults to the template for the task and language.</p> </li> <li> <p>_max_generated_tokens :  optional \u2014 The maximum number of tokens to generate when benchmarking the dataset using few-shot evaluation. Defaults to the template for the task and language.</p> </li> <li> <p>_labels :  optional \u2014 The labels in the dataset. Defaults to the template for the task and language.</p> </li> <li> <p>_prompt_label_mapping :  optional \u2014 A mapping from the labels to another phrase which is used as a substitute for the label in few-shot evaluation. If \"auto\" then the mapping will be set to a 1:1 mapping between the labels and themselves. If None then the mapping will be set to the default mapping for the task and language. Defaults to None.</p> </li> <li> <p>splits :  optional \u2014 The names of the splits in the dataset. If not provided, defaults to [\"train\", \"val\", \"test\"].</p> </li> <li> <p>bootstrap_samples :  optional \u2014 Whether to bootstrap the dataset samples. Defaults to True.</p> </li> <li> <p>unofficial :  optional \u2014 Whether the dataset is unofficial. Defaults to False.</p> </li> <li> <p>prompt_prefix :  str \u2014 The prefix to use in the few-shot prompt.</p> </li> <li> <p>prompt_template :  str \u2014 The template used during few-shot evaluation.</p> </li> <li> <p>instruction_prompt :  str \u2014 The prompt to use when evaluating instruction-tuned models.</p> </li> <li> <p>num_few_shot_examples :  int \u2014 The number of few-shot examples to use.</p> </li> <li> <p>max_generated_tokens :  int \u2014 The maximum number of tokens to generate when evaluating a model.</p> </li> <li> <p>labels :  list[str] \u2014 The labels in the dataset.</p> </li> <li> <p>prompt_label_mapping :  dict[str, str] \u2014 Mapping from English labels to localised labels.</p> </li> </ul> <p> source property DatasetConfig.prompt_prefix: str </p> <p>The prefix to use in the few-shot prompt.</p> <p> source property DatasetConfig.prompt_template: str </p> <p>The template used during few-shot evaluation.</p> <p> source property DatasetConfig.instruction_prompt: str </p> <p>The prompt to use when evaluating instruction-tuned models.</p> <p> source property DatasetConfig.num_few_shot_examples: int </p> <p>The number of few-shot examples to use.</p> <p> source property DatasetConfig.max_generated_tokens: int </p> <p>The maximum number of tokens to generate when evaluating a model.</p> <p> source property DatasetConfig.labels: list[str] </p> <p>The labels in the dataset.</p> <p> source property DatasetConfig.prompt_label_mapping: dict[str, str] </p> <p>Mapping from English labels to localised labels.</p> <p> source property DatasetConfig.id2label: dict[int, str] </p> <p>The mapping from ID to label.</p> <p> source property DatasetConfig.label2id: dict[str, int] </p> <p>The mapping from label to ID.</p> <p> source property DatasetConfig.num_labels: int </p> <p>The number of labels in the dataset.</p> <p> source dataclass ModelConfig(model_id: str, revision: str, task: str, languages: list[Language], inference_backend: InferenceBackend, merge: bool, model_type: ModelType, fresh: bool, model_cache_dir: str, adapter_base_model_id: str | None) </p> <p>Configuration for a model.</p> <p> Attributes </p> <ul> <li> <p>model_id :  str \u2014 The ID of the model.</p> </li> <li> <p>revision :  str \u2014 The revision of the model.</p> </li> <li> <p>task :  str \u2014 The task that the model was trained on.</p> </li> <li> <p>languages :  list[Language] \u2014 The languages of the model.</p> </li> <li> <p>inference_backend :  InferenceBackend \u2014 The backend used to perform inference with the model.</p> </li> <li> <p>merge :  bool \u2014 Whether the model is a merged model.</p> </li> <li> <p>model_type :  ModelType \u2014 The type of the model (e.g., encoder, base decoder, instruction tuned).</p> </li> <li> <p>fresh :  bool \u2014 Whether the model is freshly initialised.</p> </li> <li> <p>model_cache_dir :  str \u2014 The directory to cache the model in.</p> </li> <li> <p>adapter_base_model_id :  str | None \u2014 The model ID of the base model if the model is an adapter model. Can be None if the model is not an adapter model.</p> </li> </ul> <p> source dataclass PreparedModelInputs(texts: list[str] | None = None, input_ids: torch.Tensor | None = None, attention_mask: torch.Tensor | None = None) </p> <p>The inputs to a model.</p> <p> Attributes </p> <ul> <li> <p>texts :  list[str] | None \u2014 The texts to input to the model. Can be None if the input IDs and attention mask are provided instead.</p> </li> <li> <p>input_ids :  torch.Tensor | None \u2014 The input IDs of the texts. Can be None if the texts are provided instead.</p> </li> <li> <p>attention_mask :  torch.Tensor | None \u2014 The attention mask of the texts. Can be None if the texts are provided instead.</p> </li> </ul> <p> source dataclass GenerativeModelOutput(sequences: list[str], scores: list[list[list[tuple[str, float]]]] | None = None) </p> <p>The output of a generative model.</p> <p> Attributes </p> <ul> <li> <p>sequences :  list[str] \u2014 The generated sequences.</p> </li> <li> <p>scores :  list[list[list[tuple[str, float]]]] | None \u2014 The scores of the sequences. This is an array of shape (batch_size, num_tokens, num_logprobs, 2), where the last dimension contains the token and its logprob. Can be None if the scores are not available.</p> </li> </ul> <p> source dataclass SingleGenerativeModelOutput(sequence: str, scores: list[list[tuple[str, float]]] | None = None) </p> <p>A single output of a generative model.</p> <p> Attributes </p> <ul> <li> <p>sequence :  str \u2014 The generated sequence.</p> </li> <li> <p>scores :  list[list[tuple[str, float]]] | None \u2014 The scores of the sequence. This is an array of shape (num_tokens, num_logprobs, 2), where the last dimension contains the token and its logprob. Can be None if the scores are not available.</p> </li> </ul> <p> source dataclass HFModelInfo(pipeline_tag: str, tags: list[str], adapter_base_model_id: str | None) </p> <p>Information about a Hugging Face model.</p> <p> Attributes </p> <ul> <li> <p>pipeline_tag :  str \u2014 The pipeline tag of the model.</p> </li> <li> <p>tags :  list[str] \u2014 The other tags of the model.</p> </li> <li> <p>adapter_base_model_id :  str | None \u2014 The model ID of the base model if the model is an adapter model. Can be None if the model is not an adapter model.</p> </li> </ul> <p> source dataclass PromptConfig(default_prompt_prefix: str, default_prompt_template: str, default_instruction_prompt: str, default_prompt_label_mapping: dict[str, str] | t.Literal['auto']) </p> <p>Configuration for task-specific prompting across languages.</p> <p>Defines the prompt templates needed for evaluating a specific task in a given language.</p> <p> Attributes </p> <ul> <li> <p>default_prompt_prefix :  str \u2014 The default prefix to use in the few-shot prompt.</p> </li> <li> <p>default_prompt_template :  str \u2014 The default template for the prompt to use when benchmarking the dataset using few-shot evaluation.</p> </li> <li> <p>default_instruction_prompt :  str \u2014 The default prompt to use when benchmarking the dataset using instruction-based evaluation.</p> </li> <li> <p>default_prompt_label_mapping :  dict[str, str] | t.Literal['auto'] \u2014 The default mapping from the labels to another phrase which is used as a substitute for the label in few-shot evaluation. If set to \"auto\", the mapping will be set to a 1:1 mapping between the labels and themselves.</p> </li> </ul>"},{"location":"api/euroeval/enums/","title":"euroeval.enums","text":"euroeval.enums<p> source module euroeval.enums </p> <p>Enums used in the project.</p> <p> Classes </p> <ul> <li> <p>AutoStrEnum \u2014 StrEnum where auto() returns the field name in lower case.</p> </li> <li> <p>Device \u2014 The compute device to use for the evaluation.</p> </li> <li> <p>InferenceBackend \u2014 The backend used for model inference.</p> </li> <li> <p>ModelType \u2014 The type of a model.</p> </li> <li> <p>GenerativeType \u2014 The type of a generative model.</p> </li> <li> <p>DataType \u2014 The data type of the model weights.</p> </li> <li> <p>BatchingPreference \u2014 The preference for batching.</p> </li> <li> <p>TaskGroup \u2014 The overall task group of a task.</p> </li> </ul> <p> source enum AutoStrEnum(*args, **kwds) </p> <p>Bases : str, Enum</p> <p>StrEnum where auto() returns the field name in lower case.</p> <p> source enum Device(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The compute device to use for the evaluation.</p> <p> Attributes </p> <ul> <li> <p>CPU \u2014 CPU device.</p> </li> <li> <p>MPS \u2014 MPS GPU, used in M-series MacBooks.</p> </li> <li> <p>CUDA \u2014 CUDA GPU, used with NVIDIA GPUs.</p> </li> </ul> <p> source enum InferenceBackend(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The backend used for model inference.</p> <p> Attributes </p> <ul> <li> <p>TRANSFORMERS \u2014 Hugging Face <code>transformers</code> library.</p> </li> <li> <p>VLLM \u2014 VLLM library.</p> </li> <li> <p>LITELLM \u2014 LiteLLM library.</p> </li> </ul> <p> source enum ModelType(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The type of a model.</p> <p> Attributes </p> <ul> <li> <p>ENCODER \u2014 An encoder (i.e., BERT-style) model.</p> </li> <li> <p>GENERATIVE \u2014 A generative model. Can be either decoder or encoder-decoder (aka seq2seq).</p> </li> </ul> <p> source enum GenerativeType(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The type of a generative model.</p> <p> Attributes </p> <ul> <li> <p>BASE \u2014 A base (i.e., pretrained) generative model.</p> </li> <li> <p>INSTRUCTION_TUNED \u2014 An instruction-tuned generative model.</p> </li> <li> <p>REASONING \u2014 A generative reasoning model.</p> </li> </ul> <p> source enum DataType(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The data type of the model weights.</p> <p> Attributes </p> <ul> <li> <p>FP32 \u2014 32-bit floating point.</p> </li> <li> <p>FP16 \u2014 16-bit floating point.</p> </li> <li> <p>BF16 \u2014 16-bit bfloat.</p> </li> </ul> <p> source enum BatchingPreference(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The preference for batching.</p> <p> Attributes </p> <ul> <li> <p>NO_PREFERENCE \u2014 No preference for batching.</p> </li> <li> <p>SINGLE_SAMPLE \u2014 Single sample batching.</p> </li> <li> <p>ALL_AT_ONCE \u2014 All samples at once batching.</p> </li> </ul> <p> source enum TaskGroup(*args, **kwds) </p> <p>Bases : AutoStrEnum</p> <p>The overall task group of a task.</p> <p> Attributes </p> <ul> <li> <p>SEQUENCE_CLASSIFICATION \u2014 Classification of documents.</p> </li> <li> <p>MULTIPLE_CHOICE_CLASSIFICATION \u2014 Classification of documents with multiple-choice options.</p> </li> <li> <p>TOKEN_CLASSIFICATION \u2014 Token-level classification.</p> </li> <li> <p>QUESTION_ANSWERING \u2014 Extractive question answering.</p> </li> <li> <p>TEXT_TO_TEXT \u2014 Text-to-text generation.</p> </li> <li> <p>SPEED \u2014 Speed benchmark.</p> </li> </ul>"},{"location":"api/euroeval/exceptions/","title":"euroeval.exceptions","text":"euroeval.exceptions<p> source module euroeval.exceptions </p> <p>Exceptions to used by other functions.</p> <p> Classes </p> <ul> <li> <p>InvalidBenchmark \u2014 The (model, dataset) combination cannot be benchmarked.</p> </li> <li> <p>InvalidModel \u2014 The model cannot be benchmarked on any datasets.</p> </li> <li> <p>HuggingFaceHubDown \u2014 The Hugging Face Hub seems to be down.</p> </li> <li> <p>NoInternetConnection \u2014 There seems to be no internet connection.</p> </li> <li> <p>NaNValueInModelOutput \u2014 There is a NaN value in the model output.</p> </li> <li> <p>NeedsExtraInstalled \u2014 The evaluation requires extra to be installed.</p> </li> <li> <p>NeedsManualDependency \u2014 The evaluation requires a dependency to be manually installed.</p> </li> <li> <p>NeedsAdditionalArgument \u2014 The evaluation requires additional arguments to the <code>euroeval</code> command.</p> </li> <li> <p>NeedsEnvironmentVariable \u2014 The evaluation requires an environment variable to be set.</p> </li> </ul> <p> source class InvalidBenchmark(message: str = 'This model cannot be benchmarked on the given dataset.') </p> <p>Bases : Exception</p> <p>The (model, dataset) combination cannot be benchmarked.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>message :  str \u2014 The message to display.</p> </li> </ul> <p> source class InvalidModel(message: str = 'The model cannot be benchmarked on any datasets.') </p> <p>Bases : Exception</p> <p>The model cannot be benchmarked on any datasets.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>message :  str \u2014 The message to display.</p> </li> </ul> <p> source class HuggingFaceHubDown(message: str = 'The Hugging Face Hub is currently down.') </p> <p>Bases : Exception</p> <p>The Hugging Face Hub seems to be down.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>message :  str \u2014 The message to display.</p> </li> </ul> <p> source class NoInternetConnection(message: str = 'There is currently no internet connection.') </p> <p>Bases : Exception</p> <p>There seems to be no internet connection.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>message :  str \u2014 The message to display.</p> </li> </ul> <p> source class NaNValueInModelOutput(message: str = 'There is a NaN value in the model output.') </p> <p>Bases : Exception</p> <p>There is a NaN value in the model output.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>message :  str \u2014 The message to display.</p> </li> </ul> <p> source class NeedsExtraInstalled(extra: str) </p> <p>Bases : InvalidModel</p> <p>The evaluation requires extra to be installed.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>extra :  str \u2014 The extra that needs to be installed.</p> </li> </ul> <p> source class NeedsManualDependency(package: str) </p> <p>Bases : InvalidModel</p> <p>The evaluation requires a dependency to be manually installed.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>package :  str \u2014 The package that needs to be manually installed.</p> </li> </ul> <p> source class NeedsAdditionalArgument(cli_argument: str, script_argument: str, run_with_cli: bool) </p> <p>Bases : InvalidModel</p> <p>The evaluation requires additional arguments to the <code>euroeval</code> command.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>cli_argument :  str \u2014 The argument that needs to be passed to the <code>euroeval</code> command.</p> </li> <li> <p>script_argument :  str \u2014 The argument that needs to be passed to the <code>Benchmarker</code> class.</p> </li> <li> <p>run_with_cli :  bool \u2014 Whether the benchmark is being run with the CLI.</p> </li> </ul> <p> source class NeedsEnvironmentVariable(env_var: str) </p> <p>Bases : InvalidModel</p> <p>The evaluation requires an environment variable to be set.</p> <p>Initialise the exception.</p> <p> Parameters </p> <ul> <li> <p>env_var :  str \u2014 The environment variable that needs to be set.</p> </li> </ul>"},{"location":"api/euroeval/finetuning/","title":"euroeval.finetuning","text":"euroeval.finetuning<p> source module euroeval.finetuning </p> <p>Functions related to the finetuning of models.</p> <p> Functions </p> <ul> <li> <p>finetune \u2014 Evaluate a model on a dataset through finetuning.</p> </li> <li> <p>finetune_single_iteration \u2014 Run a single iteration of a benchmark.</p> </li> <li> <p>get_training_args \u2014 Get the training arguments for the current iteration.</p> </li> <li> <p>remove_extra_tensors_from_logits \u2014 If the logits are a tuple, return only the first element.</p> </li> </ul> <p> source finetune(model: BenchmarkModule, datasets: list['DatasetDict'], model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 list[dict[str, float]] </p> <p>Evaluate a model on a dataset through finetuning.</p> <p> Parameters </p> <ul> <li> <p>model :  BenchmarkModule \u2014 The model to evaluate.</p> </li> <li> <p>datasets :  list['DatasetDict'] \u2014 The datasets to use for training and evaluation.</p> </li> <li> <p>model_config :  ModelConfig \u2014 The configuration of the model.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[dict[str, float]] \u2014 A list of dicts containing the scores for each metric for each iteration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source finetune_single_iteration(model: BenchmarkModule | None, dataset: DatasetDict, training_args: TrainingArguments, model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 dict[str, float] </p> <p>Run a single iteration of a benchmark.</p> <p> Parameters </p> <ul> <li> <p>model :  BenchmarkModule | None \u2014 The model to use in the benchmark. If None then a new model will be loaded.</p> </li> <li> <p>dataset :  DatasetDict \u2014 The dataset to use for training and evaluation.</p> </li> <li> <p>training_args :  TrainingArguments \u2014 The training arguments.</p> </li> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 The scores for the test dataset.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>e</p> </li> <li> <p>InvalidBenchmark</p> </li> </ul> <p> source get_training_args(benchmark_config: BenchmarkConfig, model_config: ModelConfig, iteration_idx: int, dtype: DataType, batch_size: int | None = None) \u2192 TrainingArguments </p> <p>Get the training arguments for the current iteration.</p> <p> Parameters </p> <ul> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>iteration_idx :  int \u2014 The index of the current iteration. This is only used to generate a unique random seed for the current iteration.</p> </li> <li> <p>dtype :  DataType \u2014 The data type to use for the model weights.</p> </li> <li> <p>batch_size :  int | None \u2014 The batch size to use for the current iteration, or None if the batch size in the benchmark config should be used.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>TrainingArguments \u2014 The training arguments for the current iteration.</p> </li> </ul> <p> source remove_extra_tensors_from_logits(logits: torch.Tensor | tuple[torch.Tensor, ...], labels: torch.Tensor) \u2192 torch.Tensor | tuple[torch.Tensor, ...] </p> <p>If the logits are a tuple, return only the first element.</p> <p> Parameters </p> <ul> <li> <p>logits :  torch.Tensor | tuple[torch.Tensor, ...] \u2014 The logits to process.</p> </li> <li> <p>labels :  torch.Tensor \u2014 The labels to use for the processing.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>torch.Tensor | tuple[torch.Tensor, ...] \u2014 The processed logits.</p> </li> </ul>"},{"location":"api/euroeval/generation/","title":"euroeval.generation","text":"euroeval.generation<p> source module euroeval.generation </p> <p>Functions related to text generation of models.</p> <p> Functions </p> <ul> <li> <p>generate \u2014 Evaluate a model on a dataset through generation.</p> </li> <li> <p>generate_single_iteration \u2014 Evaluate a model on a dataset in a single iteration through generation.</p> </li> <li> <p>debug_log \u2014 Log inputs and outputs for debugging purposes.</p> </li> </ul> <p> source generate(model: BenchmarkModule, datasets: list['DatasetDict'], model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 list[dict[str, float]] </p> <p>Evaluate a model on a dataset through generation.</p> <p> Parameters </p> <ul> <li> <p>model :  BenchmarkModule \u2014 The model to evaluate.</p> </li> <li> <p>datasets :  list['DatasetDict'] \u2014 The datasets to evaluate on.</p> </li> <li> <p>model_config :  ModelConfig \u2014 The configuration of the model.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[dict[str, float]] \u2014 A list of dictionaries containing the test scores.</p> </li> </ul> <p> source generate_single_iteration(dataset: Dataset, model: BenchmarkModule, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, cache: ModelCache) \u2192 dict[str, float] </p> <p>Evaluate a model on a dataset in a single iteration through generation.</p> <p> Parameters </p> <ul> <li> <p>dataset :  Dataset \u2014 The dataset to evaluate on.</p> </li> <li> <p>model :  BenchmarkModule \u2014 The model to evaluate.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> <li> <p>cache :  ModelCache \u2014 The model output cache.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 A list of dictionaries containing the scores for each metric.</p> </li> </ul> <p> source debug_log(batch: dict[str, t.Any], model_output: GenerativeModelOutput, extracted_labels: list[dict | str | list[str]], dataset_config: DatasetConfig) \u2192 None </p> <p>Log inputs and outputs for debugging purposes.</p> <p> Parameters </p> <ul> <li> <p>batch :  dict[str, t.Any] \u2014 The batch of examples to evaluate on.</p> </li> <li> <p>model_output :  GenerativeModelOutput \u2014 The output of the model.</p> </li> <li> <p>extracted_labels :  list[dict | str | list[str]] \u2014 The extracted labels from the model output.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The configuration of the dataset.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> </ul>"},{"location":"api/euroeval/generation_utils/","title":"euroeval.generation_utils","text":"euroeval.generation_utils<p> source module euroeval.generation_utils </p> <p>Utility functions related to generative models.</p> <p> Functions </p> <ul> <li> <p>extract_few_shot_examples \u2014 Extract few-shot examples from a dataset.</p> </li> <li> <p>apply_prompt \u2014 Apply prompt template to an example, potentially with few-shot examples.</p> </li> </ul> <p> source extract_few_shot_examples(dataset: DatasetDict, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig, itr_idx: int) \u2192 list[dict[str, t.Any]] </p> <p>Extract few-shot examples from a dataset.</p> <p>This will always extract the examples from the training split.</p> <p>We ensure that the few-shot examples are unique by picking them one at a time.</p> <p> Parameters </p> <ul> <li> <p>dataset :  DatasetDict \u2014 The dataset to extract the few-shot examples from.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the dataset in the iterator.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[dict[str, t.Any]] \u2014 The few-shot examples.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark \u2014 If there are not enough short examples for few-shot learning.</p> </li> <li> <p>NotImplementedError</p> </li> </ul> <p> source apply_prompt(examples: dict[str, t.Any], few_shot_examples: list[dict[str, t.Any]], model_config: ModelConfig, dataset_config: DatasetConfig, instruction_model: bool, always_populate_text_field: bool, tokeniser: PreTrainedTokenizer | None) \u2192 dict[str, t.Any] </p> <p>Apply prompt template to an example, potentially with few-shot examples.</p> <p> Parameters </p> <ul> <li> <p>examples :  dict[str, t.Any] \u2014 The examples to apply the few-shot examples to.</p> </li> <li> <p>few_shot_examples :  list[dict[str, t.Any]] \u2014 The few-shot examples to apply.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>instruction_model :  bool \u2014 Whether the model is instruction-tuned.</p> </li> <li> <p>always_populate_text_field :  bool \u2014 Whether to always populate the 'text' field in the examples, as opposed to the 'messages' field.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer | None \u2014 The tokeniser to use for the model. If None, the tokeniser is not used.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, t.Any] \u2014 The example with the few-shot examples applied.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError</p> </li> <li> <p>NotImplementedError</p> </li> </ul>"},{"location":"api/euroeval/languages/","title":"euroeval.languages","text":"euroeval.languages<p> source module euroeval.languages </p> <p>List of languages and their language codes.</p> <p>The language codes contain both all the ISO 639-1 codes, as well as the ISO 639-3 codes for languages that do not have an ISO 639-1 code.</p> <p> Functions </p> <ul> <li> <p>get_all_languages \u2014 Get a list of all the languages.</p> </li> </ul> <p> source get_all_languages() \u2192 dict[str, Language] </p> <p>Get a list of all the languages.</p> <p> Returns </p> <ul> <li> <p>dict[str, Language] \u2014 A mapping between language codes and their configurations.</p> </li> </ul>"},{"location":"api/euroeval/model_cache/","title":"euroeval.model_cache","text":"euroeval.model_cache<p> source module euroeval.model_cache </p> <p>ModelCache class for caching model outputs.</p> <p> Classes </p> <ul> <li> <p>ModelCache \u2014 A cache for model outputs.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>split_dataset_into_cached_and_non_cached \u2014 Split a dataset into a cached and non-cached part.</p> </li> <li> <p>load_cached_model_outputs \u2014 Load the cached model outputs.</p> </li> </ul> <p> source class ModelCache(model_cache_dir: Path, cache_name: str, max_generated_tokens: int) </p> <p>A cache for model outputs.</p> <p>Initialise the model output cache.</p> <p> Attributes </p> <ul> <li> <p>model_cache_dir \u2014 The directory to store the cache in.</p> </li> <li> <p>cache_path \u2014 The path to the cache file.</p> </li> <li> <p>cache \u2014 The model output cache.</p> </li> <li> <p>max_generated_tokens \u2014 The maximum number of tokens to generate for each example.</p> </li> </ul> <p> Parameters </p> <ul> <li> <p>model_cache_dir :  Path \u2014 The directory to store the cache in.</p> </li> <li> <p>cache_name :  str \u2014 The name of the cache file.</p> </li> <li> <p>max_generated_tokens :  int \u2014 The maximum number of tokens to generate for each example.</p> </li> </ul> <p> Methods </p> <ul> <li> <p>load \u2014 Load the model output cache.</p> </li> <li> <p>save \u2014 Save the model output cache to disk.</p> </li> <li> <p>remove \u2014 Remove the cache from memory and delete it from disk.</p> </li> <li> <p>add_to_cache \u2014 Add the model input/output to the cache.</p> </li> </ul> <p> source method ModelCache.load() \u2192 None </p> <p>Load the model output cache.</p> <p> source method ModelCache.save() \u2192 None </p> <p>Save the model output cache to disk.</p> <p> source method ModelCache.remove() \u2192 None </p> <p>Remove the cache from memory and delete it from disk.</p> <p> source method ModelCache.add_to_cache(model_inputs: dict, model_output: GenerativeModelOutput) \u2192 None </p> <p>Add the model input/output to the cache.</p> <p> Parameters </p> <ul> <li> <p>model_inputs :  dict \u2014 The model inputs.</p> </li> <li> <p>model_output :  GenerativeModelOutput \u2014 The model output.</p> </li> </ul> <p> source split_dataset_into_cached_and_non_cached(dataset: Dataset, cache: ModelCache) \u2192 tuple['Dataset', 'Dataset'] </p> <p>Split a dataset into a cached and non-cached part.</p> <p> Parameters </p> <ul> <li> <p>dataset :  Dataset \u2014 The dataset to split.</p> </li> <li> <p>cache :  ModelCache \u2014 The model output cache.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple['Dataset', 'Dataset'] \u2014 The cached and non-cached parts of the dataset.</p> </li> </ul> <p> source load_cached_model_outputs(cached_dataset: Dataset, cache: ModelCache) \u2192 GenerativeModelOutput </p> <p>Load the cached model outputs.</p> <p> Parameters </p> <ul> <li> <p>cached_dataset :  Dataset \u2014 The dataset containing the cached examples.</p> </li> <li> <p>cache :  ModelCache \u2014 The model output cache.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>GenerativeModelOutput \u2014 The model output containing the cached sequences.</p> </li> </ul>"},{"location":"api/euroeval/model_config/","title":"euroeval.model_config","text":"euroeval.model_config<p> source module euroeval.model_config </p> <p>Functions related to getting the model configuration.</p> <p> Functions </p> <ul> <li> <p>get_model_config \u2014 Fetches configuration for a model.</p> </li> </ul> <p> source get_model_config(model_id: str, benchmark_config: BenchmarkConfig) \u2192 ModelConfig </p> <p>Fetches configuration for a model.</p> <p> Parameters </p> <ul> <li> <p>model_id :  str \u2014 The model ID.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The configuration of the benchmark.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ModelConfig \u2014 The model configuration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel \u2014 If all model setups can handle the model, but the model does not exist.</p> </li> </ul>"},{"location":"api/euroeval/model_loading/","title":"euroeval.model_loading","text":"euroeval.model_loading<p> source module euroeval.model_loading </p> <p>Functions related to the loading of models.</p> <p> Functions </p> <ul> <li> <p>load_model \u2014 Load a model.</p> </li> </ul> <p> source load_model(model_config: ModelConfig, dataset_config: DatasetConfig, benchmark_config: BenchmarkConfig) \u2192 BenchmarkModule </p> <p>Load a model.</p> <p> Parameters </p> <ul> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 The benchmark configuration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>BenchmarkModule \u2014 The model.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel</p> </li> </ul>"},{"location":"api/euroeval/scores/","title":"euroeval.scores","text":"euroeval.scores<p> source module euroeval.scores </p> <p>Aggregation of raw scores into the mean and a confidence interval.</p> <p> Functions </p> <ul> <li> <p>log_scores \u2014 Log the scores.</p> </li> <li> <p>aggregate_scores \u2014 Helper function to compute the mean with confidence intervals.</p> </li> </ul> <p> source log_scores(dataset_name: str, metrics: list['Metric'], scores: list[dict[str, float]], model_id: str, model_revision: str) \u2192 ScoreDict </p> <p>Log the scores.</p> <p> Parameters </p> <ul> <li> <p>dataset_name :  str \u2014 Name of the dataset.</p> </li> <li> <p>metrics :  list['Metric'] \u2014 List of metrics to log.</p> </li> <li> <p>scores :  list[dict[str, float]] \u2014 The scores that are to be logged. This is a list of dictionaries full of scores.</p> </li> <li> <p>model_id :  str \u2014 The model ID of the model that was evaluated.</p> </li> <li> <p>model_revision :  str \u2014 The revision of the model.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>ScoreDict \u2014 A dictionary with keys 'raw_scores' and 'total', with 'raw_scores' being identical to <code>scores</code> and 'total' being a dictionary with the aggregated scores (means and standard errors).</p> </li> </ul> <p> source aggregate_scores(scores: list[dict[str, float]], metric: Metric) \u2192 tuple[float, float] </p> <p>Helper function to compute the mean with confidence intervals.</p> <p> Parameters </p> <ul> <li> <p>scores :  list[dict[str, float]] \u2014 Dictionary with the names of the metrics as keys, of the form \"_\", such as \"val_f1\", and values the metric values. <li> <p>metric :  Metric \u2014 The metric, which is used to collect the correct metric from <code>scores</code>.</p> </li> <p> Returns </p> <ul> <li> <p>tuple[float, float] \u2014 A pair of floats, containing the score and the radius of its 95% confidence interval.</p> </li> </ul>"},{"location":"api/euroeval/speed_benchmark/","title":"euroeval.speed_benchmark","text":"euroeval.speed_benchmark<p> source module euroeval.speed_benchmark </p> <p>Benchmarking model inference speed.</p> <p> Functions </p> <ul> <li> <p>benchmark_speed \u2014 Benchmark model inference speed.</p> </li> <li> <p>benchmark_speed_single_iteration \u2014 Run a single iteration of the speed benchmark.</p> </li> </ul> <p> source benchmark_speed(model: BenchmarkModule, benchmark_config: BenchmarkConfig) \u2192 list[dict[str, float]] </p> <p>Benchmark model inference speed.</p> <p> Parameters </p> <ul> <li> <p>model :  BenchmarkModule \u2014 Model to use.</p> </li> <li> <p>benchmark_config :  BenchmarkConfig \u2014 Configuration for the benchmark.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[dict[str, float]] \u2014 Dictionary of scores.</p> </li> </ul> <p> source benchmark_speed_single_iteration(model: BenchmarkModule, itr_idx: int) \u2192 dict[str, float] </p> <p>Run a single iteration of the speed benchmark.</p> <p> Parameters </p> <ul> <li> <p>model :  BenchmarkModule \u2014 The model to use in the benchmark.</p> </li> <li> <p>itr_idx :  int \u2014 The index of the iteration.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, float] \u2014 A dictionary containing the scores for the current iteration.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidBenchmark</p> </li> <li> <p>ValueError</p> </li> </ul>"},{"location":"api/euroeval/tasks/","title":"euroeval.tasks","text":"euroeval.tasks<p> source module euroeval.tasks </p> <p>All benchmarks tasks used in EuroEval.</p> <p> Functions </p> <ul> <li> <p>get_all_tasks \u2014 Get a list of all the dataset tasks.</p> </li> </ul> <p> source get_all_tasks() \u2192 dict[str, Task] </p> <p>Get a list of all the dataset tasks.</p> <p> Returns </p> <ul> <li> <p>dict[str, Task] \u2014 A mapping between names of dataset tasks and their configurations.</p> </li> </ul>"},{"location":"api/euroeval/tokenization_utils/","title":"euroeval.tokenization_utils","text":"euroeval.tokenization_utils<p> source module euroeval.tokenization_utils </p> <p>Utility functions related to tokenization.</p> <p> Functions </p> <ul> <li> <p>get_special_token_metadata \u2014 Get the special token metadata for a tokeniser.</p> </li> <li> <p>should_prompts_be_stripped \u2014 Determine if we should strip the prompts for few-shot evaluation.</p> </li> <li> <p>should_prefix_space_be_added_to_labels \u2014 Determine if we should add a prefix space to the labels.</p> </li> <li> <p>get_bos_token \u2014 Get the beginning-of-sequence token from a tokeniser.</p> </li> <li> <p>get_eos_token \u2014 Get the end-of-sequence token from a tokeniser.</p> </li> <li> <p>get_pad_token \u2014 Get the padding token from a tokeniser.</p> </li> <li> <p>get_end_of_chat_token_ids \u2014 Get the end token ID for chat models.</p> </li> <li> <p>get_first_label_token_mapping \u2014 Check if the model should output scores.</p> </li> <li> <p>has_chat_template \u2014 Check if a tokeniser has a chat template.</p> </li> <li> <p>apply_chat_template \u2014 Apply the chat template to a prompt.</p> </li> </ul> <p> source get_special_token_metadata(tokeniser: PreTrainedTokenizerBase) \u2192 dict </p> <p>Get the special token metadata for a tokeniser.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizerBase \u2014 The tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict \u2014 The special token metadata.</p> </li> </ul> <p> source should_prompts_be_stripped(labels_to_be_generated: list[str], tokeniser: PreTrainedTokenizer) \u2192 bool </p> <p>Determine if we should strip the prompts for few-shot evaluation.</p> <p>This is the case if the tokeniser needs to include the space as part of the label token. The strategy is thus to tokenize a label with a preceeding colon (as in the prompts), i.e., \": positive\", and check if the tokenization starts with the tokens of \": \". If this is the case, then we should not strip the prompts, since the tokeniser produces the whitespace token separately.</p> <p> Parameters </p> <ul> <li> <p>labels_to_be_generated :  list[str] \u2014 The labels that are to be generated.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser used to tokenize the labels.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool \u2014 Whether we should strip the prompts.</p> </li> </ul> <p> source should_prefix_space_be_added_to_labels(labels_to_be_generated: list[str], tokeniser: PreTrainedTokenizer) \u2192 bool </p> <p>Determine if we should add a prefix space to the labels.</p> <p>This is the case if the prompts are stripped and the tokeniser doesn't automatically add prefix whitespaces to the labels.</p> <p> Parameters </p> <ul> <li> <p>labels_to_be_generated :  list[str] \u2014 The labels that are to be generated.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser used to tokenize the labels.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool \u2014 Whether we should add a prefix space to the labels.</p> </li> </ul> <p> source get_bos_token(tokeniser: PreTrainedTokenizer) \u2192 tuple[str, int] | tuple[None, None] </p> <p>Get the beginning-of-sequence token from a tokeniser.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple[str, int] | tuple[None, None] \u2014 A pair (token, token_id) representing the beginning-of-sequence token and its token ID, or (None, None) if no BOS token is found.</p> </li> </ul> <p> source get_eos_token(tokeniser: PreTrainedTokenizer) \u2192 tuple[str, int] | tuple[None, None] </p> <p>Get the end-of-sequence token from a tokeniser.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple[str, int] | tuple[None, None] \u2014 A pair (token, token_id) representing the end-of-sequence token and its token ID, or (None, None) if no EOS token is found.</p> </li> </ul> <p> source get_pad_token(tokeniser: PreTrainedTokenizer) \u2192 tuple[str, int] | tuple[None, None] </p> <p>Get the padding token from a tokeniser.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>tuple[str, int] | tuple[None, None] \u2014 A pair (token, token_id) representing the padding token and its token ID, or (None, None) if no padding token is found.</p> </li> </ul> <p> source get_end_of_chat_token_ids(tokeniser: PreTrainedTokenizer) \u2192 list[int] | None </p> <p>Get the end token ID for chat models.</p> <p>This is only relevant for tokenisers with a chat template.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>list[int] | None \u2014 The token IDs used to end chats, or None if the tokeniser does not have a chat template or if no end-of-chat token could be found.</p> </li> </ul> <p> source get_first_label_token_mapping(dataset_config: DatasetConfig, model_config: ModelConfig, tokeniser: PreTrainedTokenizer | None, generative_type: GenerativeType | None, log_metadata: bool) \u2192 dict[str, str] | bool </p> <p>Check if the model should output scores.</p> <p> Parameters </p> <ul> <li> <p>dataset_config :  DatasetConfig \u2014 The dataset configuration.</p> </li> <li> <p>model_config :  ModelConfig \u2014 The model configuration.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer | None \u2014 The tokeniser, or None if not available.</p> </li> <li> <p>generative_type :  GenerativeType | None \u2014 The generative type, or None if not available.</p> </li> <li> <p>log_metadata :  bool \u2014 Whether to log metadata.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict[str, str] | bool \u2014 A mapping from labels to the first token in each label, or alternatively a Boolean value indicating whether the model should output scores (if the mapping is outputted then the model will always output scores).</p> </li> </ul> <p> source has_chat_template(tokeniser: PreTrainedTokenizer) \u2192 bool </p> <p>Check if a tokeniser has a chat template.</p> <p> Parameters </p> <ul> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>bool \u2014 Whether the tokeniser has a chat template.</p> </li> </ul> <p> source apply_chat_template(conversation: list[dict[str, str]], tokeniser: PreTrainedTokenizer, tokenize: bool = False, add_generation_prompt: bool = True, **transformers_tokeniser_kwargs) \u2192 str | list[int] </p> <p>Apply the chat template to a prompt.</p> <p> Parameters </p> <ul> <li> <p>conversation :  list[dict[str, str]] \u2014 The conversation to apply the chat template to.</p> </li> <li> <p>tokeniser :  PreTrainedTokenizer \u2014 The tokeniser.</p> </li> <li> <p>tokenize :  bool \u2014 Whether to tokenize the resulting prompt, returning a list of token IDs instead of a string.</p> </li> <li> <p>add_generation_prompt :  bool \u2014 Whether to add a generation prompt at the end of the conversation. This is only relevant for regular Hugging Face tokenisers, as Mistral tokenisers always add a generation prompt.</p> </li> <li> <p>**transformers_tokeniser_kwargs \u2014 Additional keyword arguments to pass to the tokeniser, in case the tokeniser is a regular Hugging Face tokeniser.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str | list[int] \u2014 The prompt with the chat template applied, either as a string or a list of token IDs, depending on the value of <code>tokenize</code>.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>InvalidModel \u2014 If the tokeniser does not have a chat template.</p> </li> </ul>"},{"location":"api/euroeval/types/","title":"euroeval.types","text":"euroeval.types<p> source module euroeval.types </p> <p>Types used throughout the project.</p> <p> Classes </p> <ul> <li> <p>ComputeMetricsFunction \u2014 A function used to compute the metrics.</p> </li> <li> <p>ExtractLabelsFunction \u2014 A function used to extract the labels from the generated output.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>is_list_of_int \u2014 Check if an object is a list of integers.</p> </li> <li> <p>is_list_of_list_of_int \u2014 Check if an object is a list of list of integers.</p> </li> <li> <p>is_list_of_str \u2014 Check if an object is a list of integers.</p> </li> </ul> <p> source class ComputeMetricsFunction() </p> <p>Bases : t.Protocol</p> <p>A function used to compute the metrics.</p> <p> source class ExtractLabelsFunction() </p> <p>Bases : t.Protocol</p> <p>A function used to extract the labels from the generated output.</p> <p> source is_list_of_int(x: object) \u2192 t.TypeGuard[list[int]] </p> <p>Check if an object is a list of integers.</p> <p> Parameters </p> <ul> <li> <p>x :  object \u2014 The object to check.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>t.TypeGuard[list[int]] \u2014 Whether the object is a list of integers.</p> </li> </ul> <p> source is_list_of_list_of_int(x: object) \u2192 t.TypeGuard[list[list[int]]] </p> <p>Check if an object is a list of list of integers.</p> <p> Parameters </p> <ul> <li> <p>x :  object \u2014 The object to check.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>t.TypeGuard[list[list[int]]] \u2014 Whether the object is a list of list of integers.</p> </li> </ul> <p> source is_list_of_str(x: object) \u2192 t.TypeGuard[list[str]] </p> <p>Check if an object is a list of integers.</p> <p> Parameters </p> <ul> <li> <p>x :  object \u2014 The object to check.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>t.TypeGuard[list[str]] \u2014 Whether the object is a list of strings.</p> </li> </ul>"},{"location":"api/euroeval/utils/","title":"euroeval.utils","text":"euroeval.utils<p> source module euroeval.utils </p> <p>Utility functions to be used in other scripts.</p> <p> Classes </p> <ul> <li> <p>HiddenPrints \u2014 Context manager which removes all terminal output.</p> </li> </ul> <p> Functions </p> <ul> <li> <p>create_model_cache_dir \u2014 Create cache directory for a model.</p> </li> <li> <p>clear_memory \u2014 Clears the memory of unused items.</p> </li> <li> <p>enforce_reproducibility \u2014 Ensures reproducibility of experiments.</p> </li> <li> <p>block_terminal_output \u2014 Blocks libraries from writing output to the terminal.</p> </li> <li> <p>get_class_by_name \u2014 Get a class by its name.</p> </li> <li> <p>get_min_cuda_compute_capability \u2014 Gets the lowest cuda capability.</p> </li> <li> <p>internet_connection_available \u2014 Checks if internet connection is available by pinging google.com.</p> </li> <li> <p>raise_if_model_output_contains_nan_values \u2014 Raise an exception if the model output contains NaN values.</p> </li> <li> <p>scramble \u2014 Scramble a string in a bijective manner.</p> </li> <li> <p>unscramble \u2014 Unscramble a string in a bijective manner.</p> </li> <li> <p>log_once \u2014 Log a message once.</p> </li> <li> <p>get_package_version \u2014 Get the version of a package.</p> </li> <li> <p>safe_run \u2014 Run a coroutine, ensuring that the event loop is always closed when we're done.</p> </li> <li> <p>add_semaphore_and_catch_exception \u2014 Run a coroutine with a semaphore.</p> </li> <li> <p>extract_json_dict_from_string \u2014 Extract a JSON dictionary from a string.</p> </li> <li> <p>get_hf_token \u2014 Get the Hugging Face token.</p> </li> </ul> <p> source create_model_cache_dir(cache_dir: str, model_id: str) \u2192 str </p> <p>Create cache directory for a model.</p> <p> Parameters </p> <ul> <li> <p>cache_dir :  str \u2014 The cache directory.</p> </li> <li> <p>model_id :  str \u2014 The model ID.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str \u2014 The path to the cache directory.</p> </li> </ul> <p> source clear_memory() \u2192 None </p> <p>Clears the memory of unused items.</p> <p> source enforce_reproducibility(seed: int = 4242) \u2192 np.random.Generator </p> <p>Ensures reproducibility of experiments.</p> <p> Parameters </p> <ul> <li> <p>seed :  int \u2014 Seed for the random number generator.</p> </li> </ul> <p> source block_terminal_output() \u2192 None </p> <p>Blocks libraries from writing output to the terminal.</p> <p>This filters warnings from some libraries, sets the logging level to ERROR for some libraries, disabled tokeniser progress bars when using Hugging Face tokenisers, and disables most of the logging from the <code>transformers</code> library.</p> <p> source get_class_by_name(class_name: str | list[str], module_name: str) \u2192 t.Type | None </p> <p>Get a class by its name.</p> <p> Parameters </p> <ul> <li> <p>class_name :  str | list[str] \u2014 The name of the class, written in kebab-case. The corresponding class name must be the same, but written in PascalCase, and lying in a module with the same name, but written in snake_case. If a list of strings is passed, the first class that is found is returned.</p> </li> <li> <p>module_name :  str \u2014 The name of the module where the class is located.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>t.Type | None \u2014 The class. If the class is not found, None is returned.</p> </li> </ul> <p> source get_min_cuda_compute_capability() \u2192 float | None </p> <p>Gets the lowest cuda capability.</p> <p> Returns </p> <ul> <li> <p>float | None \u2014 Device capability as float, or None if CUDA is not available.</p> </li> </ul> <p> source internet_connection_available() \u2192 bool </p> <p>Checks if internet connection is available by pinging google.com.</p> <p> Returns </p> <ul> <li> <p>bool \u2014 Whether or not internet connection is available.</p> </li> </ul> <p> source class HiddenPrints() </p> <p>Context manager which removes all terminal output.</p> <p> source raise_if_model_output_contains_nan_values(model_output: Predictions) \u2192 None </p> <p>Raise an exception if the model output contains NaN values.</p> <p> Parameters </p> <ul> <li> <p>model_output :  Predictions \u2014 The model output to check.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>If the model output contains NaN values.</p> </li> <li> <p>NaNValueInModelOutput</p> </li> </ul> <p> source scramble(text: str) \u2192 str </p> <p>Scramble a string in a bijective manner.</p> <p> Parameters </p> <ul> <li> <p>text :  str \u2014 The string to scramble.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str \u2014 The scrambled string.</p> </li> </ul> <p> source unscramble(scrambled_text: str) \u2192 str </p> <p>Unscramble a string in a bijective manner.</p> <p> Parameters </p> <ul> <li> <p>scrambled_text :  str \u2014 The scrambled string to unscramble.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str \u2014 The unscrambled string.</p> </li> </ul> <p> source log_once(message: str, level: int = logging.INFO) \u2192 None </p> <p>Log a message once.</p> <p>This is ensured by caching the input/output pairs of this function, using the <code>functools.cache</code> decorator.</p> <p> Parameters </p> <ul> <li> <p>message :  str \u2014 The message to log.</p> </li> <li> <p>level :  int \u2014 The logging level. Defaults to logging.INFO.</p> </li> </ul> <p> Raises </p> <ul> <li> <p>ValueError</p> </li> </ul> <p> source get_package_version(package_name: str) \u2192 str | None </p> <p>Get the version of a package.</p> <p> Parameters </p> <ul> <li> <p>package_name :  str \u2014 The name of the package.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str | None \u2014 The version of the package, or None if the package is not installed.</p> </li> </ul> <p> source safe_run(coroutine: t.Coroutine[t.Any, t.Any, T]) \u2192 T </p> <p>Run a coroutine, ensuring that the event loop is always closed when we're done.</p> <p> Parameters </p> <ul> <li> <p>coroutine :  t.Coroutine[t.Any, t.Any, T] \u2014 The coroutine to run.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>T \u2014 The result of the coroutine.</p> </li> </ul> <p> source async add_semaphore_and_catch_exception(coroutine: t.Coroutine[t.Any, t.Any, T], semaphore: asyncio.Semaphore) \u2192 T | Exception </p> <p>Run a coroutine with a semaphore.</p> <p> Parameters </p> <ul> <li> <p>coroutine :  t.Coroutine[t.Any, t.Any, T] \u2014 The coroutine to run.</p> </li> <li> <p>semaphore :  asyncio.Semaphore \u2014 The semaphore to use.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>T | Exception \u2014 The result of the coroutine.</p> </li> </ul> <p> source extract_json_dict_from_string(s: str) \u2192 dict | None </p> <p>Extract a JSON dictionary from a string.</p> <p> Parameters </p> <ul> <li> <p>s :  str \u2014 The string to extract the JSON dictionary from.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>dict | None \u2014 The extracted JSON dictionary, or None if no JSON dictionary could be found.</p> </li> </ul> <p> source get_hf_token(api_key: str | None) \u2192 str | bool </p> <p>Get the Hugging Face token.</p> <p> Parameters </p> <ul> <li> <p>api_key :  str | None \u2014 The API key to use as the Hugging Face token. If None, we will try to extract it in other ways.</p> </li> </ul> <p> Returns </p> <ul> <li> <p>str | bool \u2014 The Hugging Face token, or True if no token is set but the user is logged in, or False if no token is set and the user is not logged in.</p> </li> </ul>"}]}