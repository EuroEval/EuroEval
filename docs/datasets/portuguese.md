# üáµüáπ Portuguese

This is an overview of all the datasets used in the European Portuguese part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### Unofficial: SST-2 PT

This dataset was published in [this paper](https://arxiv.org/abs/2404.05333) and is part of the extraglue dataset. It is created by taking the original SST-2 dataset and using machine translation (DeepL) to translate it.

The original dataset contains 67,300 training, 872 validation, and 1,820 test samples. We use 1,024 / 256 / 2,048 samples for train / val / test respectively. Given that the original validation dataset only has 1,820 sample for testing, we derive that split from the training split, while ensuring no overlaps occur. This dataset only includes positive and negative labels, no neutrals.

Here are a few examples from the training split:

```json
{
  "text": "um drama psicol√≥gico absorvente e inquietante .",
  "label": "positive"
}
```

```json
{
  "text": "tudo o que n√£o se pode suportar",
  "label": "negative"
}
```

```json
{
  "text": "m√° escrita",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Abaixo encontras documentos e os seus sentimentos correspondentes, que podem ser 'positivo' ou 'negativo'.
  ```
- Base prompt template:
  ```
  Documento: {text}
  Sentimento: {label}
  ```
- Instruction-tuned prompt template:

  ```
  Texto: {text}

  Clasifica o sentimento do documento. Responde apenas com 'positivo' ou 'negativo'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset sst2-pt
```

## Reading Comprehension

### Unofficial: BoolQ-PT

This dataset was published in [this paper](https://arxiv.org/abs/2404.05333) and is part of  the extraglue dataset. It is created by taking the original BoolQ dataset and using machine translation (DeepL) to translate it.

The original dataset has a passage, question, and yes/no label. We adapt this dataset by taking the original passage, question, and yes/no options, and turning it into a Q/A style question where the model can answer yes or no.

The original dataset contains 9,430 training, 3,270 validation, and 3,250 test samples. We use 1,024 / 256 / 2,048 samples for train / val / test respectively. We've observed some overlap in the splits, so decided to concatenate all splits into a single dataset, shuffling it, and extract splits.

Here are a few examples from the training split:

```json
{
  "text": "Texto: Animais Fant√°sticos e Onde Encontr√°-los -- Fantastic Beasts and Where to Find Them √© um livro de 2001 escrito pela autora brit√¢nica J.K. Rowling (sob o pseud√≥nimo do autor fict√≠cio Newt Scamander) sobre as criaturas m√°gicas do universo Harry Potter. A vers√£o original, ilustrada pela pr√≥pria autora, pretende ser a c√≥pia de Harry Potter do livro did√°tico com o mesmo nome mencionado em Harry Potter e a Pedra Filosofal (ou Harry Potter and the Sorcerer's Stone nos EUA), o primeiro romance da s√©rie Harry Potter. Inclui v√°rias notas no seu interior, supostamente escritas √† m√£o por Harry, Ron Weasley e Hermione Granger, detalhando as suas pr√≥prias experi√™ncias com algumas das bestas descritas e incluindo piadas relacionadas com a s√©rie original.\nPergunta: Animais fant√°sticos e onde encontr√°-los est√° relacionado com Harry Potter?\nOp√ß√µes:\na. sim\nb. n√£o",
  "label": "a"
}
```

```json
{
  "text": "Texto: Leslie Aun, vocero de la Fundaci√≥n Komen, inform√≥ que rige una nueva normativa en la organizaci√≥n conforme la cual no proceder√° el otorgamiento de subvenciones o fondos en favor de entidades que sean objeto de investigaci√≥n oficial. La pol√≠tica de Komen desacredit√≥ a Planned Parenthood a ra√≠z de una investigaci√≥n en curso que dirige el representante Cliff Stearns sobre la forma en la que esta organizaci√≥n informa y utiliza sus fondos. En su rol de director del Subcomit√© de Supervisi√≥n e Investigaci√≥n, que se encuentra bajo el paraguas del Comit√© de Energ√≠a y Comercio, Stearns conduce una investigaci√≥n para determinar si los impuestos se usan para financiar interrupciones de embarazos a trav√©s de Paternidad Planificada.\nPregunta: ¬øQu√© comit√© preside Cliff Stearns?\nOpciones:\na. Comit√© de Energ√≠a y Comercio de la C√°mara de Representantes\nb. La Fundaci√≥n Komen\nc. Planned Parenthood\nd. El Subcomit√© de Supervisi√≥n e Investigaci√≥n",
  "label": "d"
}
```

```json
{
  "text": "Texto: Payola -- Payola, na ind√∫stria musical, √© a pr√°tica ilegal de pagamento ou outro incentivo por parte das empresas discogr√°ficas para a difus√£o de grava√ß√µes na r√°dio comercial, em que a can√ß√£o √© apresentada como fazendo parte da emiss√£o normal do dia, sem o anunciar antes da emiss√£o. Ao abrigo da legisla√ß√£o dos EUA, uma esta√ß√£o de r√°dio pode tocar uma can√ß√£o espec√≠fica em troca de dinheiro, mas tal deve ser divulgado no ar como sendo um tempo de antena patrocinado, e essa reprodu√ß√£o da can√ß√£o n√£o deve ser contada como uma "emiss√£o regular".\nPergunta: A payola √© legal no Canad√° e nos Estados Unidos?\nOp√ß√µes:\na. sim\nb. n√£o",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  As seguintes s√£o perguntas de escolha m√∫ltipla (com respostas).
  ```
- Base prompt template:
  ```
  Pergunta: {text}
  Op√ß√µes:
  a. {option_a}
  b. {option_b}
  Resposta: {label}
  ```
- Instruction-tuned prompt template:

  ```
  Pergunta: {text}
  Op√ß√µes:
  a. {option_a}
  b. {option_b}

  Responde √† pergunta acima usando s√≥ 'a' ou 'b', e nada mais.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset boolq-pt
```
