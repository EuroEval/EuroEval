# ğŸ‡¬ğŸ‡· Greek

This is an overview of all the datasets used in the Greek part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### Greek-SA

This dataset was published in [this paper](https://doi.org/10.1145/2801948.2802010) and
consists of data from Twitter/X.

The original dataset contains 5,936 / 383 / 767 samples for the training,
validation, and test splits, respectively. We use 1,024 / 256 / 2,048 samples for
our training, validation and test splits, respectively. The test split is created using
additional samples from the training set.

Here are a few examples from the training split:

```json
{
    "text": "Î•ÎºÏ„ÏŒÏ‚ Ï„Î¿Ï… ÏŒÏ„Î¹ Î®Ï„Î±Î½ Ï€ÏÎ¿Î²Î»Î·Î¼Î±Ï„Î¹ÎºÏŒ Ï„Î¿ Ï„Î·Î»Î­Ï†Ï‰Î½ÏŒ Î±Ï€ÏŒ Ï„Î·Î½ Ï€ÏÏÏ„Î· Î¼Î­ÏÎ± ÏŒÏ„Î±Î½ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± Î¼Î¹Î»Î®ÏƒÏ‰ Î¼Îµ Ï„Î¿ service Î³Î¹Î±Ï„Î¯ Ï„Î¿ Ï„Î·Î»Î­Ï†Ï‰Î½ÏŒ Î´ÎµÎ½ Ï„Î¿ ÏƒÎ·ÎºÏÎ½Î¿Ï…Î½ Î¼Î¿Ï… ÎµÎ¯Ï€Î±Î½ Ï€Ï‰Ï‚ Î´ÎµÎ½ Î³Î¯Î½ÎµÏ„Î±Î¹ Î±Î½Ï„Î¹ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Î±Î»Î»Î¬ service ....ÏƒÎµ Ï„Î·Î»Î­Ï†Ï‰Î½ÏŒ Ï„Î¿Ï… ÎºÎ¿Ï…Ï„Î¹Î¿Ï....ÎºÎ±Î¹ ÏŒÏ„Î±Î½ Ï„Î¿ Î­ÏƒÏ„ÎµÎ¹Î»Î± Î½Î± Ï„Î¿ Î´Î¿Ï…Î½....Î±Ï…Ï„Î±!!!!! Î¤Î¿Ï‡Î¿ÏÎ½ 15 Î¼Î­ÏÎµÏ‚ ! ÎœÎµ Î­Ï‡Î¿Ï…Î½ Î±Ï†Î®ÏƒÎµÎ¹ Î´Î¯Ï‡Ï‰Ï‚ Ï„Î·Î»Î­Ï†Ï‰Î½Î¿ 15 Î¼Î­ÏÎµÏ‚ ÎºÎ±Î¹ Î¿ÏÏ„Îµ Î­Î½Î± Ï„Î·Î»Î­Ï†Ï‰Î½Î¿. ÎŸÏÏ„Îµ Î½Î± Î¼Î¿Ï… Ï€Î¿ÏÎ½Îµ ÎºÎ¬Ï„Î¹. Î¤ÏƒÎ±Î¼Ï€Î¯ÎºÎ± ÎºÏÎ±Ï„Î¬Î½Îµ ÎŒÎ¼Î·ÏÎ¿ ÎºÎ±Î¹ Î¼Î­Î½Î± ÎºÎ±Î¹ Ï„Î± Ï‡ÏÎ®Î¼Î±Ï„Î± Î¼Î¿Ï…. Î‘Ï€Î±ÏÎ¬Î´ÎµÎºÏ„Î¿Î¹. Î›Ï…Ï€Î¬Î¼Î±Î¹ Î³Î¹Î±Ï„Î¯ cubot Ï„Î·Î»Î­Ï†Ï‰Î½Î± Î±Î³Î¿ÏÎ¬Î¶Î±Î¼Îµ Ï€Î¬Î½Ï„Î±. ÎœÎ·Î½ Ï€Î­ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ Î±Î½Î¬Î³ÎºÎ· Ï„Î¿Ï…Ï‚. ÎœÎ±ÎºÏÎ¹Î¬!",
    "label": "negative"
}
```

```json
{
    "text": "Î¤Î¿ Ï„Î·Î»ÎµÏ†Ï‰Î½Î±ÎºÎ¹ ÎµÎ¹Î½Î±Î¹ Ï†Î±Î½Ï„Î±ÏƒÏ„Î¹ÎºÎ¿ ÎµÎ¹Î´Î¹ÎºÎ± Î³Î¹Î± Ï„Î±  Î»ÎµÏ†Ï„Î± Î±Ï…Ï„Î±! Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ· ÎµÎ¼Ï€ÎµÎ¹ÏÎ¹Î± Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼Î¿Ï… Îº Ï€Î»Î¿Î·Î³Î·ÏƒÎ·Ï‚, ÎºÎ±Ï€Î¿Î¹ÎµÏ‚ Î±Ï€ÎµÎ¹ÏÎ¿ÎµÎ»Î±Ï‡Î¹ÏƒÏ„ÎµÏ‚ ÎºÎ±Î¸Ï…ÏƒÏ„ÎµÏÎ·ÏƒÎµÎ¹Ï‚ Î”Î•Î Ï‡Î±Î»Î¿Ï…Î½ Ï„Î·Î½ Ï„ÎµÎ»Î¹ÎºÎ· ÎµÎ¼Ï€ÎµÎ¹ÏÎ¹Î±. Î ÏÏ‰Î¹Î½ÎµÏ‚ Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¹ÎµÏ‚ Ï€Î¿Î»Ï… ÎºÎ±Î»ÎµÏ‚, Î²ÏÎ±Î´Ï…Î½ÎµÏ‚ Ï€Î¿Î»Ï… Î¼ÎµÏ„ÏÎ¹ÎµÏ‚ Î±Î»Î»Î± Î¿Ï‡Î¹ ÎµÎ½Ï„ÎµÎ»Ï‰Ï‚ Ï‡Î±Î»Î¹Î±. Î¤Î¿ Î·Ï‡ÎµÎ¹Î¿ Î±ÎºÎ¿Ï…Î³ÎµÏ„Î±Î¹ Ï€Î±Î½Ï„Î±, Î´ÎµÎ½ ÎºÎ±Î»Ï…Ï€Ï„ÎµÏ„Î±Î¹ ÎºÎ¹ ÎµÎ¹Î½Î±Î¹ Î±Î¾Î¹Î¿Ï€ÏÎµÏ€ÎµÏ‚ Î³Î¹Î± ÎºÎ¹Î½Î·Ï„Î¿. ÎŸÎ¸Î¿Î½Î·, Ï„Î¿ Î´Ï…Î½Î±Ï„Î¿ Ï‡Î±ÏÏ„Î¹, ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ·, Î¼Ï€Î±Ï„Î±ÏÎ¹Î±, Î¼Îµ Î²Î³Î±Î¶ÎµÎ¹ 48 ÏƒÏ…Î½ÎµÏ‡Î¿Î¼ÎµÎ½ÎµÏ‚ Ï‰ÏÎµÏ‚ Î¼Îµ Î»Î¹Î³Î¿ gaming Ï€Î¿Î»Ï… social texting Îº Î³ÎµÎ½Î¹ÎºÏ‰Ï‚ ÏˆÎ±Ï‡Î¿Ï…Î»ÎµÎ¼Î± Î±ÏÎºÎµÏ„Î¿. ÎšÎ±Ï€Î¿Î¹Î¿ Î±ÏÎ½Î·Ï„Î¹ÎºÎ¿, Î¸Î± Î¼Ï€Î¿ÏÎ¿Ï…ÏƒÎ± Î½Î± ÎµÎ»ÎµÎ³Î± Î· Ï„Î±Ï‡Ï…Ï„Î·Ï„Î± Ï„Î¿Ï… ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„Î· , Î¼ÎµÏ„Î± Ï„Î¹Ï‚ Î²ÏÎ±Î´Ï…Î½ÎµÏ‚ Ï†Ï‰Ï„Î¿, Î±Î»Î»Î± Î¼Îµ 200+ euros Î·Î¾ÎµÏÎ± Ï„Î¹ ÎµÏ€Î±Î¹ÏÎ½Î± Îº ÎµÎ¹Î¼Î±Î¹ Ï€Î¿Î»Ï… ÎµÏ…Ï‡Î±ÏÎ¹ÏƒÏ„Î·Î¼ÎµÎ½Î¿Ï‚.",
    "label": "positive"
}
```

```json
{
    "text": "Î¤ÏŒÏƒÎ· Î±Ï…Ï„Î¿Î»ÏÏ€Î·ÏƒÎ· ÏƒÏ„Î¿ Î Î‘Î£ÎŸÎš, ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î± Î½Î± Ï„Î¿Ï…Ï‚ Î»Ï…Ï€Î¬ÏƒÎ±Î¹. #dendiavasetomnimonio",
    "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Î¤Î± Î±ÎºÏŒÎ»Î¿Ï…Î¸Î± ÎµÎ¯Î½Î±Î¹ Î­Î³Î³ÏÎ±Ï†Î± ÎºÎ±Î¹ Ï„Î¿ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î¬ Ï„Î¿Ï…Ï‚, Ï„Î¿ Î¿Ï€Î¿Î¯Î¿ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ 'Î¸ÎµÏ„Î¹ÎºÏŒ', 'Î¿Ï…Î´Î­Ï„ÎµÏÎ¿' Î® 'Î±ÏÎ½Î·Ï„Î¹ÎºÏŒ'.
  ```

- Base prompt template:

  ```text
  ÎˆÎ³Î³ÏÎ±Ï†Î¿: {text}
  Î£Ï…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î±: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  ÎˆÎ³Î³ÏÎ±Ï†Î¿: {text}

  Î¤Î±Î¾Î¹Î½Î¿Î¼Î®ÏƒÏ„Îµ Ï„Î¿ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î± ÏƒÏ„Î¿ Î­Î³Î³ÏÎ±Ï†Î¿. Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ Î¼Îµ 'Î¸ÎµÏ„Î¹ÎºÏŒ', 'Î¿Ï…Î´Î­Ï„ÎµÏÎ¿', Î® 'Î±ÏÎ½Î·Ï„Î¹ÎºÏŒ', ÎºÎ±Î¹ Ï„Î¯Ï€Î¿Ï„Î± Î¬Î»Î»Î¿.
  ```

- Label mapping:
  - `positive` â¡ï¸ `Î¸ÎµÏ„Î¹ÎºÏŒ`
  - `negative` â¡ï¸ `Î±ÏÎ½Î·Ï„Î¹ÎºÏŒ`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset greek-sa
```

## Named Entity Recognition

### UNER-sk

This dataset was published in
[this paper](https://aclanthology.org/2024.naacl-long.243/).

The original dataset consists of 8,482 / 1,059 / 1,060 samples for the
training, validation, and test splits, respectively. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively. The train and
validation splits are subsets of the original splits, while the test split is
created using additional samples from the train split.

Here are a few examples from the training split:

```json
{
  "tokens": ["Bude", "maÅ¥", "nÃ¡zov", "Shanghai", "Noon", "a", "reÅ¾isÃ©rom", "bude", "debutujÃºci", "Tom", "Dey", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-PER", "I-PER", "O"]
}
```

```json
{
  "tokens": ["Ako", "Å¡esÅ¥roÄnÃ©ho", "(", "o", "rok", "skÃ´r", ",", "neÅ¾", "bolo", "zvykom", ")", "ho", "na", "zÃ¡klade", "zvlÃ¡Å¡tnej", "vÃ½nimky", "prijali", "medzi", "Zvedov", "a", "ako", "devÃ¤Å¥roÄnÃ½", "sa", "stal", "vedÃºcim", "skupiny", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

```json
{
  "tokens": ["To", "predsa", "stojÃ­", "za", "pokus", "!"],
  "labels": ["O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  NasledujÃºce sÃº vety a JSON-objekty s pomenovanÃ½mi entitami, ktorÃ© sa nachÃ¡dzajÃº v danej vete.
  ```

- Base prompt template:

  ```text
  Veta: {text}
  PomenovanÃ© entity: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Veta: {text}

  Identifikujte pomenovanÃ© entity vo vete. VÃ½stup by mal byÅ¥ vo forme JSON-objektu s kÄ¾ÃºÄmi 'osoba', 'miesto', 'organizÃ¡cia' a 'rÃ´zne'. Hodnoty by mali byÅ¥ zoznamy pomenovanÃ½ch entÃ­t danej kategÃ³rie, presne tak, ako sa vyskytujÃº vo vete.
  ```

- Label mapping:
  - `B-PER` â¡ï¸ `osoba`
  - `I-PER` â¡ï¸ `osoba`
  - `B-LOC` â¡ï¸ `miesto`
  - `I-LOC` â¡ï¸ `miesto`
  - `B-ORG` â¡ï¸ `organizÃ¡cia`
  - `I-ORG` â¡ï¸ `organizÃ¡cia`
  - `B-MISC` â¡ï¸ `rÃ´zne`
  - `I-MISC` â¡ï¸ `rÃ´zne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset uner-sk
```

## Linguistic Acceptability

### ScaLA-el

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Greek Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Greek-GUD) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "Î Î¯ÏƒÏ‰ Ïƒ Ï„Î¿ Î³ÏÎ±Ï†ÎµÎ¯Î¿, Ï€ÏÎ¿ÏƒÏ€Î±Î¸Ï Î½Î± Î²Î¬Î»Ï‰ ÏƒÎµ Ï„Î¬Î¾Î· Ï„Î¹Ï‚ ÏƒÎºÎ­ÏˆÎµÎ¹Ï‚ Î¼Î¿Ï….",
    "label": "correct"
}
```

```json
{
    "text": "Î ÏÏÏ„Î± Î­ÎºÎ±Î½Îµ Ï„Î·Î½ ÎºÎ¿Ï…Ï„ÏƒÎ¿Ï…ÎºÎ­Î»Î± Ï„Î·Ï‚ ÎºÎ±Î¹ Î¼ÎµÏ„Î¬ Î¬ÏÏ‡Î¹Î¶Îµ Ï„Î¹Ï‚ Î´Î¹Î±Ï‡ÏÏƒÎµÎ¹Ï‚.",
    "label": "correct"
}
```

```json
{
    "text": "Î‘Î½ Î±Ï€Î¿Ï†Î±ÏƒÎ¯ÏƒÎµÎ¹ ÏŒÏ„Î¹ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÎ¿Ï…Î¼Îµ Ï„Î·Î½ Î­ÏÎµÏ…Î½Î±, Î¸Î± Î¶Î·Ï„Î®ÏƒÎ¿Ï…Î¼Îµ Î³ÏÎ±Ï€Ï„Î® ÎµÎ½Ï„Î¿Î»Î®.",
    "label": "correct"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  ÎŸÎ¹ Î±ÎºÏŒÎ»Î¿Ï…Î¸ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎµÎ¬Î½ ÎµÎ¯Î½Î±Î¹ Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ¬ ÏƒÏ‰ÏƒÏ„Î­Ï‚.
  ```

- Base prompt template:

  ```text
  Î ÏÏŒÏ„Î±ÏƒÎ·: {text}
  Î“ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ¬ ÏƒÏ‰ÏƒÏ„Î®: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Î ÏÏŒÏ„Î±ÏƒÎ·: {text}

  Î ÏÎ¿ÏƒÎ´Î¹Î¿ÏÎ¯ÏƒÏ„Îµ ÎµÎ¬Î½ Î· Ï€ÏÏŒÏ„Î±ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ¬ ÏƒÏ‰ÏƒÏ„Î® Î® ÏŒÏ‡Î¹. Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ Î¼Îµ 'Î½Î±Î¹' Î±Î½ ÎµÎ¯Î½Î±Î¹ ÏƒÏ‰ÏƒÏ„Î®, Î® 'ÏŒÏ‡Î¹' Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹. Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ Î¼ÏŒÎ½Î¿ Î¼Îµ Î±Ï…Ï„Î® Ï„Î· Î»Î­Î¾Î·, ÎºÎ±Î¹ Ï„Î¯Ï€Î¿Ï„Î± Î¬Î»Î»Î¿.
  ```

- Label mapping:
  - `correct` â¡ï¸ `Î½Î±Î¹`
  - `incorrect` â¡ï¸ `ÏŒÏ‡Î¹`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-el
```

## Reading Comprehension

### MultiWikiQA-sk

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
  "context": "Register toxickÃ½ch ÃºÄinkov chemickÃ½ch lÃ¡tok (anglicky Registry of Toxic Effects of Chemical Substances, RTECS) je databÃ¡za toxikologickÃ½ch informÃ¡ciÃ­ zostavenÃ½ch z voÄ¾ne dostupnej vedeckej literatÃºry bez odkazu na platnosÅ¥ alebo uÅ¾itoÄnosÅ¥ publikovanÃ½ch Å¡tÃºdiÃ­. Do roku 2001 bola databÃ¡za spravovanÃ¡ americkou organizÃ¡ciou NIOSH (National Institute for Occupational Safety and Health, slov. NÃ¡rodnÃ½ Ãºstav pre bezpeÄnosÅ¥ a ochranu zdravia pri prÃ¡ci) ako verejne dostupnÃ¡ publikÃ¡cia. Teraz ju spravuje sÃºkromnÃ¡ spoloÄnosÅ¥ Symyx Technologies a je dostupnÃ¡ len za poplatok.\n\nObsah \nDatabÃ¡za obsahuje Å¡esÅ¥ typov toxikologickÃ½ch informÃ¡ciÃ­:\n primÃ¡rne podrÃ¡Å¾denie\n mutagÃ©nne ÃºÄinky\n reprodukÄnÃ© ÃºÄinky\n karcinogÃ©nne ÃºÄinky\n akÃºtna toxicita\n toxicita viacnÃ¡sobnÃ½ch dÃ¡vok\nV databÃ¡ze sa spomÃ­najÃº ako Å¡pecifickÃ© ÄÃ­selnÃ© hodnoty, ako naprÃ­klad LD50, LC50, TDLo alebo TCLo, tak aj Å¡tudovanÃ© organizmy a spÃ´sob podÃ¡vania lÃ¡tky. Pre vÅ¡etky dÃ¡ta sÃº uvedenÃ© bibliografickÃ© zdroje. Å tÃºdie pritom nie sÃº nijako hodnotenÃ©.\n\nHistÃ³ria \nDatabÃ¡za RTECS bola aktivitou schvÃ¡lenou americkÃ½m Kongresom, zakotvenou v Sekcii 20(a)(6) zÃ¡kona Occupational Safety and Health Act z roku 1970 (PL 91-596). PÃ´vodnÃ© vydanie, znÃ¡me ako Zoznam toxickÃ½ch lÃ¡tok (Toxic Substances List), bolo publikovanÃ© 28. jÃºna 1971 a obsahovalo toxikologickÃ© dÃ¡ta o pribliÅ¾ne 5 000 chemikÃ¡liÃ¡ch. NÃ¡zov bol neskÃ´r zmenenÃ½ na dneÅ¡nÃ½ Register toxickÃ½ch ÃºÄinkov chemickÃ½ch lÃ¡tok (Registry of Toxic Effects of Chemical Substances). V januÃ¡ri 2001 databÃ¡za obsahovala 152 970 chemikÃ¡liÃ­. V decembri 2001 bola sprÃ¡va RTECS prevedenÃ¡ z NIOSH do sÃºkromnej firmy Elsevier MDL. TÃºto firmu kÃºpila v roku 2007 spoloÄnosÅ¥ Symyx, sÃºÄasÅ¥ou akvizÃ­cie bola aj databÃ¡za RTECS. TÃ¡ je teraz dostupnÃ¡ len za poplatok vo forme roÄnÃ©ho predplatnÃ©ho.\n\nRTECS je k dispozÃ­cii v angliÄtine, francÃºzÅ¡tine a Å¡panielÄine, a to prostrednÃ­ctvom KanadskÃ©ho centra pre bezpeÄnosÅ¥ a ochranu zdravia pri prÃ¡ci. Predplatitelia majÃº prÃ­stup cez web, na CD-ROM a vo formÃ¡te pre intranet. DatabÃ¡za je dostupnÃ¡ na webe aj cez NISC (National Information Services Corporation) a ExPub (Expert Publishing, LLC).\n\nExternÃ© odkazy \n\n RTECS overview \n Symyx website \n Expert Publishing, LLC Website\n\nZdroj \n\nChemickÃ© nÃ¡zvy a kÃ³dy\nToxikolÃ³gia",
  "question": "AkÃ© sÃº tri moÅ¾nosti prÃ­stupu k databÃ¡ze RTECS, ak som predplatiteÄ¾?",
  "answers": {"answer_start": [1949], "text": ["cez web, na CD-ROM a vo formÃ¡te pre intranet"]}}
```

```json
{
  "context": "Herta NaglovÃ¡-DocekalovÃ¡ (* 29. mÃ¡j 1944, Wels, RakÃºsko) je rakÃºska filozofka a profesorka, Älenka vedenia MedzinÃ¡rodnej asociÃ¡cie filozofiek (IAPf), Ã–sterreichische Akademie der Wissenschaften, Institut International de Philosophie (ParÃ­Å¾), viceprezidentka FÃ©dÃ©ration Internationale des SociÃ©tÃ©s de Philosophie (FISP), zakladajÃºca Älenka interdisciplinÃ¡rnych pracovnÃ½ch skupÃ­n Frauengeschichte a Philosophische Frauenforschung na Viedenskej univerzite, Älenka redakÄnÃ½ch rÃ¡d poprednÃ½ch vedeckÃ½ch Äasopisov, napr. Philosophin, LÂ´Homme, Deutsche Zeitschrift fÃ¼r Philosophie.\n\nÅ½ivotopis \nVyÅ¡tudovala histÃ³riu, filozofiu a germanistiku na Viedenskej univerzite. V roku 1967 zÃ­skala na svojej alma mater doktorÃ¡t z histÃ³rie prÃ¡cou o filozofovi dejÃ­n Ernstovi von Lasaulx). V rokoch 1968 - 1985 bola asistentkou na InÅ¡titÃºte filozofie Viedenskej univerzity. V lete 1980 prednÃ¡Å¡ala na Millersville University of Pennsylvania v USA.\n\nV roku 1981 sa habilitovala z filozofie na Viedenskej univerzite dielom Die ObjektivitÃ¤t der Geschichtswissenschaft. V rokoch 1985 aÅ¾ 2009 bola profesorkou InÅ¡titÃºtu filozofie Viedenskej univerzity. Od roku 2009 je univerzitnou profesorkou na dÃ´chodku (UniversitÃ¤tsprofessorin i. R.)\n\nBola hosÅ¥ujÃºcou profesorkou v roku 1990 na Universiteit Utrecht v holandskom Utrechte; v Nemecku 1991/1992 na Goethe-UniversitÃ¤t Frankfurt vo Frankfurte nad Mohanom; 1993 na UniversitÃ¤t Konstanz v Konstanzi; 1994/1995 na Freie UniversitÃ¤t Berlin v BerlÃ­ne. V rokoch 1995/1996 prednÃ¡Å¡ala na UniversitÃ¤t Innsbruck a 2011 na univerzite v Petrohrade v Rusku.\n\nDielo (vÃ½ber) \n Jenseits der SÃ¤kularisierung. Religionsphilosophische Studien. - Berlin 2008 (Hg., gem.m. Friedrich Wolfram).\n Viele Religionen - eine Vernunft? Ein Disput zu Hegel. - Wien/Berlin 2008 (Hg., gem.m. Wolfgang Kaltenbacher und Ludwig Nagl).\n Glauben und Wissen. Ein Symposium mit JÃ¼rgen Habermas. - Wien/Berlin 2007 (Hg., gem.m. Rudolf Langthaler).\n Geschichtsphilosophie und Kulturkritik. - Darmstadt 2003 (Hrsg., gem.m. Johannes Rohbeck).\n Feministische Philosophie. Ergebnisse, Probleme, Perspektiven. - Frankfurt a.M. 2000 a 2004 \n Continental Philosophy in Feminist Perspective. - Pennsylviania State University Press 2000 (Hg. gem.m. Cornelia Klingler).\n Der Sinn des Historischen. - Frankfurt a.M. 1996 (Hrsg.).\n Politische Theorie. Differenz und LebensqualitÃ¤t. - Frankfurt a.M. 1996 (Hrsg. gem.m. Herlinde Pauer-Studer).\n Postkoloniales Philosophieren: Afrika. - Wien/MÃ¼nchen 1992 (Hrsg., gem.m. Franz Wimmer).\n Tod des Subjekts? - Wien/MÃ¼nchen 1987 (Hrsg., gem.m. Helmuth Vetter).\n Die ObjektivitÃ¤t der Geschichtswissenschaft. Systematische Untersuchungen zum wissenschaftlichen Status der Historie. - Wien/MÃ¼nchen 1982\n spoluvydavateÄ¾ka: Wiener Reihe. Themen der Philosophie (od 1986). \n spoluvydavateÄ¾ka: Deutsche Zeitschrift fÃ¼r Philosophie (1993-2004). \n spoluvydavateÄ¾ka: L'Homme. EuropÃ¤ische Zeitschrift fÃ¼r feministische Geschichtswissenschaft (1990 - 2003).\n\nOcenenia \n FÃ¶rderpreis mesta ViedeÅˆ, 1983\n KÃ¤the Leichter Preis (rakÃºska Å¡tÃ¡tna cena), 1997 \n Preis fÃ¼r Geistes- und Sozialwissenschaften der Stadt Wien, 2009\n\nReferencie\n\nExternÃ© odkazy \n OficiÃ¡lna strÃ¡nka, UniversitÃ¤t Wien \n Austria Forum, Wissenssammlungen/Biographien: Herta Nagl-Docekal\n\nZdroj \n\nRakÃºski filozofi",
  "question": "Kedy priÅ¡la na svet Herta NaglovÃ¡-DocekalovÃ¡?",
  "answers": {"answer_start": [28], "text": ["29. mÃ¡j 1944"]}}
```

```json
{
  "context": "Martin BareÅ¡ (* 25. november 1968, Brno) je ÄeskÃ½ profesor neurolÃ³gie, od septembra 2019 rektor Masarykovej univerzity, predtÃ½m od februÃ¡ra 2018 do septembra 2019 dekan LekÃ¡rskej fakulty Masarykovej univerzity.\n\nRiadiace funkcie \nVo februÃ¡ri 2018 sa stal dekanom LekÃ¡rskej fakulty Masarykovej univerzity. Funkciu prevzal po JiÅ™Ã­m Mayerovi, ktorÃ½ zastÃ¡val pozÃ­ciu dekana v obdobÃ­ 20102018. S nÃ¡stupom na post dekana ukonÄil svoje pÃ´sobenie ako prorektor univerzity, ako i zÃ¡stupca prednostu I. neurologickej kliniky pre vedu a vÃ½skum.\n\nDo funkcie rektora univerzity bol zvolenÃ½ 1. aprÃ­la 2019 AkademickÃ½m senÃ¡tom Masarykovej univerzity. V prvom kole tajnej voÄ¾by zÃ­skal BareÅ¡ 36 hlasov z 50 prÃ­tomnÃ½ch senÃ¡torov. ProtikandidÃ¡ta, prodekana PrÃ­rodovedeckej fakulty JaromÃ­ra Leichmana, volilo 11 senÃ¡torov. 3 odovzdanÃ© hlasy boli neplatnÃ©.\n\nSkÃºsenosti s pÃ´sobenÃ­m vo vedenÃ­ Å¡koly zbieral BareÅ¡ v rokoch 20112018, kedy pÃ´sobil najskÃ´r ako jej prorektor pre rozvoj a potom ako prorektor pre akademickÃ© zÃ¡leÅ¾itosti. Za svoje priority oznaÄil BareÅ¡ v dobe voÄ¾by posilÅˆovanie role univerzity ako piliera slobody v sÃºÄasnej spoloÄnosti a zvÃ½Å¡enie kvality vzdelÃ¡vania, vedy a vÃ½skumu na medzinÃ¡rodnej Ãºrovni.\n\nDo funkcie rektora ho vymenoval 11. jÃºna 2019 prezident MiloÅ¡ Zeman s ÃºÄinnosÅ¥ou od 1. septembra 2019. Vo funkcii tak nahradil MikulÃ¡Å¡a Beka, ktorÃ©mu sa skonÄilo druhÃ© volebnÃ© obdobie a o zvolenie sa teda uÅ¾ opÃ¤Å¥ uchÃ¡dzaÅ¥ nemohol. BareÅ¡ k 1. septembru 2019 rezignoval na post dekana LekÃ¡rskej fakulty.\n\nVedeckÃ¡ ÄinnosÅ¥ \nJe prednÃ¡Å¡ajÃºcim v odboroch vÅ¡eobecnÃ© lekÃ¡rstvo, zubnÃ© lekÃ¡rstvo, optometria, fyzioterapia, neurofyziolÃ³gia pre Å¡tudentov prÃ­rodnÃ½ch vied LekÃ¡rskej fakulty Masarykovej univerzity a Å¡koliteÄ¾ doktorandov odborovej rady neurolÃ³gia a neurovedy.\n\nPÃ´sobÃ­ v tÃ½chto vedeckÃ½ch radÃ¡ch: Masarykova univerzita, LekÃ¡rska fakulta Masarykovej univerzity a CEITEC MU. Äalej tieÅ¾ Univerzita PalackÃ©ho v Olomouci, LekÃ¡rska fakulta UPOL, Fakulta veterinÃ¡rnÃ­ho lÃ©kaÅ™stvÃ­ VFU, Äalej je tieÅ¾ Älenom ÄŒeskej lekÃ¡rskej komory, ÄŒeskej neurologickej spoloÄnosti, ÄŒeskej spoloÄnosti klinickej neurofyziolÃ³gie, ÄŒeskej lekÃ¡rskej spoloÄnosti Jana Evangelisty PurkynÄ›, Movement Disorders Society, Society for the Research on the Cerebellum a Society for Neuroscience. Takisto je Älenom redakÄnej rady Äasopisov Clinical Neurophysiology, Behavioural Neurology, Tremor and Other Hyperkinetic Movements a Biomedical Papers.\n\nOsobnÃ½ Å¾ivot \nJe Å¾enatÃ½, mÃ¡ dvoch synov a dcÃ©ru.\n\nReferencie\n\nExternÃ© odkazy \n Martin BareÅ¡\n\nZdroj \n\nÄŒeskÃ­ lekÃ¡ri\nNeurolÃ³govia\nRektori Masarykovej univerzity\nÄŒeskÃ­ univerzitnÃ­ profesori\nDekani LekÃ¡rskej fakulty Masarykovej univerzity\nAbsolventi LekÃ¡rskej fakulty Masarykovej univerzity\nOsobnosti z Brna",
  "question": "AkÃº pozÃ­ciu mal Martin BareÅ¡ na Masarykovej univerzite poÄnÃºc septembrom 2019?",
  "answers": {
    "answer_start": [89],
    "text": ["rektor"]
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  NasledujÃº texty s pridruÅ¾enÃ½mi otÃ¡zkami a odpoveÄami.
  ```

- Base prompt template:

  ```text
  Text: {text}
  OtÃ¡zka: {question}
  OdpoveÄ na maximÃ¡lne 3 slovÃ¡:
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Odpovedzte na nasledujÃºcu otÃ¡zku tÃ½kajÃºcu sa textu uvedenÃ©ho vyÅ¡Å¡ie maximÃ¡lne 3 slovami.

  OtÃ¡zka: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-sk
```

## Knowledge

### MMLU-sk

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Slovak was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "V akÃ½ch smeroch je prÃ­pad pre humanitÃ¡rnu intervenciu, ako je uvedenÃ© v tejto kapitol... mocnÃ½mi Å¡tÃ¡tmi.\nd. VÅ¡etky tieto moÅ¾nosti.",
  "label": "d",
}
```

```json
{
  "text": "FAKTORIÃLOVÃ ANOVA sa pouÅ¾Ã­va v prÃ­pade, Å¾e Å¡tÃºdia zahÅ•Åˆa viac ako 1 VI. AkÃ½ je INTER...Äinok VI na rovnakej Ãºrovni ako ostatnÃ© VI",
  "label": "a"
}
```

```json
{
  "text": "Pre ktorÃº z tÃ½chto dvoch situÃ¡ciÃ­ urobÃ­ hlavnÃ¡ postava (ktorÃ¡ pouÅ¾Ã­va ja/mÅˆa/mÃ´j) nie...ie zlÃ©\nc. Nie zlÃ©, zlÃ©\nd. Nie zlÃ©, nie zlÃ©",
  "label": "d",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  NasledujÃº otÃ¡zky s viacerÃ½mi moÅ¾nosÅ¥ami (s odpoveÄami).
  ```

- Base prompt template:

  ```text
  OtÃ¡zka: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  OdpoveÄ: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  OtÃ¡zka: {text}

  Odpovedzte na nasledujÃºcu otÃ¡zku pouÅ¾itÃ­m 'a', 'b', 'c' alebo 'd', a niÄ inÃ©.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-sk
```

### Winogrande-sk

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "NedokÃ¡zal som ovlÃ¡daÅ¥ vlhkosÅ¥ ako som ovlÃ¡dal dÃ¡Å¾Ä, pretoÅ¾e _ prichÃ¡dzalo odvÅ¡adiaÄ¾. Na koho sa vzÅ¥ahuje prÃ¡zdne miesto _?\nMoÅ¾nosti:\na. MoÅ¾nosÅ¥ A: vlhkosÅ¥\nb. MoÅ¾nosÅ¥ B: dÃ¡Å¾Ä",
  "label": "a"
}
```

```json
{
  "text": "Jessica si myslela, Å¾e Sandstorm je najlepÅ¡ia pieseÅˆ, akÃ¡ bola kedy napÃ­sanÃ¡, ale Patricia ju nenÃ¡videla. _ si kÃºpila lÃ­stok na jazzovÃ½ koncert. Na koho sa vzÅ¥ahuje prÃ¡zdne miesto _?\nMoÅ¾nosti:\na. MoÅ¾nosÅ¥ A: Jessica\nb. MoÅ¾nosÅ¥ B: Patricia",
  "label": "b"
}
```

```json
{
  "text": "Termostat ukazoval, Å¾e dole bolo o dvadsaÅ¥ stupÅˆov chladnejÅ¡ie ako hore, takÅ¾e Byron zostal v _ pretoÅ¾e mu bola zima. Na koho sa vzÅ¥ahuje prÃ¡zdne miesto _?\nMoÅ¾nosti:\na. MoÅ¾nosÅ¥ A: dole\nb. MoÅ¾nosÅ¥ B: hore",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  NasledujÃº otÃ¡zky s viacerÃ½mi moÅ¾nosÅ¥ami (s odpoveÄami).
  ```

- Base prompt template:

  ```text
  OtÃ¡zka: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}
  OdpoveÄ: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  OtÃ¡zka: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}

  Odpovedzte na nasledujÃºcu otÃ¡zku pouÅ¾itÃ­m 'a' alebo 'b', a niÄ inÃ©.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-sk
```
