# üá™üá™ Estonian

This is an overview of all the datasets used in the Estonian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Estonian Valence Corpus

This dataset was published in [this paper](http://dx.doi.org/10.7592/FEJF2016.64.polarity). The dataset was compiled of articles of different rubrics of online
dailies, weeklies, and reader comments, while the polarity of each paragraph was determined by native Estonian readers.

There are 4 labels in the original dataset instead of the usual 3.
Examples with the labels representing 'mixed' emotion (vastuoluline) were filtered out
mainly to be consistent with rest of the languages in EuroEval.

The original full dataset consists of 3,277 / 818 samples for the training and test splits,
respectively. Having filtered out 'mixed' examples, we truncate the train split to 1,024
examples, and redistribute the rest to validation and test resulting in the final size of
1,024 / 256 / 2,048 for the training, validation and test splits, respectively.


Here are a few examples from the training split:

```json
{
  "text": "S√ºgisest algav pikk koolitee Oskari perekonda ei hirmuta.",
  "label": "positiivne"
}
```
```json
{
  "text": "Sellises eas, nagu teie olete, tundub muidugi ka 20-aastane √ºsna laps ...",
  "label": "neutraalne"
}
```
```json
{
  "text": "ka ainus m√§rkimisv√§√§rne saavutus temalt selle loo esituse juures.",
  "label": "negatiivne"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  J√§rgmised on dokumendid ja nende meelestatus, mis v√µib olla 'positiivne', 'neutraalne' v√µi 'negatiivne'.
  ```
- Base prompt template:
  ```
  Dokument: {text}
  Meelestatus: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Dokument: {text}

  Klassifitseeri dokument meelestatuse j√§rgi. V√µimalikud vastused: 'positiivne', 'neutraalne' v√µi 'negatiivne'. Muud vastused ei ole lubatud.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positiivne`
    - `neutral` ‚û°Ô∏è `neutraalne`
    - `negative` ‚û°Ô∏è `negatiivne`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset estonian-valence
```

## Common-sense Reasoning

### WinoGrande-ET

The dataset includes the [WinoGrande](https://doi.org/10.48550/arXiv.1907.10641) test set translated and culturally adapted by hand by a professional translator (citation TBA).
The structure of the dataset is identical to the original. Since train and dev splits were not translated manually, we employ
the GPT-4o model to translate the expected number of examples starting from the beginning of the respective splits.
The final dataset size is 1,024 / 256 / 1,767 for the training, validation and test splits, respectively.

Here are a few examples from the training split (note that unlike the test split these are machine translated):

```json
{
  "text": "Ian vabatahtlikult s√µi Dennise menudo p√§rast seda, kui oli juba kausi s√∂√∂nud, sest _ p√µlgas soolte s√∂√∂mist.\nVastusevariandid:\na. Ian\nb. Dennis",
  "label": "b"
}
```
```json
{
  "text": "Ian vabatahtlikult s√µi Dennise menudo p√§rast seda, kui oli juba kausit√§ie s√∂√∂nud, sest _ nautis soolte s√∂√∂mist.\nVastusevariandid:\na. Ian\nb. Dennis", "label": "a"
}
```
```json
{
  "text": "Ta ei tule kunagi minu koju, aga mina l√§hen alati tema majja, sest _ on v√§iksem.\nVastusevariandid:\na. kodu\nb. maja",
  "label": "a"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Sulle esitatakse l√ºngaga (_) tekst√ºlesanne ja kaks vastusevarianti (a ja b).
  ```
- Base prompt template:
  ```
  Tekst√ºlesanne: {text}
  Vastusevariandid:
  a. {option_a}
  b. {option_b}
  Vastus: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst√ºlesanne: {text}
  Vastusevariandid:
  a. {option_a}
  b. {option_b}

  Sinu √ºlesanne on valida l√ºnka sobiv vastusevariant. Vasta ainult 'a' v√µi 'b'. Muud vastused ei ole lubatud.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset winogrande-et
```

## Named Entity Recognition

### EstNER

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.76/).
The dataset is a manually annotated collection of Estonian news and
social media texts.

The original dataset contains 16,966 / 3,297 / 2,797 samples for the training,
validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our
training, validation and test splits, respectively. All the new splits are subsets of
the original splits.

Here are a few examples from the training split:

```json
{
  "tokens": ["Katse", "l√µpuni", "j√§tkas", "34aastane", "tiitlijahtija", "kolmel", "rattal", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O"]
}
```
```json
{
  "tokens": ["‚Äú", "Kui", "tegemist", "oleks", "olnud", "piletiga", "peoga", ",", "peaksime", "inimestele", "raha", "tagasi", "maksma", ",", "n√º√ºd", "saame", "√ºksnes", "k√ºlalistelt", "vabandust", "paluda", ",‚Äù√ºtles", "J√§rvamaa", "omavalitsuste", "liidu", "tegevdirektor", "Krista", "Nurm", "ajalehele", "J√§rvamaa", "Teataja", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "I-ORG", "B-MISC", "B-PER", "I-PER", "O", "B-MISC", "I-MISC", "O"]
}
```
```json
{
  "tokens": ["Makke", "l√µpetas", "Quincy", "keskkooli", "Illinoisi", "osariigis", "ja", "plaanib", "sportlasstipendiumi", "abil", "edasi", "√µppida", "L√§√§ne-Illinoisi", "√ºlikoolis", ",", "mille", "korvpallimeeskond", "kuulub", "USA", "√ºli√µpilasliiga", "NCAA", "esimesse", "divisjoni", "."],
  "labels": ["B-PER", "O", "B-ORG", "I-ORG", "B-MISC", "I-MISC", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "O", "O", "O", "O", "B-ORG", "I-ORG", "B-ORG", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Allpool on laused ja JSON-s√µnastikud, mis sisaldavad antud lauses esinevaid nimetatud √ºksuseid.
  ```
- Base prompt template:
  ```
  Lause: {text}
  Nimetatud √ºksused: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Lause: {text}

  Tuvasta lauses nimetatud √ºksused. V√§ljund peaks olema JSON-s√µnastik, mille v√µtmed on 'inimene', 'asukoht', 'organisatsioon' ja 'muu'.
  V√§√§rtused peaksid olema kindlat t√º√ºpi nimetatud √ºksuste loendid, t√§pselt nii nagu need lauses esinevad.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `inimene`
    - `I-PER` ‚û°Ô∏è `inimene`
    - `B-LOC` ‚û°Ô∏è `asukoht`
    - `I-LOC` ‚û°Ô∏è `asukoht`
    - `B-ORG` ‚û°Ô∏è `organisatsioon`
    - `I-ORG` ‚û°Ô∏è `organisatsioon`
    - `B-MISC` ‚û°Ô∏è `muu`
    - `I-MISC` ‚û°Ô∏è `muu`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset estner
```

## Knowledge

### Trivia-ET

This dataset was published [here](https://huggingface.co/datasets/TalTechNLP/trivia_et). It was extracted from
the "Eesti M√§ng" board game, and contains trivia questions about Estonia.

The original dataset contains 800 examples. From these, we use 240 / 60 / 500 samples for our training,
validation and test splits, respectively.

Note that this is a gated dataset, and we would like to avoid contaminating LLM pre-training data as much as possible.
Accordingly, we selected more generic questions not representative of the full dataset in terms of question content
to show here:

```json
{
  "text": "Mis on isoterm?\nVastusevariandid:\na. samatemperatuurijoon\nb. sama√µhur√µhujoon\nc. samapingejoon\nd. samak√µrgusjoon",
  "label": "a"
}
```

```json
{
  "text": "Mis on isobaat?\nVastusevariandid:\na. samas√ºgavusjoon\nb. sama√µhur√µhujoon\nc. samatemperatuurijoon\nd. samak√µrgusjoon",
  "label": "a"
}
```

```json
{
  "text": "Mida m√µ√µdetakse baromeetriga?\nVastusevariandid:\na. veekogude s√ºgavust\nb. temperatuuri\nc. j√µgede voolukiirust\nd. √µhur√µhku",
  "label": "d"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  J√§rgnevad on vastusevariantidega k√ºsimused (koos vastustega).
  ```
- Base prompt template:
  ```
  K√ºsimus: {text}
  Vastusevariandid:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Vastus: {label}
  ```
- Instruction-tuned prompt template:
  ```
  K√ºsimus: {text}
  Vastusevariandid:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  V√µimalikud vastused:  'a', 'b', 'c' or 'd'. Muud vastused ei ole lubatud.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset trivia-et
```
