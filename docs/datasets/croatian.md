# ğŸ‡­ğŸ‡· Croatian

This is an overview of all the datasets used in the Croatian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### MMS-hr

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2306.07902).
The corpus consists of 79 manually selected datasets from over 350 datasets reported in the
scientific literature based on strict quality criteria.

The original dataset contains a single split with 77,594 Croatian samples. We use
1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
    "text": "ali kako mozete biti ovako trijezni u ovo doba ajde molim vas",
    "label": "negative"
}
```

```json
{
    "text": "RT @bsimun: Thompson okupio 100 000 ljudi u ÄŒavoglavama. Sad Ä‡e valjda platiti porez. #domoljublje #DanPobjede",
    "label": "neutral"
}
```

```json
{
    "text": "\n Å esti \"El ClÃ¡sico\" za\n \n  Luku ModriÄ‡a\n \n bio je i najdraÅ¾i. Real je dobio BarÃ§u 3-1, a hrvatski veznjak bio je jedan od najboljih igraÄa \"kraljeva\".\n\n\n\n - Otkako sam u Madridu, meni je to djelovalo kao\n \n  najuvjerljivija demonstracija moÄ‡i\n \n . BarÃ§a je izgledala manje moÄ‡no jer je Real odigrao impresivno. Meni ta pobjeda viÅ¡e govori o snazi naÅ¡e momÄadi, o potvrdi kako forma koju iskazujemo veÄ‡ osam-devet utakmica nije sluÄajna - rekao je Luka za\n \n  SN\n \n .\n\n\n - Imali su psiholoÅ¡ku prednost zbog stanja na ljestvici i manjeg imperativa. Zato je\n \n  Realov uspjeh impresivan\n \n , tim prije Å¡to smo gubili 0-1 - dodao je.\n\n\n\n  Izvorni Älanak proÄitajte u\n  \n   Sportskim novostima\n  \n  .\n \n\n\n Pohvalio suigraÄe\n  \n\n\n -\n \n  ÄŒudesna utakmica\n \n cijele momÄadi i pobjeda protiv Barcelone. Ajmo, halÃ¡ Madrid! - napisao je ModriÄ‡ na druÅ¡tvenim mreÅ¾ama.\n  \n",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Slijede dokumenti i njihova osjetila, koja mogu biti pozitivno, neutralno ili negativno.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Osjetilo: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  Klasificirajte osjeÄ‡aj u dokumentu. Odgovorite samo s pozitivno, neutralno, ili negativno, i niÅ¡ta drugo.
  ```

- Label mapping:
  - `positive` â¡ï¸ `pozitivno`
  - `neutral` â¡ï¸ `neutralno`
  - `negative` â¡ï¸ `negativno`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mms-hr
```

## Named Entity Recognition

### WikiANN-hr

This dataset was published in [this paper](https://aclanthology.org/P17-1178/) and is
part of a cross-lingual named entity recognition framework for 282 languages from
Wikipedia. It uses silver-standard annotations transferred from English through
cross-lingual links and performs both name tagging and linking to an english Knowledge
Base.

The original full dataset consists of 10,000 / 10,000 / 10,000 samples for the training,
validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our
training, validation and test splits, respectively. All the new splits are subsets of
the original splits.

Here are a few examples from the training split:

```json
{
    "tokens": array(["Ubrzo", "su", "uslijedile", "narudÅ¾be", "iz", "cijele", "Britanske", "zajednice", "naroda", "."], dtype=object),
    "labels": ["O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "I-ORG", "O"]
}
```

```json
{
    "tokens": array(["``", "(", "Cole", "Porter", ")"], dtype=object),
    "labels": ["O", "O", "B-PER", "I-PER", "O"]
}
```

```json
{
    "tokens": array(["'", "''", "La", "Liga", "2009.", "/", "10", "."], dtype=object),
    "labels": ["O", "O", "B-ORG", "I-ORG", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  SljedeÄ‡e su reÄenice i JSON rjeÄnici s imenicama koje se pojavljuju u reÄenicama.
  ```

- Base prompt template:

  ```text
  ReÄenica: {text}
  Imenovane entiteti: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  ReÄenica: {text}

  Identificirajte imenovane entitete u reÄenici. PrikaÅ¾ite ih kao JSON rjeÄnik s kljuÄevima 'osoba', 'mjesto', 'organizacija' i 'razno'. Vrijednosti trebaju biti popisi imenovanih entiteta navedenog tipa, toÄno kako se pojavljuju u reÄenici.
  ```

- Label mapping:
  - `B-PER` â¡ï¸ `osoba`
  - `I-PER` â¡ï¸ `osoba`
  - `B-LOC` â¡ï¸ `mjesto`
  - `I-LOC` â¡ï¸ `mjesto`
  - `B-ORG` â¡ï¸ `organizacija`
  - `I-ORG` â¡ï¸ `organizacija`
  - `B-MISC` â¡ï¸ `razno`
  - `I-MISC` â¡ï¸ `razno`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset wikiann-hr
```

## Linguistic Acceptability

### ScaLA-hr

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Croatian Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Croatian-SET) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "Nakon kratke intervencije, tijekom koje sam saznala kada se taj osjeÄ‡aj prvog puta pojavio i zbog Äega, sve je nestalo i veÄ‡ mjesecima Å¾ivim bez optereÄ‡enja koji me pratilo cijelog Å¾ivota.",
    "label": "correct"
}
```

```json
{
    "text": "Svaki od tih sklopova, i dijelova mora biti homologiran i sukladan s ostalima.",
    "label": "incorrect"
}
```

```json
{
    "text": "Prvi meÄ‘u njima je Laurent Blanc, koji drÅ¾i Romu na Äekanju, a s Parkom prinÄeva povezivan je i Fabio Capello.",
    "label": "correct"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  SljedeÄ‡e su reÄenice i jesu li gramatiÄki ispravne.
  ```

- Base prompt template:

  ```text
  ReÄenica: {text}
  GramatiÄki ispravna: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  ReÄenica: {text}

  Odredite je li reÄenica gramatiÄki ispravna ili ne. Odgovorite s 'da' ako je ispravna, i s 'ne' ako nije. Odgovorite samo tom rijeÄju i niÄim drugim.
  ```

- Label mapping:
  - `correct` â¡ï¸ `da`
  - `incorrect` â¡ï¸ `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-hr
```

## Reading Comprehension

### MultiWikiQA-sl

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": "1891 (MDCCCXCI) je bilo navadno leto, ki se je po gregorijanskem koledarju zaÄelo na Äetrtek, po 12 dni poÄasnejÅ¡em julijanskem koledarju pa na torek.\n\nDogodki \n 15. maj â€“ papeÅ¾ Leon XIII. izda encikliko Rerum Novarum\n\nRojstva \n 22. januar - Antonio Gramsci, italijanski filozof, politik in politiÄni teoretik (â€  1937)\n 24. januar - Abraham SamojloviÄ BezikoviÄ, ruski matematik (â€  1970)\n 11. marec - Michael Polanyi, madÅ¾arsko-britanski kemik in filozof (â€  1976)\n 24. marec - John Knittel, Å¡vicarski pisatelj (â€  1970)\n 14. april - Bhimrao RamdÅ¾i Ambedkar, indijski budistiÄni socialni reformator, pravnik in filozof (â€  1956)\n 22. april - sir Harold Jeffreys, angleÅ¡ki geofizik, astronom, matematik (â€  1989)\n 23. april - Sergej SergejeviÄ Prokofjev, ruski skladatelj, pianist (â€  1953)\n 15. maj - Mihail AfanasjeviÄ Bulgakov, ruski pisatelj (â€  1940)\n 18. maj - Rudolf Carnap, nemÅ¡ki filozof (â€  1970)\n 16. junij - Vladimir AleksandroviÄ Albicki, ruski astronom (â€  1952)\n 19. avgust - Milton Lasell Humason, ameriÅ¡ki astronom (â€  1972)\n 26. september - Hans Reichenbach, nemÅ¡ki filozof (â€  1953)\n 20. oktober - sir James Chadwick, angleÅ¡ki fizik, nobelovec 1935 (â€  1974)\n 12. november - Seth Barnes Nicholson, ameriÅ¡ki astronom (â€  1963)\n 15. november - Erwin Rommel, nemÅ¡ki feldmarÅ¡al in vojaÅ¡ki strateg (â€  1944)\n 26. december - Henry Miller, ameriÅ¡ki pisatelj (â€  1980)\n\nSmrti \n 23. junij - Norman Robert Pogson, angleÅ¡ki astronom (* 1829)\n 23. junij - Wilhelm Eduard Weber nemÅ¡ki fizik (* 1804)\n 3. oktober - Ã‰douard Lucas, francoski matematik (* 1842)\n 10. november - Å tefan Å½emliÄ, madÅ¾arsko-slovenski pisatelj (* 1840)\n 20. december - George Bassett Clark, ameriÅ¡ki astronom, optik (* 1827)\n 29. december - Leopold Kronecker, nemÅ¡ki matematik, logik (* 1823)",
    "question": "Kateri je bil prvi dan leta 1891 po gregorijanskem koledarju?",
    "answers": {
        "answer_start": [82],
        "text": ["na Äetrtek"]
    }
}
```

```json
{
    "context": "The Night the Light Went On in Long Beach je prvi album v Å¾ivo skupine Electric Light Orchestra, ki je izÅ¡el leta 1974, posnet pa je bil 12. maja 1974 v Long Beach Auditoriumu na Long Beachu. Naslov albuma je sposojen od pesmi Â»The Night the Lights Went Out in GeorgiaÂ«, ki jo je posnela Vicki Lawrence.\n\nOzadje in omejena izdaja \nAlbum je bil predviden kot naslednik albuma On the Third Day, a so bili posnetki poÅ¡kodovani zaradi tehniÄnih teÅ¾av tako na odru kot zunaj njega. TeÅ¾ave so se zaÄele ko se je tovornjak z opremo skupine na poti pokvaril, pred koncertom pa skupina ni imela dovolj Äasa za preizkus zvoka.\n\nÅ tevilna preÅ¡anja albuma so bila tako slabe kvalitete, da je vodstvo skupine vloÅ¾ilo toÅ¾bo proti proizvodnem podjetju. Naslovnico albuma je oblikoval Mick Haggerty. \n\nNa koncu sta se tako ameriÅ¡ka kot britanska zaloÅ¾ba odloÄili da ne izdata albuma. Album je tako izÅ¡el le v NemÄiji in nekaterih drugih drÅ¾avah, leta 1985 pa je vseeno izÅ¡el v ZdruÅ¾enem kraljestvu. Album ni nikoli izÅ¡el v ZDA, Äeprav je bil tja uvoÅ¾en in se je dobro prodajal, je pa Å¾iva verzija Â»10538 OvertureÂ« izÅ¡la kot b-stran singla Â»Evil WomanÂ« z albuma Face the Music. Å½iva verzija Â»Roll Over BeethovenÂ« je v ZDA izÅ¡la kot b-stran alternativne verzije Â»Telephone LineÂ« v seriji reizdaj.\n\nObnova \nRemastering v 90. letih je popravil slabo kvaliteto albuma. Odkrito je bilo, da je bila originalna LP ploÅ¡Äa masterizirana z uporabo slabÅ¡e kopije koncerta, zaradi katere je bila kvaliteta zvoka slaba. Originalni trak je bil odkrit v trezorju proizvodnje ploÅ¡Ä in album je bil obnovljen v boljÅ¡i kvaliteti zvoka.\n\nTo je edini Å¾ivi album ELO iz Äasa zaÄetkov skupine.\n\nSeznam skladb\n\nZasedba \nJeff Lynne\tâ€“ solo vokal, elektriÄna kitara\nBev Bevan â€“ bobni\nRichard Tandy â€“ Wurlitzer, Minimoog\nMike de Albuquerque â€“ solo vokal, spremljevalni vokal, bas\nMik Kaminski â€“ violina\nHugh McDowell â€“ Äelo\nMike Edwards â€“ Äelo\n\nSklici \n\nAlbumi leta 1974\nAlbumi Electric Light Orchestra\nAlbumi v Å¾ivo\nAlbumi, ki jih je produciral Jeff Lynne",
    "question": "Zaradi Äesa je bila slaba kakovost albuma The Night the Light Went On in Long Beach odpravljena?",
    "answers": {
        "answer_start": [1287],
        "text": ["Remastering v 90. letih"]
    }
}
```

```json
{
    "context": "Surangel S. Whipps ml., palavski poslovneÅ¾ in politik; * 9. avgust 1968, Baltimore, Maryland, ZdruÅ¾ene drÅ¾ave Amerike.\n\nOd 21. januarja 2021 je predsednik Palava. Senator je bil od leta 2008 do 2016. Prihaja iz deÅ¾ele Ngatpang.\n\nZgodnje Å¾ivljenje in izobraÅ¾evanje \nWhipps se je rodil v Baltimorju v Marylandu materi samohranilki Surangel Whipps Sr., rojeni v Marylandu. Diplomiral je iz poslovne administracije in ekonomije na Univerzi Andrews in magistriral iz poslovne znanosti na kalifornijski univerzi v Los Angelesu. Poleg tega vodi verigo supermarketov Palauan. Na sploÅ¡nih volitvah leta 2016 v Palavu se je potegoval proti svojemu zetu, predsedniku Thomasu Remengesauju mlajÅ¡emu.\n\nMandat \nWhipps je na predsedniÅ¡kih volitvah 2020 kandidiral za predsednika in premagal podpredsednika Raynolda Oiloucha. V intervjuju za Guardian je takratni izvoljeni predsednik Whipps ml. podal izjavo, da se bo Palav odloÄneje upiral ukrepom kitajske vlade, vkljuÄno z nezakonitim ribolovom in vstopom v palavske vode ter obljubil, da bo ohranil priznanje Tajvana. Poleg tega je predlagal distribucijo cepiva proti COVID-19 med PalavÄani, s poudarkom na zdravstvenih delavcih.\n\nSklici \nWhipps, Surangel\nWhipps, Surangel",
    "question": "Proti komu je Whipps zmagal na predsedniÅ¡kih volitvah leta 2020?",
    "answers": {
        "answer_start": [790],
        "text": ["Raynolda Oiloucha"]
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Spodaj so besedila z ustreznimi vpraÅ¡anji in odgovori.
  ```

- Base prompt template:

  ```text
  Besedilo: {text}
  VpraÅ¡anje: {question}
  Odgovor v najveÄ 3 besedah:
  ```

- Instruction-tuned prompt template:

  ```text
  Besedilo: {text}

  Odgovorite na naslednje vpraÅ¡anje o zgornjem besedilu v najveÄ 3 besedah.

  VpraÅ¡anje: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-sl
```

## Knowledge

### MMLU-sl

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2410.08928)
and is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Slovenian was done using DeepL.

The original full dataset consists of 285 / 1,531 / 14,042 samples for training,
validation, and testing, respectively. These splits were merged, duplicates removed, and
new splits were created with 1,024 / 256 / 2048 samples for training, validation, and
testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "Kaj je deklarativna teorija priznanja?\nMoÅ¾nosti:\na. Priznanje je odloÄilno za obstoj drÅ¾avnosti\nb. Priznanje je zgolj deklarativno za drÅ¾avnost, ni pa odloÄilno\nc. Priznanje je zgolj izjava o interesu\nd. Priznanje zahteva izjavo novoustanovljene drÅ¾avnosti",
    "label": "b",
}
```

```json
{
    "text": "Katera od naslednjih moÅ¾nosti bi bila verjeten odziv na ugotovljeno nenormalnost ostanka?\nMoÅ¾nosti:\na. Uporabite logaritemsko funkcionalno obliko namesto linearne\nb. Dodajte zamike spremenljivk na desni strani regresijskega modela\nc. Ocenite model v prvi diferencirani obliki\nd. Iz podatkov odstranite vsa velika odstopanja.",
    "label": "d",
}
```

```json
{
    "text": "To vpraÅ¡anje se nanaÅ¡a na naslednje informacije. Stopnje pismenosti med rusko govoreÄim prebivalstvom pozne carske Rusije in Sovjetske zveze, 1897-1955 Stopnja pismenosti 1897 24% 1917 45% 1926 56% 1937 75% 1939 81.10% 1955 99.90% Vir: Podatki iz popisa prebivalstva in sovjetskega ministrstva za Å¡olstvo Informacije, predstavljene v zgornji tabeli, je najbolje razumeti v katerem od naslednjih zgodovinskih kontekstov?\nMoÅ¾nosti:\na. IzobraÅ¾evalna reforma v moderni dobi\nb. Centralizirane in od drÅ¾ave usmerjene kampanje modernizacije\nc. Eksperimentiranje s sindikalistiÄnimi oblikami druÅ¾benoekonomske organizacije\nd. Druga faza industrializacije v nezahodnem svetu",
    "label": "b",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Naslednja so vpraÅ¡anja z veÄ moÅ¾nostmi (z odgovori).
  ```

- Base prompt template:

  ```text
  VpraÅ¡anje: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Odgovor: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  VpraÅ¡anje: {text}

  Odgovorite na navedeno vpraÅ¡anje z uporabo 'a', 'b', 'c' ali 'd', in niÄ drugega.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-sl
```

## Common-sense Reasoning

### Winogrande-sl

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "Nisem mogel nadzorovati vlage, kot sem nadzoroval deÅ¾, ker je _ prihajal od vsepovsod. Na kaj se nanaÅ¡a prazno mesto _?\nMoÅ¾nosti:\na. vlaga\nb. deÅ¾",
    "label": "a"
}
```

```json
{
    "text": "Jessica je mislila, da je Sandstorm najboljÅ¡a pesem, kar jih je bilo kdaj napisanih, vendar jo je Patricia sovraÅ¾ila. _ je kupila vstopnico za jazz koncert. Na kaj se nanaÅ¡a prazno mesto _?\nMoÅ¾nosti:\na. Jessica\nb. Patricia",
    "label": "b"
}
```

```json
{
    "text": "Termostat je pokazal, da je bilo spodaj dvajset stopinj hladneje kot zgoraj, zato je Byron ostal v _, ker mu je bilo hladno. Na kaj se nanaÅ¡a prazno mesto _?\nMoÅ¾nosti:\na. spodaj\nb. zgoraj",
    "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Naslednja so vpraÅ¡anja z veÄ moÅ¾nostmi (z odgovori).
  ```

- Base prompt template:

  ```text
  VpraÅ¡anje: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}
  Odgovor: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  VpraÅ¡anje: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}

  Odgovorite na navedeno vpraÅ¡anje z uporabo 'a' ali 'b', in niÄ drugega.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-sl
```
