# üá´üáÆ Finnish

This is an overview of all the datasets used in the Finnish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### ScandiSent-fi

This dataset consists of reviews from Trustpilot and was published [here](https://github.com/timpal0l/ScandiSent). It is a binary sentiment classification dataset, with labels "positive" and "negative".

For the Finnish part of the dataset, there are 10,000 training samples. From these samples, we have created a 1,024 / 256 / 2,048 split for the train, validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Kaikki meni niinkuin piti. Nopea toimitus.",
  "label": "positive"
}
```
```json
{
  "text": "En pid√§ t√§st√§, kun ei l√∂ydy linkki√§ mist√§ p√§√§sis heti maksamaan. En todellakaan pid√§ siit√§, ett√§ joka tieto pit√§√§ kopioida erikseen. Haluaisin p√§√§st√§ suoraan oston j√§lkeen maksamaa mobiilipankkiin. Pari laskua on j√§√§nyt t√§n takia kokonaan huomioimatta. Ja ihan turhaa.... √§rsytt√§√§ sitten se kotiin tuleva muistutuslasku.",
  "label": "negative"
}
```
```json
{
  "text": "Todella hidas toimitus, ja virheellist√§ tietoa tuotteiden saatavuudesta, paketti ja tuotteet perill√§ vasta kuukauden p√§√§st√§ tilauksesta....",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Seuraavassa on arvosteluja ja niiden tunnes√§vy, joka voi olla 'positiivinen' tai 'negatiivinen'.
  ```
- Base prompt template:
  ```
  Teksti: {text}
  Tunnes√§vy: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Teksti: {text}

  Luokittele arvostelun tunnes√§vy. Vastaa vain 'positiivinen' tai 'negatiivinen', ei muuta.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positiivinen`
    - `negative` ‚û°Ô∏è `negatiivinen`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scandisent-fi
```

## Named Entity Recognition

### Turku-NER-fi

This dataset was published in [this paper](https://aclanthology.org/2020.lrec-1.567/).

The original dataset contains 12,217 / 1,364 / 1,555 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "tokens": ["Suomalaiset", "vaihtoivat", "Tukholman", "Tallinnaan"],
  "labels": ["O", "O", "B-LOC", "B-LOC"]
}
```
```json
{
  "tokens": ["Liuhto", "nosti", "Kreikan", "tapauksen", "yhteydess√§", "esille", "kysymyksen", "siit√§", ",", "miten", "Euroopan", "unionissa", "yleisesti", "sanktioidaan", "pelis√§√§nt√∂jen", "rikkomisesta", "."],
  "labels": ["B-PER", "O", "B-LOC", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "O", "O", "O", "O", "O"],
}
```
```json
{
  "tokens": ["Mithridates", "oli", "Pontoksen", "merkitt√§vin", "kuningas", "ja", "Rooman", "valtakunnan", "vaarallisin", "vihollinen", "ensimm√§isell√§", "vuosisadalla", "eaa.", "."],
  "labels": ["B-PER", "O", "B-LOC", "O", "O", "O", "B-LOC", "I-LOC", "O", "O", "O", "O", "O", "O"],
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Seuraavassa on lauseita ja JSON-sanakirjoja, jotka sis√§lt√§v√§t annetussa lauseessa esiintyv√§t nimetyt entiteetit.
  ```
- Base prompt template:
  ```
  Lause: {text}
  Nimetyt entiteetit: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Lause: {text}

  Tunnista lauseessa esiintyv√§t nimetyt entiteetit. Tulosta ne JSON-sanakirjana, jonka avaimet ovat 'henkil√∂', 'paikka', 'organisaatio' ja 'muut'. Arvojen tulee olla listoja kyseisen tyypin nimetyist√§ entiteeteist√§ t√§sm√§lleen siin√§ muodossa kuin ne esiintyv√§t lauseessa.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `person`
    - `I-PER` ‚û°Ô∏è `person`
    - `B-LOC` ‚û°Ô∏è `sted`
    - `I-LOC` ‚û°Ô∏è `sted`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `diverse`
    - `I-MISC` ‚û°Ô∏è `diverse`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset turku-ner-fi
```



## Linguistic Acceptability

## Reading Comprehension

### TydiQA-fi

This question-answering dataset was published in [this paper](https://arxiv.org/abs/2003.05002).

The original Finnish TydiQA dataset contains 6,855 training and 782 validation samples (we use the [secondary task subset](https://huggingface.co/datasets/google-research-datasets/tydiqa/viewer/secondary_task?views%5B%5D=secondary_task_train)).  We created a 1,024 / 256 / 2,024 split, where the samples from the train and validation split are sampled from the original train and validation splits, respectively. The test set consists of the remaining samples from the original validation split + additional samples from the original train split.

Here are a few examples from the training split:

```json
{
  "question": "Kuka n√§ytteli Dumbledorea Harry Potter elokuvissa?",
  "context": "Dumbledorea esitt√§√§ kirjasarjasta tehdyss√§ elokuvasarjassa Richard Harris kahdessa ensimm√§isess√§ elokuvassa. Harrisin kuoltua Michael Gambon esitti hahmoa sarjan lopuissa elokuvissa.",
  "answers": {
    "text": ["Richard Harris kahdessa ensimm√§isess√§ elokuvassa. Harrisin kuoltua Michael Gambon"],
    "answer_start": [59]
  }
}

```json
{
  "question": "Milloin Cristiano Ronaldo liittyi Juventukseen?",
  "context": "Ronaldo siirtyi hein√§kuussa 2018 Juventukseen 105 miljoonalla eurolla. Sopimus on nelivuotinen, ja sen aikana h√§n tienaa verojen j√§lkeen noin 120 miljoonaa euroa.[133]",
  "answers": {
    "text": ["hein√§kuussa 2018"],
    "answer_start": [16]
  }
}
```json
{
  "question": "Kuka hallitsi Mithridates VI j√§lkeen?",
  "context": "Mithridates laajensi valtakuntaansa ymp√§ri Mustanmeren rantoja, ja h√§n ajautui kolmesti sotaan Rooman valtakuntaa vastaan. Ensimm√§isess√§ sodassa (89 eaa.‚Äì85 eaa.) h√§n valtasi suuren osan V√§h√§√§-Aasiaa ja Rooman valtakunnalle kuuluneet osat, jolloin h√§nen sanotaan teloittaneen 80000 roomalaista. Mithridates valtasi my√∂s Kreikan, mutta konsuli Sulla kukisti h√§nen joukkonsa vuonna 85 eaa., ja Mithridateen oli luovuttava valloituksistaan. Toinen sota (83 eaa.‚Äì81 eaa.) oli suppeampi laajuudeltaan. Kolmannessa sodassa (73 eaa.‚Äì63 eaa.) roomalaiset sotap√§√§llik√∂t Lucullus ja Pompeius kukistivat Mithridateen perusteellisesti. Mithridates surmasi tai surmautti itsens√§ jouduttuaan poikansa Farnakes II:n syrj√§ytt√§m√§ksi.",
  "answers": {
    "text": ["Farnakes II"],
    "answer_start": [687]
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Seuraavassa on tekstej√§ ja niihin liittyvi√§ kysymyksi√§ ja vastauksia.
  ```
- Base prompt template:
  ```
  Teksti: {text}
  Kysymys: {question}
  Vastaa enint√§√§n 3 sanalla: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Teksti: {text}

  Vastaa seuraavaan kysymykseen yll√§ olevasta tekstist√§ enint√§√§n 3 sanalla.

  Kysymys: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset tydiqa-fi
```

## Knowledge

## Common-sense Reasoning

## Summarization
