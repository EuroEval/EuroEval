# üá≠üá∫ Hungarian

This is an overview of all the datasets used in the Hungarian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### HuSST

This dataset was published in [this paper](https://acta.bibl.u-szeged.hu/75891/1/msznykonf_018_431-446.pdf)
and is the Hungarian version of the Stanford Sentiment Treebank.

The original dataset contains 9,328 / 1,165 / 1,165 samples for the training, validation,
and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training,
validation and test splits, respectively. The train and validation splits are subsets of
the original splits. The orignial test split does not contain any labels, so our test split
is created from the training split.

Here are a few examples from the training split:

```json
{
    "text": "Egy var√°zslatos film, amely egy mer√©sz utaz√°st k√≠n√°l a m√∫ltba, √©s forr√≥ √∂lel√©s√©be z√°rja a szentp√©terv√°ri Ermit√°zs M√∫zeumban tal√°lhat√≥ kultur√°lis erekly√©ket.",
    "label": "positive"
}
```

```json
{
    "text": "Az elm√∫lt id≈ëszakban jellemz≈ë volt a t√∂bbszerepl≈ës romantikus filmek l√°nca... de Petter Mattei Szerelem a p√©nz idej√©n c√≠m≈± m≈±ve k√ºl√∂nv√°lik az√°ltal, hogy olyan kapcsolati l√°ncolatot hoz l√©tre, ami teljes k√∂rr√© √°ll √∂ssze, hogy pozit√≠v ‚Äúm√©g ha tragikus is‚Äù v√©get kanyar√≠tson a t√∂rt√©netnek.",
    "label": "positive"
}
```

```json
{
    "text": "A \"Feh√©r Olajf≈±\" film olyan, mintha a forr√°sanyag a Reader's Digest t√∂m√∂r√≠tett v√°ltozata lenne.",
    "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Az al√°bbiak dokumentumok √©s √©rzelm√ºk, ami lehet pozit√≠v, semleges vagy negat√≠v.
  ```

- Base prompt template:

  ```text
  Dokumentum: {text}
  √ârzelem: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokumentum: {text}

  Oszt√°lyozza az √©rzelmet a dokumentumban. V√°laszoljon pozit√≠v, semleges, vagy negat√≠v kifejez√©ssel, √©s semmi m√°ssal.
  ```

- Label mapping:
  - `positive` ‚û°Ô∏è `pozit√≠v`
  - `neutral` ‚û°Ô∏è `semleges`
  - `negative` ‚û°Ô∏è `negat√≠v`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset husst
```

## Named Entity Recognition

### SzegedNER

This dataset was published in [this paper](https://aclanthology.org/L06-1215/).
The data is a segment of the Szeged Corpus, consisting of short business news
articles collected from MTI (Hungarian News Agency, <www.mti.hu>).

The original dataset consists of 8,220 / 874 / 1,656 samples for the
training, validation, and test splits, respectively. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively. All the new
splits are subsets of the original splits.

Here are a few examples from the training split:

```json
{
    "tokens": ["R√°ad√°sul", "kir√∫gt√°k", "a", "br√ºsszeli", "bizotts√°gt√≥l", "azt", "az", "alkalmazottat", ",", "aki", "egy", "csokor", "gyan√∫s", "t√©nyr√µl", "sz√≥l√≥", "inform√°ci√≥kat", "juttatott", "el", "az", "Eur√≥pai", "Parlament", "(", "EP", ")", "n√©h√°ny", "k√©pvisel√µj√©nek", "."],
    "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "O", "B-ORG", "O", "O", "O", "O"]
}
```

```json
{
    "tokens": ["A", "londoni", "Eur√≥pai", "√öjj√°√©p√≠t√©si", "√©s", "Fejleszt√©si", "Bank", "(", "EBRD", ")", "10,1", "milli√≥", "eur√≥√©rt", "r√©szv√©nyeket", "vesz", "a", "szlov√°k", "Polnobank√°b√≥l", "az", "olasz", "UniCredito", "p√©nzint√©zett≈ël", "."],
    "labels": ["O", "O", "B-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "O", "B-ORG", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "O", "O", "B-ORG", "O", "O"]
}
```

```json
{
    "tokens": ["Clinton", "a", "Netanjahuval", "tartott", "vas√°rnapi", "tal√°lkoz√≥", "ut√°ni", "sajt√≥konferenci√°n", "s√ºrgette", "a", "palesztinokat", "k√∂telezetts√©geik", "betart√°s√°ra", ",", "de", "egy√∫ttal", "felsz√≥l√≠totta", "Izraelt", ",", "hogy", "ne", "f√ºggessze", "fel", "az", "okt√≥beri", "meg√°llapod√°s", "v√©grehajt√°s√°t", "."],
    "labels": ["B-PER", "O", "B-PER", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-LOC", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  Az al√°bbiakban mondatok √©s JSON sz√≥t√°rak tal√°lhat√≥k
  az adott mondatokban el≈ëfordul√≥ n√©vjegyz√©kkel.
  ```

- Base prompt template:

  ```text
  Mondat: {text}
  N√©vjegyz√©k: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Mondat: {text}

  Nevezze meg a mondatban szerepl≈ë neveket. JSON sz√≥t√°rk√©nt adja meg a 'szem√©ly', 'helysz√≠n', 'szervezet' √©s 'egy√©b' kulcsszavakat. Az √©rt√©kek a mondatban szerepl≈ë n√©vjegyz√©kek list√°i legyenek, pontosan √∫gy, ahogyan megjelennek.
  ```

- Label mapping:
  - `B-PER` ‚û°Ô∏è `szem√©ly`
  - `I-PER` ‚û°Ô∏è `szem√©ly`
  - `B-LOC` ‚û°Ô∏è `helysz√≠n`
  - `I-LOC` ‚û°Ô∏è `helysz√≠n`
  - `B-ORG` ‚û°Ô∏è `szervezet`
  - `I-ORG` ‚û°Ô∏è `szervezet`
  - `B-MISC` ‚û°Ô∏è `egy√©b`
  - `I-MISC` ‚û°Ô∏è `egy√©b`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset szeged-ner
```

## Linguistic Acceptability

### ScaLA-hu

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Hungarian Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Hungarian-Szeged) by assuming that
the documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "A kiskereskedelemben teljesen m√°s okra vezethet≈ë vissza a mamutv√°llalkoz√°sok l√©trej√∂tte, mint az √©lelmiszeriparban.",
    "label": "correct"
}
```

```json
{
    "text": "M√©g egy j√∂v≈ë √©vi k√∂lts√©gvet√©si m√©rleggel sem tisztelte meg a korm√°ny a k√©pvisel≈ëh√°zat, az √°llamh√°ztart√°si m√©rlegb≈ël kellene azt a k√©pvisel≈ëknek kibogar√°szniuk.",
    "label": "correct"
}
```

```json
{
    "text": "A Nawa B√°ny√°szati Kft. ahhoz Nawa a c√©gcsoporthoz tartozott, amely a taxisblok√°d idej√©n jelentette be, hogy az akkor hord√≥nk√©nt 29 doll√°ros vil√°gpiaci √°rn√°l olcs√≥bban, 22-23 doll√°r√©rt tud olajat szerezni.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  A k√∂vetkez≈ë mondatok, √©s hogy helyesek-e nyelvtanilag.
  ```

- Base prompt template:

  ```text
  Mondat: {text}
  Nyelvtanilag helyes: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Mondat: {text}

  Hat√°rozza meg, hogy a mondat nyelvtanilag helyes-e vagy sem. Csak 'igen'-nel v√°laszoljon, ha helyes, √©s 'nem'-mel, ha nem helyes. Csak ezzel a sz√≥val v√°laszoljon, √©s semmi m√°ssal.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `–¥–∞`
  - `incorrect` ‚û°Ô∏è `–Ω–µ`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-hu
```

## Reading Comprehension

### MultiWikiQA-hu

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": "Az utols√≥ mester (The Last of the Masters) Philip K. Dick egyik novell√°ja, amelyet 1953-ban √≠rt, majd 1954-ben az Orbit Science Fiction magazin november-decemberi sz√°m√°ban jelent meg. Magyarul a Lenn a siv√°r F√∂ld√∂n c√≠m≈± novell√°sk√∂tetben olvashat√≥.\n\nT√∂rt√©net \n\nA vil√°gon k√©tsz√°z √©ve az anarchia uralkodik. Akkor t√∂rt√©nt, hogy el≈ësz√∂r Eur√≥p√°ban, majd szerte a vil√°gban fell√°zadtak a polg√°rok, √©s megd√∂nt√∂tt√©k a korm√°nyokat. Meg√∂lt√©k a vezet≈ëket, elpuszt√≠tott√°k a robotokat √©s megsemmis√≠tettek minden addig a korm√°ny kez√©ben l√©v≈ë kutat√°si anyagot, elpuszt√≠tott√°k az atombomb√°kat. A vil√°gon most egyetlenegy szervezet van, az Anarchista Sz√∂vets√©g, aki csak arra √ºgyel, hogy nehogy valaki √∫jra fel√©p√≠tsen mag√°nak egy rendszert. A robotok k√∂z√ºl viszont az egyik ‚Äì Bors ‚Äì t√∫l√©lte a puszt√≠t√°st, √©s bujdosva a k√©tsz√°z √©v alatt fel√©p√≠tett mag√°nak egy kis eldugott birodalmat. Ennek a birodalomnak vannak a legmodernebb eszk√∂zei (hiszen a k√©t √©vsz√°zaddal ezel≈ëtti kutat√°si eredm√©nyek m√°r csak Bors agy√°ban maradtak meg), f√∂ldcsuszaml√°soknak √°lc√°zva elz√°rt√°k a telephez vezet≈ë f√∂ldutakat, √©s a szomsz√©dos falukban elhelyezett k√©meknek k√∂sz√∂nhet≈ëen mindig id≈ëben tudt√°k, ha a Sz√∂vets√©g √ºgyn√∂kei k√∂zelednek, √≠gy mindig id≈ëben f√©lres√∂p√∂rt√©k ≈ëket. Nem siker√ºl azonban ezt megtenni Edward Tolbyval √©s l√°ny√°val, Silvi√°val. √çgy (b√°r Silvi√°t siker√ºl elkapni) Tolby egyed√ºl pr√≥b√°lja meg felvenni a harcot az er≈ëddel. Az ≈ërs√©gen k√∂nnyen √°tjut, hiszen azok soha nem harcoltak, de v√©g√ºl m√©gis elkezdik ≈ët √ºld√∂zni. Bemenek√ºl Fowler, Bors egyik helyettes√©nek szob√°j√°ba. Szerencs√©j√©re Fowlernek az az √∂tlete t√°mad, hogy Tolbyval √∂leti meg Borst (mivel ≈ë maga erre nem lenne k√©pes, viszont az anarchia szimpatikus neki). Tolbynak v√©g√ºl is siker√ºl sz√©tvernie Bors robotfej√©t, akinek hal√°la miatt sz√©tesik az √°ltala fel√©p√≠tett rendszer. Fowler a biztons√°g kedv√©√©rt elteszi Bors adatb√°zis√°t, h√°tha m√©g sz√ºks√©ge lesz r√°‚Ä¶\n\nForr√°sok \n Philip K. Dick: Lenn a siv√°r f√∂ld√∂n (Agave Kiad√≥, 2005)\n\nPhilip K. Dick-novell√°k",
    "question": "Mely kutat√≥ munk√°j√°t puszt√≠tott√°k el a felkel≈ëk?",
    "answers": {
        "answer_start": [407],
        "text": ["a korm√°ny"]
    }
}
```

```json
{
    "context": 'Az U‚Äì1230 tengeralattj√°r√≥t a n√©met haditenger√©szet rendelte a hamburgi Deutsche Werft AG-t≈ël 1941. okt√≥ber 14-√©n. A haj√≥t 1944. janu√°r 26-√°n vett√©k hadrendbe. Egy j√°r≈ërutat tett, amelyen egy haj√≥t s√ºllyesztett el.\n\nP√°lyafut√°sa \nAz U‚Äì1230 els≈ë √©s egyetlen harci k√ºldet√©s√©re Hans Hilbig kapit√°ny ir√°ny√≠t√°s√°val 1944. okt√≥ber 8-√°n futott ki Hortenb≈ël. Az Atlanti-√≥ce√°n √©szaki r√©sz√©n kelt √°t, majd november 29-√©n ‚Äì az Elster hadm≈±velet (n√©met√ºl Unternehmen Elster, magyarul Szarka hadm≈±velet) ‚Äì k√©t n√©met √ºgyn√∂k√∂t rakott partra az amerikai Hancock Pointn√°l. Ezut√°n az Amerikai Egyes√ºlt √Ållamok partjain√°l, Connecticutt√≥l √©szakra vad√°szott. \n\nDecember 3-√°n Maine √°llam partjainak k√∂zel√©ben megtorped√≥zta a kanadai Cornwallis nev≈± g≈ëz√∂st, amely Barbadosr√≥l tartott St. Johnba, fed√©lzet√©n cukorral √©s melasszal. A Cornwallis 1942. szeptember 11-√©n kapott m√°r torped√≥tal√°latot Bridgetownban az U‚Äì514-t≈ël, de akkor m√©g ki lehetett emelni a sek√©ly v√≠zb≈ël. Az U‚Äì1230 torped√≥ja azonban v√©gzetes volt, a fed√©lzeten tart√≥zkod√≥ 48 emberb≈ël 43 meghalt.\n\n≈êrj√°rata befejezt√©vel a tengeralattj√°r√≥ visszat√©rt Norv√©gi√°ba, majd onnan 1945. febru√°r 20-√°n Flensburgba haj√≥zott. 1945. m√°jus 5-√©n a n√©metorsz√°gi Heligolandn√°l adta meg mag√°t. 1945. j√∫lius 24-√©n Wilhelmshavenb≈ël indult a sk√≥ciai Loch Ryanbe, ahol a sz√∂vets√©gesek a megsemmis√≠t√©sre kijel√∂lt b√∫v√°rhaj√≥kat gy≈±jt√∂tt√©k. Az U‚Äì √∂ssze 1230-at a HMS Cubitt brit fregatt s√ºllyesztette el a Deadlight hadm≈±veletben.\n\nKapit√°ny\n\n≈êrj√°rat\n\nEls√ºllyesztett haj√≥\n\nJegyzetek\n\nForr√°sok \n  \n  \n  \n  \n\nIXC/40 t√≠pus√∫ n√©met tengeralattj√°r√≥k',
    "question": "Ki rendelte meg az U-1230-as tengeralattj√°r√≥t?",
    "answers": {
        "answer_start": [62],
        "text": ["hamburgi Deutsche Werft AG-t≈ël"]
    }
}
```

```json
{
    "context": "A budapesti 56B jelz√©s≈± villamos H≈±v√∂sv√∂lgy √©s a Cs√≥ka utca k√∂z√∂tt k√∂zlekedett a 2022-es budafoki v√°g√°nyz√°r idej√©n. A viszonylatot a Budapesti K√∂zleked√©si Zrt. √ºzemeltette.\n\nT√∂rt√©nete \n\n1981. okt√≥ber 22-√©t≈ël a Sz√©ll K√°lm√°n (akkor Moszkva) t√©r √©s H≈±v√∂sv√∂lgy k√∂z√∂tti p√°lyafel√∫j√≠t√°si munk√°latok miatt az 56-os villamos megosztott √∫tvonalon, 56A jelz√©ssel a Sz√©ll K√°lm√°n t√©r fel≈ël, 56B jelz√©ssel pedig H≈±v√∂sv√∂lgy fel≈ël Budagy√∂ngy√©ig k√∂zlekedett. 1982. m√°jus 24-√©t≈ël az 56B r√∂vid√≠tett √∫tvonalon, minden nap 6 √©s 12 √≥ra k√∂z√∂tt Budagy√∂ngy√©t≈ël a Vadaskerti utc√°ig, majd 12 √≥ra ut√°n a Nagyh√≠d meg√°ll√≥helyig j√°rt. 1982. szeptember 18-√°n a fel√∫j√≠t√°s befejezt√©vel megsz≈±nt. 1983. j√∫nius 13. √©s 19. k√∂z√∂tt ism√©t k√∂zlekedett, ekkor a Budagy√∂ngye √©s a Ny√©ki √∫t k√∂z√∂tti szakaszon. November 8-√°n √∫jraindult a Heinrich Istv√°n √∫tig, majd november 24-√©n v√©gleg megsz≈±nt.\n\n2022. okt√≥ber 3. √©s november 18. k√∂z√∂tt a H≈±v√∂sv√∂lgy √©s a Cs√≥ka utca k√∂z√∂tt k√∂zlekedett a budafoki v√°g√°nyz√°r idej√©n.\n\n√ötvonala\n\nMeg√°ll√≥helyei \nAz √°tsz√°ll√°si kapcsolatok k√∂z√∂tt a H≈±v√∂sv√∂lgy √©s a M√≥ricz Zsigmond k√∂rt√©r k√∂z√∂tt azonos √∫tvonalon k√∂zleked≈ë 56-os √©s 56A villamos nincs felt√ºntetve.\n\n!Perc\xa0(‚Üì)\n!Meg√°ll√≥hely\n!Perc\xa0(‚Üë)\n!√Åtsz√°ll√°si kapcsolatok a j√°rat k√∂zleked√©se idej√©n\n|-\n|0||H≈±v√∂sv√∂lgyv√©g√°llom√°s||41\n|align=left|\n|-\n|2||Heinrich Istv√°n utca||38\n|align=left|\n|-\n|3||V√∂lgy utca||37\n|align=left|\n|-\n|4||Vadaskerti utca||36\n|align=left|\n|-\n|5||Nagyh√≠d||35\n|align=left|\n|-\n|6||Zuhatag sor||34\n|align=left|\n|-\n|8||Kelemen L√°szl√≥ utca||33\n|align=left|\n|-\n|9||Akad√©mia||32\n|align=left|\n|-\n|10||Budagy√∂ngye||31\n|align=left|\n|-\n|11||Nagyajtai utca||29\n|align=left|\n|-\n|14||Szent\xa0J√°nos\xa0K√≥rh√°z||27\n|align=left|\n|-\n|15||V√°rosmajor||26\n|align=left|\n|-\n|16||Ny√∫l utca||25\n|align=left|\n|-\n|18||Sz√©ll\xa0K√°lm√°n\xa0t√©r\xa0M||24\n|align=left|\n|-\n|20||D√©li p√°lyaudvar M||22\n|align=left|\n|-\n|21||Mik√≥ utca||20\n|\n|-\n|22||Krisztina t√©r||18\n|align=left|\n|-\n|24||D√≥zsa Gy√∂rgy t√©r||16\n|align=left|\n|-\n|26||D√∂brentei t√©r||14\n|align=left|\n|-\n|27||Rudas Gy√≥gyf√ºrd≈ë||13\n|align=left|\n|-\n|30||Szent Gell√©rt t√©r ‚Äì M≈±egyetem M||11\n|align=left|\n|-\n|32||G√°rdonyi t√©r||9\n|align=left|\n|-\n|35||M√≥ricz Zsigmond k√∂rt√©r\xa0M||6\n|align=left|\n|-\n|37||Kosztol√°nyi Dezs≈ë t√©r||4\n|align=left|\n|-\n|38||Karolina √∫t||2\n|align=left|\n|-\n|39||Cs√≥ka utcav√©g√°llom√°s||0\n|align=left|\n|}\n\nJegyzetek\n\nForr√°sok \n\nBudapest megsz≈±nt villamosvonalai",
    "question": "A 2022-es budafoki v√°g√°nyz√°r alatt mikor j√°rt az 56B jelz√©s≈± villamos a H≈±v√∂sv√∂lgy √©s a Cs√≥ka utca k√∂z√∂tt?",
    "answers": {
        "answer_start": [852],
        "text": ["2022. okt√≥ber 3. √©s november 18. k√∂z√∂tt"]
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Az al√°bbiakban sz√∂vegek szerepelnek a hozz√°juk tartoz√≥ k√©rd√©sekkel √©s v√°laszokkal.
  ```

- Base prompt template:

  ```text
  Sz√∂veg: {text}
  K√©rd√©s: {question}
  V√°lasz legfeljebb 3 sz√≥ban:
  ```

- Instruction-tuned prompt template:

  ```text
  Sz√∂veg: {text}

  V√°laszoljon az al√°bbi k√©rd√©sre a fenti sz√∂veg alapj√°n legfeljebb 3 sz√≥ban.

  K√©rd√©s: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-hu
```

## Knowledge

### Exams-bg

This dataset was published in [this paper](https://aclanthology.org/2023.acl-long.487/)
and contains questions collected from high school (HS) examinations in Bulgaria.

The original full dataset consists of 1,329 / 365 / 1,472 samples for
training, validation and testing, respectively. We only keep samples that have 4 choices,
and we thus use a 1,024 / 94 / 2,048 split for training, validation and testing,
respectively. The train and validation set are sampled from the original splits, but
the test set has additional samples from both the original train and validation sets.

Here are a few examples from the training split:

```json
{
    "text": "–ü—Ä–∏ —Å–≤—ä—Ä–∑–≤–∞–Ω–µ—Ç–æ –Ω–∞ —Ç—Ä–∏ –∞–º–∏–Ω–æ–∫–∏—Å–µ–ª–∏–Ω–∏ —Å–µ –æ–±—Ä–∞–∑—É–≤–∞:\n–í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\na. —Ç—Ä–∏–∑–∞—Ö–∞—Ä–∏–¥\nb. —Ç—Ä–∏–ø–µ–ø—Ç–∏–¥\nc. —Ç—Ä–∏–Ω—É–∫–ª–µ–æ—Ç–∏–¥\nd. —Ç—Ä–∏–≥–ª–∏—Ü–µ—Ä–∏–¥",
    "label": "b"
}
```

```json
{
    "text": "–ü—Ä–µ–∑ 1911 –≥. –ë—ä–ª–≥–∞—Ä—Å–∫–æ—Ç–æ –∫–Ω–∏–∂–æ–≤–Ω–æ –¥—Ä—É–∂–µ—Å—Ç–≤–æ —Å–µ –ø—Ä–µ–∏–º–µ–Ω—É–≤–∞ –Ω–∞:\n–í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\na. –ù–∞—Ä–æ–¥–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ ‚Äû–ö–∏—Ä–∏–ª –∏ –ú–µ—Ç–æ–¥–∏–π‚Äù\nb. –°–æ—Ñ–∏–π—Å–∫–∏ –¥—ä—Ä–∂–∞–≤–µ–Ω —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç\nc. –ë—ä–ª–≥–∞—Ä—Å–∫–∞ –∞–∫–∞–¥–µ–º–∏—è –Ω–∞ –Ω–∞—É–∫–∏—Ç–µ\nd. –í–∏—Å—à–µ –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–æ —É—á–∏–ª–∏—â–µ",
    "label": "c"
}
```

```json
{
    "text": "–ö–æ—è –∑–µ–º–µ–¥–µ–ª—Å–∫–∞ –∫—É–ª—Ç—É—Ä–∞ —Å–µ –æ—Ç–≥–ª–µ–∂–¥–∞ —Å–∞–º–æ –≤ –Æ–∂–Ω–∞ –ë—ä–ª–≥–∞—Ä–∏—è?\n–í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\na. —Ç—é—Ç—é–Ω\nb. —Å–ª—ä–Ω—á–æ–≥–ª–µ–¥\nc. –æ—Ä–∏–∑\nd. —Ü–∞—Ä–µ–≤–∏—Ü–∞",
    "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  –°–ª–µ–¥–≤–∞—Ç –≤—ä–ø—Ä–æ—Å–∏ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω –∏–∑–±–æ—Ä (—Å –æ—Ç–≥–æ–≤–æ—Ä–∏).
  ```

- Base prompt template:

  ```text
  –í—ä–ø—Ä–æ—Å: {text}
  –í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  –û—Ç–≥–æ–≤–æ—Ä: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  –í—ä–ø—Ä–æ—Å: {text}

  –û—Ç–≥–æ–≤–æ—Ä–µ—Ç–µ –Ω–∞ –≥–æ—Ä–Ω–∏—è –≤—ä–ø—Ä–æ—Å –∫–∞—Ç–æ –æ—Ç–≥–æ–≤–æ—Ä–∏—Ç–µ —Å 'a', 'b', 'c' –∏–ª–∏ 'd', –∏ –Ω–∏—â–æ –¥—Ä—É–≥–æ.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset exams-bg
```

## Common-sense Reasoning

### Winogrande-bg

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "–ù–µ –º–æ–∂–µ—Ö –¥–∞ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–∞–º –≤–ª–∞–≥–∞—Ç–∞ –∫–∞–∫—Ç–æ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–∞—Ö –¥—ä–∂–¥–∞, –∑–∞—â–æ—Ç–æ _ –∏–¥–≤–∞—à–µ –æ—Ç–≤—Å—è–∫—ä–¥–µ. –ù–∞ –∫–∞–∫–≤–æ —Å–µ –æ—Ç–Ω–∞—Å—è –ø—Ä–∞–∑–Ω–æ—Ç–æ –º—è—Å—Ç–æ _?\n–í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\na. –≤–ª–∞–≥–∞\nb. –¥—ä–∂–¥",
    "label": "a"
}
```

```json
{
    "text": "–î–∂–µ—Å–∏–∫–∞ —Å–º—è—Ç–∞—à–µ, —á–µ "Sandstorm" –µ –Ω–∞–π-–≤–µ–ª–∏–∫–∞—Ç–∞ –ø–µ—Å–µ–Ω, –ø–∏—Å–∞–Ω–∞ –Ω—è–∫–æ–≥–∞, –Ω–æ –ü–∞—Ç—Ä–∏—Ü–∏—è —è –º—Ä–∞–∑–µ—à–µ. _ –∫—É–ø–∏ –±–∏–ª–µ—Ç –∑–∞ –¥–∂–∞–∑ –∫–æ–Ω—Ü–µ—Ä—Ç–∞. –ù–∞ –∫–∞–∫–≤–æ —Å–µ –æ—Ç–Ω–∞—Å—è –ø—Ä–∞–∑–Ω–æ—Ç–æ –º—è—Å—Ç–æ _?\n–í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\na. –î–∂–µ—Å–∏–∫–∞\nb. –ü–∞—Ç—Ä–∏—Ü–∏—è",
    "label": "b"
}
```

```json
{
    "text": "–¢–µ—Ä–º–æ—Å—Ç–∞—Ç—ä—Ç –ø–æ–∫–∞–∑–∞, —á–µ –¥–æ–ª—É –µ –¥–≤–∞–¥–µ—Å–µ—Ç –≥—Ä–∞–¥—É—Å–∞ –ø–æ-—Ö–ª–∞–¥–Ω–æ, –æ—Ç–∫–æ–ª–∫–æ—Ç–æ –≥–æ—Ä–µ, –∑–∞—Ç–æ–≤–∞ –ë–∞–π—Ä–æ–Ω –æ—Å—Ç–∞–Ω–∞ –≤ _ –∑–∞—â–æ—Ç–æ –º—É –±–µ—à–µ —Å—Ç—É–¥–µ–Ω–æ. –ù–∞ –∫–∞–∫–≤–æ —Å–µ –æ—Ç–Ω–∞—Å—è –ø—Ä–∞–∑–Ω–æ—Ç–æ –º—è—Å—Ç–æ _?\n–í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\na. –¥–æ–ª—É\nb. –≥–æ—Ä–µ",
    "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  –°–ª–µ–¥–≤–∞—Ç –≤—ä–ø—Ä–æ—Å–∏ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω –∏–∑–±–æ—Ä (—Å –æ—Ç–≥–æ–≤–æ—Ä–∏).
  ```

- Base prompt template:

  ```text
  –í—ä–ø—Ä–æ—Å: {text}
  –í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
  a. {option_a}
  b. {option_b}
  –û—Ç–≥–æ–≤–æ—Ä: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  –í—ä–ø—Ä–æ—Å: {text}
  –í—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
  a. {option_a}
  b. {option_b}

  –û—Ç–≥–æ–≤–æ—Ä–µ—Ç–µ –Ω–∞ –≥–æ—Ä–Ω–∏—è –≤—ä–ø—Ä–æ—Å –∫–∞—Ç–æ –æ—Ç–≥–æ–≤–æ—Ä–∏—Ç–µ —Å 'a' –∏–ª–∏ 'b', –∏ –Ω–∏—â–æ –¥—Ä—É–≥–æ.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-bg
```
