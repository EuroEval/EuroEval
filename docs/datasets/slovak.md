# ğŸ‡¸ğŸ‡° Slovak

This is an overview of all the datasets used in the Slovak part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### CSFD Sentiment-sk

This dataset was published in [this paper](https://aclanthology.org/R13-1016/) and
consists of reviews from the the Czech/Slovak Movie
Database (CSFD).

The original dataset contains 25,000 / 2,500 / 2,500 samples for the training,
validation, and test splits, respectively. We use 1,024 / 256 / 2,048 samples for
our training, validation and test splits, respectively. All the new splits are
subsets of the original splits.

Here are a few examples from the training split:

```json
{
    "text": "JÃ³ Steve Buacemi...jinak sraÄka",
    "label": "negative"
}
```

```json
{
    "text": "Letny oddychovy comicsovy blockbuster. Po celkom fresh traileri a hlavne podla momentalnych hodnoteni (89%, 76. najlepsi film!!!) som cakal, ze to bude daka svieza pecka a prijemne prekvapenie. Ale nakoniec je to dost taky priemer. Taka ta klasika, universe s roznymi rasami, (anti)hrdinova, neoriginalna zapletka, kopa akcie.. Co vycnievalo boli zaujimave postavy a hlavne vtipne hlasky. Prave tymto sa mohol film viac odlisit od ostatnych comicsoviek, vtedy by som isiel s hodnotenim vyssie.. Od polky filmu mi bolo jasne, ze to je kvazi ochutnavka na (minimalne) dalsie 2 casti, tak uvidime kam to posunu. [#40/2013]",
    "label": "neutral"
}
```

```json
{
    "text": "Prevapivo prÃ­jemnÃ©, vtipnÃ©, rozprÃ¡vkovÃ©. KoneÄne fantasy film, ktorÃ½ sa sÃºstredÃ­ na rozprÃ¡vanie prÃ­behu a nepotrebuje k tomu zbesilÃ© tempo ani veÄ¾kolepÃ© poÄÃ­taÄovÃ© armÃ¡dy. Vo svojej podstate to nie je aÅ¾ takÃ© originÃ¡lne, ale je tam pÃ¡r zaujÃ­mavÃ½ch nÃ¡padov a ako celok to skvelo funguje - vÅ¡etko je skrÃ¡tka na svojom mieste...",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  NiÅ¾Å¡ie sÃº dokumenty a ich sentiment, ktorÃ½ mÃ´Å¾e byÅ¥ 'pozitÃ­vne', 'neutrÃ¡lne' alebo 'negatÃ­vne'.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Sentiment: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  Klasifikujte pocit v dokumente. Odpovedzte so 'pozitÃ­vne', 'neutrÃ¡lne', alebo 'negatÃ­vne', a niÄ inÃ©.
  ```

- Label mapping:
  - `positive` â¡ï¸ `pozitÃ­vne`
  - `neutral` â¡ï¸ `neutrÃ¡lne`
  - `negative` â¡ï¸ `negatÃ­vne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset csfd-sentiment-sk
```

## Named Entity Recognition

### UNER-sk

This dataset was published in
[this paper](https://aclanthology.org/2024.naacl-long.243/).

The original dataset consists of 8,482 / 1,059 / 1,060 samples for the
training, validation, and test splits, respectively. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively. The train and
validation splits are subsets of the original splits, while the test split is
created using additional samples from the train split.

Here are a few examples from the training split:

```json
{
  "tokens": ["Bude", "maÅ¥", "nÃ¡zov", "Shanghai", "Noon", "a", "reÅ¾isÃ©rom", "bude", "debutujÃºci", "Tom", "Dey", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-PER", "I-PER", "O"]
}
```

```json
{
  "tokens": ["Ako", "Å¡esÅ¥roÄnÃ©ho", "(", "o", "rok", "skÃ´r", ",", "neÅ¾", "bolo", "zvykom", ")", "ho", "na", "zÃ¡klade", "zvlÃ¡Å¡tnej", "vÃ½nimky", "prijali", "medzi", "Zvedov", "a", "ako", "devÃ¤Å¥roÄnÃ½", "sa", "stal", "vedÃºcim", "skupiny", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

```json
{
  "tokens": ["To", "predsa", "stojÃ­", "za", "pokus", "!"],
  "labels": ["O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  NasledujÃºce sÃº vety a JSON-objekty s pomenovanÃ½mi entitami, ktorÃ© sa nachÃ¡dzajÃº v danej vete.
  ```

- Base prompt template:

  ```text
  Veta: {text}
  PomenovanÃ© entity: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Veta: {text}

  Identifikujte pomenovanÃ© entity vo vete. VÃ½stup by mal byÅ¥ vo forme JSON-objektu s kÄ¾ÃºÄmi 'osoba', 'miesto', 'organizÃ¡cia' a 'rÃ´zne'. Hodnoty by mali byÅ¥ zoznamy pomenovanÃ½ch entÃ­t danej kategÃ³rie, presne tak, ako sa vyskytujÃº vo vete.
  ```

- Label mapping:
  - `B-PER` â¡ï¸ `osoba`
  - `I-PER` â¡ï¸ `osoba`
  - `B-LOC` â¡ï¸ `miesto`
  - `I-LOC` â¡ï¸ `miesto`
  - `B-ORG` â¡ï¸ `organizÃ¡cia`
  - `I-ORG` â¡ï¸ `organizÃ¡cia`
  - `B-MISC` â¡ï¸ `rÃ´zne`
  - `I-MISC` â¡ï¸ `rÃ´zne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset uner-sk
```

## Linguistic Acceptability

### CS-GEC

This dataset is extracted by postprocessing data from
[this paper](https://aclanthology.org/D19-5545/). Specifically,
grammatically incorrect sentences and their corresponding corrections
were extracted.

The original full dataset consists of 59,493 training and 4,668 test
samples, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation, and testing, respectively. The train and test splits are
subsets of the original splits, and the validation split is created
using examples from the train split.

Here are a few examples from the training split:

```json
{
  "text": "MusÃ­me ochutnÃ¡t pivo a knedlÃ­ky .",
  "label": "incorrect"
}
```

```json
{
  "text": "V budoucnosti bych chtÄ›la mÃ­t velkou rodinu a dÅ¯m mÃ½ch snÅ¯ .",
  "label": "correct"
}
```

```json
{
  "text": "DÄ›deÄek i babiÄka po druhÃ© svÄ›tovÃ© vÃ¡lce nÄ›kolik let Å¾ili v ÄŒR a pak se zase vratili do LuÅ¾ice .",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  NÃ¡sledujÃ­cÃ­ jsou vÄ›ty a zda jsou gramaticky sprÃ¡vnÃ©.
  ```

- Base prompt template:

  ```text
  VÄ›ta: {text}
  Gramaticky sprÃ¡vnÃ¡: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  VÄ›ta: {text}

  UrÄete, zda je vÄ›ta gramaticky sprÃ¡vnÃ¡ nebo ne. OdpovÄ›zte 'ano', pokud je vÄ›ta sprÃ¡vnÃ¡, a 'ne', pokud nenÃ­. OdpovÄ›zte pouze tÃ­mto slovem, a niÄÃ­m jinÃ½m.
  ```

- Label mapping:
  - `correct` â¡ï¸ `ano`
  - `incorrect` â¡ï¸ `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset cs-gec
```

### Unofficial: ScaLA-cs

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Czech Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Slovak-SNK) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "NiektorÃ­ pozorovatelia povaÅ¾ujÃº ropnÃ© zÃ¡ujmy USA za jednu z hlavnÃ½ch motivÃ¡ciÃ­ vstupu do vojny v Iraku.",
    "label": "correct"
}
```

```json
{
    "text": "PopÃ¡liÅ¥ sa na jedinom pÃ­smene je klasickÃ½ prÃ­pad, ktorÃ½ sa mÃ´Å¾e vyskytnÃºÅ¥ v rÃ´znych podobÃ¡ch.",
    "label": "correct"
}
```

```json
{
    "text": "Zo strachu o seba, pre svoju povÃ½Å¡enÃº zbabelosÅ¥ zaprel svojho Majstra PÃ¡na.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  NasledujÃº vety a Äi sÃº gramaticky sprÃ¡vne.
  ```

- Base prompt template:

  ```text
  Veta: {text}
  Gramaticky sprÃ¡vna: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Veta: {text}

  UrÄite, Äi je veta gramaticky sprÃ¡vna alebo nie. Odpovedzte so 'Ã¡no', ak je veta sprÃ¡vna, a 'nie', ak nie je. Odpovedzte iba tÃ½mto slovom, a niÄ inÃ©.
  ```

- Label mapping:
  - `correct` â¡ï¸ `Ã¡no`
  - `incorrect` â¡ï¸ `nie`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-cs
```

### CS-GEC

This dataset is extracted by postprocessing data from
[this paper](https://doi.org/10.18653/v1/D19-5545). Specifically,
grammatically incorrect sentences and their corresponding corrections
were extracted.

The original full dataset consists of 59,493 training and 4,668 test
samples, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation, and testing, respectively. The train and test splits are
subsets of the original splits, and the validation split is created
using examples from the train split.

Here are a few examples from the training split:

```json
{
  "text": "MusÃ­me ochutnÃ¡t pivo a knedlÃ­ky .",
  "label": "incorrect"
}
```

```json
{
  "text": "V budoucnosti bych chtÄ›la mÃ­t velkou rodinu a dÅ¯m mÃ½ch snÅ¯ .",
  "label": "correct"
}
```

```json
{
  "text": "DÄ›deÄek i babiÄka po druhÃ© svÄ›tovÃ© vÃ¡lce nÄ›kolik let Å¾ili v ÄŒR a pak se zase vratili do LuÅ¾ice .",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  NÃ¡sledujÃ­cÃ­ jsou vÄ›ty a zda jsou gramaticky sprÃ¡vnÃ©.
  ```

- Base prompt template:

  ```text
  VÄ›ta: {text}
  Gramaticky sprÃ¡vnÃ¡: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  VÄ›ta: {text}

  UrÄete, zda je vÄ›ta gramaticky sprÃ¡vnÃ¡ nebo ne. OdpovÄ›zte 'ano', pokud je vÄ›ta sprÃ¡vnÃ¡, a 'ne', pokud nenÃ­. OdpovÄ›zte pouze tÃ­mto slovem, a niÄÃ­m jinÃ½m.
  ```

- Label mapping:
  - `correct` â¡ï¸ `ano`
  - `incorrect` â¡ï¸ `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset cs-gec
```

## Reading Comprehension

### MultiWikiQA-sk

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
  "context": "Register toxickÃ½ch ÃºÄinkov chemickÃ½ch lÃ¡tok (anglicky Registry of Toxic Effects of Chemical Substances, RTECS) je databÃ¡za toxikologickÃ½ch informÃ¡ciÃ­ zostavenÃ½ch z voÄ¾ne dostupnej vedeckej literatÃºry bez odkazu na platnosÅ¥ alebo uÅ¾itoÄnosÅ¥ publikovanÃ½ch Å¡tÃºdiÃ­. Do roku 2001 bola databÃ¡za spravovanÃ¡ americkou organizÃ¡ciou NIOSH (National Institute for Occupational Safety and Health, slov. NÃ¡rodnÃ½ Ãºstav pre bezpeÄnosÅ¥ a ochranu zdravia pri prÃ¡ci) ako verejne dostupnÃ¡ publikÃ¡cia. Teraz ju spravuje sÃºkromnÃ¡ spoloÄnosÅ¥ Symyx Technologies a je dostupnÃ¡ len za poplatok.\n\nObsah \nDatabÃ¡za obsahuje Å¡esÅ¥ typov toxikologickÃ½ch informÃ¡ciÃ­:\n primÃ¡rne podrÃ¡Å¾denie\n mutagÃ©nne ÃºÄinky\n reprodukÄnÃ© ÃºÄinky\n karcinogÃ©nne ÃºÄinky\n akÃºtna toxicita\n toxicita viacnÃ¡sobnÃ½ch dÃ¡vok\nV databÃ¡ze sa spomÃ­najÃº ako Å¡pecifickÃ© ÄÃ­selnÃ© hodnoty, ako naprÃ­klad LD50, LC50, TDLo alebo TCLo, tak aj Å¡tudovanÃ© organizmy a spÃ´sob podÃ¡vania lÃ¡tky. Pre vÅ¡etky dÃ¡ta sÃº uvedenÃ© bibliografickÃ© zdroje. Å tÃºdie pritom nie sÃº nijako hodnotenÃ©.\n\nHistÃ³ria \nDatabÃ¡za RTECS bola aktivitou schvÃ¡lenou americkÃ½m Kongresom, zakotvenou v Sekcii 20(a)(6) zÃ¡kona Occupational Safety and Health Act z roku 1970 (PL 91-596). PÃ´vodnÃ© vydanie, znÃ¡me ako Zoznam toxickÃ½ch lÃ¡tok (Toxic Substances List), bolo publikovanÃ© 28. jÃºna 1971 a obsahovalo toxikologickÃ© dÃ¡ta o pribliÅ¾ne 5 000 chemikÃ¡liÃ¡ch. NÃ¡zov bol neskÃ´r zmenenÃ½ na dneÅ¡nÃ½ Register toxickÃ½ch ÃºÄinkov chemickÃ½ch lÃ¡tok (Registry of Toxic Effects of Chemical Substances). V januÃ¡ri 2001 databÃ¡za obsahovala 152 970 chemikÃ¡liÃ­. V decembri 2001 bola sprÃ¡va RTECS prevedenÃ¡ z NIOSH do sÃºkromnej firmy Elsevier MDL. TÃºto firmu kÃºpila v roku 2007 spoloÄnosÅ¥ Symyx, sÃºÄasÅ¥ou akvizÃ­cie bola aj databÃ¡za RTECS. TÃ¡ je teraz dostupnÃ¡ len za poplatok vo forme roÄnÃ©ho predplatnÃ©ho.\n\nRTECS je k dispozÃ­cii v angliÄtine, francÃºzÅ¡tine a Å¡panielÄine, a to prostrednÃ­ctvom KanadskÃ©ho centra pre bezpeÄnosÅ¥ a ochranu zdravia pri prÃ¡ci. Predplatitelia majÃº prÃ­stup cez web, na CD-ROM a vo formÃ¡te pre intranet. DatabÃ¡za je dostupnÃ¡ na webe aj cez NISC (National Information Services Corporation) a ExPub (Expert Publishing, LLC).\n\nExternÃ© odkazy \n\n RTECS overview \n Symyx website \n Expert Publishing, LLC Website\n\nZdroj \n\nChemickÃ© nÃ¡zvy a kÃ³dy\nToxikolÃ³gia",
  "question": "AkÃ© sÃº tri moÅ¾nosti prÃ­stupu k databÃ¡ze RTECS, ak som predplatiteÄ¾?",
  "answers": {"answer_start": [1949], "text": ["cez web, na CD-ROM a vo formÃ¡te pre intranet"]}}
```

```json
{
  "context": "Herta NaglovÃ¡-DocekalovÃ¡ (* 29. mÃ¡j 1944, Wels, RakÃºsko) je rakÃºska filozofka a profesorka, Älenka vedenia MedzinÃ¡rodnej asociÃ¡cie filozofiek (IAPf), Ã–sterreichische Akademie der Wissenschaften, Institut International de Philosophie (ParÃ­Å¾), viceprezidentka FÃ©dÃ©ration Internationale des SociÃ©tÃ©s de Philosophie (FISP), zakladajÃºca Älenka interdisciplinÃ¡rnych pracovnÃ½ch skupÃ­n Frauengeschichte a Philosophische Frauenforschung na Viedenskej univerzite, Älenka redakÄnÃ½ch rÃ¡d poprednÃ½ch vedeckÃ½ch Äasopisov, napr. Philosophin, LÂ´Homme, Deutsche Zeitschrift fÃ¼r Philosophie.\n\nÅ½ivotopis \nVyÅ¡tudovala histÃ³riu, filozofiu a germanistiku na Viedenskej univerzite. V roku 1967 zÃ­skala na svojej alma mater doktorÃ¡t z histÃ³rie prÃ¡cou o filozofovi dejÃ­n Ernstovi von Lasaulx). V rokoch 1968 - 1985 bola asistentkou na InÅ¡titÃºte filozofie Viedenskej univerzity. V lete 1980 prednÃ¡Å¡ala na Millersville University of Pennsylvania v USA.\n\nV roku 1981 sa habilitovala z filozofie na Viedenskej univerzite dielom Die ObjektivitÃ¤t der Geschichtswissenschaft. V rokoch 1985 aÅ¾ 2009 bola profesorkou InÅ¡titÃºtu filozofie Viedenskej univerzity. Od roku 2009 je univerzitnou profesorkou na dÃ´chodku (UniversitÃ¤tsprofessorin i. R.)\n\nBola hosÅ¥ujÃºcou profesorkou v roku 1990 na Universiteit Utrecht v holandskom Utrechte; v Nemecku 1991/1992 na Goethe-UniversitÃ¤t Frankfurt vo Frankfurte nad Mohanom; 1993 na UniversitÃ¤t Konstanz v Konstanzi; 1994/1995 na Freie UniversitÃ¤t Berlin v BerlÃ­ne. V rokoch 1995/1996 prednÃ¡Å¡ala na UniversitÃ¤t Innsbruck a 2011 na univerzite v Petrohrade v Rusku.\n\nDielo (vÃ½ber) \n Jenseits der SÃ¤kularisierung. Religionsphilosophische Studien. - Berlin 2008 (Hg., gem.m. Friedrich Wolfram).\n Viele Religionen - eine Vernunft? Ein Disput zu Hegel. - Wien/Berlin 2008 (Hg., gem.m. Wolfgang Kaltenbacher und Ludwig Nagl).\n Glauben und Wissen. Ein Symposium mit JÃ¼rgen Habermas. - Wien/Berlin 2007 (Hg., gem.m. Rudolf Langthaler).\n Geschichtsphilosophie und Kulturkritik. - Darmstadt 2003 (Hrsg., gem.m. Johannes Rohbeck).\n Feministische Philosophie. Ergebnisse, Probleme, Perspektiven. - Frankfurt a.M. 2000 a 2004 \n Continental Philosophy in Feminist Perspective. - Pennsylviania State University Press 2000 (Hg. gem.m. Cornelia Klingler).\n Der Sinn des Historischen. - Frankfurt a.M. 1996 (Hrsg.).\n Politische Theorie. Differenz und LebensqualitÃ¤t. - Frankfurt a.M. 1996 (Hrsg. gem.m. Herlinde Pauer-Studer).\n Postkoloniales Philosophieren: Afrika. - Wien/MÃ¼nchen 1992 (Hrsg., gem.m. Franz Wimmer).\n Tod des Subjekts? - Wien/MÃ¼nchen 1987 (Hrsg., gem.m. Helmuth Vetter).\n Die ObjektivitÃ¤t der Geschichtswissenschaft. Systematische Untersuchungen zum wissenschaftlichen Status der Historie. - Wien/MÃ¼nchen 1982\n spoluvydavateÄ¾ka: Wiener Reihe. Themen der Philosophie (od 1986). \n spoluvydavateÄ¾ka: Deutsche Zeitschrift fÃ¼r Philosophie (1993-2004). \n spoluvydavateÄ¾ka: L'Homme. EuropÃ¤ische Zeitschrift fÃ¼r feministische Geschichtswissenschaft (1990 - 2003).\n\nOcenenia \n FÃ¶rderpreis mesta ViedeÅˆ, 1983\n KÃ¤the Leichter Preis (rakÃºska Å¡tÃ¡tna cena), 1997 \n Preis fÃ¼r Geistes- und Sozialwissenschaften der Stadt Wien, 2009\n\nReferencie\n\nExternÃ© odkazy \n OficiÃ¡lna strÃ¡nka, UniversitÃ¤t Wien \n Austria Forum, Wissenssammlungen/Biographien: Herta Nagl-Docekal\n\nZdroj \n\nRakÃºski filozofi",
  "question": "Kedy priÅ¡la na svet Herta NaglovÃ¡-DocekalovÃ¡?",
  "answers": {"answer_start": [28], "text": ["29. mÃ¡j 1944"]}}
```

```json
{"context": "Martin BareÅ¡ (* 25. november 1968, Brno) je ÄeskÃ½ profesor neurolÃ³gie, od septembra 2019 rektor Masarykovej univerzity, predtÃ½m od februÃ¡ra 2018 do septembra 2019 dekan LekÃ¡rskej fakulty Masarykovej univerzity.\n\nRiadiace funkcie \nVo februÃ¡ri 2018 sa stal dekanom LekÃ¡rskej fakulty Masarykovej univerzity. Funkciu prevzal po JiÅ™Ã­m Mayerovi, ktorÃ½ zastÃ¡val pozÃ­ciu dekana v obdobÃ­ 20102018. S nÃ¡stupom na post dekana ukonÄil svoje pÃ´sobenie ako prorektor univerzity, ako i zÃ¡stupca prednostu I. neurologickej kliniky pre vedu a vÃ½skum.\n\nDo funkcie rektora univerzity bol zvolenÃ½ 1. aprÃ­la 2019 AkademickÃ½m senÃ¡tom Masarykovej univerzity. V prvom kole tajnej voÄ¾by zÃ­skal BareÅ¡ 36 hlasov z 50 prÃ­tomnÃ½ch senÃ¡torov. ProtikandidÃ¡ta, prodekana PrÃ­rodovedeckej fakulty JaromÃ­ra Leichmana, volilo 11 senÃ¡torov. 3 odovzdanÃ© hlasy boli neplatnÃ©.\n\nSkÃºsenosti s pÃ´sobenÃ­m vo vedenÃ­ Å¡koly zbieral BareÅ¡ v rokoch 20112018, kedy pÃ´sobil najskÃ´r ako jej prorektor pre rozvoj a potom ako prorektor pre akademickÃ© zÃ¡leÅ¾itosti. Za svoje priority oznaÄil BareÅ¡ v dobe voÄ¾by posilÅˆovanie role univerzity ako piliera slobody v sÃºÄasnej spoloÄnosti a zvÃ½Å¡enie kvality vzdelÃ¡vania, vedy a vÃ½skumu na medzinÃ¡rodnej Ãºrovni.\n\nDo funkcie rektora ho vymenoval 11. jÃºna 2019 prezident MiloÅ¡ Zeman s ÃºÄinnosÅ¥ou od 1. septembra 2019. Vo funkcii tak nahradil MikulÃ¡Å¡a Beka, ktorÃ©mu sa skonÄilo druhÃ© volebnÃ© obdobie a o zvolenie sa teda uÅ¾ opÃ¤Å¥ uchÃ¡dzaÅ¥ nemohol. BareÅ¡ k 1. septembru 2019 rezignoval na post dekana LekÃ¡rskej fakulty.\n\nVedeckÃ¡ ÄinnosÅ¥ \nJe prednÃ¡Å¡ajÃºcim v odboroch vÅ¡eobecnÃ© lekÃ¡rstvo, zubnÃ© lekÃ¡rstvo, optometria, fyzioterapia, neurofyziolÃ³gia pre Å¡tudentov prÃ­rodnÃ½ch vied LekÃ¡rskej fakulty Masarykovej univerzity a Å¡koliteÄ¾ doktorandov odborovej rady neurolÃ³gia a neurovedy.\n\nPÃ´sobÃ­ v tÃ½chto vedeckÃ½ch radÃ¡ch: Masarykova univerzita, LekÃ¡rska fakulta Masarykovej univerzity a CEITEC MU. Äalej tieÅ¾ Univerzita PalackÃ©ho v Olomouci, LekÃ¡rska fakulta UPOL, Fakulta veterinÃ¡rnÃ­ho lÃ©kaÅ™stvÃ­ VFU, Äalej je tieÅ¾ Älenom ÄŒeskej lekÃ¡rskej komory, ÄŒeskej neurologickej spoloÄnosti, ÄŒeskej spoloÄnosti klinickej neurofyziolÃ³gie, ÄŒeskej lekÃ¡rskej spoloÄnosti Jana Evangelisty PurkynÄ›, Movement Disorders Society, Society for the Research on the Cerebellum a Society for Neuroscience. Takisto je Älenom redakÄnej rady Äasopisov Clinical Neurophysiology, Behavioural Neurology, Tremor and Other Hyperkinetic Movements a Biomedical Papers.\n\nOsobnÃ½ Å¾ivot \nJe Å¾enatÃ½, mÃ¡ dvoch synov a dcÃ©ru.\n\nReferencie\n\nExternÃ© odkazy \n Martin BareÅ¡\n\nZdroj \n\nÄŒeskÃ­ lekÃ¡ri\nNeurolÃ³govia\nRektori Masarykovej univerzity\nÄŒeskÃ­ univerzitnÃ­ profesori\nDekani LekÃ¡rskej fakulty Masarykovej univerzity\nAbsolventi LekÃ¡rskej fakulty Masarykovej univerzity\nOsobnosti z Brna",
"question": "AkÃº pozÃ­ciu mal Martin BareÅ¡ na Masarykovej univerzite poÄnÃºc septembrom 2019?",
"answers": {"answer_start": [89], "text": ["rektor"]}}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  NasledujÃº texty s pridruÅ¾enÃ½mi otÃ¡zkami a odpoveÄami.
  ```

- Base prompt template:

  ```text
  Text: {text}
  OtÃ¡zka: {question}
  OdpoveÄ na maximÃ¡lne 3 slovÃ¡:
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Odpovedzte na nasledujÃºcu otÃ¡zku tÃ½kajÃºcu sa textu uvedenÃ©ho vyÅ¡Å¡ie maximÃ¡lne 3 slovami.

  OtÃ¡zka: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-sk
```

## Knowledge

### MMLU-sk

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Swedish was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "V akÃ½ch smeroch je prÃ­pad pre humanitÃ¡rnu intervenciu, ako je uvedenÃ© v tejto kapitol... mocnÃ½mi Å¡tÃ¡tmi.\nd. VÅ¡etky tieto moÅ¾nosti.",
  "label": "d",
}
```

```json
{
  "text": "FAKTORIÃLOVÃ ANOVA sa pouÅ¾Ã­va v prÃ­pade, Å¾e Å¡tÃºdia zahÅ•Åˆa viac ako 1 VI. AkÃ½ je INTER...Äinok VI na rovnakej Ãºrovni ako ostatnÃ© VI",
  "label": "a"
}
```

```json
{
  "text": "Pre ktorÃº z tÃ½chto dvoch situÃ¡ciÃ­ urobÃ­ hlavnÃ¡ postava (ktorÃ¡ pouÅ¾Ã­va ja/mÅˆa/mÃ´j) nie...ie zlÃ©\nc. Nie zlÃ©, zlÃ©\nd. Nie zlÃ©, nie zlÃ©",
  "label": "d",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  NasledujÃº otÃ¡zky s viacerÃ½mi moÅ¾nosÅ¥ami (s odpoveÄami).
  ```

- Base prompt template:

  ```text
  OtÃ¡zka: {text}
  OdpoveÄ: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  OtÃ¡zka: {text}

  Odpovedzte na nasledujÃºcu otÃ¡zku pouÅ¾itÃ­m 'a', 'b', 'c' alebo 'd', a niÄ inÃ©.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-sk
```

## Common-sense Reasoning

### HellaSwag-cs

This dataset is a machine translated version of the English [HellaSwag
dataset](https://doi.org/10.18653/v1/P19-1472). The dataset was translated using
[LINDAT Translation Service](https://lindat.mff.cuni.cz/services/translation/docs).

The original dataset has 10,000 samples. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively.

Here are a few examples from the training split (which have _not_ been post-edited):

```json
{
  "text": "RybaÅ™enÃ­ na ledu: VidÃ­me ÃºvodnÃ­ titulnÃ­ obrazovku. Na snÄ›hu a ledovÃ© rybÄ› sedÃ­ muÅ¾ a chlapec. My\nVÃ½bÄ›r:\na. vidÃ­me mÄ›sta a zmÄ›ny kolem nich.\nb. vidÃ­me dole kreslenou animaci bocku.\nc. pak vidÃ­me sport.\nd. vidÃ­me titulnÃ­ obrazovku a letadlo letÃ­ na obloze a v dÃ¡lce vidÃ­me lidi na ledu a nÃ¡klaÄÃ¡k.",
  "label": "d"
}
```

```json
{
  "text": "BÄ›h maratonu: Sportovci dÃ¡vajÃ­ rozhovory a nÄ›kteÅ™Ã­ pÅ™edvÃ¡dÄ›jÃ­ medaile za ÃºÄast. Sportovci nastupujÃ­ do bÃ­lÃ½ch autobusÅ¯. Autobusy\nVÃ½bÄ›r:\na. se pohybujÃ­ po silnici.\nb. odstartujÃ­ z rampy.\nc. se pohybujÃ­ po drÃ¡ze a lidÃ© skÃ¡Äou po rampÃ¡ch.\nd. mÃ­jÃ­ nÄ›kolik sportovcÅ¯ sedÃ­cÃ­ch na zelenÃ½ch baldachÃ½nech.",
  "label": "a"
}
```

```json
{
  "text": "Family Life: Jak uspoÅ™Ã¡dat havajskou svatebnÃ­ hostinu. Vyberte tradiÄnÃ­ havajskÃ½ odÄ›v pro nevÄ›stu a Å¾enicha. HavajskÃ¡ nevÄ›sta tradiÄnÄ› nosÃ­ bÃ­lÃ© dlouhÃ© splÃ½vavÃ© Å¡aty s vÄ›ncem z haku neboli prstenem z hawajskÃ½ch kvÄ›tin kolem hlavy. HavajskÃ½ Å¾enich tradiÄnÄ› nosÃ­ bÃ­lÃ© kalhoty a bÃ­lou koÅ¡ili s pestrobarevnou Å¡erpou kolem pasu.\nVÃ½bÄ›r:\na. NoÅ¡enÃ­ hawajskÃ©ho vÄ›nce pÅ™i pÅ™Ã­leÅ¾itosti vaÅ¡Ã­ recepce mÅ¯Å¾e takÃ© pomoci cementovat hawajskÃ© svatebnÃ­ sliby. HavajskÃ© splÃ½vavÃ© Å¡aty jsou stÃ¡le tradiÄnÃ­ se svatebnÃ­m odÄ›vem, navzdory povaze svatby.\nb. Å½enich takÃ© nosÃ­ kolem krku zelenou poÅ¡tolku lei.. Vyberte hawajskÃ½ odÄ›v pro svatebnÃ­ hostinu.\nc. Tyto prvky spolu velmi dobÅ™e splÃ½vajÃ­. Fotografie se budou odehrÃ¡vat ve velkÃ©m studiu na letiÅ¡ti v mÄ›lkÃ© vodÄ›.\nd. Vyberte si neformÃ¡lnÃ­ odÄ›v na svatbu na plÃ¡Å¾i. HavajskÃ© svatby bÃ½vajÃ­ velmi formÃ¡lnÃ­, takÅ¾e si vyberte havajskÃ© svatebnÃ­ Å¡aty s motivem kasina.",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  NÃ¡sledujÃ­cÃ­ jsou otÃ¡zky s vÃ½bÄ›rem z vÃ­ce moÅ¾nostÃ­ (s odpovÄ›Ämi).
  ```

- Base prompt template:

  ```text
  OtÃ¡zka: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  OdpovÄ›Ä: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  OtÃ¡zka: {text}
  MoÅ¾nosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  OdpovÄ›zte na vÃ½Å¡e uvedenou otÃ¡zku pomocÃ­ 'a', 'b', 'c' nebo 'd', a nic jinÃ©ho.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset hellaswag-cs
```

## Summarisation

### Czech News

This dataset was published in
[this paper](https://doi.org/10.48550/arXiv.2307.10666) and contains news articles
from major online news outlets collected from 2000-2022.

The original dataset consists of 1,641,471 / 144,836 / 144,837 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively, sampled from the original splits.

Here are a few examples from the training split:

```json
{
  "text": "VymetÃ¡m zÃ¡koutÃ­, oÄi na Å¡Å¥opkÃ¡ch, kde jeÅ¡tÄ› nÄ›co zÅ¯stalo, abych to mohl popsat a tÃ­m popsÃ¡nÃ­m zaevidovat, zkatalogizovat. TÅ™eba na tom SmÃ­chovÄ›, tam je to o Å¾ivot. Ale vÃ½sledky jsou. PÅ™ed hostincem U SmolÃ­kÅ¯, Å¡ikmo naproti SmÃ­chovskÃ©mu nÃ¡draÅ¾Ã­, bylo na tabuli kÅ™Ã­dou, kterou vedla pevnÃ¡ ruka, naÅ¡krÃ¡bÃ¡no jako souÄÃ¡st nabÃ­dky: V ÃºterÃ½ od 18 na hoÅ™e bez koz. Autor je bezesporu velkÃ½m bÃ¡snÃ­kem, jeho rozmÃ¡chlÃ¡ gesta nepotÅ™ebujÃ­ dodateÄnÃ© korekce. PÅ™edstavte si tu nÃ¡dheru - po Å¡estÃ© veÄernÃ­ nastupuje na plac servÃ­rka plochÃ¡ jak lineÃ¡l. ChlapÅ¯m sklapne Äelist a o to vÃ­ce vypijÃ­ hladinek. MezitÃ­m, neÅ¾ jsem dofabuloval, vy uÅ¾ pÅ™echÃ¡zÃ­te do haly zmÃ­nÄ›nÃ©ho nÃ¡draÅ¾Ã­, na jehoÅ¾ pravÃ©m konci si ÄetbymilovnÃ½ odjÃ­Å¾dÄ›Ä Äi pÅ™ijÃ­Å¾dÄ›Ä mÅ¯Å¾e zakoupit knihy v antikvariÃ¡tu. A jÃ¡ zde zase jako vandal vyloupÃ¡vÃ¡m zasazenÃ© dÃ©manty, kterÃ½ch si nikdo nevÅ¡Ã­mÃ¡. Nad pÅ™ihrÃ¡dkou, kde na obÃ¡lkÃ¡ch knih a ÄasopisÅ¯ pÅ™evaÅ¾uje ta partie Å¾enskÃ©ho tÄ›la, o kterÃ© byla Å™eÄ vÃ½Å¡e, umÃ­stil prodejce sÃ©manticky neobyÄejnÄ› komplikovanÃ½ nÃ¡pis: Erotika nenÃ­ k prohlÃ­Å¾enÃ­! No nenÃ­ to krÃ¡sa? To, co "dÄ›lÃ¡" erotiku erotikou, je zde vÃ½slovnÄ› zapovÄ›zeno. Je tÅ™eba kupovat, a ne jen listovat a zadarmiko se vzruÅ¡ovat! A jÃ¡ hned vytahuji zÃ¡pisnÃ­Äek a v tom dusnÃ©m nÃ¡draÅ¾nÃ­m prostÅ™edÃ­ zachycuji tuto opozdilou slzu ztracenou z grÃ¡lu. Co s tÃ­m mÃ¡ co dÄ›lat ta sebelÃ­tost? ZatÃ­mco si tady hraju na soukromÃ©ho badatele, kterÃ½ pak plody prÃ¡ce vÄ›nuje svÃ©mu nÃ¡rodu, v centru Prahy se dÄ›jou zÃ¡sadnÃ­ vÄ›ci, proti kterÃ½m je tohle moje motÃ½lkaÅ™enÃ­ pouhÃ½m okresnÃ­m pÅ™eborem. A je mi to lÃ­to. www.desir.cz 5. Å™Ã­jna 2004 probÄ›hla v nejpouÅ¾Ã­vanÄ›jÅ¡Ã­m praÅ¾skÃ©m demonstraÄnÃ­m prostoru Demonstrace za nic. Demonstranti nesli prÃ¡zdnÃ© transparenty (povolenÃ© byly pouze teÄky, vykÅ™iÄnÃ­ky a otaznÃ­ky), dokonce i prÅ¯hlednÃ© transparenty (ty byly absolutnÄ› transparentnÃ­) a rozdÃ¡vali prÃ¡zdnÃ© letÃ¡ky. Akce byla Å™Ã¡dnÄ› nahlÃ¡Å¡ena, proto ji doprovÃ¡zeli orgÃ¡ni vpÅ™edu a vzadu. KonÄilo se (150-200 osob) pod ocasem, kde byla drÅ¾ena minuta ticha za nic. GeniÃ¡lnÃ­ pakÃ¡rna, Å¡vejkÃ¡rna i kafkÃ¡rna. Tento zÃ¡sadnÃ­ nÃ¡zor obÄanskÃ© angaÅ¾ovanosti probÄ›hl pod taktovkou partiÄky jmÃ©nem DÄšSÃR (DÄšti SÃdliÅ¡tnÃ­ Recese), kterÃ¡ poÅ™Ã¡dÃ¡ recesnÃ­ a hravÃ© akce v Praze se zamÄ›Å™enÃ­m na Å¡kolÃ¡ky ze SÅ  a VÅ . Ve svÃ©m programu majÃ­ napsÃ¡no: Chceme vyuÅ¾Ã­t mÄ›stskÃ½ch prvkÅ¯ ve prospÄ›ch blaha hravÃ½ch jedincÅ¯. Na jejich strÃ¡nkÃ¡ch najdete mj. poloÅ¾ky: Fotogalerie, Kronika, KalendÃ¡Å™ akcÃ­, Pravidla her. Podle nÃ¡vodu si mÅ¯Å¾ete sami zahrÃ¡t tÅ™eba hry Lapni dav nebo PiÅ¡kvorky nabÃ­jenÃ© tramvajÃ­. DomnÃ­vÃ¡m se, uÅ¾ bez lÃ­tosti, Å¾e DÄšSÃR je daleko vÃ­ce literÃ¡rnÄ›jÅ¡Ã­ neÅ¾ mnoho praktikujÃ­cÃ­ch spisovatelÅ¯. Tohle je Å¾ivÃ¡ abeceda, tamti kladou uÅ¾ jen mrtvÃ© litery.",
  "target_text": "UÅ¾ dlouho jsem neprovÃ¡dÄ›l cviÄenÃ­ v sebelÃ­tosti. ÄŒas bÄ›Å¾Ã­ tak rychle, Å¾e zapomÃ­nÃ¡m vÄ›novat se tÄ›mto lacinÃ½m konÃ­ÄkÅ¯m. Tak se v tom zas troÅ¡ku procviÄÃ­m.JinÃ­ si uÅ¾Ã­vajÃ­ Å¾ivota, a jÃ¡ se tady pachtÃ­m jako motÃ½lkÃ¡Å™ za prchavÃ½mi kÅ™Ã­dly, za okamÅ¾iky, za tÄ›mi HrabalovÃ½mi perliÄkami"
}
```

```json
{
  "text": "DillÃ­ - IndickÃ½ nejvyÅ¡Å¡Ã­ soud zakÃ¡zal turistiku ve stanovenÃ½ch zÃ³nÃ¡ch vÃ­ce neÅ¾ 40 tygÅ™Ã­ch rezervacÃ­ pod sprÃ¡vou centrÃ¡lnÃ­ vlÃ¡dy. Å esti stÃ¡tÅ¯m, kterÃ© nedodrÅ¾ovaly pÅ™edchozÃ­ smÄ›rnice, navÃ­c uloÅ¾il pokuty. Ve volnÃ© pÅ™Ã­rodÄ› subkontinentu Å¾ije podle poslednÃ­ho sÄÃ­tÃ¡nÃ­ z loÅˆskÃ©ho roku kolem 1700 tygrÅ¯. JeÅ¡tÄ› pÅ™ed 100 lety pÅ™itom v indickÃ© divoÄinÄ› podle BBC Å¾ilo na 100 tisÃ­c tÄ›chto koÄkovitÃ½ch Å¡elem. Organizace na ochranu pÅ™Ã­rody verdikt soudu uvÃ­taly. RozhodnutÃ­ vychÃ¡zÃ­ vstÅ™Ã­c pÅ™Ã­sluÅ¡nÃ© petici, kterÃ¡ Å¾Ã¡dala vytlaÄenÃ­ komerÄnÃ­ch turistickÃ½ch aktivit z oblastÃ­ nejÄastÄ›jÅ¡Ã­ho vÃ½skytu tygrÅ¯ v rezervacÃ­ch. V zÃ³nÃ¡ch stanovenÃ½ch soudem Å¾ije vÄ›tÅ¡ina indickÃ½ch tygrÅ¯. TygrÅ¯m se daÅ™Ã­ takÃ© v praÅ¾skÃ© zoo: SouvisejÃ­cÃ­ PraÅ¾skÃ¡ zoo pÅ™edstavila tygÅ™Ã­ mlÃ¡Äata, jsou to samiÄky 6 fotografiÃ­ I kdyÅ¾ je rozhodnutÃ­ soudu oznaÄovÃ¡no za vÃ½znamnÃ©, nenÃ­ jasnÃ©, jakÃ½ dopad bude mÃ­t na turismus. Ten se soustÅ™eÄuje do takzvanÃ½ch nÃ¡raznÃ­kovÃ½ch zÃ³n, coÅ¾ jsou aÅ¾ deset kilometrÅ¯ Å¡irokÃ¡ pÃ¡sma kolem vymezenÃ½ch zÃ³n. SoudnÃ­ verdikt je jednÃ­m z Å™ady krokÅ¯, kterÃ© indickÃ© orgÃ¡ny v poslednÃ­ dobÄ› podnikly na ochranu tygrÅ¯. V Ãºnoru byla ve stÃ¡tÄ› RÃ¡dÅ¾asthÃ¡n pÅ™estÄ›hovÃ¡na celÃ¡ vesnice, jeÅ¾ musela zvÃ­Å™atÅ¯m ustoupit. OpatÅ™enÃ­ zjevnÄ› zabÃ­rajÃ­. Podle ÃºÅ™adÅ¯ poÄet tygrÅ¯ v Indii opÄ›t roste. NadÃ¡le je ale ohroÅ¾ujÃ­ lidÃ© Å¾ijÃ­cÃ­ uvnitÅ™ nebo na okraji rezervacÃ­.",
  "target_text": "NejvyÅ¡Å¡Ã­ soud zakÃ¡zal vstup do 40 tygÅ™Ã­ch rezervacÃ­"
}
```

```json
{
  "text": "V Klementinu byly napÅ™Ã­klad objeveny tÅ™i studny, pozÅ¯statky kamennÃ½ch domÅ¯ nebo ÄÃ¡st trativodu z obdobÃ­ 16. aÅ¾ 17. stoletÃ­. V zÃ¡kladech baroknÃ­ stavby byly objeveny ÄÃ¡sti klenebnÃ­ch Å¾eber Äi ostÄ›nÃ­ oken, kterÃ© s nejvÄ›tÅ¡Ã­ pravdÄ›podobnostÃ­ pochÃ¡zejÃ­ z konstrukcÃ­ stÅ™edovÄ›kÃ©ho klÃ¡Å¡tera odstranÄ›nÃ©ho pÅ™i vÃ½stavbÄ› Klementina. Novinky o tom informovala Irena MaÅˆÃ¡kovÃ¡ z NÃ¡rodnÃ­ knihovny ÄŒR. ArcheologovÃ© slavÃ­ v NÃ¡rodnÃ­ knihovnÄ› mnoho ÃºspÄ›chÅ¯. FOTO: NÃ¡rodnÃ­ knihovna ÄŒR K nejvÃ½znamnÄ›jÅ¡Ã­mu nÃ¡lezu podle nÃ­ doÅ¡lo pÅ™i pÅ™esunu vÃ½zkumu ze zÃ¡padnÃ­ho kÅ™Ã­dla do traktu mezi StudentskÃ½m a RÃ©vovÃ½m nÃ¡dvoÅ™Ã­m, kde byly pod baroknÃ­ podlahou suterÃ©nu odkryty zbytky zdiv nÃ¡leÅ¾ejÃ­cÃ­ch k dominikÃ¡nskÃ©mu klÃ¡Å¡teru, kterÃ½ zde stÃ¡l od 30. let 13. stoletÃ­. Odkryli i mnoÅ¾stvÃ­ reliktÅ¯ â€VÃ½znam nÃ¡lezu spoÄÃ­vÃ¡ pÅ™edevÅ¡Ã­m v tom, Å¾e se jednÃ¡ o prvnÃ­ hmotnÃ½ doklad tohoto klÃ¡Å¡tera, o nÄ›mÅ¾ jsme dosud vÄ›dÄ›li pouze z pÃ­semnÃ½ch pramenÅ¯,â€œ vysvÄ›tlil vedoucÃ­ archeolog Jan Havrda. NÃ¡lezy doklÃ¡dajÃ­ i vÃ½stavnost gotickÃ© stavby, jeÅ¾ ve svÃ© dobÄ› pÅ™edstavovala jednu z nejvÃ½znamnÄ›jÅ¡Ã­ch praÅ¾skÃ½ch cÃ­rkevnÃ­ch institucÃ­. PÅ™i vÃ½zkumu byly rovnÄ›Å¾ odkryty ÄetnÃ© relikty stÅ™edovÄ›kÃ© a ranÄ› novovÄ›kÃ© zÃ¡stavby, kterÃ¡ byla odstranÄ›na v souvislosti s vÃ½stavbou tÃ©to ÄÃ¡sti baroknÃ­ho areÃ¡lu v roce 1654. VysokÃ¡ pamÃ¡tkovÃ¡ hodnota KromÄ› pozÅ¯statkÅ¯ kamennÃ½ch domÅ¯ byly odkryty i tÅ™i stÅ™edovÄ›kÃ© studny, z nichÅ¾ nÄ›kterÃ© pozdÄ›ji slouÅ¾ily jako odpadnÃ­ jÃ­mky. NejvÃ½znamnÄ›jÅ¡Ã­m nÃ¡lezem v tÄ›chto prostorÃ¡ch byla lineÃ¡rnÃ­ zdÄ›nÃ¡ konstrukce vystavÄ›nÃ¡ romÃ¡nskou technikou. ZaznamenanÃ¡ dÃ©lka 0,7 metru Å¡irokÃ© zdi dosahuje 11,7 metru a jejÃ­ koruna se nalÃ©zala bezprostÅ™ednÄ› pod souÄasnou podlahou sklepa. ArcheologovÃ© uÄinili pÅ™es zimu hned nÄ›kolik zajÃ­mavÃ½ch objevÅ¯. PozÅ¯statky dominikÃ¡nskÃ©ho klÃ¡Å¡tera ze 13. stoletÃ­ jsou vÅ¡ak nejvÃ½znamnÄ›jÅ¡Ã­. FOTO: NÃ¡rodnÃ­ knihovna ÄŒR â€JednÃ¡ se o unikÃ¡tnÃ­ architektonickou pamÃ¡tku nÃ¡leÅ¾ejÃ­cÃ­ ke skupinÄ› praÅ¾skÃ½ch profÃ¡nnÃ­ch romÃ¡nskÃ½ch staveb, kterÃ© pÅ™edstavujÃ­ nejstarÅ¡Ã­ horizont kamennÃ© architektury na ÃºzemÃ­ PraÅ¾skÃ© pamÃ¡tkovÃ© rezervace a jejichÅ¾ pamÃ¡tkovÃ¡ hodnota je nespornÃ¡. Interpretace tohoto nÃ¡lezu nenÃ­ jednoznaÄnÃ¡, mohlo by se vÅ¡ak jednat o severnÃ­ obvodovou zeÄ rozlehlejÅ¡Ã­ho romÃ¡nskÃ©ho domu,â€œ uvedl Havrda.",
  "target_text": "ArcheologovÃ© pracujÃ­ pÅ™es zimu v NÃ¡rodnÃ­ knihovnÄ› jako o Å¾ivot. V poslednÃ­ dobÄ› zkoumali klementinskÃ© suterÃ©ny pod zÃ¡padnÃ­m kÅ™Ã­dlem bÃ½valÃ© jezuitskÃ© koleje a sklepnÃ­ trakt mezi StudentskÃ½m a RÃ©vovÃ½m nÃ¡dvoÅ™Ã­m. NejvÃ½znamnÄ›jÅ¡Ã­m nÃ¡lezem je objev zbytkÅ¯ zdiv, kterÃ© poprvÃ© hmotnÄ› doklÃ¡dajÃ­ existenci zdejÅ¡Ã­ho dominikÃ¡nskÃ©ho klÃ¡Å¡tera ze 13. stoletÃ­"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:

  ```text
  NÃ¡sledujÃ­cÃ­ jsou dokumenty s pÅ™iloÅ¾enÃ½mi souhrny.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Souhrn: {target_text}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  NapiÅ¡te souhrn vÃ½Å¡e uvedenÃ©ho dokumentu.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset czech-news
```
