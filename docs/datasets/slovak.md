# üá∏üá∞ Slovak

This is an overview of all the datasets used in the Slovak part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### CSFD Sentiment-sk

This dataset was published in [this paper](https://aclanthology.org/R13-1016/) and
consists of reviews from the the Czech/Slovak Movie
Database (CSFD).

The original dataset contains 25,000 / 2,500 / 2,500 samples for the training,
validation, and test splits, respectively. We use 1,024 / 256 / 2,048 samples for
our training, validation and test splits, respectively. All the new splits are
subsets of the original splits.

Here are a few examples from the training split:

```json
{
    "text": "J√≥ Steve Buacemi...jinak sraƒçka",
    "label": "negative"
}
```

```json
{
    "text": "Letny oddychovy comicsovy blockbuster. Po celkom fresh traileri a hlavne podla momentalnych hodnoteni (89%, 76. najlepsi film!!!) som cakal, ze to bude daka svieza pecka a prijemne prekvapenie. Ale nakoniec je to dost taky priemer. Taka ta klasika, universe s roznymi rasami, (anti)hrdinova, neoriginalna zapletka, kopa akcie.. Co vycnievalo boli zaujimave postavy a hlavne vtipne hlasky. Prave tymto sa mohol film viac odlisit od ostatnych comicsoviek, vtedy by som isiel s hodnotenim vyssie.. Od polky filmu mi bolo jasne, ze to je kvazi ochutnavka na (minimalne) dalsie 2 casti, tak uvidime kam to posunu. [#40/2013]",
    "label": "neutral"
}
```

```json
{
    "text": "Prevapivo pr√≠jemn√©, vtipn√©, rozpr√°vkov√©. Koneƒçne fantasy film, ktor√Ω sa s√∫stred√≠ na rozpr√°vanie pr√≠behu a nepotrebuje k tomu zbesil√© tempo ani veƒækolep√© poƒç√≠taƒçov√© arm√°dy. Vo svojej podstate to nie je a≈æ tak√© origin√°lne, ale je tam p√°r zauj√≠mav√Ωch n√°padov a ako celok to skvelo funguje - v≈°etko je skr√°tka na svojom mieste...",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Ni≈æ≈°ie s√∫ dokumenty a ich sentiment, ktor√Ω m√¥≈æe by≈• 'pozit√≠vne', 'neutr√°lne' alebo 'negat√≠vne'.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Sentiment: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  Klasifikujte pocit v dokumente. Odpovedzte so 'pozit√≠vne', 'neutr√°lne', alebo 'negat√≠vne', a niƒç in√©.
  ```

- Label mapping:
  - `positive` ‚û°Ô∏è `pozit√≠vne`
  - `neutral` ‚û°Ô∏è `neutr√°lne`
  - `negative` ‚û°Ô∏è `negat√≠vne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset csfd-sentiment-sk
```

## Named Entity Recognition

### UNER-sk

This dataset was published in
[this paper](https://aclanthology.org/2024.naacl-long.243/).

The original dataset consists of 8,482 / 1,059 / 1,060 samples for the
training, validation, and test splits, respectively. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively. The train and
validation splits are subsets of the original splits, while the test split is
created using additional samples from the train split.

Here are a few examples from the training split:

```json
{
  "tokens": ["Bude", "ma≈•", "n√°zov", "Shanghai", "Noon", "a", "re≈æis√©rom", "bude", "debutuj√∫ci", "Tom", "Dey", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-PER", "I-PER", "O"]
}
```

```json
{
  "tokens": ["Ako", "≈°es≈•roƒçn√©ho", "(", "o", "rok", "sk√¥r", ",", "ne≈æ", "bolo", "zvykom", ")", "ho", "na", "z√°klade", "zvl√°≈°tnej", "v√Ωnimky", "prijali", "medzi", "Zvedov", "a", "ako", "dev√§≈•roƒçn√Ω", "sa", "stal", "ved√∫cim", "skupiny", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

```json
{
  "tokens": ["To", "predsa", "stoj√≠", "za", "pokus", "!"],
  "labels": ["O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  Nasleduj√∫ce s√∫ vety a JSON-objekty s pomenovan√Ωmi entitami, ktor√© sa nach√°dzaj√∫ v danej vete.
  ```

- Base prompt template:

  ```text
  Veta: {text}
  Pomenovan√© entity: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Veta: {text}

  Identifikujte pomenovan√© entity vo vete. V√Ωstup by mal by≈• vo forme JSON-objektu s kƒæ√∫ƒçmi 'osoba', 'miesto', 'organiz√°cia' a 'r√¥zne'. Hodnoty by mali by≈• zoznamy pomenovan√Ωch ent√≠t danej kateg√≥rie, presne tak, ako sa vyskytuj√∫ vo vete.
  ```

- Label mapping:
  - `B-PER` ‚û°Ô∏è `osoba`
  - `I-PER` ‚û°Ô∏è `osoba`
  - `B-LOC` ‚û°Ô∏è `miesto`
  - `I-LOC` ‚û°Ô∏è `miesto`
  - `B-ORG` ‚û°Ô∏è `organiz√°cia`
  - `I-ORG` ‚û°Ô∏è `organiz√°cia`
  - `B-MISC` ‚û°Ô∏è `r√¥zne`
  - `I-MISC` ‚û°Ô∏è `r√¥zne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset uner-sk
```

## Linguistic Acceptability

### CS-GEC

This dataset is extracted by postprocessing data from
[this paper](https://aclanthology.org/D19-5545/). Specifically,
grammatically incorrect sentences and their corresponding corrections
were extracted.

The original full dataset consists of 59,493 training and 4,668 test
samples, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation, and testing, respectively. The train and test splits are
subsets of the original splits, and the validation split is created
using examples from the train split.

Here are a few examples from the training split:

```json
{
  "text": "Mus√≠me ochutn√°t pivo a knedl√≠ky .",
  "label": "incorrect"
}
```

```json
{
  "text": "V budoucnosti bych chtƒõla m√≠t velkou rodinu a d≈Øm m√Ωch sn≈Ø .",
  "label": "correct"
}
```

```json
{
  "text": "Dƒõdeƒçek i babiƒçka po druh√© svƒõtov√© v√°lce nƒõkolik let ≈æili v ƒåR a pak se zase vratili do Lu≈æice .",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  N√°sleduj√≠c√≠ jsou vƒõty a zda jsou gramaticky spr√°vn√©.
  ```

- Base prompt template:

  ```text
  Vƒõta: {text}
  Gramaticky spr√°vn√°: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Vƒõta: {text}

  Urƒçete, zda je vƒõta gramaticky spr√°vn√° nebo ne. Odpovƒõzte 'ano', pokud je vƒõta spr√°vn√°, a 'ne', pokud nen√≠. Odpovƒõzte pouze t√≠mto slovem, a niƒç√≠m jin√Ωm.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `ano`
  - `incorrect` ‚û°Ô∏è `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset cs-gec
```

### Unofficial: ScaLA-cs

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Czech Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Slovak-SNK) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "Niektor√≠ pozorovatelia pova≈æuj√∫ ropn√© z√°ujmy USA za jednu z hlavn√Ωch motiv√°ci√≠ vstupu do vojny v Iraku.",
    "label": "correct"
}
```

```json
{
    "text": "Pop√°li≈• sa na jedinom p√≠smene je klasick√Ω pr√≠pad, ktor√Ω sa m√¥≈æe vyskytn√∫≈• v r√¥znych podob√°ch.",
    "label": "correct"
}
```

```json
{
    "text": "Zo strachu o seba, pre svoju pov√Ω≈°en√∫ zbabelos≈• zaprel svojho Majstra P√°na.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Nasleduj√∫ vety a ƒçi s√∫ gramaticky spr√°vne.
  ```

- Base prompt template:

  ```text
  Veta: {text}
  Gramaticky spr√°vna: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Veta: {text}

  Urƒçite, ƒçi je veta gramaticky spr√°vna alebo nie. Odpovedzte so '√°no', ak je veta spr√°vna, a 'nie', ak nie je. Odpovedzte iba t√Ωmto slovom, a niƒç in√©.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `√°no`
  - `incorrect` ‚û°Ô∏è `nie`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-cs
```

### CS-GEC

This dataset is extracted by postprocessing data from
[this paper](https://doi.org/10.18653/v1/D19-5545). Specifically,
grammatically incorrect sentences and their corresponding corrections
were extracted.

The original full dataset consists of 59,493 training and 4,668 test
samples, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation, and testing, respectively. The train and test splits are
subsets of the original splits, and the validation split is created
using examples from the train split.

Here are a few examples from the training split:

```json
{
  "text": "Mus√≠me ochutn√°t pivo a knedl√≠ky .",
  "label": "incorrect"
}
```

```json
{
  "text": "V budoucnosti bych chtƒõla m√≠t velkou rodinu a d≈Øm m√Ωch sn≈Ø .",
  "label": "correct"
}
```

```json
{
  "text": "Dƒõdeƒçek i babiƒçka po druh√© svƒõtov√© v√°lce nƒõkolik let ≈æili v ƒåR a pak se zase vratili do Lu≈æice .",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  N√°sleduj√≠c√≠ jsou vƒõty a zda jsou gramaticky spr√°vn√©.
  ```

- Base prompt template:

  ```text
  Vƒõta: {text}
  Gramaticky spr√°vn√°: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Vƒõta: {text}

  Urƒçete, zda je vƒõta gramaticky spr√°vn√° nebo ne. Odpovƒõzte 'ano', pokud je vƒõta spr√°vn√°, a 'ne', pokud nen√≠. Odpovƒõzte pouze t√≠mto slovem, a niƒç√≠m jin√Ωm.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `ano`
  - `incorrect` ‚û°Ô∏è `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset cs-gec
```

## Reading Comprehension

### MultiWikiQA-sk

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
  "context": "Register toxick√Ωch √∫ƒçinkov chemick√Ωch l√°tok (anglicky Registry of Toxic Effects of Chemical Substances, RTECS) je datab√°za toxikologick√Ωch inform√°ci√≠ zostaven√Ωch z voƒæne dostupnej vedeckej literat√∫ry bez odkazu na platnos≈• alebo u≈æitoƒçnos≈• publikovan√Ωch ≈°t√∫di√≠. Do roku 2001 bola datab√°za spravovan√° americkou organiz√°ciou NIOSH (National Institute for Occupational Safety and Health, slov. N√°rodn√Ω √∫stav pre bezpeƒçnos≈• a ochranu zdravia pri pr√°ci) ako verejne dostupn√° publik√°cia. Teraz ju spravuje s√∫kromn√° spoloƒçnos≈• Symyx Technologies a je dostupn√° len za poplatok.\n\nObsah \nDatab√°za obsahuje ≈°es≈• typov toxikologick√Ωch inform√°ci√≠:\n prim√°rne podr√°≈ædenie\n mutag√©nne √∫ƒçinky\n reprodukƒçn√© √∫ƒçinky\n karcinog√©nne √∫ƒçinky\n ak√∫tna toxicita\n toxicita viacn√°sobn√Ωch d√°vok\nV datab√°ze sa spom√≠naj√∫ ako ≈°pecifick√© ƒç√≠seln√© hodnoty, ako napr√≠klad LD50, LC50, TDLo alebo TCLo, tak aj ≈°tudovan√© organizmy a sp√¥sob pod√°vania l√°tky. Pre v≈°etky d√°ta s√∫ uveden√© bibliografick√© zdroje. ≈†t√∫die pritom nie s√∫ nijako hodnoten√©.\n\nHist√≥ria \nDatab√°za RTECS bola aktivitou schv√°lenou americk√Ωm Kongresom, zakotvenou v Sekcii 20(a)(6) z√°kona Occupational Safety and Health Act z roku 1970 (PL 91-596). P√¥vodn√© vydanie, zn√°me ako Zoznam toxick√Ωch l√°tok (Toxic Substances List), bolo publikovan√© 28. j√∫na 1971 a obsahovalo toxikologick√© d√°ta o pribli≈æne 5 000 chemik√°li√°ch. N√°zov bol nesk√¥r zmenen√Ω na dne≈°n√Ω Register toxick√Ωch √∫ƒçinkov chemick√Ωch l√°tok (Registry of Toxic Effects of Chemical Substances). V janu√°ri 2001 datab√°za obsahovala 152 970 chemik√°li√≠. V decembri 2001 bola spr√°va RTECS preveden√° z NIOSH do s√∫kromnej firmy Elsevier MDL. T√∫to firmu k√∫pila v roku 2007 spoloƒçnos≈• Symyx, s√∫ƒças≈•ou akviz√≠cie bola aj datab√°za RTECS. T√° je teraz dostupn√° len za poplatok vo forme roƒçn√©ho predplatn√©ho.\n\nRTECS je k dispoz√≠cii v angliƒçtine, franc√∫z≈°tine a ≈°panielƒçine, a to prostredn√≠ctvom Kanadsk√©ho centra pre bezpeƒçnos≈• a ochranu zdravia pri pr√°ci. Predplatitelia maj√∫ pr√≠stup cez web, na CD-ROM a vo form√°te pre intranet. Datab√°za je dostupn√° na webe aj cez NISC (National Information Services Corporation) a ExPub (Expert Publishing, LLC).\n\nExtern√© odkazy \n\n RTECS overview \n Symyx website \n Expert Publishing, LLC Website\n\nZdroj \n\nChemick√© n√°zvy a k√≥dy\nToxikol√≥gia",
  "question": "Ak√© s√∫ tri mo≈ænosti pr√≠stupu k datab√°ze RTECS, ak som predplatiteƒæ?",
  "answers": {"answer_start": [1949], "text": ["cez web, na CD-ROM a vo form√°te pre intranet"]}}
```

```json
{
  "context": "Herta Naglov√°-Docekalov√° (* 29. m√°j 1944, Wels, Rak√∫sko) je rak√∫ska filozofka a profesorka, ƒçlenka vedenia Medzin√°rodnej asoci√°cie filozofiek (IAPf), √ñsterreichische Akademie der Wissenschaften, Institut International de Philosophie (Par√≠≈æ), viceprezidentka F√©d√©ration Internationale des Soci√©t√©s de Philosophie (FISP), zakladaj√∫ca ƒçlenka interdisciplin√°rnych pracovn√Ωch skup√≠n Frauengeschichte a Philosophische Frauenforschung na Viedenskej univerzite, ƒçlenka redakƒçn√Ωch r√°d popredn√Ωch vedeck√Ωch ƒçasopisov, napr. Philosophin, L¬¥Homme, Deutsche Zeitschrift f√ºr Philosophie.\n\n≈Ωivotopis \nVy≈°tudovala hist√≥riu, filozofiu a germanistiku na Viedenskej univerzite. V roku 1967 z√≠skala na svojej alma mater doktor√°t z hist√≥rie pr√°cou o filozofovi dej√≠n Ernstovi von Lasaulx). V rokoch 1968 - 1985 bola asistentkou na In≈°tit√∫te filozofie Viedenskej univerzity. V lete 1980 predn√°≈°ala na Millersville University of Pennsylvania v USA.\n\nV roku 1981 sa habilitovala z filozofie na Viedenskej univerzite dielom Die Objektivit√§t der Geschichtswissenschaft. V rokoch 1985 a≈æ 2009 bola profesorkou In≈°tit√∫tu filozofie Viedenskej univerzity. Od roku 2009 je univerzitnou profesorkou na d√¥chodku (Universit√§tsprofessorin i. R.)\n\nBola hos≈•uj√∫cou profesorkou v roku 1990 na Universiteit Utrecht v holandskom Utrechte; v Nemecku 1991/1992 na Goethe-Universit√§t Frankfurt vo Frankfurte nad Mohanom; 1993 na Universit√§t Konstanz v Konstanzi; 1994/1995 na Freie Universit√§t Berlin v Berl√≠ne. V rokoch 1995/1996 predn√°≈°ala na Universit√§t Innsbruck a 2011 na univerzite v Petrohrade v Rusku.\n\nDielo (v√Ωber) \n Jenseits der S√§kularisierung. Religionsphilosophische Studien. - Berlin 2008 (Hg., gem.m. Friedrich Wolfram).\n Viele Religionen - eine Vernunft? Ein Disput zu Hegel. - Wien/Berlin 2008 (Hg., gem.m. Wolfgang Kaltenbacher und Ludwig Nagl).\n Glauben und Wissen. Ein Symposium mit J√ºrgen Habermas. - Wien/Berlin 2007 (Hg., gem.m. Rudolf Langthaler).\n Geschichtsphilosophie und Kulturkritik. - Darmstadt 2003 (Hrsg., gem.m. Johannes Rohbeck).\n Feministische Philosophie. Ergebnisse, Probleme, Perspektiven. - Frankfurt a.M. 2000 a 2004 \n Continental Philosophy in Feminist Perspective. - Pennsylviania State University Press 2000 (Hg. gem.m. Cornelia Klingler).\n Der Sinn des Historischen. - Frankfurt a.M. 1996 (Hrsg.).\n Politische Theorie. Differenz und Lebensqualit√§t. - Frankfurt a.M. 1996 (Hrsg. gem.m. Herlinde Pauer-Studer).\n Postkoloniales Philosophieren: Afrika. - Wien/M√ºnchen 1992 (Hrsg., gem.m. Franz Wimmer).\n Tod des Subjekts? - Wien/M√ºnchen 1987 (Hrsg., gem.m. Helmuth Vetter).\n Die Objektivit√§t der Geschichtswissenschaft. Systematische Untersuchungen zum wissenschaftlichen Status der Historie. - Wien/M√ºnchen 1982\n spoluvydavateƒæka: Wiener Reihe. Themen der Philosophie (od 1986). \n spoluvydavateƒæka: Deutsche Zeitschrift f√ºr Philosophie (1993-2004). \n spoluvydavateƒæka: L'Homme. Europ√§ische Zeitschrift f√ºr feministische Geschichtswissenschaft (1990 - 2003).\n\nOcenenia \n F√∂rderpreis mesta Viede≈à, 1983\n K√§the Leichter Preis (rak√∫ska ≈°t√°tna cena), 1997 \n Preis f√ºr Geistes- und Sozialwissenschaften der Stadt Wien, 2009\n\nReferencie\n\nExtern√© odkazy \n Ofici√°lna str√°nka, Universit√§t Wien \n Austria Forum, Wissenssammlungen/Biographien: Herta Nagl-Docekal\n\nZdroj \n\nRak√∫ski filozofi",
  "question": "Kedy pri≈°la na svet Herta Naglov√°-Docekalov√°?",
  "answers": {"answer_start": [28], "text": ["29. m√°j 1944"]}}
```

```json
{"context": "Martin Bare≈° (* 25. november 1968, Brno) je ƒçesk√Ω profesor neurol√≥gie, od septembra 2019 rektor Masarykovej univerzity, predt√Ωm od febru√°ra 2018 do septembra 2019 dekan Lek√°rskej fakulty Masarykovej univerzity.\n\nRiadiace funkcie \nVo febru√°ri 2018 sa stal dekanom Lek√°rskej fakulty Masarykovej univerzity. Funkciu prevzal po Ji≈ô√≠m Mayerovi, ktor√Ω zast√°val poz√≠ciu dekana v obdob√≠ 20102018. S n√°stupom na post dekana ukonƒçil svoje p√¥sobenie ako prorektor univerzity, ako i z√°stupca prednostu I. neurologickej kliniky pre vedu a v√Ωskum.\n\nDo funkcie rektora univerzity bol zvolen√Ω 1. apr√≠la 2019 Akademick√Ωm sen√°tom Masarykovej univerzity. V prvom kole tajnej voƒæby z√≠skal Bare≈° 36 hlasov z 50 pr√≠tomn√Ωch sen√°torov. Protikandid√°ta, prodekana Pr√≠rodovedeckej fakulty Jarom√≠ra Leichmana, volilo 11 sen√°torov. 3 odovzdan√© hlasy boli neplatn√©.\n\nSk√∫senosti s p√¥soben√≠m vo veden√≠ ≈°koly zbieral Bare≈° v rokoch 20112018, kedy p√¥sobil najsk√¥r ako jej prorektor pre rozvoj a potom ako prorektor pre akademick√© z√°le≈æitosti. Za svoje priority oznaƒçil Bare≈° v dobe voƒæby posil≈àovanie role univerzity ako piliera slobody v s√∫ƒçasnej spoloƒçnosti a zv√Ω≈°enie kvality vzdel√°vania, vedy a v√Ωskumu na medzin√°rodnej √∫rovni.\n\nDo funkcie rektora ho vymenoval 11. j√∫na 2019 prezident Milo≈° Zeman s √∫ƒçinnos≈•ou od 1. septembra 2019. Vo funkcii tak nahradil Mikul√°≈°a Beka, ktor√©mu sa skonƒçilo druh√© volebn√© obdobie a o zvolenie sa teda u≈æ op√§≈• uch√°dza≈• nemohol. Bare≈° k 1. septembru 2019 rezignoval na post dekana Lek√°rskej fakulty.\n\nVedeck√° ƒçinnos≈• \nJe predn√°≈°aj√∫cim v odboroch v≈°eobecn√© lek√°rstvo, zubn√© lek√°rstvo, optometria, fyzioterapia, neurofyziol√≥gia pre ≈°tudentov pr√≠rodn√Ωch vied Lek√°rskej fakulty Masarykovej univerzity a ≈°koliteƒæ doktorandov odborovej rady neurol√≥gia a neurovedy.\n\nP√¥sob√≠ v t√Ωchto vedeck√Ωch rad√°ch: Masarykova univerzita, Lek√°rska fakulta Masarykovej univerzity a CEITEC MU. ƒéalej tie≈æ Univerzita Palack√©ho v Olomouci, Lek√°rska fakulta UPOL, Fakulta veterin√°rn√≠ho l√©ka≈ôstv√≠ VFU, ƒèalej je tie≈æ ƒçlenom ƒåeskej lek√°rskej komory, ƒåeskej neurologickej spoloƒçnosti, ƒåeskej spoloƒçnosti klinickej neurofyziol√≥gie, ƒåeskej lek√°rskej spoloƒçnosti Jana Evangelisty Purkynƒõ, Movement Disorders Society, Society for the Research on the Cerebellum a Society for Neuroscience. Takisto je ƒçlenom redakƒçnej rady ƒçasopisov Clinical Neurophysiology, Behavioural Neurology, Tremor and Other Hyperkinetic Movements a Biomedical Papers.\n\nOsobn√Ω ≈æivot \nJe ≈æenat√Ω, m√° dvoch synov a dc√©ru.\n\nReferencie\n\nExtern√© odkazy \n Martin Bare≈°\n\nZdroj \n\nƒåesk√≠ lek√°ri\nNeurol√≥govia\nRektori Masarykovej univerzity\nƒåesk√≠ univerzitn√≠ profesori\nDekani Lek√°rskej fakulty Masarykovej univerzity\nAbsolventi Lek√°rskej fakulty Masarykovej univerzity\nOsobnosti z Brna",
"question": "Ak√∫ poz√≠ciu mal Martin Bare≈° na Masarykovej univerzite poƒçn√∫c septembrom 2019?",
"answers": {"answer_start": [89], "text": ["rektor"]}}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Nasleduj√∫ texty s pridru≈æen√Ωmi ot√°zkami a odpoveƒèami.
  ```

- Base prompt template:

  ```text
  Text: {text}
  Ot√°zka: {question}
  Odpoveƒè na maxim√°lne 3 slov√°:
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Odpovedzte na nasleduj√∫cu ot√°zku t√Ωkaj√∫cu sa textu uveden√©ho vy≈°≈°ie maxim√°lne 3 slovami.

  Ot√°zka: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-sk
```

## Knowledge

### MMLU-sk

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Swedish was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "V ak√Ωch smeroch je pr√≠pad pre humanit√°rnu intervenciu, ako je uveden√© v tejto kapitol... mocn√Ωmi ≈°t√°tmi.\nd. V≈°etky tieto mo≈ænosti.",
  "label": "d",
}
```

```json
{
  "text": "FAKTORI√ÅLOV√ù ANOVA sa pou≈æ√≠va v pr√≠pade, ≈æe ≈°t√∫dia zah≈ï≈àa viac ako 1 VI. Ak√Ω je INTER...ƒçinok VI na rovnakej √∫rovni ako ostatn√© VI",
  "label": "a"
}
```

```json
{
  "text": "Pre ktor√∫ z t√Ωchto dvoch situ√°ci√≠ urob√≠ hlavn√° postava (ktor√° pou≈æ√≠va ja/m≈àa/m√¥j) nie...ie zl√©\nc. Nie zl√©, zl√©\nd. Nie zl√©, nie zl√©",
  "label": "d",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Nasleduj√∫ ot√°zky s viacer√Ωmi mo≈ænos≈•ami (s odpoveƒèami).
  ```

- Base prompt template:

  ```text
  Ot√°zka: {text}
  Odpoveƒè: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Ot√°zka: {text}

  Odpovedzte na nasleduj√∫cu ot√°zku pou≈æit√≠m 'a', 'b', 'c' alebo 'd', a niƒç in√©.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-sk
```

## Common-sense Reasoning

### HellaSwag-cs

This dataset is a machine translated version of the English [HellaSwag
dataset](https://doi.org/10.18653/v1/P19-1472). The dataset was translated using
[LINDAT Translation Service](https://lindat.mff.cuni.cz/services/translation/docs).

The original dataset has 10,000 samples. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively.

Here are a few examples from the training split (which have _not_ been post-edited):

```json
{
  "text": "Ryba≈ôen√≠ na ledu: Vid√≠me √∫vodn√≠ tituln√≠ obrazovku. Na snƒõhu a ledov√© rybƒõ sed√≠ mu≈æ a chlapec. My\nV√Ωbƒõr:\na. vid√≠me mƒõsta a zmƒõny kolem nich.\nb. vid√≠me dole kreslenou animaci bocku.\nc. pak vid√≠me sport.\nd. vid√≠me tituln√≠ obrazovku a letadlo let√≠ na obloze a v d√°lce vid√≠me lidi na ledu a n√°klaƒè√°k.",
  "label": "d"
}
```

```json
{
  "text": "Bƒõh maratonu: Sportovci d√°vaj√≠ rozhovory a nƒõkte≈ô√≠ p≈ôedv√°dƒõj√≠ medaile za √∫ƒçast. Sportovci nastupuj√≠ do b√≠l√Ωch autobus≈Ø. Autobusy\nV√Ωbƒõr:\na. se pohybuj√≠ po silnici.\nb. odstartuj√≠ z rampy.\nc. se pohybuj√≠ po dr√°ze a lid√© sk√°ƒçou po ramp√°ch.\nd. m√≠j√≠ nƒõkolik sportovc≈Ø sed√≠c√≠ch na zelen√Ωch baldach√Ωnech.",
  "label": "a"
}
```

```json
{
  "text": "Family Life: Jak uspo≈ô√°dat havajskou svatebn√≠ hostinu. Vyberte tradiƒçn√≠ havajsk√Ω odƒõv pro nevƒõstu a ≈æenicha. Havajsk√° nevƒõsta tradiƒçnƒõ nos√≠ b√≠l√© dlouh√© spl√Ωvav√© ≈°aty s vƒõncem z haku neboli prstenem z hawajsk√Ωch kvƒõtin kolem hlavy. Havajsk√Ω ≈æenich tradiƒçnƒõ nos√≠ b√≠l√© kalhoty a b√≠lou ko≈°ili s pestrobarevnou ≈°erpou kolem pasu.\nV√Ωbƒõr:\na. No≈°en√≠ hawajsk√©ho vƒõnce p≈ôi p≈ô√≠le≈æitosti va≈°√≠ recepce m≈Ø≈æe tak√© pomoci cementovat hawajsk√© svatebn√≠ sliby. Havajsk√© spl√Ωvav√© ≈°aty jsou st√°le tradiƒçn√≠ se svatebn√≠m odƒõvem, navzdory povaze svatby.\nb. ≈Ωenich tak√© nos√≠ kolem krku zelenou po≈°tolku lei.. Vyberte hawajsk√Ω odƒõv pro svatebn√≠ hostinu.\nc. Tyto prvky spolu velmi dob≈ôe spl√Ωvaj√≠. Fotografie se budou odehr√°vat ve velk√©m studiu na leti≈°ti v mƒõlk√© vodƒõ.\nd. Vyberte si neform√°ln√≠ odƒõv na svatbu na pl√°≈æi. Havajsk√© svatby b√Ωvaj√≠ velmi form√°ln√≠, tak≈æe si vyberte havajsk√© svatebn√≠ ≈°aty s motivem kasina.",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  N√°sleduj√≠c√≠ jsou ot√°zky s v√Ωbƒõrem z v√≠ce mo≈ænost√≠ (s odpovƒõƒèmi).
  ```

- Base prompt template:

  ```text
  Ot√°zka: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Odpovƒõƒè: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Ot√°zka: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Odpovƒõzte na v√Ω≈°e uvedenou ot√°zku pomoc√≠ 'a', 'b', 'c' nebo 'd', a nic jin√©ho.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset hellaswag-cs
```

## Summarisation

### Czech News

This dataset was published in
[this paper](https://doi.org/10.48550/arXiv.2307.10666) and contains news articles
from major online news outlets collected from 2000-2022.

The original dataset consists of 1,641,471 / 144,836 / 144,837 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively, sampled from the original splits.

Here are a few examples from the training split:

```json
{
  "text": "Vymet√°m z√°kout√≠, oƒçi na ≈°≈•opk√°ch, kde je≈°tƒõ nƒõco z≈Østalo, abych to mohl popsat a t√≠m pops√°n√≠m zaevidovat, zkatalogizovat. T≈ôeba na tom Sm√≠chovƒõ, tam je to o ≈æivot. Ale v√Ωsledky jsou. P≈ôed hostincem U Smol√≠k≈Ø, ≈°ikmo naproti Sm√≠chovsk√©mu n√°dra≈æ√≠, bylo na tabuli k≈ô√≠dou, kterou vedla pevn√° ruka, na≈°kr√°b√°no jako souƒç√°st nab√≠dky: V √∫ter√Ω od 18 na ho≈ôe bez koz. Autor je bezesporu velk√Ωm b√°sn√≠kem, jeho rozm√°chl√° gesta nepot≈ôebuj√≠ dodateƒçn√© korekce. P≈ôedstavte si tu n√°dheru - po ≈°est√© veƒçern√≠ nastupuje na plac serv√≠rka ploch√° jak line√°l. Chlap≈Øm sklapne ƒçelist a o to v√≠ce vypij√≠ hladinek. Mezit√≠m, ne≈æ jsem dofabuloval, vy u≈æ p≈ôech√°z√≠te do haly zm√≠nƒõn√©ho n√°dra≈æ√≠, na jeho≈æ prav√©m konci si ƒçetbymilovn√Ω odj√≠≈ædƒõƒç ƒçi p≈ôij√≠≈ædƒõƒç m≈Ø≈æe zakoupit knihy v antikvari√°tu. A j√° zde zase jako vandal vyloup√°v√°m zasazen√© d√©manty, kter√Ωch si nikdo nev≈°√≠m√°. Nad p≈ôihr√°dkou, kde na ob√°lk√°ch knih a ƒçasopis≈Ø p≈ôeva≈æuje ta partie ≈æensk√©ho tƒõla, o kter√© byla ≈ôeƒç v√Ω≈°e, um√≠stil prodejce s√©manticky neobyƒçejnƒõ komplikovan√Ω n√°pis: Erotika nen√≠ k prohl√≠≈æen√≠! No nen√≠ to kr√°sa? To, co "dƒõl√°" erotiku erotikou, je zde v√Ωslovnƒõ zapovƒõzeno. Je t≈ôeba kupovat, a ne jen listovat a zadarmiko se vzru≈°ovat! A j√° hned vytahuji z√°pisn√≠ƒçek a v tom dusn√©m n√°dra≈æn√≠m prost≈ôed√≠ zachycuji tuto opozdilou slzu ztracenou z gr√°lu. Co s t√≠m m√° co dƒõlat ta sebel√≠tost? Zat√≠mco si tady hraju na soukrom√©ho badatele, kter√Ω pak plody pr√°ce vƒõnuje sv√©mu n√°rodu, v centru Prahy se dƒõjou z√°sadn√≠ vƒõci, proti kter√Ωm je tohle moje mot√Ωlka≈ôen√≠ pouh√Ωm okresn√≠m p≈ôeborem. A je mi to l√≠to. www.desir.cz 5. ≈ô√≠jna 2004 probƒõhla v nejpou≈æ√≠vanƒõj≈°√≠m pra≈æsk√©m demonstraƒçn√≠m prostoru Demonstrace za nic. Demonstranti nesli pr√°zdn√© transparenty (povolen√© byly pouze teƒçky, vyk≈ôiƒçn√≠ky a otazn√≠ky), dokonce i pr≈Øhledn√© transparenty (ty byly absolutnƒõ transparentn√≠) a rozd√°vali pr√°zdn√© let√°ky. Akce byla ≈ô√°dnƒõ nahl√°≈°ena, proto ji doprov√°zeli org√°ni vp≈ôedu a vzadu. Konƒçilo se (150-200 osob) pod ocasem, kde byla dr≈æena minuta ticha za nic. Geni√°ln√≠ pak√°rna, ≈°vejk√°rna i kafk√°rna. Tento z√°sadn√≠ n√°zor obƒçansk√© anga≈æovanosti probƒõhl pod taktovkou partiƒçky jm√©nem DƒöS√çR (Dƒöti S√çdli≈°tn√≠ Recese), kter√° po≈ô√°d√° recesn√≠ a hrav√© akce v Praze se zamƒõ≈ôen√≠m na ≈°kol√°ky ze S≈† a V≈†. Ve sv√©m programu maj√≠ naps√°no: Chceme vyu≈æ√≠t mƒõstsk√Ωch prvk≈Ø ve prospƒõch blaha hrav√Ωch jedinc≈Ø. Na jejich str√°nk√°ch najdete mj. polo≈æky: Fotogalerie, Kronika, Kalend√°≈ô akc√≠, Pravidla her. Podle n√°vodu si m≈Ø≈æete sami zahr√°t t≈ôeba hry Lapni dav nebo Pi≈°kvorky nab√≠jen√© tramvaj√≠. Domn√≠v√°m se, u≈æ bez l√≠tosti, ≈æe DƒöS√çR je daleko v√≠ce liter√°rnƒõj≈°√≠ ne≈æ mnoho praktikuj√≠c√≠ch spisovatel≈Ø. Tohle je ≈æiv√° abeceda, tamti kladou u≈æ jen mrtv√© litery.",
  "target_text": "U≈æ dlouho jsem neprov√°dƒõl cviƒçen√≠ v sebel√≠tosti. ƒåas bƒõ≈æ√≠ tak rychle, ≈æe zapom√≠n√°m vƒõnovat se tƒõmto lacin√Ωm kon√≠ƒçk≈Øm. Tak se v tom zas tro≈°ku procviƒç√≠m.Jin√≠ si u≈æ√≠vaj√≠ ≈æivota, a j√° se tady pacht√≠m jako mot√Ωlk√°≈ô za prchav√Ωmi k≈ô√≠dly, za okam≈æiky, za tƒõmi Hrabalov√Ωmi perliƒçkami"
}
```

```json
{
  "text": "Dill√≠ - Indick√Ω nejvy≈°≈°√≠ soud zak√°zal turistiku ve stanoven√Ωch z√≥n√°ch v√≠ce ne≈æ 40 tyg≈ô√≠ch rezervac√≠ pod spr√°vou centr√°ln√≠ vl√°dy. ≈†esti st√°t≈Øm, kter√© nedodr≈æovaly p≈ôedchoz√≠ smƒõrnice, nav√≠c ulo≈æil pokuty. Ve voln√© p≈ô√≠rodƒõ subkontinentu ≈æije podle posledn√≠ho sƒç√≠t√°n√≠ z lo≈àsk√©ho roku kolem 1700 tygr≈Ø. Je≈°tƒõ p≈ôed 100 lety p≈ôitom v indick√© divoƒçinƒõ podle BBC ≈æilo na 100 tis√≠c tƒõchto koƒçkovit√Ωch ≈°elem. Organizace na ochranu p≈ô√≠rody verdikt soudu uv√≠taly. Rozhodnut√≠ vych√°z√≠ vst≈ô√≠c p≈ô√≠slu≈°n√© petici, kter√° ≈æ√°dala vytlaƒçen√≠ komerƒçn√≠ch turistick√Ωch aktivit z oblast√≠ nejƒçastƒõj≈°√≠ho v√Ωskytu tygr≈Ø v rezervac√≠ch. V z√≥n√°ch stanoven√Ωch soudem ≈æije vƒõt≈°ina indick√Ωch tygr≈Ø. Tygr≈Øm se da≈ô√≠ tak√© v pra≈æsk√© zoo: Souvisej√≠c√≠ Pra≈æsk√° zoo p≈ôedstavila tyg≈ô√≠ ml√°ƒèata, jsou to samiƒçky 6 fotografi√≠ I kdy≈æ je rozhodnut√≠ soudu oznaƒçov√°no za v√Ωznamn√©, nen√≠ jasn√©, jak√Ω dopad bude m√≠t na turismus. Ten se soust≈ôeƒèuje do takzvan√Ωch n√°razn√≠kov√Ωch z√≥n, co≈æ jsou a≈æ deset kilometr≈Ø ≈°irok√° p√°sma kolem vymezen√Ωch z√≥n. Soudn√≠ verdikt je jedn√≠m z ≈ôady krok≈Ø, kter√© indick√© org√°ny v posledn√≠ dobƒõ podnikly na ochranu tygr≈Ø. V √∫noru byla ve st√°tƒõ R√°d≈æasth√°n p≈ôestƒõhov√°na cel√° vesnice, je≈æ musela zv√≠≈ôat≈Øm ustoupit. Opat≈ôen√≠ zjevnƒõ zab√≠raj√≠. Podle √∫≈ôad≈Ø poƒçet tygr≈Ø v Indii opƒõt roste. Nad√°le je ale ohro≈æuj√≠ lid√© ≈æij√≠c√≠ uvnit≈ô nebo na okraji rezervac√≠.",
  "target_text": "Nejvy≈°≈°√≠ soud zak√°zal vstup do 40 tyg≈ô√≠ch rezervac√≠"
}
```

```json
{
  "text": "V Klementinu byly nap≈ô√≠klad objeveny t≈ôi studny, poz≈Østatky kamenn√Ωch dom≈Ø nebo ƒç√°st trativodu z obdob√≠ 16. a≈æ 17. stolet√≠. V z√°kladech barokn√≠ stavby byly objeveny ƒç√°sti klenebn√≠ch ≈æeber ƒçi ostƒõn√≠ oken, kter√© s nejvƒõt≈°√≠ pravdƒõpodobnost√≠ poch√°zej√≠ z konstrukc√≠ st≈ôedovƒõk√©ho kl√°≈°tera odstranƒõn√©ho p≈ôi v√Ωstavbƒõ Klementina. Novinky o tom informovala Irena Ma≈à√°kov√° z N√°rodn√≠ knihovny ƒåR. Archeologov√© slav√≠ v N√°rodn√≠ knihovnƒõ mnoho √∫spƒõch≈Ø. FOTO: N√°rodn√≠ knihovna ƒåR K nejv√Ωznamnƒõj≈°√≠mu n√°lezu podle n√≠ do≈°lo p≈ôi p≈ôesunu v√Ωzkumu ze z√°padn√≠ho k≈ô√≠dla do traktu mezi Studentsk√Ωm a R√©vov√Ωm n√°dvo≈ô√≠m, kde byly pod barokn√≠ podlahou suter√©nu odkryty zbytky zdiv n√°le≈æej√≠c√≠ch k dominik√°nsk√©mu kl√°≈°teru, kter√Ω zde st√°l od 30. let 13. stolet√≠. Odkryli i mno≈æstv√≠ relikt≈Ø ‚ÄûV√Ωznam n√°lezu spoƒç√≠v√° p≈ôedev≈°√≠m v tom, ≈æe se jedn√° o prvn√≠ hmotn√Ω doklad tohoto kl√°≈°tera, o nƒõm≈æ jsme dosud vƒõdƒõli pouze z p√≠semn√Ωch pramen≈Ø,‚Äú vysvƒõtlil vedouc√≠ archeolog Jan Havrda. N√°lezy dokl√°daj√≠ i v√Ωstavnost gotick√© stavby, je≈æ ve sv√© dobƒõ p≈ôedstavovala jednu z nejv√Ωznamnƒõj≈°√≠ch pra≈æsk√Ωch c√≠rkevn√≠ch instituc√≠. P≈ôi v√Ωzkumu byly rovnƒõ≈æ odkryty ƒçetn√© relikty st≈ôedovƒõk√© a ranƒõ novovƒõk√© z√°stavby, kter√° byla odstranƒõna v souvislosti s v√Ωstavbou t√©to ƒç√°sti barokn√≠ho are√°lu v roce 1654. Vysok√° pam√°tkov√° hodnota Kromƒõ poz≈Østatk≈Ø kamenn√Ωch dom≈Ø byly odkryty i t≈ôi st≈ôedovƒõk√© studny, z nich≈æ nƒõkter√© pozdƒõji slou≈æily jako odpadn√≠ j√≠mky. Nejv√Ωznamnƒõj≈°√≠m n√°lezem v tƒõchto prostor√°ch byla line√°rn√≠ zdƒõn√° konstrukce vystavƒõn√° rom√°nskou technikou. Zaznamenan√° d√©lka 0,7 metru ≈°irok√© zdi dosahuje 11,7 metru a jej√≠ koruna se nal√©zala bezprost≈ôednƒõ pod souƒçasnou podlahou sklepa. Archeologov√© uƒçinili p≈ôes zimu hned nƒõkolik zaj√≠mav√Ωch objev≈Ø. Poz≈Østatky dominik√°nsk√©ho kl√°≈°tera ze 13. stolet√≠ jsou v≈°ak nejv√Ωznamnƒõj≈°√≠. FOTO: N√°rodn√≠ knihovna ƒåR ‚ÄûJedn√° se o unik√°tn√≠ architektonickou pam√°tku n√°le≈æej√≠c√≠ ke skupinƒõ pra≈æsk√Ωch prof√°nn√≠ch rom√°nsk√Ωch staveb, kter√© p≈ôedstavuj√≠ nejstar≈°√≠ horizont kamenn√© architektury na √∫zem√≠ Pra≈æsk√© pam√°tkov√© rezervace a jejich≈æ pam√°tkov√° hodnota je nesporn√°. Interpretace tohoto n√°lezu nen√≠ jednoznaƒçn√°, mohlo by se v≈°ak jednat o severn√≠ obvodovou zeƒè rozlehlej≈°√≠ho rom√°nsk√©ho domu,‚Äú uvedl Havrda.",
  "target_text": "Archeologov√© pracuj√≠ p≈ôes zimu v N√°rodn√≠ knihovnƒõ jako o ≈æivot. V posledn√≠ dobƒõ zkoumali klementinsk√© suter√©ny pod z√°padn√≠m k≈ô√≠dlem b√Ωval√© jezuitsk√© koleje a sklepn√≠ trakt mezi Studentsk√Ωm a R√©vov√Ωm n√°dvo≈ô√≠m. Nejv√Ωznamnƒõj≈°√≠m n√°lezem je objev zbytk≈Ø zdiv, kter√© poprv√© hmotnƒõ dokl√°daj√≠ existenci zdej≈°√≠ho dominik√°nsk√©ho kl√°≈°tera ze 13. stolet√≠"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:

  ```text
  N√°sleduj√≠c√≠ jsou dokumenty s p≈ôilo≈æen√Ωmi souhrny.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Souhrn: {target_text}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  Napi≈°te souhrn v√Ω≈°e uveden√©ho dokumentu.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset czech-news
```
