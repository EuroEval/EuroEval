# üáÆüá∏ Icelandic

This is an overview of all the datasets used in the Icelandic part of ScandEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Hotter and Colder Sentiment

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Eftirfarandi eru yfirfer√∞ir √°samt lyndisgildi √æeirra, sem getur veri√∞ 'j√°kv√¶tt', 'hlutlaust' e√∞a 'neikv√¶tt'.
  ```
- Base prompt template:
  ```
  Yfirfer√∞: {text}
  Lyndi: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texti: {text}

  Flokka√∞u tilfinninguna √≠ textanum. Svara√∞u me√∞ 'j√°kv√¶tt', 'hlutlaust' e√∞a 'neikv√¶tt'.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `j√°kv√¶tt`
    - `neutral` ‚û°Ô∏è `hlutlaust`
    - `negative` ‚û°Ô∏è `neikv√¶tt`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset hotter-and-colder-sentiment
```


## Named Entity Recognition

### MIM-GOLD-NER

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Eftirfarandi eru setningar √°samt JSON lyklum me√∞ nefndum einingum sem koma fyrir √≠ setningunum.
  ```
- Base prompt template:
  ```
  Setning: {text}
  Nefndar einingar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Setning: {text}

  Greini√∞ nefndu einingarnar √≠ setningunni. √û√∫ √¶ttir a√∞ skila √æessu sem JSON or√∞ab√≥k me√∞ lyklunum 'einstaklingur', 'sta√∞setning', 'stofnun' og '√Ωmislegt'. Gildin √¶ttu a√∞ vera listi yfir nefndu einingarnar af √æeirri ger√∞, n√°kv√¶mlega eins og √æ√¶r koma fram √≠ setningunni.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `einstaklingur`
    - `I-PER` ‚û°Ô∏è `einstaklingur`
    - `B-LOC` ‚û°Ô∏è `sta√∞setning`
    - `I-LOC` ‚û°Ô∏è `sta√∞setning`
    - `B-ORG` ‚û°Ô∏è `stofnun`
    - `I-ORG` ‚û°Ô∏è `stofnun`
    - `B-MISC` ‚û°Ô∏è `√Ωmislegt`
    - `I-MISC` ‚û°Ô∏è `√Ωmislegt`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset mim-gold-ner
```


## Linguistic Acceptability

### ScaLA-is

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Eftirfarandi eru setningar og hvort √æ√¶r eru m√°lfr√¶√∞ilega r√©ttar.
  ```
- Base prompt template:
  ```
  Setning: {text}
  M√°lfr√¶√∞ilega r√©tt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Setning: {text}

  Greini√∞ hvort setningin er m√°lfr√¶√∞ilega r√©tt e√∞a ekki. Svari√∞ skal vera 'j√°' ef setningin er r√©tt og 'nei' ef h√∫n er ekki.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `j√°`
    - `incorrect` ‚û°Ô∏è `nei`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset scala-is
```


### Unofficial: IceEC

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Eftirfarandi eru setningar og hvort √æ√¶r eru m√°lfr√¶√∞ilega r√©ttar.
  ```
- Base prompt template:
  ```
  Setning: {text}
  M√°lfr√¶√∞ilega r√©tt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Setning: {text}

  Greini√∞ hvort setningin er m√°lfr√¶√∞ilega r√©tt e√∞a ekki. Svari√∞ skal vera 'j√°' ef setningin er r√©tt og 'nei' ef h√∫n er ekki.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `j√°`
    - `incorrect` ‚û°Ô∏è `nei`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset ice-ec
```


### Unofficial: IceLinguistic

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Eftirfarandi eru setningar og hvort √æ√¶r eru m√°lfr√¶√∞ilega r√©ttar.
  ```
- Base prompt template:
  ```
  Setning: {text}
  M√°lfr√¶√∞ilega r√©tt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Setning: {text}

  Greini√∞ hvort setningin er m√°lfr√¶√∞ilega r√©tt e√∞a ekki. Svari√∞ skal vera 'j√°' ef setningin er r√©tt og 'nei' ef h√∫n er ekki.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `j√°`
    - `incorrect` ‚û°Ô∏è `nei`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset ice-linguistic
```


## Reading Comprehension

### NQiI

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Eftirfarandi eru textar me√∞ tilheyrandi spurningum og sv√∂rum.
  ```
- Base prompt template:
  ```
  Texti: {text}
  Spurning: {question}
  Svara√∞u me√∞ a√∞ h√°marki 3 or√∞um: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texti: {text}

  Svara√∞u eftirfarandi spurningu um textann a√∞ h√°marki √≠ 3 or√∞um.

  Spurning: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset nqii
```


### Unofficial: IcelandicQA

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Eftirfarandi eru textar me√∞ tilheyrandi spurningum og sv√∂rum.
  ```
- Base prompt template:
  ```
  Texti: {text}
  Spurning: {question}
  Svara√∞u me√∞ a√∞ h√°marki 3 or√∞um: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texti: {text}

  Svara√∞u eftirfarandi spurningu um textann a√∞ h√°marki √≠ 3 or√∞um.

  Spurning: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset icelandic-qa
```


## Knowledge

### ARC-is

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Eftirfarandi eru fj√∂lvalsspurningar (me√∞ sv√∂rum).
  ```
- Base prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svara: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Svara√∞u eftirfarandi spurningum me√∞ 'a', 'b', 'c' e√∞a 'd'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset arc-is
```


### Unofficial: MMLU-is

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Eftirfarandi eru fj√∂lvalsspurningar (me√∞ sv√∂rum).
  ```
- Base prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svara: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Svara√∞u eftirfarandi spurningum me√∞ 'a', 'b', 'c' e√∞a 'd'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset mmlu-is
```


## Common-sense Reasoning

### Winogrande-is

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Eftirfarandi eru fj√∂lvalsspurningar (me√∞ sv√∂rum).
  ```
- Base prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svara: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Svara√∞u eftirfarandi spurningum me√∞ 'a', 'b', 'c' e√∞a 'd'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset winogrande-is
```


### Unofficial: HellaSwag-is

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Eftirfarandi eru fj√∂lvalsspurningar (me√∞ sv√∂rum).
  ```
- Base prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svara: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Spurningar: {text}
  Svarm√∂guleikar:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Svara√∞u eftirfarandi spurningum me√∞ 'a', 'b', 'c' e√∞a 'd'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset hellaswag-is
```


## Summarization

### RRN

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  Eftirfarandi eru fr√©ttagreinar me√∞ tilheyrandi samantektum.
  ```
- Base prompt template:
  ```
  Fr√©ttagrein: {text}
  Samantekt: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Fr√©ttagrein: {text}

  Skrifa√∞u samantekt um ofangreindu grein.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset rrn
```


### Unofficial: IceSum

[description]

[size-info]

Here are a few examples from the training split:

```json
[example-1]
```
```json
[example-2]
```
```json
[example-3]
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  Eftirfarandi eru fr√©ttagreinar me√∞ tilheyrandi samantektum.
  ```
- Base prompt template:
  ```
  Fr√©ttagrein: {text}
  Samantekt: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Fr√©ttagrein: {text}

  Skrifa√∞u samantekt um ofangreindu grein.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset icesum
```
