# üáµüá± Polish

This is an overview of all the datasets used in the Polish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### PolEmo 2.0
This dataset was published in [this paper](https://aclanthology.org/K19-1092/) and consists of Polish online reviews from the medicine and hotels domains, annotated for sentiment. Each review is labelled as positive, negative, neutral, or ambiguous. We have filtered out the ambiguous samples.

The original full dataset consists of 6,573 / 823 / 820 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The train and validation splits are subsets of the original splits. For the test split, we use all available test samples and supplement with additional samples from the training set to reach 2,048 samples in total.

The distribution of sentiment labels across the combined splits is as follows:
- **Negative**: 1,592 samples
- **Positive**: 1,119 samples
- **Neutral**: 617 samples

Here are a few examples from the training split:

```json
{
    "text": "Stary , bardzo zaniedbany hotel , obsluga czesto nie w humorze nie wykluczajac wlasciciela hotelu . Sniadania malo urozmaicone , powtarzajace sie przez caly tydzien dwa rodzaje byle jakiej wedliny , jednego rodzaju zoltego sera i jajecznicy ze sproszkowanych jajek . Obiadokolacja bardzo pozno 19 . 30 . Dla malych dzieci i zmeczonych narciarzy stanowczo za pozno . Napewno odwiedze Livignio , ale nigdy wiecej hotel Europa .",
    "label": "negative"
}
```
```json
{
    "text": "Arkadiusz Miszuk zosta≈Ç powo≈Çany na stanowisko prezesa , za≈õ Dariusz Rutowicz na stanowisko wiceprezesa , gie≈Çdowej sp√≥≈Çki hotelowej Interferie SA , poinformowa≈Ça sp√≥≈Çka w komunikacie z 16 marca : ‚Äû ZarzƒÖd sp√≥≈Çki Interferie INTERFERIE S . A . w Lubinie , informuje i≈º Rada Nadzorcza Sp√≥≈Çki na posiedzeniu w dniu 16 . 03 . 2012 roku odwo≈Ça≈Ça ze sk≈Çadu ZarzƒÖdu : 1 ) Pana Adama Milanowskiego , 2 ) Pana Rados≈Çawa Besztygƒô . Jednocze≈õnie ZarzƒÖd INTERFERIE S . A . w Lubinie , informuje i≈º w dniu 16 . 03 . 2012 roku Rada Nadzorcza Sp√≥≈Çki powo≈Ça≈Ça w sk≈Çad ZarzƒÖdu : 1 ) Pana Arkadiusza Miszuka - na stanowisko Prezesa ZarzƒÖdu , 2 ) Pana Dariusza Rutowicza - na stanowisko Wiceprezesa ZarzƒÖdu .",
    "label": "neutral"
}
```
```json
{
    "text": "Hotel znajduje siƒô w idealnym miejscu dla fan√≥w pieszych wycieczek . Z dala od zgie≈Çku Krup√≥wek - blisko szlak√≥w wychodzƒÖcych w g√≥ry . Pokoje przestronne i czyste . Obs≈Çuga bardzo mi≈Ça . Basen jest aczkolwiek swoim urokiem nie zachwyca . Bardzo bogate i smaczne ≈õniadania . R√≥wnie≈º jedzenie w restauracji jest naprawdƒô godne polecenia . Byli ≈õmy go≈õƒámi hotelu ju≈º dwa razy za r√≥wno jako para jaki i rodzina z dzieƒámi i za ka≈ºdym razem byli ≈õmy zadowoleni .",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Liczba przyk≈Çad√≥w few-shot: 12
- Prefiks promptu:
  ```
  Poni≈ºej znajdujƒÖ siƒô dokumenty i ich sentyment, kt√≥ry mo≈ºe byƒá 'pozytywny', 'neutralny' lub 'negatywny'.
  ```
- Szablon podstawowy promptu:
  ```
  Dokument: {text}
  Sentyment: {label}
  ```
- Szablon promptu instrukcyjnego:
  ```
  Dokument: {text}

  Klasyfikuj sentyment w dokumencie. Odpowiedz z 'pozytywny', 'neutralny' lub 'negatywny', i nic wiƒôcej.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positive`
    - `neutral` ‚û°Ô∏è `neutral`
    - `negative` ‚û°Ô∏è `negative`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset polemo2
```


## Named Entity Recognition

### KPWr-NER

This dataset was published in [this paper](https://aclanthology.org/L12-1574/) and is part of the KPWr (Krak√≥wPoland Wroc≈Çaw) corpus - a free Polish corpus annotated with various types of linguistic entities including named entities. The corpus was created to serve as training and testing material for Machine Learning algorithms and is released under a Creative Commons licence. The named entity annotations include persons, locations, organizations, and miscellaneous entities, which are mapped to standard BIO format labels.

The original dataset uses the train and test splits from the source corpus. The validation split is created from the original training split. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The train and validation splits are subsets of the original training split, while the test split is a subset of the original test split.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Rublowka', '(', 'ros', '.', '–†—É–±–ª—ë–≤–∫–∞', ')', '‚Äì', 'potoczna',
       'nazwa', 'zachodniego', 'przedmie≈õcia', 'Moskwy', '.'], dtype=object),
  "labels": array(['B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Wiele', 'z', 'nich', 'zebra≈Ç', 'w', 'tomie', 'Cymelium', '(',
       '1978', ')', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Raul', 'Lozano', ':', '≈ªeby', 'nie', 'by≈Ço', ',', '≈ºe',
       'faworyzuje', 'mistrza', 'Polski', 'w', 'siatk√≥wce', ',', 'nie',
       'przyjecha≈Ç', 'na', 'mecze', 'rozgrywane', 'w', 'Be≈Çchatowie', '.'],
      dtype=object),
  "labels": array(['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô zdania i s≈Çowniki JSON z nazwanymi jednostkami wystƒôpujƒÖcymi w danym zdaniu.
  ```
- Base prompt template:
  ```
  Zdanie: {text}
  Nazwane jednostki: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Zdanie: {text}

  Zidentyfikuj nazwane jednostki w zdaniu. Powiniene≈õ wypisaƒá to jako s≈Çownik JSON z kluczami 'osoba', 'lokalizacja', 'organizacja' i 'r√≥≈ºne'. Warto≈õci powinny byƒá listami nazwanych jednostek tego typu, dok≈Çadnie tak jak pojawiajƒÖ siƒô w zdaniu.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `osoba`
    - `I-PER` ‚û°Ô∏è `osoba`
    - `B-LOC` ‚û°Ô∏è `lokalizacja`
    - `I-LOC` ‚û°Ô∏è `lokalizacja`
    - `B-ORG` ‚û°Ô∏è `organizacja`
    - `I-ORG` ‚û°Ô∏è `organizacja`
    - `B-MISC` ‚û°Ô∏è `r√≥≈ºne`
    - `I-MISC` ‚û°Ô∏è `r√≥≈ºne`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset kpwr-ner
```


## Linguistic Acceptability

### ScaLA-Pl

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Polish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Polish-PDB) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 22,152 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "PapierowƒÖ ≈õmierƒá zafundowali≈õmy zafundowali ≈õmy ju≈º kilku osobom.",
    "label": "correct"
}
```
```json
{
    "text": "To tylko ma≈Çy krok; znam doskonale jego rozmiar; jestem ≈õwiadomy, ≈ºe polityka nieustanny wysi≈Çek, a kiedy jedno zadanie siƒô ko≈Ñczy, zaraz znajdzie siƒô nastƒôpne.",
    "label": "incorrect"
}
```
```json
{
    "text": "Tutaj interesuje mnie etyczny kontekst transferu naukowej wiedzy psychologicznej z laboratorium badacza do sali wyk≈Çadowej i laboratorium studenckiego - czynniki u≈ÇatwiajƒÖce i utrudniajƒÖce, ale lokowane na stosunkowo wysokim poziomie og√≥lno≈õci.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô teksty i czy sƒÖ gramatycznie poprawne.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Gramatycznie poprawny: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Okre≈õl czy tekst jest gramatycznie poprawny czy nie. Odpowiedz {labels_str}, i nic wiƒôcej.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `tak`
    - `incorrect` ‚û°Ô∏è `nie`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-pl
```

## Reading Comprehension

### PoQuAD

PoQuAD is a Polish Question Answering dataset with contexts from Polish Wikipedia. It follows the SQuAD format with innovations including lower annotation density, abstractive answers, polar questions, and impossible questions.

This dataset was published in [this paper](https://dl.acm.org/doi/10.1145/3587259.3627548).

The original dataset consists of 51,951 samples. We use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "context": "Gda≈Ñski MKS reprezentuje 388 zak≈Çad√≥w. Lech Wa≈Çƒôsa zwraca siƒô do SB, by zaprzesta≈Çy szykan wobec strajkujƒÖcych i opozycyjnych dzia≈Çaczy. O godzinie 14 do stoczni przybywa wojewoda gda≈Ñski w celu ustalenia szczeg√≥≈Ç√≥w rozm√≥w z delegacjƒÖ rzƒÖdowƒÖ. 6 godzin p√≥≈∫niej przybywa ona z wicepremierem Jagielskim na czele do Gda≈Ñska i rozpoczyna rozmowy z MKS-em. Transmituje siƒô je na ca≈Çy zak≈Çad. Nieco p√≥≈∫niej do rozm√≥w do≈ÇƒÖcza delegacja szczeci≈Ñskiego MKS-u (skupia≈Ç on wtedy 134 zak≈Çady). Ukazuje siƒô pierwszy numer Strajkowego Biuletynu Informacyjnego ‚ÄûSolidarno≈õƒá‚Äù.\nW Gda≈Ñskiej Stoczni Remontowej na placu przed budynkiem Dyrekcji GSR odbywa siƒô Msza ≈öwiƒôta, kt√≥rƒÖ koncelebruje ks. Henryk Jankowski.",
    "question": "Kto odprawi≈Ç mszƒô w stoczni?",
    "answers": {
        "text": array(["ks. Henryk Jankowski"], dtype=object),
        "answer_start": array([673], dtype=int32)
    }
}
```
```json
{
    "context": "W swojej kampanii reklamowej, uruchomionej z okazji otwarcia roller coastera, park b≈Çƒôdnie okre≈õli≈Ç Zadrƒô jako kolejkƒô g√≥rskƒÖ drewnianƒÖ (ang. wooden coaster), podczas gdy wed≈Çug standard√≥w bran≈ºy model I-Box stanowi kolejkƒô g√≥rskƒÖ stalowƒÖ (stalowy tor) o hybrydowej konstrukcji podp√≥r (stalowo-drewnianej). Niejasna by≈Ça r√≥wnie≈º sytuacja dotyczƒÖca ostatecznej wysoko≈õci konstrukcji, kt√≥rƒÖ park okre≈õla≈Ç w swoich materia≈Çach jako 61, 63, a nawet 63,8 m. Podana wysoko≈õƒá 62,8 m pochodzi z wywiadu udzielonego w 2018 roku magazynowi bran≈ºowemu First Drop przez projektanta kolejki, Alana Schilke. W 2021 roku producent atrakcji potwierdzi≈Ç wymienione w wywiadzie parametry techniczne.", "question": "Z jakich materia≈Ç√≥w zosta≈Çy wykonane filary hybrydowej kolejki?",
    "answers": {
        "text": array(["stalowo-drewnianej"], dtype=object),
        "answer_start": array([286], dtype=int32)
        }
}
```
```json
{
    "context": "Kr√≥l spƒôdza≈Ç sw√≥j czas w Aubonne, ma≈Çej szwajcarskiej wiosce nad jeziorem Leman, ale od kilku lat mieszka≈Ç te≈º w swojej rezydencji w zachodniej Rumunii (w SƒÉv√¢r≈üin, zamku kupionym przez rodzinƒô kr√≥lewskƒÖ w 1943 roku). Rodzina kr√≥lewska korzysta tak≈ºe z prywatno≈õci zapewnionej przez Pa≈Çac El≈ºbiety, posiad≈Ço≈õci w zielonym obszarze na p√≥≈Çnoc od Bukaresztu, udostƒôpnionym rodzinie kr√≥lewskiej przez w≈Çadze Rumunii. Tutaj w≈Ça≈õnie, na pierwszym piƒôtrze pa≈Çacu, kr√≥l Micha≈Ç zmuszony zosta≈Ç do abdykacji 30 grudnia 1947 roku.",
    "question": "Jaki organ pozwoli≈Ç rodzinie kr√≥lewskiej dysponowaƒá Pa≈Çacem El≈ºbiety?",
    "answers": {
        "text": array(["w≈Çadze Rumunii"], dtype=object),
        "answer_start": array([397], dtype=int32)
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô teksty z towarzyszƒÖcymi pytaniami i
  odpowiedziami.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Pytanie: {question}
  Odpowied≈∫ w maksymalnie 3 s≈Çowach: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Odpowiedz na nastƒôpujƒÖce pytanie dotyczƒÖce powy≈ºszego tekstu w maksymalnie 3 s≈Çowach.

  Pytanie: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset poquad
```


## Knowledge

## Common-sense Reasoning

## Summarization
