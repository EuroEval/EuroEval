# üáµüá± Polish

This is an overview of all the datasets used in the Polish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### PolEmo2
This dataset was published in [this paper](https://aclanthology.org/K19-1092/) and consists of Polish online reviews from the medicine and hotels domains, annotated for sentiment. Each review is labelled as positive, negative, neutral, or ambiguous. We have filtered out the ambiguous samples.

The original full dataset consists of 6,573 / 823 / 820 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The train and validation splits are subsets of the original splits. For the test split, we use all available test samples and supplement with additional samples from the training set to reach 2,048 samples in total.

The distribution of sentiment labels across the combined splits is as follows:
- **Negative**: 1,592 samples
- **Positive**: 1,119 samples
- **Neutral**: 617 samples

Here are a few examples from the training split:

```json
{
    "text": "Stary , bardzo zaniedbany hotel , obsluga czesto nie w humorze nie wykluczajac wlasciciela hotelu . Sniadania malo urozmaicone , powtarzajace sie przez caly tydzien dwa rodzaje byle jakiej wedliny , jednego rodzaju zoltego sera i jajecznicy ze sproszkowanych jajek . Obiadokolacja bardzo pozno 19 . 30 . Dla malych dzieci i zmeczonych narciarzy stanowczo za pozno . Napewno odwiedze Livignio , ale nigdy wiecej hotel Europa .",
    "label": "negative"
}
```
```json
{
    "text": "Arkadiusz Miszuk zosta≈Ç powo≈Çany na stanowisko prezesa , za≈õ Dariusz Rutowicz na stanowisko wiceprezesa , gie≈Çdowej sp√≥≈Çki hotelowej Interferie SA , poinformowa≈Ça sp√≥≈Çka w komunikacie z 16 marca : ‚Äû ZarzƒÖd sp√≥≈Çki Interferie INTERFERIE S . A . w Lubinie , informuje i≈º Rada Nadzorcza Sp√≥≈Çki na posiedzeniu w dniu 16 . 03 . 2012 roku odwo≈Ça≈Ça ze sk≈Çadu ZarzƒÖdu : 1 ) Pana Adama Milanowskiego , 2 ) Pana Rados≈Çawa Besztygƒô . Jednocze≈õnie ZarzƒÖd INTERFERIE S . A . w Lubinie , informuje i≈º w dniu 16 . 03 . 2012 roku Rada Nadzorcza Sp√≥≈Çki powo≈Ça≈Ça w sk≈Çad ZarzƒÖdu : 1 ) Pana Arkadiusza Miszuka - na stanowisko Prezesa ZarzƒÖdu , 2 ) Pana Dariusza Rutowicza - na stanowisko Wiceprezesa ZarzƒÖdu .",
    "label": "neutral"
}
```
```json
{
    "text": "Hotel znajduje siƒô w idealnym miejscu dla fan√≥w pieszych wycieczek . Z dala od zgie≈Çku Krup√≥wek - blisko szlak√≥w wychodzƒÖcych w g√≥ry . Pokoje przestronne i czyste . Obs≈Çuga bardzo mi≈Ça . Basen jest aczkolwiek swoim urokiem nie zachwyca . Bardzo bogate i smaczne ≈õniadania . R√≥wnie≈º jedzenie w restauracji jest naprawdƒô godne polecenia . Byli ≈õmy go≈õƒámi hotelu ju≈º dwa razy za r√≥wno jako para jaki i rodzina z dzieƒámi i za ka≈ºdym razem byli ≈õmy zadowoleni .",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Liczba przyk≈Çad√≥w few-shot: 12
- Prefiks promptu:
  ```
  Poni≈ºej znajdujƒÖ siƒô dokumenty i ich sentyment, kt√≥ry mo≈ºe byƒá 'pozytywny', 'neutralny' lub 'negatywny'.
  ```
- Szablon podstawowy promptu:
  ```
  Dokument: {text}
  Sentyment: {label}
  ```
- Szablon promptu instrukcyjnego:
  ```
  Dokument: {text}

  Klasyfikuj sentyment w dokumencie. Odpowiedz z 'pozytywny', 'neutralny' lub 'negatywny', i nic wiƒôcej.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positive`
    - `neutral` ‚û°Ô∏è `neutral`
    - `negative` ‚û°Ô∏è `negative`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset polemo2
```


## Named Entity Recognition

### KPWr-NER

This dataset was published in [this paper](https://aclanthology.org/L12-1574/) and is part of the KPWr (Krak√≥wPoland Wroc≈Çaw) corpus - a free Polish corpus annotated with various types of linguistic entities including named entities. The corpus was created to serve as training and testing material for Machine Learning algorithms and is released under a Creative Commons licence. The named entity annotations include persons, locations, organizations, and miscellaneous entities, which are mapped to standard BIO format labels.

The original dataset uses the train and test splits from the source corpus. The validation split is created from the original training split. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The train and validation splits are subsets of the original training split, while the test split is a subset of the original test split.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Rublowka', '(', 'ros', '.', '–†—É–±–ª—ë–≤–∫–∞', ')', '‚Äì', 'potoczna',
       'nazwa', 'zachodniego', 'przedmie≈õcia', 'Moskwy', '.'], dtype=object),
  "labels": array(['B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Wiele', 'z', 'nich', 'zebra≈Ç', 'w', 'tomie', 'Cymelium', '(',
       '1978', ')', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Raul', 'Lozano', ':', '≈ªeby', 'nie', 'by≈Ço', ',', '≈ºe',
       'faworyzuje', 'mistrza', 'Polski', 'w', 'siatk√≥wce', ',', 'nie',
       'przyjecha≈Ç', 'na', 'mecze', 'rozgrywane', 'w', 'Be≈Çchatowie', '.'],
      dtype=object),
  "labels": array(['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô zdania i s≈Çowniki JSON z nazwanymi jednostkami wystƒôpujƒÖcymi w danym zdaniu.
  ```
- Base prompt template:
  ```
  Zdanie: {text}
  Nazwane jednostki: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Zdanie: {text}

  Zidentyfikuj nazwane jednostki w zdaniu. Powiniene≈õ wypisaƒá to jako s≈Çownik JSON z kluczami 'osoba', 'lokalizacja', 'organizacja' i 'r√≥≈ºne'. Warto≈õci powinny byƒá listami nazwanych jednostek tego typu, dok≈Çadnie tak jak pojawiajƒÖ siƒô w zdaniu.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `osoba`
    - `I-PER` ‚û°Ô∏è `osoba`
    - `B-LOC` ‚û°Ô∏è `lokalizacja`
    - `I-LOC` ‚û°Ô∏è `lokalizacja`
    - `B-ORG` ‚û°Ô∏è `organizacja`
    - `I-ORG` ‚û°Ô∏è `organizacja`
    - `B-MISC` ‚û°Ô∏è `r√≥≈ºne`
    - `I-MISC` ‚û°Ô∏è `r√≥≈ºne`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset kpwr-ner
```


## Linguistic Acceptability

### ScaLA-pl

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Polish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Polish-PDB) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 22,152 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "PapierowƒÖ ≈õmierƒá zafundowali≈õmy zafundowali ≈õmy ju≈º kilku osobom.",
    "label": "correct"
}
```
```json
{
    "text": "To tylko ma≈Çy krok; znam doskonale jego rozmiar; jestem ≈õwiadomy, ≈ºe polityka nieustanny wysi≈Çek, a kiedy jedno zadanie siƒô ko≈Ñczy, zaraz znajdzie siƒô nastƒôpne.",
    "label": "incorrect"
}
```
```json
{
    "text": "Tutaj interesuje mnie etyczny kontekst transferu naukowej wiedzy psychologicznej z laboratorium badacza do sali wyk≈Çadowej i laboratorium studenckiego - czynniki u≈ÇatwiajƒÖce i utrudniajƒÖce, ale lokowane na stosunkowo wysokim poziomie og√≥lno≈õci.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô teksty i czy sƒÖ gramatycznie poprawne.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Gramatycznie poprawny: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Okre≈õl czy tekst jest gramatycznie poprawny czy nie. Odpowiedz {labels_str}, i nic wiƒôcej.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `tak`
    - `incorrect` ‚û°Ô∏è `nie`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-pl
```


## Reading Comprehension

### PoQuAD

PoQuAD is a Polish Question Answering dataset with contexts from Polish Wikipedia. It follows the SQuAD format with innovations including lower annotation density, abstractive answers, polar questions, and impossible questions.

This dataset was published in [this paper](https://dl.acm.org/doi/10.1145/3587259.3627548).

The original dataset consists of 51,951 samples. We use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively.
We do not use the impossible questions in this version of the dataset.

Here are a few examples from the training split:

```json
{
  "context": "Luna (Karol Sevilla) jest nastolatkƒÖ z Meksyku, kt√≥ra szczƒô≈õliwie jedzie przez ≈ºycie na wrotkach. Jak ka≈ºda dziewczyna w jej wieku, mieszka wraz ze swojƒÖ rodzinƒÖ, chodzi do szko≈Çy i ma swojƒÖ grupƒô znajomych. Ma r√≥wnie≈º pracƒô jako dostawca w restauracji typu fast food. Luna spƒôdza wiƒôkszo≈õƒá swojego czasu na wrotkach na nabrze≈ºu swego ukochanego miasta, s≈ÇuchajƒÖc piosenek skomponowanych przez jej najlepszego przyjaciela, Sim√≥na (Michael Ronda). Ale jej ≈ºycie przybiera jednak niespodziewany obr√≥t, gdy jej rodzice otrzymujƒÖ propozycjƒô niemo≈ºliwƒÖ do odrzucenia..., jutro rodzina Valente musi opu≈õciƒá sw√≥j ukochany dom i przenie≈õƒá siƒô do innego kraju, do Argentyny. Luna musi przystosowaƒá siƒô do nowego ≈ºycia, nowych przyjaci√≥≈Ç i nowej szko≈Çy, gdzie spotyka siƒô ≈õwiat luksusu i elit, kt√≥ry niewiele ma z niƒÖ wsp√≥lnego. Luna szuka schronienia w swojej je≈∫dzie na wrotkach, a przez nie odkrywa tor wrotkarski, Jam & Roller, kt√≥ry oferuje jej nowy wszech≈õwiat na ko≈Çach. Podczas tego nowego etapu w swoim ≈ºyciu Luna rozwija swojƒÖ pasjƒô do jazdy i ta≈Ñca na wrotkach oraz odkrywa drogƒô do nowych przyjaci√≥≈Ç i pierwszej mi≈Ço≈õci, kt√≥rƒÖ znajduje w osobie zupe≈Çnie innej od niej samej, Matteo (Ruggero Pasquarelli). Na przeszkodzie stoi jednak najpopularniejsza dziewczyna w szkole i dziewczyna Matteo, √Åmbar (Valentina Zenere), kt√≥ra za wszelkƒÖ cenƒô chce uczyniƒá ≈ºycie Luny niemo≈ºliwym. R√≥wnie≈º podczas rozwijania swych pasji, Luna mo≈ºe byƒá o krok od odkrycia swojej prawdziwej to≈ºsamo≈õci.",
  "question": "Gdzie przeprowadza siƒô Luna?",
  "answers": {'text': array(['do Argentyny'], dtype=object), 'answer_start': array([652], dtype=int32), 'generative_answer': array(['do Argentyny'], dtype=object)}}
```
```json
{
  "context": "W sezonie 1933 Ruch zdoby≈Ç mistrzostwo Polski. Katzy zagra≈Ç w dziewiƒôtnastu kolejkach ligowych. Jedynym meczem, w kt√≥rym nie wystƒÖpi≈Ç, by≈Ço spotkanie inauguracyjne sezon przeciwko Garbarni Krak√≥w (6:0, 2 kwietnia 1933 roku). Podczas wyjazdowego meczu towarzyskiego z PoloniƒÖ Karwina (4:1, 14 maja 1933 roku) zosta≈Ç usuniƒôty z boiska za krytykowanie decyzji sƒôdziego. W pa≈∫dzierniku zagra≈Ç w przegranym sparingu reprezentacji ≈ölƒÖska, kt√≥rej przeciwnikiem by≈Ça reprezentacja Polski (1:2, 4 pa≈∫dziernika 1933 roku).",
  "question": "W ilu rundach spotka≈Ñ wziƒÖ≈Ç udzia≈Ç Stefan Katzy?",
  "answers": {'text': array(['w dziewiƒôtnastu'], dtype=object), 'answer_start': array([60], dtype=int32), 'generative_answer': array(['W dziewiƒôtnastu'], dtype=object)}}
```
```json
{
  "context": "Nastƒôpnego dnia Amerykanie wys≈Çali nad stacjƒô kolejowƒÖ w Ploeszti 136 B-24 i 94 B-17 w asy≈õcie 132 P-38 i 48 P-47. 1 Grupa wys≈Ça≈Ça na przechwycenie 23 my≈õliwce IAR, ale tylko czƒô≈õƒá z nich odnalaz≈Ça bombowce meldujƒÖc o zestrzeleniu trzech B-24. Sier≈º. Raghiga Dumitrescu stoczy≈Ç walkƒô z czterema P-38, uszkadzajƒÖc jeden z nich, jednak p√≥≈∫niej sam zosta≈Ç zestrzelony. Dwa inne samoloty lƒÖdowa≈Çy na brzuchach. 5 Grupa poderwa≈Ça 8 IAR-80 i 4 Bf 109E z 51 eskadry oraz 7 Bf 109E z 52 eskadry. Ich piloci odnotowali piƒôƒá zestrzele≈Ñ pewnych i jedno prawdopodobne. Kpt. Iliescu lƒÖdowa≈Ç awaryjnie uszkodzonym samolotem. 6 Grupa wykona≈Ça 49 lot√≥w na IAR odnotowujƒÖc piƒôƒá zwyciƒôstw, w tym trzy potwierdzone, bez strat w≈Çasnych. 7 Grupa wys≈Ça≈Ça 15 IAR-81C i 13 Bf 109G, meldujƒÖc o trzech zwyciƒôstwach przy stracie jednego samolotu. Piloci niemieckiego III/JG 77 meldowali o 16 zestrzelonych B-24 ze stratƒÖ 7 Bf 109G. O strƒÖceniu 4 B-24 i 1 B-17 meldowali piloci z 10./JG 301. Sze≈õƒá kolejnych Liberator√≥w mieli zestrzeliƒá piloci II/JG 51, jednego B-17 lotnicy 12./NJG 6, a jednego P-51 pilot 1./JG 302. Prawdziwe straty Amerykan√≥w wynios≈Çy 10 B-24 (po piƒôƒá z 450. i 451. BG), trzy B-17 oraz jeden P-38 z 14. FG. My≈õliwce eskorty nie odnotowa≈Çy ani jednego zestrzelenia.", "question": "Czy sier≈ºantowi Raghiga Dumitrescu uda≈Ço siƒô doprowadziƒá do awarii kt√≥rego z samolot√≥w P-38?",
  "answers": {'text': array(['Sier≈º. Raghiga Dumitrescu stoczy≈Ç walkƒô z czterema P-38, uszkadzajƒÖc jeden z nich'],
      dtype=object), 'answer_start': array([244], dtype=int32), 'generative_answer': array(['tak'], dtype=object)}}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô teksty z towarzyszƒÖcymi pytaniami i
  odpowiedziami.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Pytanie: {question}
  Odpowied≈∫ w maksymalnie 3 s≈Çowach: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Odpowiedz na nastƒôpujƒÖce pytanie dotyczƒÖce powy≈ºszego tekstu w maksymalnie 3 s≈Çowach.

  Pytanie: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset poquad
```


## Knowledge

### LLMzSz≈Å

This dataset was created based on Polish national exams extracted from the archives of the Polish Central Examination Board. LLMzSz≈Å (LLMs Behind the School Desk) represents the first comprehensive benchmark for the Polish language at this scale. The dataset features both academic and professional tests covering 4 types of exams from 154 different domains. The dataset was created to evaluate the ability of language models to transfer knowledge between languages and to assess their performance on Polish educational content.

The original dataset consisted of almost 19,000 closed-ended questions in a single test split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Czujnik do pomiaru poziomu obciƒÖ≈ºenia, stosowany w wozach paszowych jako element systemu zdalnego wa≈ºenia masy mieszanki, jest czujnikiem\nChoices:\na. tensometrycznym.\nb. podczerwieni.\nc. indukcyjnym.\nd. optycznym.",
  "label": "a"
}
```
```json
{
  "text": "Wybierz prawid≈ÇowƒÖ kolejno≈õƒá wykonania operacji remontowych maszyny.\nChoices:\na. Weryfikacja, regeneracja, oczyszczenie, demonta≈º, badanie i odbi√≥r maszyny po remoncie.\nb. Demonta≈º, weryfikacja, oczyszczenie, regeneracja, badanie i odbi√≥r maszyny po remoncie.\nc. Oczyszczenie, demonta≈º, weryfikacja, regeneracja, naprawa zespo≈Ç√≥w, monta≈º, badanie i odbi√≥r maszyny po remoncie.\nd. Regeneracja, demonta≈º, weryfikacja, oczyszczenie, naprawa zespo≈Ç√≥w, regeneracja, badanie i odbi√≥r maszyny po remoncie.",
  "label": "c"
}
```
```json
{
  "text": "CieczƒÖ ciƒô≈ºkƒÖ jednorodnƒÖ nazywamy substancjƒô ciek≈ÇƒÖ, kt√≥rej gƒôsto≈õƒá jest\nChoices:\na. r√≥wna gƒôsto≈õci wody.\nb. wiƒôksza od gƒôsto≈õci wody.\nc. mniejsza od gƒôsto≈õci wody.\nd. wypadkowƒÖ gƒôsto≈õci cieczy ciƒô≈ºkiej i wody.",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô pytania wielokrotnego wyboru (z odpowiedziami).
  ```
- Base prompt template:
  ```
  Pytanie: {text}
  Odpowied≈∫: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Pytanie: {text}

  Odpowiedz na powy≈ºsze pytanie, odpowiadajƒÖc {labels_str}, i nic wiƒôcej.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset llmzszl
```


## Common-sense Reasoning

## Summarization

### PSC

The Polish Summaries Corpus (PSC) was published in [this paper](https://aclanthology.org/L14-1145/) and is a resource created for automated single-document summarization of Polish. The corpus contains manual summaries of news articles, with multiple independently created summaries for single texts to overcome annotator bias. It includes both abstract free-word summaries and extraction-based summaries created by selecting text spans from the original documents.

The original dataset consists only of a training split. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All splits are subsets of the original training data, with the validation and test splits sampled from the original training set.

Here are a few examples from the training split:

```json
{
  "text": "RozpoczynajƒÖcy siƒô 31 grudnia 2000 roku The Race ma staƒá siƒô pokazem mo≈ºliwo≈õci technicznych wsp√≥≈Çczesnego jachtingu, rozwoju technologii telekomunikacyjnych, ma dowie≈õƒá si≈Çy marketingowej wielkich wydarze≈Ñ sportowych, a tak≈ºe potƒôgi finansowej sponsor√≥w tego przedsiƒôwziƒôcia. Oko≈Ço dziesiƒôciu superjacht√≥w wystartuje 31 grudnia 2000 roku o p√≥≈Çnocy z Barcelony. Najlepszy po oko≈Ço dw√≥ch miesiƒÖcach powinien wp≈ÇynƒÖƒá do Starego Portu w Marsylii.",
  "target_text": "31 grudnia 2000 roku rozpoczynajƒÖ siƒô regaty The Race, bƒôdƒÖce rozwiniƒôciem regat dooko≈Ça ≈õwiata - Jules Verne Trophy. Jachty wystartujƒÖ z Barcelony i przep≈ÇynƒÖ bez pomocy  i zawijania do port√≥w trzy oceany.  Organizatorzy regat chcƒÖ dotrzeƒá do miliard√≥w odbiorc√≥w.  By pobiƒá rekordy oglƒÖdalno≈õci i zaprezentowaƒá sponsor√≥w wykorzystana zostanie najnowsza technika m.in kamery na jachtach."
}
```
```json
{
  "text": "je≈õli w polskich przedsiƒôbiorstwach nie zostanie przeprowadzona restrukturyzacja, z ograniczeniem zatrudnienia i wzrostem wydajno≈õci, nie ma co marzyƒá, aby sta≈Çy siƒô one konkurencyjne w momencie wej≈õcia Polski do Unii Europejskiej. wej≈õcie zagranicznego inwestora czƒôsto oznacza zmniejszenie zatrudnienia. Do zmniejszania liczby pracownik√≥w prowadzƒÖ fuzje przedsiƒôbiorstw. Na ochronny parasol pakiet√≥w socjalnych i odprawy dla zwalnianych mogƒÖ liczyƒá zatrudnieni g√≥rnictwie i hutnictwie. Na os≈Çonƒô nie mogƒÖ liczyƒá pracownicy przemys≈Çu lekkiego.",
  "target_text": "W firmach konieczne sƒÖ zwolnienia restrukturyzacyjne i wzrost wydajno≈õci pracy. Je≈õli por√≥wnamy polskie przedsiƒôbiorstwa z ich zachodnimi odpowiednikami, okazuje siƒô, ≈ºe w stosunku do wielko≈õci produkcji zatrudnienie u nas jest drastycznie wiƒôksze. G≈Çƒôboka restrukturyzacja jest konieczna, je≈õli polscy producenci chcƒÖ byƒá konkurencyjni po wstƒÖpieniu Polski do Unii Europejskiej. Wymusza jƒÖ te≈º kryzys na Wschodzie. Czƒôsto sƒÖ one r√≥wnie≈º wynikami wej≈õcia zagranicznego inwestora lub fuzji. Opr√≥cz zwolnie≈Ñ potrzebne sƒÖ inwestycje."
}
```
```json
{
  "text": "Podczas II Kongresu Filmu Polskiego ogromne poruszenie ≈õrodowiska filmowego wywo≈Ça≈Ç list ministra Andrzeja Zakrzewskiego. Minister Zakrzewski zaatakowa≈Ç ≈õrodowisko filmowe za to, ≈ºe dotƒÖd nie ma nowego prawa filmowego.  Filmowcy Poczuli siƒô skrzywdzeni ocenami, bo straty by≈Çy przy zmianie ustrojowej i likwidacji pa≈Ñstwowego mecenatu nieuniknione. A Polska najlepiej chyba ze wszystkich kraj√≥w postkomunistycznych przeprowadzi≈Ça swojƒÖ kinematografiƒô przez ten trudny okres.",
  "target_text": "≈örodowisko filmowe jest poruszone listem ministra kultury, kt√≥ry krytykuje polskie kino i atakuje filmowc√≥w m.in. za niewypracowanie nowego prawa filmowego. Tw√≥rcy czujƒÖ siƒô skrzywdzeni bezpodstawnymi zarzutami. ZaznaczajƒÖ, ≈ºe to ministerstwo odpowiada za zatrzymanie prac nad ustawƒÖ o kinematografii. Publiczna krytyka i niedba≈Ço≈õƒá o interesy ≈õrodowiska tw√≥rczego sƒÖ oburzajƒÖce. Minister potwierdza, ≈ºe jest autorem listu, i nie akceptuje obecnej formu≈Çy Komitetu Kinematografii."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  Poni≈ºej znajdujƒÖ siƒô artyku≈Çy z towarzyszƒÖcymi streszczeniami.
  ```
- Base prompt template:
  ```
  Artyku≈Ç: {text}
  Streszczenie: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Artyku≈Ç: {text}

  Napisz streszczenie powy≈ºszego artyku≈Çu.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset psc
```
