# üá´üá∑ French

This is an overview of all the datasets used in the French part of ScandEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Allocine

This dataset was published in [this Github
repository](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert) and
features reviews from the French movie review website Allocine. The reviews range from
0.5 to 5 (inclusive), with steps of 0.5. The negative samples are reviews with a rating
of at most 2, and the positive ones are reviews with a rating of at least 4. The reviews
in between were discarded.

The original full dataset consists of 160,000 / 20,000 / 20,000 samples for training,
validation, and testing, respectively. We use 1,024 / 256 / 2,048 samples for training,
validation, and testing, respectively. All our splits are subsets of the original ones.

Here are a few examples from the training split:

```json
{
  "text": "Ce 7√®me volet ne m√©rite pas de notre part une grande attention, au vu du pr√©c√©dent New Police Story. √Ä la limite du huis clos, Jackie √©volue dans une bo√Æte de nuit, sorte de pi√®ge du m√©chant cherchant √† se venger, ou du moins √† d√©couvrir la v√©rit√© sur la mort de sa s≈ìur. Notre cascadeur acteur ne b√©n√©ficie pas d'un d√©cors √† la hauteur de son potentiel acrobatique et le film d'un sc√©nario √† la hauteur d'une production, et cette production d'une large distribution, ce qui explique son arriv√©e direct tout √©tag√®re.",
  "label": "negative"
}
```
```json
{
  "text": "Meme pour ceux qui n'aime pas les Chevaliers du Fiel allez voir. 1 il est meilleur que le 1 et cela est rare de voir une suite qui est meilleur que le 1. Des sc√®nes qui peuvent faire rire les petit et les grands. On ne s'ennuie pas. Super film allez le voir. L'interpretation des acteurs sont super. Bonne journ√©e",
  "label": "positive"
}
```
```json
{
  "text": "Une ambiance envo√ªtante, un r√©cit o√π se m√©langent sorcellerie, croyances indiennes, enqu√™te polici√®re sur fond de trafic de drogue, tout est conforme au livre de Tony Hillerman, m√™me si ce dernier a \"reni√©\" le film. Personnellement j'adore. H√©las introuvable en France et diffus√© seulement sur canal , il y a ..... un certain temps.",
  "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Voici des textes et leur sentiment, qui peut √™tre 'positif' ou 'n√©gatif'.
  ```
- Base prompt template:
  ```
  Texte: {text}
  Sentiment: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texte: {text}

  Classez le sentiment dans le texte. R√©pondez par ‚Äòpositif' ou ‚Äòn√©gatif'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset allocine
```


## Named Entity Recognition

### ELTeC

This dataset was published in [this paper](https://doi.org/10.3828/mlo.v0i0.364) and
consists of sentences from 100 novels in French during the period 1840-1920, all of
which are in the public domain. These novels were automatically labelled with named
entities using Stanza-NER, and then manually corrected.

The original dataset consists of 100 samples, one for each novel. We split the novels
into sentences using the French NLTK sentence splitter, resulting in 4,815 samples. We
use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.

We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003
labelling scheme, which is more common in the NER literature. The mapping is as follows:

- `PERS` ‚û°Ô∏è `PER`
- `LOC` ‚û°Ô∏è `LOC`
- `ORG` ‚û°Ô∏è `ORG`
- `OTHER` ‚û°Ô∏è `MISC`
- `DEMO` ‚û°Ô∏è `O`
- `ROLE` ‚û°Ô∏è `O`
- `EVENT` ‚û°Ô∏è `O`

Here are a few examples from the training split:

```json
{
  'tokens': array(['Jamais', 'ils', 'ne', 'firent', 'de', 'provisions', ',', 'except√©', 'quelques', 'bottes', "d'ail", 'ou', "d'oignons", 'qui', 'ne', 'craignaient', 'rien', 'et', 'ne', 'co√ªtaient', 'pas', "grand'chose", ';', 'le', 'peu', 'de', 'bois', "qu'ils", 'consommaient', 'en', 'hiver', ',', 'la', 'Sauviat', "l'achetait", 'aux', 'fagotteurs', 'qui', 'passaient', ',', 'et', 'au', 'jour', 'le', 'jour', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  'tokens': array(['I', 'Il', 'y', 'avait', 'plus', 'de', 'soixante', 'ans', 'que', "l'empereur", 'Napol√©on', ',', 'press√©', "d'argent", ',', 'avait', 'vendu', 'les', 'provinces', 'de', 'la', 'Louisiane', '√†', 'la', 'R√©publique', 'des', '√âtats-Unis', ';', 'mais', ',', 'en', 'd√©pit', 'de', "l'infiltration", 'yankee', ',', 'les', 'traditions', 'des', 'cr√©oles', 'fran√ßais', 'se', 'perp√©tuaient', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  'tokens': array(['Les', 'fen√™tres', 'de', 'la', 'vieille', 'demeure', 'royale', ',', 'ordinairement', 'si', 'sombres', ',', '√©taient', 'ardemment', '√©clair√©es', ';', 'les', 'places', 'et', 'les', 'rues', 'attenantes', ',', 'habituellement', 'si', 'solitaires', ',', 'd√®s', 'que', 'neuf', 'heures', 'sonnaient', '√†', "Saint-Germain-l'Auxerrois", ',', '√©taient', ',', "quoiqu'il", 'f√ªt', 'minuit', ',', 'encombr√©es', 'de', 'populaire', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Vous trouverez ci-dessous des phrases et des dictionnaires JSON avec les entit√©s nomm√©es qui apparaissent dans la phrase donn√©e.
  ```
- Base prompt template:
  ```
  Sentence: {text}
  Entit√©s nomm√©es: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sentence: {text}

  Identifiez les entit√©s nomm√©es dans la phrase. Vous devez produire ceci sous forme de dictionnaire JSON avec les cl√©s 'personne', 'lieu', 'organisation' et 'divers'. Les valeurs doivent √™tre des listes des entit√©s nomm√©es de ce type, exactement comme elles apparaissent dans la phrase.
  ```

- Label mapping:
    - `B-PER` ‚û°Ô∏è `personne`
    - `I-PER` ‚û°Ô∏è `personne`
    - `B-LOC` ‚û°Ô∏è `lieu`
    - `I-LOC` ‚û°Ô∏è `lieu`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `divers`
    - `I-MISC` ‚û°Ô∏è `divers`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset eltec
```


## Linguistic Acceptability

### ScaLA-fr

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [French Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_French-GSD/tree/master) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Le dessert est une part minuscule de g√¢teau.",
  "label": "correct"
}
```
```json
{
  "text": "Le trafic international sera normal vendredi sur Eurostar, Thalys, et sur les trains √† grande vitesse √† destination de l', a indiqu√© la SNCF dans un communiqu√©.",
  "label": "incorrect"
}
```
```json
{
  "text": "Certains craignent qu' un avantage comp√©titif trop net et trop durable favorise les positions dominantes, monopoles et oligopoles, qui limitent la et concurrence finissent par peser sur le consommateur.",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∏lgende er s√¶tninger og om de er grammatisk korrekte.
  ```
- Base prompt template:
  ```
  S√¶tning: {text}
  Grammatisk korrekt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S√¶tning: {text}

  Bestem om s√¶tningen er grammatisk korrekt eller ej. Svar med 'ja', hvis s√¶tningen er korrekt, og 'nej', hvis den ikke er.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `ja`
    - `incorrect` ‚û°Ô∏è `nej`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset scala-da
```


## Reading Comprehension

### FQuAD

This dataset was published in [this
paper](https://aclanthology.org/2020.findings-emnlp.107/), and is a manually annotated
dataset of questions and answers from the French Wikipedia.

The original full dataset consists of 20,731 / 3,188 / 2,189 samples for training,
validation and testing, respectively. Note that the testing split is not publicly
accessible, however, so we only use the training and validation split. We use 1,024 /
256 / 2,048 samples for training, validation, and testing, respectively. Our training
split is a subset of the original training split, and our validation and testing splits
are subsets of the original validation split.

Here are a few examples from the training split:

```json
{
  'context': "Parmi leurs th√®mes r√©currents, on en trouve qui sont communs √† beaucoup d'autres groupes contemporains ou plus anciens : les Stranglers ont d√©crit, √† plusieurs reprises, la vie d'un groupe de rock dans toutes ses dimensions (fans, autres groupes, vie en tourn√©e). Le th√®me rebattu - chez les groupes des ann√©es 1960-1970 - de la drogue, est abord√©e sur une demi-douzaine de chansons (Don't Bring Harry), tandis que la vision angoiss√©e du futur, dans le contexte de la guerre froide ou en lien avec les avanc√©es de la science, a donn√© lieu √† plusieurs titres (Curfew). On retrouve √©galement chez eux des pr√©occupations √©cologiques (Dreamtime) ou sociales. La guerre, notamment les deux guerres mondiales (Northwinds), mais aussi les guerres contemporaines (I Don't Agree), sont √† l'origine de divers textes. Mais le th√®me qui les a le plus inspir√©s, c'est de loin les femmes (The Man They Love to Hate).",
  'question': 'Sur combien de chanson le th√®me de la drogue est il abord√© ?',
  'answers': {
    'answer_start': array([353]),
    'text': array(['une demi-douzaine'], dtype=object)
  }
}
```
```json
{
  'context': "Au cours de cette p√©riode, Cavour se distingue par son talent de financier. Il contribue de mani√®re pr√©pond√©rante √† la fusion de la Banque de G√™nes et de la nouvelle Banque de Turin au sein de la Banque Nationale des √âtats sardes (Banca Nazionale degli Stati Sardi). Apr√®s le succ√®s √©lectoral de d√©cembre 1849, Cavour devient √©galement une des figures dominantes de la politique pi√©montaise et il prend la fonction de porte-parole de la majorit√© mod√©r√©e qui vient de se cr√©er. Fort de cette position, il fait valoir que le moment des r√©formes est arriv√©, favoris√© par le Statut albertin qui a cr√©√© de r√©elles perspectives de progr√®s. Le Pi√©mont peut ainsi s'√©loigner du front catholique et r√©actionnaire, qui triomphe dans le reste de l'Italie. ",
  'question': "En quel ann√©e sort-il vainqueur d'une √©lection ?",
  'answers': {
    'answer_start': array([305]),
    'text': array(['1849'], dtype=object)
  }
}
```
```json
{
  'context': "Pour autant, le ph√©nom√®ne m√©t√©orologique se d√©cline sous d'autres variantes : ocelles du paon, √©voquant les cent yeux d'Argus, fleurs champ√™tres et ornant les jardins o√π s'√©tablit l'osmose entre couleurs compl√©mentaires. La po√©sie tient en main la palette du peintre,, celle de Claude Gell√©e ou de Poussin. Pour autant, il ne s'agit pas l√† d'une posture habituelle chez lui, qui privil√©gie les paysages quasi-monochromes.",
  'question': "Qu'est ce que l'auteur pr√©f√®re d√©crire ?",
  'answers': {
    'answer_start': array([394]),
    'text': array(['paysages'], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Les textes suivants sont accompagn√©s de questions et de r√©ponses.
  ```
- Base prompt template:
  ```
  Texte: {text}
  Question: {question}
  R√©ponse en 3 mots maximum: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texte: {text}

  R√©pondez √† la question suivante sur le texte ci-dessus en 3 mots maximum.

  Question: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset fquad
```


## Knowledge

Missing!


## Common-sense Reasoning

Missing!


## Summarization

Missing!
