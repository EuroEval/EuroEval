# üá∏üá™ Swedish

This is an overview of all the datasets used in the Swedish part of ScandEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### SweReC

This dataset was published [in this B.Sc.
thesis](https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1105494&dswid=3392) and
is a manually annotated dataset of Swedish reviews from both Trustpilot and Reco.se.

The original dataset contains 10,757 reviews. We use a split of 1,024 / 256 / 2,048
samples for training, validation, and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "J√§ttebra och rekommenderas till alla",
  "label": "positive"
}
```
```json
{
  "text": "Lugnt och trevlig st√§mning, inte f√∂r bullrigt. god mat, lite mer variation hade √∂nskats p√• de varma r√§tterna. trevlig personal, dock missade de att ta dryckesbest√§llningar fr√•n oss vilket var ett litet minus. √∂verlag trevlig st√§lle.",
  "label": "neutral"
}
```
```json
{
  "text": "Extremt d√•lig mottagning - b√•de gsm och 3g? samtalen bryts hela tiden och s√• tar dom betalt f√∂r en ny uppkopplingsavgift varje g√•ng.",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∂ljande √§r recensioner och deras sentiment, som kan vara 'positiv', 'neutral' eller 'negativ'.
  ```
- Base prompt template:
  ```
  Recension: {text}
  Sentiment: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Recension: {text}

  Klassificera sentimentet i recensionen. Svara med 'positiv', 'neutral' eller 'negativ'.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positiv`
    - `neutral` ‚û°Ô∏è `neutral`
    - `negative` ‚û°Ô∏è `negativ`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset swerec
```


## Named Entity Recognition

### SUC 3.0

This dataset, also known as the Stockholm-Ume√• Corpus 3.0, was published
[here](https://doi.org/10.23695%2Fwy84-ar30) and is a manually NER-annotated dataset,
based on Swedish texts from the 1990s. The dataset does not follow the CONLL format, so
we convert it into that format using the following mapping:

- `animal` ‚û°Ô∏è `MISC`
- `event` ‚û°Ô∏è `MISC`
- `inst` ‚û°Ô∏è `ORG`
- `myth` ‚û°Ô∏è `MISC`
- `other` ‚û°Ô∏è `MISC`
- `person` ‚û°Ô∏è `PER`
- `place` ‚û°Ô∏è `LOC`
- `product` ‚û°Ô∏è `MISC`
- `work` ‚û°Ô∏è `MISC`

The dataset consists of 74,245 samples, which we split into 1,024 / 256 / 2,048 samples
for training, validation, and testing, respectively.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Det', 'l√•ter', 'som', 'en', 'v√§stanfl√§kt', 'j√§mf√∂rt', 'med', 'den', 'i', 'filmen', 'f√∂rk√§ttrade', 'bilj√§tten', 'General', 'Motors', ',', 'som', 'frist√§llt', '35000', 'jobbare', 'i', 'staden', 'Flint', ',', 'Michigan', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['En', 'liknande', 'kunskapsteoretisk', 'grundfr√•ga', ',', 'fast', 'i', 'mer', 'modernt', 'sofistikerad', 'form', ',', 'n√•r', 'oss', 'nu', 'fr√•n', 'Paris', ':'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['-', 'Dessv√§rre', ',', 'sa', 'man', ',', 'vi', 'har', 'ingen', 'Bj√∂rn', 'Eriksson', 'p√•', 'passagerarlistan', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  F√∂ljande √§r meningar och JSON-ordb√∂cker med de namngivna enheter som f√∂rekommer i den givna meningen.
  ```
- Base prompt template:
  ```
  Mening: {text}
  Namngivna entiteter: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Mening: {text}

  Identifiera de namngivna enheterna i meningen. Du ska outputta detta som en JSON-ordbok med nycklarna 'person', 'plats', 'organisation' och 'diverse'. V√§rdena ska vara listor √∂ver de namngivna enheter av den typen, precis som de f√∂rekommer i meningen.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `person`
    - `I-PER` ‚û°Ô∏è `person`
    - `B-LOC` ‚û°Ô∏è `plats`
    - `I-LOC` ‚û°Ô∏è `plats`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `diverse`
    - `I-MISC` ‚û°Ô∏è `diverse`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset suc3
```


## Linguistic Acceptability

### ScaLA-sv

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Swedish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Swedish-Talbanken) by assuming
that the documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "U-l√§nderna m√•ste ta en genv√§g f√∂r att komma i fatt.",
  "label": "correct"
}
```
```json
{
  "text": "Undra att vi blev lite undandragna.",
  "label": "incorrect"
}
```
```json
{
  "text": "Det √§r ocks√• att viktigt ha tillr√§ckligt korta dubbar.",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∂ljande √§r meningar och huruvida de √§r grammatiskt korrekta.
  ```
- Base prompt template:
  ```
  Mening: {text}
  Grammatisk korrekt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Mening: {text}

  Best√§m om meningen √§r grammatiskt korrekt eller inte. Svara med 'ja' om meningen √§r korrekt och 'nej' om den inte √§r.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `ja`
    - `incorrect` ‚û°Ô∏è `nej`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset scala-sv
```


## Reading Comprehension

### ScandiQA-sv

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the Swedish part of the [MKQA
dataset](https://aclanthology.org/2021.tacl-1.82/). The MKQA dataset is based on the
English [Natural Questions dataset](https://aclanthology.org/Q19-1026/), based on search
queries from the Google search engine. The questions and answers were manually
translated to Swedish (and other languages) as part of MKQA, and the contexts were in
ScandiQA-sv machine translated using the [DeepL translation
API](https://www.deepl.com/en/pro-api/). A rule-based approach was used to ensure that
the translated contexts still contained the answer to the question, potentially by
changing the answers slightly.

The original full dataset consists of 6,810 / 500 / 500 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). All validation
samples in our version also belong to the original validation set, and all original test
samples are included in our test set. The remaining 1,548 test samples in our version
was sampled from the original training set.

Here are a few examples from the training split:

```json
{
  "context": "I Freedom Cry f√•r spelaren ta rollen som Ad√©wal√©, en frigiven slav fr√•n Trinidad som blev Edward Kenways kvarterm√§stare och senare medlem av Assassin Order. Ber√§ttelsel√§get utspelar sig 15 √•r efter h√§ndelserna i Assassin's Creed IV: Black Flag d√§r Ad√©wal√© har blivit en tr√§nad l√∂nnm√∂rdare och finner sig sj√§lv skeppsbruten i Saint-Domingue, d√§r han st√§lls √∂ga mot √∂ga med n√•got av det mest brutala slaveriet i V√§stindien. DLC:n √§r skriven av Jill Murray, som skrev Liberation och Aveline-inneh√•llet f√∂r Black Flag. I februari 2014 meddelades att Freedom Cry skulle sl√§ppas som en frist√•ende titel till PlayStation 4 och PlayStation 3 den 18 februari 2014 f√∂r Nordamerika och den 19 februari 2014 f√∂r Europa. Det sl√§pptes f√∂r PC den 25 februari 2014.",
  "question": "N√§r sl√§pptes assassin's creed freedom cry?",
  "answers": {
    "answer_start": array([637]),
    "text": array(['18 februari 2014'], dtype=object)
  }
}
```
```json
{
  "context": 'Political history of the United Kingdom (1945‚Äìpresent)\n√Ör 1950 orsakade Koreakriget ett nytt tungt tryck p√• statskassan f√∂r milit√§ra utgifter. Detta orsakade en bitter splittring inom Labourpartiet.  De konservativa gjorde √•tstramningspolitiken till en viktig fr√•ga i parlamentsvalet 1950. Labour f√∂rlorade det mesta av sin stora majoritet. Sv√§ngningen var 3,6 % mot dem och de f√∂rlorade 78 platser, vilket gav Attlee en knapp majoritet i parlamentet. Ett √•r senare f√∂rlorade Labour dock parlamentsvalet 1951 trots att det fick fler r√∂ster √§n i valet 1945, och faktiskt fler r√∂ster √§n det konservativa partiet.',
  "question": 'Hur m√•nga √•r har det varit sen 1940?',
  "answers": {
    "answer_start": array([388]),
    "text": array(['78'], dtype=object)
  }
}
```
```json
{
  "context": 'Data link layer\nOSI-modellen\nper skikt\n\n\n\n\n7.  Applikationslager[visa]\n\n\nNNTP\nSIP\nSSI\nDNS\nFTP\nGopher\nHTTP\nNFS\nNTP\nSMPP\nSMTP\nSNMP\nTelnet\nDHCP\nNetconf\nmer....\n\n\n\n\n\n\n\n\n6.  Presentationslager[visa]\n\n\nMIME\nXDR\n\n\n\n\n\n\n\n\n5.  Sessionsskikt[visa]\n\n\nNamngiven pipe\nNetBIOS\nSAP\nPPTP\nRTP\nSOCKS\nSPDY\n\n\n\n\n\n\n\n\n4.  Transportlager[visa]\n\n\nTCP\nUDP\nSCTP\nDCCP\nSPX\n\n\n\n\n\n\n\n\n3.  N√§tverksskikt[visa]\n\n\nIP\n\nIPv4\nIPv6\n\n\nICMP\nIPsec\nIGMP\nIPX\nAppleTalk\nX.25 PLP\n\n\n\n\n\n\n\n\n2.  Datal√§nkskiktet[visa]\n\n\nATM\nARP\nIS-IS\nSDLC\nHDLC\nCSLIP\nSLIP\nGFP\nPLIP\nIEEE 802.2\nLLC\nMAC\nL2TP\nIEEE 802.3\nFrame Relay\nITU-T G.hn DLL\nPPP\nX.25 LAPB\nQ.921 LAPD\nQ.922 LAPF\n\n\n\n\n\n\n\n\n1.  Fysiskt lager[visa]\n\n\nEIA/TIA-232\nEIA/TIA-449\nITU-T V-serien\nI.430\nI.431\nPDH\nSONET/SDH\nPON\nOTN\nDSL\nIEEE 802.3\nIEEE 802.11\nIEEE 802.15\nIEEE 1394\nITU-T G.hn PHY\nUSB\nBluetooth\nRS-232\nRS-449\n\n\n\n\n\n\n\n\n\nv\nt\ne',
  "question": 'Vilket lager av osi-modellen √§r uppdelad i tv√• delskikt?',
  "answers": {
    "answer_start": array([0]),
    "text": array(['Data link layer'], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Nedan f√∂ljer texter med tillh√∂rande fr√•gor och svar.
  ```
- Base prompt template:
  ```
  Text: {text}
  Fr√•ga: {question}
  Svar p√• max 3 ord: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Text: {text}

  Besvara f√∂ljande fr√•ga om texten ovan med h√∂gst 3 ord.

  Fr√•ga: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset scandiqa-sv
```


### Belebele

This dataset was published in [this paper](https://aclanthology.org/2024.acl-long.44/) and is a large-scale multilingual reading comprehension dataset covering 122 languages. The questions are generated from Wikipedia articles and are designed to test various aspects of reading comprehension, including factual understanding, inference, and numerical reasoning.

The dataset provides training, validation, and test splits with human-verified question-answer pairs. The questions are generated to be answerable from the given context and cover diverse topics from Wikipedia articles.

When evaluating generative models, we use the following setup (see the [methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Nedan f√∂ljer texter med tillh√∂rande fr√•gor och svar.
  ```
- Base prompt template:
  ```
  Text: {text}
  Fr√•ga: {question}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Text: {text}

  Besvara f√∂ljande fr√•ga om texten ovan.

  Fr√•ga: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset belebele-sv
```


## Knowledge

### MMLU-sv

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Swedish was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "Varf√∂r √§r tidpunkten f√∂r monumental byggnation vid Ceibal signifikant?\nSvarsalternativ:\na. Det mots√§ger hypotesen att den monumental byggnationen av Maya i huvudsak inspirerades av Olmekerna.\nb. Det bekr√§ftar att inv√•narna i Ceibal inspirerades av Olmekerna f√∂r att bygga stora plattformar.\nc. Det mots√§ger hypotesen att utvecklingen av monumental byggnation bland Maya var en intern process.\nd. Det bekr√§ftar att Olmekerna, som byggde de flesta Maya-monumenten, inspirerades av egyptierna.",
  "label": "a"
}
```
```json
{
  "text": "Vilken populationsstatistik visar f√∂delsetalet vid vilket en befolkning precis f√•r tillr√§ckligt med f√∂dslar f√∂r att ers√§tta f√∂r√§ldrarna och kompensera f√∂r tidiga d√∂dsfall?\nSvarsalternativ:\na. R√• f√∂delsetal\nb. Ers√§ttningstal\nc. D√∂dlighetstal\nd. Total fertilitetstal",
  "label": "b"
}
```
```json
{
  "text": "En subenhet av DNA och protein som best√•r av 134-baspar l√•nga str√§ckor av DNA som omger en proteinoktomer kallas (a)\nSvarsalternativ:\na. histon\nb. kromatin\nc. nukleosom\nd. solenoid",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∂ljande √§r flervalsfr√•gor (med svar).
  ```
- Base prompt template:
  ```
  Fr√•ga: {text}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Fr√•ga: {text}

  Besvara f√∂ljande fr√•ga med 'a', 'b', 'c' eller 'd', och inget annat.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset mmlu-sv
```


### Unofficial: ARC-sv

This dataset is a machine translated version of the English [ARC
dataset](https://doi.org/10.48550/arXiv.1803.05457) and features US grade-school science
questions. The translation to Swedish was done by the University of Oregon as part of
[this paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 1,110 / 297 / 1,170 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,
validation and testing, respectively (so 2,304 samples used in total). All new splits
are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "text": "En typ av f√•gel i Afrika √§ter blodsugande insekter fr√•n stora d√§ggdjur. Vilket ord beskriver b√§st relationen mellan f√•geln och d√§ggdjuren?\nSvarsalternativ:\na. mutualism\nb. parasitism\nc. neutralism\nd. kommensalism",
  "label": "a"
}
```
```json
{
  "text": "Mr. Pratt g√∂r en vetenskaplig demonstration. Han bl√•ser upp en ballong, placerar den i en frys och tar sedan ut den efter 10 minuter. Vilket alternativ beskriver b√§st ballongens volym n√§r den √§r i frysen och efter att den har tagits ut och √•ter till√•tits att v√§rmas upp?\nSvarsalternativ:\na. expanderar i frysen och kontraherar sedan n√§r den blir varmare igen\nb. kontraherar i frysen och expanderar sedan n√§r den blir varmare igen\nc. expanderar i frysen och h√•ller sedan den volymen n√§r den v√§rms upp\nd. kontraherar i frysen och h√•ller sedan den volymen n√§r den v√§rms upp",
  "label": "b"
}
```
```json
{
  "text": "En elev tills√§tter vatten och reng√∂ringsmedel till en kopp med jord. Blandningen skakas och till√•ts s√§tta sig. Eleven observerar att silt-partiklar f√∂rblir uppsuspenderade l√•ngt efter att de andra partiklarna bildar lager p√• botten av beh√•llaren. Den mest troliga f√∂rklaringen √§r att silt-partiklarna √§r\nSvarsalternativ:\na. organiska.\nb. uppl√∂sta.\nc. mindre t√§tt packade.\nd. r√∂r sig snabbare.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∂ljande √§r flervalsfr√•gor (med svar).
  ```
- Base prompt template:
  ```
  Fr√•ga: {text}
  Svarsalternativ:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Fr√•ga: {text}
  Svarsalternativ:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvara f√∂ljande fr√•ga med 'a', 'b', 'c' eller 'd', och inget annat.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset arc-sv
```


## Common-sense Reasoning

### HellaSwag-sv

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The original dataset was based on both
video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset
was translated by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split
for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "[header] Hur man hittar de perfekta brudt√§rnekl√§nningarna [title] Internet √§r en underbar resurs f√∂r att hitta brudt√§rnekl√§nningar. [step] Vi rekommenderar ocks√• att bl√§ddra genom popul√§ra br√∂llopstidningar, s√•som brudens och moderna brudt√§rnets tidningar. Rekommenderat √§r att bruden g√•r och handlar med en eller tv√• av sina brudt√§rnor och ser vilka stilar de gillar.\nSvarsalternativ:\na. N√§r du har begr√§nsat urvalet kan du sedan f√• input fr√•n dina andra brudt√§rnor om du √∂nskar det. [title] Vilka √§r de senaste trenderna i brudt√§rnekl√§nningar? [title] A-linje kl√§nningar som ser bra ut p√• alla olika kroppsformer och storlekar √§r mycket popul√§ra.\nb. Tyv√§rr kan du inte handla lika ofta som om du letade efter matchade brudt√§rnor. [title] N√§r du v√§ljer din brud, v√§lj tre olika stilar: [step] Klipp l√§ngd, klipp tjocklek och fr√•n de flesta \"f√∂r-skjutna\" stilarna till de grundl√§ggande.\nc. Medan varje brud √§r annorlunda, alla √§r b√•de olika och har olika smaker. [title] Se om bruden har en favoritlook f√∂r sin br√∂llopskl√§nning.\nd. [title] B√∂rja s√∂ka efter id√©er eller allm√§nna √•sikter om s√§rskilda br√∂llopskl√§nningar. [step] F√∂rs√∂k att inte bli f√∂r stel och s√∂k bara efter n√•gra kl√§nningar som du tror kan fungera bra tillsammans.",
  "label": "a"
}
```
```json
{
  "text": "[header] Hur man g√∂r en pedikyr [title] Ta bort all befintlig f√§rg med nagellacksborttagare. [step] T√§ck toppen p√• din nagellacksborttagare med en bomullstuss, v√§nd snabbt upp och ner den och omedelbart upp och ner igen f√∂r att applicera lite av produkten. Gnugga sedan nagellacksborttagaren √∂ver dina t√•naglar f√∂r att ta bort f√§rgen.\nSvarsalternativ:\na. [title] L√•t dina t√•naglar bl√∂tl√§ggas i vatten i 10 till 20 minuter. [step] Vatten kan g√∂ra dina naglar vitare genom att l√∂sa upp andra f√∂reningar, s√§rskilt syror.\nb. [substeps] Flytta bomullstussen i sm√•, cirkul√§ra r√∂relser om du har sv√•rt att ta bort f√§rgen. [title] Fyll en fotspa eller en balja med varmt vatten.\nc. [substeps] Om du inte har nagellacksborttagare kan du √∂verv√§ga att anv√§nda den vita nagellacksborttagaren fr√•n f√∂reg√•ende steg f√∂r en enklare applikation. [title] T√§ck dina h√§nder med bandage eller tejp med canvas-lining.\nd. [title] Anv√§nd aceton p√• dina t√•naglar. [step] Aceton kan verkligen hj√§lpa till att ta bort gammalt nagellack fr√•n dina naglar.",
  "label": "b"
}
```
```json
{
  "text": "Han forts√§tter att klippa gr√§set. Kameran fokuserar p√• det rinnande vattnet igen. Den g√•r tillbaka till mannen som klipper gr√§set. sedan\nSvarsalternativ:\na. den g√•r tillbaka till filmen av mannen som klipper jord.\nb. √•terv√§nder till honom och dem som pratar igen.\nc. v√§xlar tillbaka till det rinnande vattnet.\nd. m√∂rk himmel igen.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∂ljande √§r flervalsfr√•gor (med svar).
  ```
- Base prompt template:
  ```
  Fr√•ga: {text}
  Svarsalternativ:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Fr√•ga: {text}
  Svarsalternativ:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvara f√∂ljande fr√•ga med 'a', 'b', 'c' eller 'd', och inget annat.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset swedn
```
