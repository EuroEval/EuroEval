# üá∫üá¶ Ukrainian

This is an overview of all the datasets used in the Ukrainian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### Cross-Domain UK Reviews

The dataset can be found [here](https://huggingface.co/datasets/vkovenko/cross_domain_uk_reviews).
The data is scrapped from [Tripadvisor](https://www.tripadvisor.com/) and [Rozetka](https://rozetka.com.ua/).

The [original dataset](https://huggingface.co/datasets/vkovenko/cross_domain_uk_reviews/blob/main/processed_data.csv)
contains 611,863 samples. We use 1,024 / 256 / 2,048 samples for our training,
validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
    "text": "—è–∫ —ñ –≤—Å—ñ Mc Donalds, —è–∫—ñ—Å—Ç—å –¥—É–∂–µ –Ω–∏–∑—å–∫–∞, –∞–ª–µ —Ä–∞—Ö—É–Ω–æ–∫ –≤–∏—Å–æ–∫–∏–π –∑–∞ —Ç–µ, —â–æ –≤–∏ —ó—Å—Ç–µ. . —à–∫–æ–¥–∞, –∞–ª–µ –Ω–µ –¥–æ—Ö–æ–¥–∏—Ç—å –¥–æ –¥–æ—Å—Ç–∞—Ç–Ω–æ—Å—Ç—ñ",
    "label": "negative"
}
```

```json
{
    "text": "–ü–æ—Å—É–¥–æ–º–∏–π–Ω–æ—é –º–∞—à–∏–Ω–æ—é –∫–æ—Ä–∏—Å—Ç—É—é—Å—å –¥–∞–≤–Ω–æ, —Ä–æ–±–æ—Ç–æ—é —Ü—ñ–ª–∫–æ–º –∑–∞–æ–≤–æ–ª–µ–Ω–∞. –ü—Ä–∞—Ü—é—î –¥—É–∂–µ —Ç–∏—Ö–æ —ñ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ —Å–ø—Ä–∞–≤–ª—è—î—Ç—å—Å—è –∑ –∑–∞–±—Ä—É–¥–Ω–µ–Ω–∏–º –ø–æ—Å—É–¥–æ–º. –í–º—ñ—â–∞—î –≤ —Å–µ–±–µ 12 –∫–æ–º–ø–ª–µ–∫—Ç—ñ–≤ –ø–æ—Å—É–¥—É.",
    "label": "positive"
}
```

```json
{
    "text": "–ó—É–ø–∏–Ω–∏–ª–∏—Å—è –≤ –≥–æ—Ç–µ–ª—ñ –≤ –ª–∏–ø–Ω—ñ 2021 —Ä–æ–∫—É –∑ —Å—ñ–º'—î—é ( 4 –ª—é–¥–∏–Ω–∏ ) , –Ω–æ–º–µ—Ä –±—É–≤ –æ–±—Ä–∞–Ω–∏–π –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏ –ª—é–∫—Å . –£ –Ω–æ–º–µ—Ä—ñ –ø—Ä–æ—Å—Ç–æ—Ä–æ —ñ —á–∏—Å—Ç–æ . –ü—Ä–∏ –±—Ä–æ–Ω—é–≤–∞–Ω–Ω—ñ –≤–æ–Ω–∏ –ø–æ–ø—Ä–æ—Å–∏–ª–∏ –≤–∏–∫–ª–∞—Å—Ç–∏ –¥–∏–≤–∞–Ω , —â–æ —ñ –±—É–ª–æ –∑—Ä–æ–±–ª–µ–Ω–æ . –£ –≤–∞–Ω–Ω—ñ–π –∫—ñ–º–Ω–∞—Ç—ñ –±—É–ª–∏ –≤—Å—ñ –≤–∏—Ç—Ä–∞—Ç–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏ —Ç–∞ —Ä—É—à–Ω–∏–∫–∏ , –≤ –¥–æ—Å—Ç–∞—Ç–Ω—ñ–π –∫—ñ–ª—å–∫–æ—Å—Ç—ñ . –£ –Ω–æ–º–µ—Ä—ñ —î –Ω–µ–≤–µ–ª–∏–∫–∏–π —Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫ , —Å–µ–π—Ñ . –ê–ª–µ —Ä–æ–∑—á–∞—Ä–æ–≤–∞–Ω–∏–π –°–ù–Ü–î–ê–ù–û–ö . –û–≥–æ–ª–æ—à–µ–Ω–∏–π —Å–Ω—ñ–¥–∞–Ω–æ–∫ —à–≤–µ–¥—Å—å–∫–∏–π —Å—Ç—ñ–ª –±—É–≤ , –∞–ª–µ —Ü–µ –±—É–ª–æ –ø–æ–≤–Ω–µ —Ä–æ–∑—á–∞—Ä—É–≤–∞–Ω–Ω—è . –í–∏–±–∞—á—Ç–µ , –∞–ª–µ –º–æ–∂–Ω–∞ –∑—Ä–æ–±–∏—Ç–∏ –±—ñ–ª—å—à —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω–∏–º —ñ –∫–æ—Ä–∏—Å–Ω–∏–º , –±–µ–∑ –º–∞–π–æ–Ω–µ–∑—É –Ω–∞ –æ–≤–æ—á–∞—Ö ? ? . –º—É—Ö–∏ –ª—ñ—Ç–∞–ª–∏ —ñ –±—É–ª–æ –Ω–µ–ø—Ä–∏—î–º–Ω–æ –ø–µ—Ä–µ–±—É–≤–∞—Ç–∏ –≤ –ø—Ä–∏–º—ñ—â–µ–Ω–Ω—ñ .",
    "label": "neutral"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  –ù–∏–∂—á–µ –Ω–∞–≤–µ–¥–µ–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ —ñ —ó—Ö –Ω–∞—Å—Ç—Ä—ñ–π, —è–∫–∏–π –º–æ–∂–µ –±—É—Ç–∏ '–ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π', '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π' –∞–±–æ '–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π'.
  ```

- Base prompt template:

  ```text
  –î–æ–∫—É–º–µ–Ω—Ç: {text}
  –ù–∞—Å—Ç—Ä—ñ–π: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  –î–æ–∫—É–º–µ–Ω—Ç: {text}

  –ö–ª–∞—Å–∏—Ñ—ñ–∫—É–π—Ç–µ –Ω–∞—Å—Ç—Ä—ñ–π —É –¥–æ–∫—É–º–µ–Ω—Ç—ñ. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π—Ç–µ '–ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π', '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π', –∞–±–æ '–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π', —ñ –Ω—ñ—á–æ–≥–æ –±—ñ–ª—å—à–µ.
  ```

- Label mapping:
  - `positive` ‚û°Ô∏è `–ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π`
  - `neutral` ‚û°Ô∏è `–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π`
  - `negative` ‚û°Ô∏è `–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset cross-domain-uk-reviews
```

## Named Entity Recognition

### NER-uk

The dataset can be found [here](https://github.com/lang-uk/ner-uk).
The dataset primarily consists of text from the
[Open Corpus of Ukrainian Texts](https://github.com/brown-uk/corpus).

The original dataset consists of 10,833 / 668 / 1,307 samples for the
training, validation, and test splits, respectively. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively. The train and
validation splits are subsets of the original splits, while the test split is
created using additional samples from the train split.

Here are a few examples from the training split:

```json
{
  "tokens": ["–•–æ—á–∞", "–Ω–µ–ø—Ä–æ—Å—Ç–æ", "–ø—Ä–æ", "–Ω–µ—ó", "—Ä–æ–∑–ø–æ–≤—ñ—Å—Ç–∏", "¬ª", ".", "–í–µ–¥–º—ñ–¥—å", "–∑–∞–º–æ–≤–∫", ",", "–ø–æ–¥–∏–≤–∏–≤—Å—è", "–Ω–∞", "–¥—Ä—É–∑—ñ–≤", ",", "—è–∫—ñ", "—É–≤–∞–∂–Ω–æ", "–π–æ–≥–æ", "—Å–ª—É—Ö–∞–ª–∏", ",", "—ñ", "–∑–∞–ø–∏—Ç–∞–≤", ":"],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "B-PER", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

```json
{
  "tokens": ["–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π", "–º–∞—Ç–µ—Ä—ñ–∞–ª", "–±—É–ª–æ", "–æ–±—Ä–æ–±–ª–µ–Ω–æ", "—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ", ".", "–ú–µ—Ç–æ—é", "–∑–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω–æ—ó", "—Å—Ç–∞—Ç—Ç—ñ", "—î", "–∞–Ω–∞–ª—ñ–∑", "—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ-–∑–º—ñ—Å—Ç–æ–≤–∏—Ö", "–æ—Å–æ–±–ª–∏–≤–æ—Å—Ç–µ–π", "–ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω—å", "—É", "—Ä–∞–π–æ–Ω–Ω—ñ–π", "–ø—Ä–µ—Å—ñ", "–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—â–∏–Ω–∏", "–æ–∑–Ω–∞—á–µ–Ω–æ–≥–æ", "–ø–µ—Ä—ñ–æ–¥—É", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-LOC", "O", "O", "O"]
}
```

```json
{
  "tokens": ["–Ø–∫", "–≤—ñ–¥–æ–º–æ", ",", "—Ä—ñ—à–µ–Ω–Ω—è", "¬´", "–ü—Ä–æ", "–≤–∏—Ö—ñ–¥", "–∑—ñ", "—Å–∫–ª–∞–¥—É", "–∑–∞—Å–Ω–æ–≤–Ω–∏–∫—ñ–≤", "—Ä–µ–¥–∞–∫—Ü—ñ—ó", "–≥–∞–∑–µ—Ç–∏", "¬´", "–ñ–∏—Ç–æ–º–∏—Ä—â–∏–Ω–∞", "¬ª", "–∑", "—ñ–Ω—ñ—Ü—ñ–∞—Ç–∏–≤–∏", "–≥–æ–ª–æ–≤–∏", "–æ–±–ª–∞—Å–Ω–æ—ó", "—Ä–∞–¥–∏", "–±—É–ª–æ", "–ø—Ä–∏–π–Ω—è—Ç–æ", "–Ω–∞", "–¥—Ä—É–≥—ñ–π", "—Å–µ—Å—ñ—ó", "–æ–±–ª–∞—Å–Ω–æ—ó", "—Ä–∞–¥–∏", "24", "–≥—Ä—É–¥–Ω—è", "–º–∏–Ω—É–ª–æ–≥–æ", "—Ä–æ–∫—É", "‚Äî", "—Å–∞–º–µ", "—Ç–æ–≥–æ", "–¥–Ω—è", ",", "–∫–æ–ª–∏", "–í–µ—Ä—Ö–æ–≤–Ω–∞", "–†–∞–¥–∞", "—É—Ö–≤–∞–ª–∏–ª–∞", "–≤", "–æ—Å—Ç–∞—Ç–æ—á–Ω—ñ–π", "—Ä–µ–¥–∞–∫—Ü—ñ—ó", "–ó–∞–∫–æ–Ω", "–ø—Ä–æ", "—Ä–µ—Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è", "–ø—Ä–µ—Å–∏", "."],
  "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "O", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  –ù–∏–∂—á–µ –Ω–∞–≤–µ–¥–µ–Ω—ñ —Ä–µ—á–µ–Ω–Ω—è —Ç–∞ JSON-—Å–ª–æ–≤–Ω–∏–∫–∏ –∑ —ñ–º–µ–Ω–æ–≤–∞–Ω–∏–º–∏ —Å—É—Ç–Ω–æ—Å—Ç—è–º–∏, —è–∫—ñ –ø—Ä–∏—Å—É—Ç–Ω—ñ —É –¥–∞–Ω–æ–º—É —Ä–µ—á–µ–Ω–Ω—ñ.
  ```

- Base prompt template:

  ```text
  –†–µ—á–µ–Ω–Ω—è: {text}
  –Ü–º–µ–Ω–æ–≤–∞–Ω—ñ —Å—É—Ç–Ω–æ—Å—Ç—ñ: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  –†–µ—á–µ–Ω–Ω—è: {text}

  –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫—É–π—Ç–µ —ñ–º–µ–Ω–æ–≤–∞–Ω—ñ —Å—É—Ç–Ω–æ—Å—Ç—ñ —É —Ä–µ—á–µ–Ω–Ω—ñ. –í–∏ –ø–æ–≤–∏–Ω–Ω—ñ –≤–∏–≤–µ—Å—Ç–∏ —Ü–µ —è–∫ JSON-—Å–ª–æ–≤–Ω–∏–∫ –∑ –∫–ª—é—á–∞–º–∏ '–æ—Å–æ–±–∞', '–º—ñ—Å—Ü–µ', '–æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è' —Ç–∞ '—Ä—ñ–∑–Ω–µ'. –ó–Ω–∞—á–µ–Ω–Ω—è –º–∞—é—Ç—å –±—É—Ç–∏ —Å–ø–∏—Å–∫–∞–º–∏ —ñ–º–µ–Ω–æ–≤–∞–Ω–∏—Ö —Å—É—Ç–Ω–æ—Å—Ç–µ–π —Ü—å–æ–≥–æ —Ç–∏–ø—É, —Ç–æ—á–Ω–æ —Ç–∞–∫–∏–º–∏, —è–∫ –≤–æ–Ω–∏ –∑'—è–≤–ª—è—é—Ç—å—Å—è —É —Ä–µ—á–µ–Ω–Ω—ñ.
  ```

- Label mapping:
  - `B-PER` ‚û°Ô∏è `–æ—Å–æ–±–∞`
  - `I-PER` ‚û°Ô∏è `–æ—Å–æ–±–∞`
  - `B-LOC` ‚û°Ô∏è `–º—ñ—Å—Ü–µ`
  - `I-LOC` ‚û°Ô∏è `–º—ñ—Å—Ü–µ`
  - `B-ORG` ‚û°Ô∏è `–æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è`
  - `I-ORG` ‚û°Ô∏è `–æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è`
  - `B-MISC` ‚û°Ô∏è `—Ä—ñ–∑–Ω–µ`
  - `I-MISC` ‚û°Ô∏è `—Ä—ñ–∑–Ω–µ`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset ner-uk-mini
```

## Linguistic Acceptability

### ScaLA-uk

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Ukrainian Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Ukrainian-ParlaMint) by assuming that
the documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "–ü—ñ–¥ –ø–∞—Ç—Ä–æ–Ω–∞—Ç–æ–º –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –£–∫—Ä–∞—ó–Ω–∏ –≤ —Ü—å–æ–º—É —Ä–æ—Ü—ñ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ –Ü–Ü –í—Å–µ—É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –ª—ñ—Ç–Ω—ñ —Å–ø–æ—Ä—Ç–∏–≤–Ω—ñ —ñ–≥—Ä–∏, —è–∫—ñ —Å—Ç–∞–ª–∏ –≤–∞–∂–ª–∏–≤–∏–º –µ—Ç–∞–ø–æ–º —É –ø—ñ–¥–≥–æ—Ç–æ–≤—Ü—ñ –¥–æ –∫–≤–∞–ª—ñ—Ñ—ñ–∫–∞—Ü—ñ–π–Ω–∏—Ö –∑–º–∞–≥–∞–Ω—å –ø–æ –≤—ñ–¥–±–æ—Ä—É –¥–æ –õ—ñ—Ç–Ω—å–æ—ó –æ–ª—ñ–º–ø—ñ–∞–¥–∏ –≤ –ê—Ñ—ñ–Ω–∞—Ö, —Å–ø—Ä–∏—è–ª–∏ –∑–º—ñ—Ü–Ω–µ–Ω–Ω—é —Ñ—ñ–∑–∫—É–ª—å—Ç—É—Ä–Ω–æ-—Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–≥–æ —Ä—É—Ö—É, –æ—Ö–æ–ø–∏–≤—à–∏ –≤—Å—ñ –≤–µ—Ä—Å—Ç–≤–∏ –Ω–∞—Å–µ–ª–µ–Ω–Ω—è.",
  "label": "correct"
}
```

```json
{
  "text": "–Ü –ø—Ä–æ—à—É, –¥–∞–≤–∞–π—Ç–µ –ø–æ–¥—è–∫—É—î–º–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥—É –Ω–∞—à–∏–º –±—ñ–ª–æ—Ä—É—Å—å–∫–∏–º —Å—É—Å—ñ–¥–∞–º.",
  "label": "correct"
}
```

```json
{
  "text": "–®–∞–Ω–æ–≤–Ω—ñ –∫–æ–ª–µ–≥–∏, —Ç–µ–ø–µ—Ä –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ.",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  –ù–∏–∂—á–µ –Ω–∞–≤–µ–¥–µ–Ω—ñ —Ä–µ—á–µ–Ω–Ω—è —ñ —ó—Ö–Ω—è –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å.
  ```

- Base prompt template:

  ```text
  –†–µ—á–µ–Ω–Ω—è: {text}
  –ì—Ä–∞–º–∞—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  –†–µ—á–µ–Ω–Ω—è: {text}

  –í–∏–∑–Ω–∞—á—Ç–µ, —á–∏ —Ä–µ—á–µ–Ω–Ω—è –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–µ —á–∏ –Ω—ñ. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π—Ç–µ '—Ç–∞–∫', —è–∫—â–æ —Ä–µ—á–µ–Ω–Ω—è –ø—Ä–∞–≤–∏–ª—å–Ω–µ, —ñ '–Ω—ñ', —è–∫—â–æ –Ω—ñ. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π—Ç–µ –ª–∏—à–µ —Ü–∏–º —Å–ª–æ–≤–æ–º, —ñ –Ω—ñ—á–∏–º –±—ñ–ª—å—à–µ.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `—Ç–∞–∫`
  - `incorrect` ‚û°Ô∏è `–Ω—ñ`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-uk
```

## Reading Comprehension

### MultiWikiQA-sk

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
  "context": "Register toxick√Ωch √∫ƒçinkov chemick√Ωch l√°tok (anglicky Registry of Toxic Effects of Chemical Substances, RTECS) je datab√°za toxikologick√Ωch inform√°ci√≠ zostaven√Ωch z voƒæne dostupnej vedeckej literat√∫ry bez odkazu na platnos≈• alebo u≈æitoƒçnos≈• publikovan√Ωch ≈°t√∫di√≠. Do roku 2001 bola datab√°za spravovan√° americkou organiz√°ciou NIOSH (National Institute for Occupational Safety and Health, slov. N√°rodn√Ω √∫stav pre bezpeƒçnos≈• a ochranu zdravia pri pr√°ci) ako verejne dostupn√° publik√°cia. Teraz ju spravuje s√∫kromn√° spoloƒçnos≈• Symyx Technologies a je dostupn√° len za poplatok.\n\nObsah \nDatab√°za obsahuje ≈°es≈• typov toxikologick√Ωch inform√°ci√≠:\n prim√°rne podr√°≈ædenie\n mutag√©nne √∫ƒçinky\n reprodukƒçn√© √∫ƒçinky\n karcinog√©nne √∫ƒçinky\n ak√∫tna toxicita\n toxicita viacn√°sobn√Ωch d√°vok\nV datab√°ze sa spom√≠naj√∫ ako ≈°pecifick√© ƒç√≠seln√© hodnoty, ako napr√≠klad LD50, LC50, TDLo alebo TCLo, tak aj ≈°tudovan√© organizmy a sp√¥sob pod√°vania l√°tky. Pre v≈°etky d√°ta s√∫ uveden√© bibliografick√© zdroje. ≈†t√∫die pritom nie s√∫ nijako hodnoten√©.\n\nHist√≥ria \nDatab√°za RTECS bola aktivitou schv√°lenou americk√Ωm Kongresom, zakotvenou v Sekcii 20(a)(6) z√°kona Occupational Safety and Health Act z roku 1970 (PL 91-596). P√¥vodn√© vydanie, zn√°me ako Zoznam toxick√Ωch l√°tok (Toxic Substances List), bolo publikovan√© 28. j√∫na 1971 a obsahovalo toxikologick√© d√°ta o pribli≈æne 5 000 chemik√°li√°ch. N√°zov bol nesk√¥r zmenen√Ω na dne≈°n√Ω Register toxick√Ωch √∫ƒçinkov chemick√Ωch l√°tok (Registry of Toxic Effects of Chemical Substances). V janu√°ri 2001 datab√°za obsahovala 152 970 chemik√°li√≠. V decembri 2001 bola spr√°va RTECS preveden√° z NIOSH do s√∫kromnej firmy Elsevier MDL. T√∫to firmu k√∫pila v roku 2007 spoloƒçnos≈• Symyx, s√∫ƒças≈•ou akviz√≠cie bola aj datab√°za RTECS. T√° je teraz dostupn√° len za poplatok vo forme roƒçn√©ho predplatn√©ho.\n\nRTECS je k dispoz√≠cii v angliƒçtine, franc√∫z≈°tine a ≈°panielƒçine, a to prostredn√≠ctvom Kanadsk√©ho centra pre bezpeƒçnos≈• a ochranu zdravia pri pr√°ci. Predplatitelia maj√∫ pr√≠stup cez web, na CD-ROM a vo form√°te pre intranet. Datab√°za je dostupn√° na webe aj cez NISC (National Information Services Corporation) a ExPub (Expert Publishing, LLC).\n\nExtern√© odkazy \n\n RTECS overview \n Symyx website \n Expert Publishing, LLC Website\n\nZdroj \n\nChemick√© n√°zvy a k√≥dy\nToxikol√≥gia",
  "question": "Ak√© s√∫ tri mo≈ænosti pr√≠stupu k datab√°ze RTECS, ak som predplatiteƒæ?",
  "answers": {"answer_start": [1949], "text": ["cez web, na CD-ROM a vo form√°te pre intranet"]}}
```

```json
{
  "context": "Herta Naglov√°-Docekalov√° (* 29. m√°j 1944, Wels, Rak√∫sko) je rak√∫ska filozofka a profesorka, ƒçlenka vedenia Medzin√°rodnej asoci√°cie filozofiek (IAPf), √ñsterreichische Akademie der Wissenschaften, Institut International de Philosophie (Par√≠≈æ), viceprezidentka F√©d√©ration Internationale des Soci√©t√©s de Philosophie (FISP), zakladaj√∫ca ƒçlenka interdisciplin√°rnych pracovn√Ωch skup√≠n Frauengeschichte a Philosophische Frauenforschung na Viedenskej univerzite, ƒçlenka redakƒçn√Ωch r√°d popredn√Ωch vedeck√Ωch ƒçasopisov, napr. Philosophin, L¬¥Homme, Deutsche Zeitschrift f√ºr Philosophie.\n\n≈Ωivotopis \nVy≈°tudovala hist√≥riu, filozofiu a germanistiku na Viedenskej univerzite. V roku 1967 z√≠skala na svojej alma mater doktor√°t z hist√≥rie pr√°cou o filozofovi dej√≠n Ernstovi von Lasaulx). V rokoch 1968 - 1985 bola asistentkou na In≈°tit√∫te filozofie Viedenskej univerzity. V lete 1980 predn√°≈°ala na Millersville University of Pennsylvania v USA.\n\nV roku 1981 sa habilitovala z filozofie na Viedenskej univerzite dielom Die Objektivit√§t der Geschichtswissenschaft. V rokoch 1985 a≈æ 2009 bola profesorkou In≈°tit√∫tu filozofie Viedenskej univerzity. Od roku 2009 je univerzitnou profesorkou na d√¥chodku (Universit√§tsprofessorin i. R.)\n\nBola hos≈•uj√∫cou profesorkou v roku 1990 na Universiteit Utrecht v holandskom Utrechte; v Nemecku 1991/1992 na Goethe-Universit√§t Frankfurt vo Frankfurte nad Mohanom; 1993 na Universit√§t Konstanz v Konstanzi; 1994/1995 na Freie Universit√§t Berlin v Berl√≠ne. V rokoch 1995/1996 predn√°≈°ala na Universit√§t Innsbruck a 2011 na univerzite v Petrohrade v Rusku.\n\nDielo (v√Ωber) \n Jenseits der S√§kularisierung. Religionsphilosophische Studien. - Berlin 2008 (Hg., gem.m. Friedrich Wolfram).\n Viele Religionen - eine Vernunft? Ein Disput zu Hegel. - Wien/Berlin 2008 (Hg., gem.m. Wolfgang Kaltenbacher und Ludwig Nagl).\n Glauben und Wissen. Ein Symposium mit J√ºrgen Habermas. - Wien/Berlin 2007 (Hg., gem.m. Rudolf Langthaler).\n Geschichtsphilosophie und Kulturkritik. - Darmstadt 2003 (Hrsg., gem.m. Johannes Rohbeck).\n Feministische Philosophie. Ergebnisse, Probleme, Perspektiven. - Frankfurt a.M. 2000 a 2004 \n Continental Philosophy in Feminist Perspective. - Pennsylviania State University Press 2000 (Hg. gem.m. Cornelia Klingler).\n Der Sinn des Historischen. - Frankfurt a.M. 1996 (Hrsg.).\n Politische Theorie. Differenz und Lebensqualit√§t. - Frankfurt a.M. 1996 (Hrsg. gem.m. Herlinde Pauer-Studer).\n Postkoloniales Philosophieren: Afrika. - Wien/M√ºnchen 1992 (Hrsg., gem.m. Franz Wimmer).\n Tod des Subjekts? - Wien/M√ºnchen 1987 (Hrsg., gem.m. Helmuth Vetter).\n Die Objektivit√§t der Geschichtswissenschaft. Systematische Untersuchungen zum wissenschaftlichen Status der Historie. - Wien/M√ºnchen 1982\n spoluvydavateƒæka: Wiener Reihe. Themen der Philosophie (od 1986). \n spoluvydavateƒæka: Deutsche Zeitschrift f√ºr Philosophie (1993-2004). \n spoluvydavateƒæka: L'Homme. Europ√§ische Zeitschrift f√ºr feministische Geschichtswissenschaft (1990 - 2003).\n\nOcenenia \n F√∂rderpreis mesta Viede≈à, 1983\n K√§the Leichter Preis (rak√∫ska ≈°t√°tna cena), 1997 \n Preis f√ºr Geistes- und Sozialwissenschaften der Stadt Wien, 2009\n\nReferencie\n\nExtern√© odkazy \n Ofici√°lna str√°nka, Universit√§t Wien \n Austria Forum, Wissenssammlungen/Biographien: Herta Nagl-Docekal\n\nZdroj \n\nRak√∫ski filozofi",
  "question": "Kedy pri≈°la na svet Herta Naglov√°-Docekalov√°?",
  "answers": {"answer_start": [28], "text": ["29. m√°j 1944"]}}
```

```json
{
  "context": "Martin Bare≈° (* 25. november 1968, Brno) je ƒçesk√Ω profesor neurol√≥gie, od septembra 2019 rektor Masarykovej univerzity, predt√Ωm od febru√°ra 2018 do septembra 2019 dekan Lek√°rskej fakulty Masarykovej univerzity.\n\nRiadiace funkcie \nVo febru√°ri 2018 sa stal dekanom Lek√°rskej fakulty Masarykovej univerzity. Funkciu prevzal po Ji≈ô√≠m Mayerovi, ktor√Ω zast√°val poz√≠ciu dekana v obdob√≠ 20102018. S n√°stupom na post dekana ukonƒçil svoje p√¥sobenie ako prorektor univerzity, ako i z√°stupca prednostu I. neurologickej kliniky pre vedu a v√Ωskum.\n\nDo funkcie rektora univerzity bol zvolen√Ω 1. apr√≠la 2019 Akademick√Ωm sen√°tom Masarykovej univerzity. V prvom kole tajnej voƒæby z√≠skal Bare≈° 36 hlasov z 50 pr√≠tomn√Ωch sen√°torov. Protikandid√°ta, prodekana Pr√≠rodovedeckej fakulty Jarom√≠ra Leichmana, volilo 11 sen√°torov. 3 odovzdan√© hlasy boli neplatn√©.\n\nSk√∫senosti s p√¥soben√≠m vo veden√≠ ≈°koly zbieral Bare≈° v rokoch 20112018, kedy p√¥sobil najsk√¥r ako jej prorektor pre rozvoj a potom ako prorektor pre akademick√© z√°le≈æitosti. Za svoje priority oznaƒçil Bare≈° v dobe voƒæby posil≈àovanie role univerzity ako piliera slobody v s√∫ƒçasnej spoloƒçnosti a zv√Ω≈°enie kvality vzdel√°vania, vedy a v√Ωskumu na medzin√°rodnej √∫rovni.\n\nDo funkcie rektora ho vymenoval 11. j√∫na 2019 prezident Milo≈° Zeman s √∫ƒçinnos≈•ou od 1. septembra 2019. Vo funkcii tak nahradil Mikul√°≈°a Beka, ktor√©mu sa skonƒçilo druh√© volebn√© obdobie a o zvolenie sa teda u≈æ op√§≈• uch√°dza≈• nemohol. Bare≈° k 1. septembru 2019 rezignoval na post dekana Lek√°rskej fakulty.\n\nVedeck√° ƒçinnos≈• \nJe predn√°≈°aj√∫cim v odboroch v≈°eobecn√© lek√°rstvo, zubn√© lek√°rstvo, optometria, fyzioterapia, neurofyziol√≥gia pre ≈°tudentov pr√≠rodn√Ωch vied Lek√°rskej fakulty Masarykovej univerzity a ≈°koliteƒæ doktorandov odborovej rady neurol√≥gia a neurovedy.\n\nP√¥sob√≠ v t√Ωchto vedeck√Ωch rad√°ch: Masarykova univerzita, Lek√°rska fakulta Masarykovej univerzity a CEITEC MU. ƒéalej tie≈æ Univerzita Palack√©ho v Olomouci, Lek√°rska fakulta UPOL, Fakulta veterin√°rn√≠ho l√©ka≈ôstv√≠ VFU, ƒèalej je tie≈æ ƒçlenom ƒåeskej lek√°rskej komory, ƒåeskej neurologickej spoloƒçnosti, ƒåeskej spoloƒçnosti klinickej neurofyziol√≥gie, ƒåeskej lek√°rskej spoloƒçnosti Jana Evangelisty Purkynƒõ, Movement Disorders Society, Society for the Research on the Cerebellum a Society for Neuroscience. Takisto je ƒçlenom redakƒçnej rady ƒçasopisov Clinical Neurophysiology, Behavioural Neurology, Tremor and Other Hyperkinetic Movements a Biomedical Papers.\n\nOsobn√Ω ≈æivot \nJe ≈æenat√Ω, m√° dvoch synov a dc√©ru.\n\nReferencie\n\nExtern√© odkazy \n Martin Bare≈°\n\nZdroj \n\nƒåesk√≠ lek√°ri\nNeurol√≥govia\nRektori Masarykovej univerzity\nƒåesk√≠ univerzitn√≠ profesori\nDekani Lek√°rskej fakulty Masarykovej univerzity\nAbsolventi Lek√°rskej fakulty Masarykovej univerzity\nOsobnosti z Brna",
  "question": "Ak√∫ poz√≠ciu mal Martin Bare≈° na Masarykovej univerzite poƒçn√∫c septembrom 2019?",
  "answers": {
    "answer_start": [89],
    "text": ["rektor"]
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Nasleduj√∫ texty s pridru≈æen√Ωmi ot√°zkami a odpoveƒèami.
  ```

- Base prompt template:

  ```text
  Text: {text}
  Ot√°zka: {question}
  Odpoveƒè na maxim√°lne 3 slov√°:
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Odpovedzte na nasleduj√∫cu ot√°zku t√Ωkaj√∫cu sa textu uveden√©ho vy≈°≈°ie maxim√°lne 3 slovami.

  Ot√°zka: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-sk
```

## Knowledge

### MMLU-sk

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Slovak was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "V ak√Ωch smeroch je pr√≠pad pre humanit√°rnu intervenciu, ako je uveden√© v tejto kapitol... mocn√Ωmi ≈°t√°tmi.\nd. V≈°etky tieto mo≈ænosti.",
  "label": "d",
}
```

```json
{
  "text": "FAKTORI√ÅLOV√ù ANOVA sa pou≈æ√≠va v pr√≠pade, ≈æe ≈°t√∫dia zah≈ï≈àa viac ako 1 VI. Ak√Ω je INTER...ƒçinok VI na rovnakej √∫rovni ako ostatn√© VI",
  "label": "a"
}
```

```json
{
  "text": "Pre ktor√∫ z t√Ωchto dvoch situ√°ci√≠ urob√≠ hlavn√° postava (ktor√° pou≈æ√≠va ja/m≈àa/m√¥j) nie...ie zl√©\nc. Nie zl√©, zl√©\nd. Nie zl√©, nie zl√©",
  "label": "d",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Nasleduj√∫ ot√°zky s viacer√Ωmi mo≈ænos≈•ami (s odpoveƒèami).
  ```

- Base prompt template:

  ```text
  Ot√°zka: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Odpoveƒè: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Ot√°zka: {text}

  Odpovedzte na nasleduj√∫cu ot√°zku pou≈æit√≠m 'a', 'b', 'c' alebo 'd', a niƒç in√©.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-sk
```

### Winogrande-sk

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Nedok√°zal som ovl√°da≈• vlhkos≈• ako som ovl√°dal d√°≈æƒè, preto≈æe _ prich√°dzalo odv≈°adiaƒæ. Na koho sa vz≈•ahuje pr√°zdne miesto _?\nMo≈ænosti:\na. Mo≈ænos≈• A: vlhkos≈•\nb. Mo≈ænos≈• B: d√°≈æƒè",
  "label": "a"
}
```

```json
{
  "text": "Jessica si myslela, ≈æe Sandstorm je najlep≈°ia piese≈à, ak√° bola kedy nap√≠san√°, ale Patricia ju nen√°videla. _ si k√∫pila l√≠stok na jazzov√Ω koncert. Na koho sa vz≈•ahuje pr√°zdne miesto _?\nMo≈ænosti:\na. Mo≈ænos≈• A: Jessica\nb. Mo≈ænos≈• B: Patricia",
  "label": "b"
}
```

```json
{
  "text": "Termostat ukazoval, ≈æe dole bolo o dvadsa≈• stup≈àov chladnej≈°ie ako hore, tak≈æe Byron zostal v _ preto≈æe mu bola zima. Na koho sa vz≈•ahuje pr√°zdne miesto _?\nMo≈ænosti:\na. Mo≈ænos≈• A: dole\nb. Mo≈ænos≈• B: hore",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Nasleduj√∫ ot√°zky s viacer√Ωmi mo≈ænos≈•ami (s odpoveƒèami).
  ```

- Base prompt template:

  ```text
  Ot√°zka: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}
  Odpoveƒè: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Ot√°zka: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}

  Odpovedzte na nasleduj√∫cu ot√°zku pou≈æit√≠m 'a' alebo 'b', a niƒç in√©.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-sk
```
