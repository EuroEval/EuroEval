# üá∏üáÆ Slovenian

This is an overview of all the datasets used in the Slovenian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### Sentinews

This dataset was published in
[this paper](https://link.springer.com/article/10.1007/s10579-018-9413-3) and
consists of five Slovene media resources on the web.

The original dataset contains 168,899 samples. We use 1,024 / 256 / 2,048 samples for
our training, validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
    "text": "V dr≈æavo pa je vpeljal stabilnost, katero je Rusija potrebovala.",
    "label": "positive"
}
```

```json
{
    "text": "Po najbolj ƒçrnogledih napovedih bo konec leta ≈æe sto tisoƒç brezposelnih.",
    "label": "negative"
}
```

```json
{
    "text": "Zdenko Pavƒçek bo vlo≈æil zasebno to≈æbo zoper Walterja Wolfa zaradi kaznivega dejanja raz≈æalitve.",
    "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Spodaj so dokumenti in njihov sentiment, ki je lahko 'pozitivno', 'nevtralno' ali 'negativno'.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Sentiment: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  Klasificirajte sentiment v dokumentu. Odgovorite z 'pozitivno', 'nevtralno' ali 'negativno', in niƒç drugega.
  ```

- Label mapping:
  - `positive` ‚û°Ô∏è `pozitivno`
  - `neutral` ‚û°Ô∏è `nevtralno`
  - `negative` ‚û°Ô∏è `negativno`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset sentinews
```

## Named Entity Recognition

### ssj500k-NER

This dataset was published in
[this paper](https://nl.ijs.si/jtdh20/pdf/JT-DH_2020_Krek-et-al_The-ssj500k-Training-Corpus-for-Slovene-Language-Processing.pdf),
and consists of a collection of text samples from the
[FidaPLUS](https://www.sketchengine.eu/fida-plus-corpus/) corpus of written
modern Slovenian.

The original dataset consists of 9,489 samples. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
    "tokens": ["Prireditev", "Po", "domaƒçe", "pri", "Repan≈°ku", "bo", "povezoval", "igralec", "in", "humorist", "Kondi", "Pi≈æorn", ",", "za", "zabavo", "in", "ples", "pa", "bo", "letos", "igral", "ansambel", "Razpotniki", "."],
    "labels": ["O", "B-MISC", "I-MISC", "I-MISC", "I-MISC", "O", "O", "O", "O", "O", "B-PER", "I-PER", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "O"]
}
```

```json
{
    "tokens": ["Upo≈°tevano", "je", ",", "da", "nekaj", "ljudi", "iz", "te", "bolni≈°nice", "odide", "drugam", ",", "nekaj", "pa", "jih", "pride", "iz", "drugih", "."],
    "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

```json
{
    "tokens": ["Ta", "ukazna", "vrstica", "obdela", "ali", "po≈°lje", "dokument", "v", "datoteko", ",", "ki", "se", "nahaja", "v", "imeniku", "/", "var", "/", "spool", "."],
    "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  Naslednje so povedi in JSON slovarji z poimenovanimi entitetami, ki se pojavijo v dani povedi.
  ```

- Base prompt template:

  ```text
  Poved: {text}
  Poimenovane entitete: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Poved: {text}

  Identificirajte poimenovane entitete v povedi. To morate izpisati kot JSON slovar s kljuƒçi 'oseba', 'kraj', 'organizacija' in 'razno'. Vrednosti morajo biti seznami poimenovanih entitet te kategorije, tako kot se pojavijo v povedi.
  ```

- Label mapping:
  - `B-PER` ‚û°Ô∏è `oseba`
  - `I-PER` ‚û°Ô∏è `oseba`
  - `B-LOC` ‚û°Ô∏è `kraj`
  - `I-LOC` ‚û°Ô∏è `kraj`
  - `B-ORG` ‚û°Ô∏è `organizacija`
  - `I-ORG` ‚û°Ô∏è `organizacija`
  - `B-MISC` ‚û°Ô∏è `razno`
  - `I-MISC` ‚û°Ô∏è `razno`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset ssj500k-ner
```

## Linguistic Acceptability

### ScaLA-sl

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Slovenian Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Slovenian-SSJ) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "Potem je nekdo planil na sejo in povedal, da je v Trade Centru pri≈°lo do eksplozije.",
    "label": "correct"
}
```

```json
{
    "text": "Miroslav Klun: S primerno zakonodajo lahko slovenska obrt ponudi 60.000 novih delovnih mest.",
    "label": "correct"
}
```

```json
{
    "text": "Priroƒçno za vse, ki veliko kupujete drugih v dr≈æavah.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Sledeƒçe so stavki in ali so slovniƒçno pravilni.
  ```

- Base prompt template:

  ```text
  Stavek: {text}
  Slovniƒçno pravilno: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Stavek: {text}

  Ugotovite, ali je stavek slovniƒçno pravilen ali ne. Odgovorite z 'da', ƒçe je stavek pravilen, in 'ne', ƒçe ni. Odgovorite le s to besedo in niƒç drugega.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `da`
  - `incorrect` ‚û°Ô∏è `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-sl
```

## Reading Comprehension

### MultiWikiQA-sl

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": "1891 (MDCCCXCI) je bilo navadno leto, ki se je po gregorijanskem koledarju zaƒçelo na ƒçetrtek, po 12 dni poƒçasnej≈°em julijanskem koledarju pa na torek.\n\nDogodki \n 15. maj ‚Äì pape≈æ Leon XIII. izda encikliko Rerum Novarum\n\nRojstva \n 22. januar - Antonio Gramsci, italijanski filozof, politik in politiƒçni teoretik (‚Ä† 1937)\n 24. januar - Abraham Samojloviƒç Bezikoviƒç, ruski matematik (‚Ä† 1970)\n 11. marec - Michael Polanyi, mad≈æarsko-britanski kemik in filozof (‚Ä† 1976)\n 24. marec - John Knittel, ≈°vicarski pisatelj (‚Ä† 1970)\n 14. april - Bhimrao Ramd≈æi Ambedkar, indijski budistiƒçni socialni reformator, pravnik in filozof (‚Ä† 1956)\n 22. april - sir Harold Jeffreys, angle≈°ki geofizik, astronom, matematik (‚Ä† 1989)\n 23. april - Sergej Sergejeviƒç Prokofjev, ruski skladatelj, pianist (‚Ä† 1953)\n 15. maj - Mihail Afanasjeviƒç Bulgakov, ruski pisatelj (‚Ä† 1940)\n 18. maj - Rudolf Carnap, nem≈°ki filozof (‚Ä† 1970)\n 16. junij - Vladimir Aleksandroviƒç Albicki, ruski astronom (‚Ä† 1952)\n 19. avgust - Milton Lasell Humason, ameri≈°ki astronom (‚Ä† 1972)\n 26. september - Hans Reichenbach, nem≈°ki filozof (‚Ä† 1953)\n 20. oktober - sir James Chadwick, angle≈°ki fizik, nobelovec 1935 (‚Ä† 1974)\n 12. november - Seth Barnes Nicholson, ameri≈°ki astronom (‚Ä† 1963)\n 15. november - Erwin Rommel, nem≈°ki feldmar≈°al in voja≈°ki strateg (‚Ä† 1944)\n 26. december - Henry Miller, ameri≈°ki pisatelj (‚Ä† 1980)\n\nSmrti \n 23. junij - Norman Robert Pogson, angle≈°ki astronom (* 1829)\n 23. junij - Wilhelm Eduard Weber nem≈°ki fizik (* 1804)\n 3. oktober - √âdouard Lucas, francoski matematik (* 1842)\n 10. november - ≈†tefan ≈Ωemliƒç, mad≈æarsko-slovenski pisatelj (* 1840)\n 20. december - George Bassett Clark, ameri≈°ki astronom, optik (* 1827)\n 29. december - Leopold Kronecker, nem≈°ki matematik, logik (* 1823)",
    "question": "Kateri je bil prvi dan leta 1891 po gregorijanskem koledarju?",
    "answers": {
        "answer_start": [82],
        "text": ["na ƒçetrtek"]
    }
}
```

```json
{
    "context": "The Night the Light Went On in Long Beach je prvi album v ≈æivo skupine Electric Light Orchestra, ki je iz≈°el leta 1974, posnet pa je bil 12. maja 1974 v Long Beach Auditoriumu na Long Beachu. Naslov albuma je sposojen od pesmi ¬ªThe Night the Lights Went Out in Georgia¬´, ki jo je posnela Vicki Lawrence.\n\nOzadje in omejena izdaja \nAlbum je bil predviden kot naslednik albuma On the Third Day, a so bili posnetki po≈°kodovani zaradi tehniƒçnih te≈æav tako na odru kot zunaj njega. Te≈æave so se zaƒçele ko se je tovornjak z opremo skupine na poti pokvaril, pred koncertom pa skupina ni imela dovolj ƒçasa za preizkus zvoka.\n\n≈†tevilna pre≈°anja albuma so bila tako slabe kvalitete, da je vodstvo skupine vlo≈æilo to≈æbo proti proizvodnem podjetju. Naslovnico albuma je oblikoval Mick Haggerty. \n\nNa koncu sta se tako ameri≈°ka kot britanska zalo≈æba odloƒçili da ne izdata albuma. Album je tako iz≈°el le v Nemƒçiji in nekaterih drugih dr≈æavah, leta 1985 pa je vseeno iz≈°el v Zdru≈æenem kraljestvu. Album ni nikoli iz≈°el v ZDA, ƒçeprav je bil tja uvo≈æen in se je dobro prodajal, je pa ≈æiva verzija ¬ª10538 Overture¬´ iz≈°la kot b-stran singla ¬ªEvil Woman¬´ z albuma Face the Music. ≈Ωiva verzija ¬ªRoll Over Beethoven¬´ je v ZDA iz≈°la kot b-stran alternativne verzije ¬ªTelephone Line¬´ v seriji reizdaj.\n\nObnova \nRemastering v 90. letih je popravil slabo kvaliteto albuma. Odkrito je bilo, da je bila originalna LP plo≈°ƒça masterizirana z uporabo slab≈°e kopije koncerta, zaradi katere je bila kvaliteta zvoka slaba. Originalni trak je bil odkrit v trezorju proizvodnje plo≈°ƒç in album je bil obnovljen v bolj≈°i kvaliteti zvoka.\n\nTo je edini ≈æivi album ELO iz ƒçasa zaƒçetkov skupine.\n\nSeznam skladb\n\nZasedba \nJeff Lynne\t‚Äì solo vokal, elektriƒçna kitara\nBev Bevan ‚Äì bobni\nRichard Tandy ‚Äì Wurlitzer, Minimoog\nMike de Albuquerque ‚Äì solo vokal, spremljevalni vokal, bas\nMik Kaminski ‚Äì violina\nHugh McDowell ‚Äì ƒçelo\nMike Edwards ‚Äì ƒçelo\n\nSklici \n\nAlbumi leta 1974\nAlbumi Electric Light Orchestra\nAlbumi v ≈æivo\nAlbumi, ki jih je produciral Jeff Lynne",
    "question": "Zaradi ƒçesa je bila slaba kakovost albuma The Night the Light Went On in Long Beach odpravljena?",
    "answers": {
        "answer_start": [1287],
        "text": ["Remastering v 90. letih"]
    }
}
```

```json
{
    "context": "Surangel S. Whipps ml., palavski poslovne≈æ in politik; * 9. avgust 1968, Baltimore, Maryland, Zdru≈æene dr≈æave Amerike.\n\nOd 21. januarja 2021 je predsednik Palava. Senator je bil od leta 2008 do 2016. Prihaja iz de≈æele Ngatpang.\n\nZgodnje ≈æivljenje in izobra≈æevanje \nWhipps se je rodil v Baltimorju v Marylandu materi samohranilki Surangel Whipps Sr., rojeni v Marylandu. Diplomiral je iz poslovne administracije in ekonomije na Univerzi Andrews in magistriral iz poslovne znanosti na kalifornijski univerzi v Los Angelesu. Poleg tega vodi verigo supermarketov Palauan. Na splo≈°nih volitvah leta 2016 v Palavu se je potegoval proti svojemu zetu, predsedniku Thomasu Remengesauju mlaj≈°emu.\n\nMandat \nWhipps je na predsedni≈°kih volitvah 2020 kandidiral za predsednika in premagal podpredsednika Raynolda Oiloucha. V intervjuju za Guardian je takratni izvoljeni predsednik Whipps ml. podal izjavo, da se bo Palav odloƒçneje upiral ukrepom kitajske vlade, vkljuƒçno z nezakonitim ribolovom in vstopom v palavske vode ter obljubil, da bo ohranil priznanje Tajvana. Poleg tega je predlagal distribucijo cepiva proti COVID-19 med Palavƒçani, s poudarkom na zdravstvenih delavcih.\n\nSklici \nWhipps, Surangel\nWhipps, Surangel",
    "question": "Proti komu je Whipps zmagal na predsedni≈°kih volitvah leta 2020?",
    "answers": {
        "answer_start": [790],
        "text": ["Raynolda Oiloucha"]
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Spodaj so besedila z ustreznimi vpra≈°anji in odgovori.
  ```

- Base prompt template:

  ```text
  Besedilo: {text}
  Vpra≈°anje: {question}
  Odgovor v najveƒç 3 besedah:
  ```

- Instruction-tuned prompt template:

  ```text
  Besedilo: {text}

  Odgovorite na naslednje vpra≈°anje o zgornjem besedilu v najveƒç 3 besedah.

  Vpra≈°anje: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-sl
```

## Knowledge

### MMLU-sl

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2410.08928)
and is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Slovenian was done using DeepL.

The original full dataset consists of 285 / 1,531 / 14,042 samples for training,
validation, and testing, respectively. These splits were merged, duplicates removed, and
new splits were created with 1,024 / 256 / 2048 samples for training, validation, and
testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "Kaj je deklarativna teorija priznanja?\nMo≈ænosti:\na. Priznanje je odloƒçilno za obstoj dr≈æavnosti\nb. Priznanje je zgolj deklarativno za dr≈æavnost, ni pa odloƒçilno\nc. Priznanje je zgolj izjava o interesu\nd. Priznanje zahteva izjavo novoustanovljene dr≈æavnosti",
    "label": "b",
}
```

```json
{
    "text": "Katera od naslednjih mo≈ænosti bi bila verjeten odziv na ugotovljeno nenormalnost ostanka?\nMo≈ænosti:\na. Uporabite logaritemsko funkcionalno obliko namesto linearne\nb. Dodajte zamike spremenljivk na desni strani regresijskega modela\nc. Ocenite model v prvi diferencirani obliki\nd. Iz podatkov odstranite vsa velika odstopanja.",
    "label": "d",
}
```

```json
{
    "text": "To vpra≈°anje se nana≈°a na naslednje informacije. Stopnje pismenosti med rusko govoreƒçim prebivalstvom pozne carske Rusije in Sovjetske zveze, 1897-1955 Stopnja pismenosti 1897 24% 1917 45% 1926 56% 1937 75% 1939 81.10% 1955 99.90% Vir: Podatki iz popisa prebivalstva in sovjetskega ministrstva za ≈°olstvo Informacije, predstavljene v zgornji tabeli, je najbolje razumeti v katerem od naslednjih zgodovinskih kontekstov?\nMo≈ænosti:\na. Izobra≈æevalna reforma v moderni dobi\nb. Centralizirane in od dr≈æave usmerjene kampanje modernizacije\nc. Eksperimentiranje s sindikalistiƒçnimi oblikami dru≈æbenoekonomske organizacije\nd. Druga faza industrializacije v nezahodnem svetu",
    "label": "b",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Naslednja so vpra≈°anja z veƒç mo≈ænostmi (z odgovori).
  ```

- Base prompt template:

  ```text
  Vpra≈°anje: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Odgovor: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Vpra≈°anje: {text}

  Odgovorite na navedeno vpra≈°anje z uporabo 'a', 'b', 'c' ali 'd', in niƒç drugega.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-sl
```

## Common-sense Reasoning

### Winogrande-sl

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "Nisem mogel nadzorovati vlage, kot sem nadzoroval de≈æ, ker je _ prihajal od vsepovsod. Na kaj se nana≈°a prazno mesto _?\nMo≈ænosti:\na. vlaga\nb. de≈æ",
    "label": "a"
}
```

```json
{
    "text": "Jessica je mislila, da je Sandstorm najbolj≈°a pesem, kar jih je bilo kdaj napisanih, vendar jo je Patricia sovra≈æila. _ je kupila vstopnico za jazz koncert. Na kaj se nana≈°a prazno mesto _?\nMo≈ænosti:\na. Jessica\nb. Patricia",
    "label": "b"
}
```

```json
{
    "text": "Termostat je pokazal, da je bilo spodaj dvajset stopinj hladneje kot zgoraj, zato je Byron ostal v _, ker mu je bilo hladno. Na kaj se nana≈°a prazno mesto _?\nMo≈ænosti:\na. spodaj\nb. zgoraj",
    "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Naslednja so vpra≈°anja z veƒç mo≈ænostmi (z odgovori).
  ```

- Base prompt template:

  ```text
  Vpra≈°anje: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}
  Odgovor: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Vpra≈°anje: {text}
  Mo≈ænosti:
  a. {option_a}
  b. {option_b}

  Odgovorite na navedeno vpra≈°anje z uporabo 'a' ali 'b', in niƒç drugega.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-sl
```
